
// MIT License
//
// Copyright (c) 2020 Sergio Izquierdo
// Copyright (c) 2020 Jiannan Liu
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in
// all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
// SOFTWARE.

/**
 * @file       raw_ops.h
 * @brief      TensorFlow raw_ops mappings
 *             THIS FILE IS AUTOGENERATED - TO UPDATE USE "generator.py"
 * @author     Jiannan Liu
 * @author     Sergio Izquierdo
 */

#ifndef INCLUDE_CPPFLOW_RAW_OPS_H_
#define INCLUDE_CPPFLOW_RAW_OPS_H_

// C headers
#include <tensorflow/c/eager/c_api.h>
#include <tensorflow/c/tf_datatype.h>
#include <tensorflow/c/tf_tensor.h>

// C++ headers
#include <cstdint>
#include <vector>
#include <limits>
#include <algorithm>

// CppFlow headers
#include "cppflow/tensor.h"
#include "cppflow/datatype.h"

namespace cppflow {


/* # Abort
# Inputs:
*    
# Attributes:
*    error_msg
*    exit_without_error

# Outputs:
*    
*/
inline void abort(const std::string& error_msg="", bool exit_without_error=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Abort", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "error_msg", (void*) error_msg.c_str(), error_msg.size());
    TFE_OpSetAttrBool(op.get(), "exit_without_error", (unsigned char)exit_without_error);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # Abs
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor abs(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Abs", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AccumulateNV2
# Inputs:
*    inputs

# Attributes:
*    N
*    shape

# Outputs:
*    sum

*/
inline tensor accumulate_n_v2(const std::vector<tensor>&inputs, const std::vector<int64_t>& shape) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AccumulateNV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), static_cast<int>(inputs.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", inputs.size());
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), static_cast<int>(shape.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AccumulatorApplyGradient
# Inputs:
*    handle
*    local_step
*    gradient

# Attributes:
*    dtype

# Outputs:
*    
*/
inline void accumulator_apply_gradient(const tensor& handle, const tensor& local_step, const tensor& gradient, datatype dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AccumulatorApplyGradient", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), local_step.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # AccumulatorNumAccumulated
# Inputs:
*    handle

# Attributes:
*    
# Outputs:
*    num_accumulated

*/
inline tensor accumulator_num_accumulated(const tensor& handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AccumulatorNumAccumulated", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AccumulatorSetGlobalStep
# Inputs:
*    handle
*    new_global_step

# Attributes:
*    
# Outputs:
*    
*/
inline void accumulator_set_global_step(const tensor& handle, const tensor& new_global_step) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AccumulatorSetGlobalStep", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), new_global_step.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # AccumulatorTakeGradient
# Inputs:
*    handle
*    num_required

# Attributes:
*    dtype

# Outputs:
*    average

*/
inline tensor accumulator_take_gradient(const tensor& handle, const tensor& num_required, datatype dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AccumulatorTakeGradient", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_required.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Acos
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor acos(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Acos", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Acosh
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor acosh(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Acosh", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Add
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor add(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Add", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AddManySparseToTensorsMap
# Inputs:
*    sparse_indices
*    sparse_values
*    sparse_shape

# Attributes:
*    container
*    shared_name

# Outputs:
*    sparse_handles

*/
inline tensor add_many_sparse_to_tensors_map(const tensor& sparse_indices, const tensor& sparse_values, const tensor& sparse_shape, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AddManySparseToTensorsMap", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sparse_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sparse_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sparse_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AddN
# Inputs:
*    inputs

# Attributes:
*    N

# Outputs:
*    sum

*/
inline tensor add_n(const std::vector<tensor>&inputs) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AddN", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), static_cast<int>(inputs.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", inputs.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AddSparseToTensorsMap
# Inputs:
*    sparse_indices
*    sparse_values
*    sparse_shape

# Attributes:
*    container
*    shared_name

# Outputs:
*    sparse_handle

*/
inline tensor add_sparse_to_tensors_map(const tensor& sparse_indices, const tensor& sparse_values, const tensor& sparse_shape, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AddSparseToTensorsMap", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sparse_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sparse_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sparse_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AddV2
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor add_v2(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AddV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AdjustContrast
# Inputs:
*    images
*    contrast_factor
*    min_value
*    max_value

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor adjust_contrast(const tensor& images, const tensor& contrast_factor, const tensor& min_value, const tensor& max_value) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AdjustContrast", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), contrast_factor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AdjustContrastv2
# Inputs:
*    images
*    contrast_factor

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor adjust_contrastv2(const tensor& images, const tensor& contrast_factor) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AdjustContrastv2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), contrast_factor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AdjustHue
# Inputs:
*    images
*    delta

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor adjust_hue(const tensor& images, const tensor& delta) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AdjustHue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), delta.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AdjustSaturation
# Inputs:
*    images
*    scale

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor adjust_saturation(const tensor& images, const tensor& scale) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AdjustSaturation", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scale.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # All
# Inputs:
*    input
*    reduction_indices

# Attributes:
*    keep_dims
*    Tidx

# Outputs:
*    output

*/
inline tensor all(const tensor& input, const tensor& reduction_indices, bool keep_dims=false, datatype Tidx=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "All", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reduction_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "keep_dims", (unsigned char)keep_dims);
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AllCandidateSampler
# Inputs:
*    true_classes

# Attributes:
*    num_true
*    num_sampled
*    unique
*    seed
*    seed2

# Outputs:
*    sampled_candidates
*    true_expected_count
*    sampled_expected_count

*/
inline std::vector<tensor> all_candidate_sampler(const tensor& true_classes, int64_t num_true, int64_t num_sampled, bool unique, int64_t seed=0, int64_t seed2=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AllCandidateSampler", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), true_classes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_true", num_true);
    TFE_OpSetAttrInt(op.get(), "num_sampled", num_sampled);
    TFE_OpSetAttrBool(op.get(), "unique", (unsigned char)unique);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # AllToAll
# Inputs:
*    input
*    group_assignment

# Attributes:
*    concat_dimension
*    split_dimension
*    split_count

# Outputs:
*    output

*/
inline tensor all_to_all(const tensor& input, const tensor& group_assignment, int64_t concat_dimension, int64_t split_dimension, int64_t split_count) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AllToAll", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), group_assignment.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "concat_dimension", concat_dimension);
    TFE_OpSetAttrInt(op.get(), "split_dimension", split_dimension);
    TFE_OpSetAttrInt(op.get(), "split_count", split_count);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Angle
# Inputs:
*    input

# Attributes:
*    Tout

# Outputs:
*    output

*/
inline tensor angle(const tensor& input, datatype Tout=static_cast<datatype>(1)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Angle", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tout", Tout);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AnonymousHashTable
# Inputs:
*    
# Attributes:
*    key_dtype
*    value_dtype

# Outputs:
*    table_handle

*/
inline tensor anonymous_hash_table(datatype key_dtype, datatype value_dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AnonymousHashTable", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "key_dtype", key_dtype);
    TFE_OpSetAttrType(op.get(), "value_dtype", value_dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AnonymousIterator
# Inputs:
*    
# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor anonymous_iterator(const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AnonymousIterator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AnonymousIteratorV2
# Inputs:
*    
# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle
*    deleter

*/
inline std::vector<tensor> anonymous_iterator_v2(const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AnonymousIteratorV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # AnonymousIteratorV3
# Inputs:
*    
# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor anonymous_iterator_v3(const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AnonymousIteratorV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AnonymousMemoryCache
# Inputs:
*    
# Attributes:
*    
# Outputs:
*    handle
*    deleter

*/
inline std::vector<tensor> anonymous_memory_cache() {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AnonymousMemoryCache", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # AnonymousMultiDeviceIterator
# Inputs:
*    
# Attributes:
*    devices
*    output_types
*    output_shapes

# Outputs:
*    handle
*    deleter

*/
inline std::vector<tensor> anonymous_multi_device_iterator(const std::vector< std::string>& devices, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AnonymousMultiDeviceIterator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    
    std::vector<std::size_t> devices_sizes; devices_sizes.reserve(devices.size());
    std::transform(devices.begin(), devices.end(), std::back_inserter(devices_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "devices", reinterpret_cast<const void *const *>(devices.data()), devices_sizes.data(), static_cast<int>(devices.size()));
    
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # AnonymousMultiDeviceIteratorV3
# Inputs:
*    
# Attributes:
*    devices
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor anonymous_multi_device_iterator_v3(const std::vector< std::string>& devices, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AnonymousMultiDeviceIteratorV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    
    std::vector<std::size_t> devices_sizes; devices_sizes.reserve(devices.size());
    std::transform(devices.begin(), devices.end(), std::back_inserter(devices_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "devices", reinterpret_cast<const void *const *>(devices.data()), devices_sizes.data(), static_cast<int>(devices.size()));
    
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AnonymousMutableDenseHashTable
# Inputs:
*    empty_key
*    deleted_key

# Attributes:
*    key_dtype
*    value_dtype
*    value_shape
*    initial_num_buckets
*    max_load_factor

# Outputs:
*    table_handle

*/
inline tensor anonymous_mutable_dense_hash_table(const tensor& empty_key, const tensor& deleted_key, datatype key_dtype, datatype value_dtype, const std::vector<int64_t>& value_shape, int64_t initial_num_buckets=131072, float max_load_factor=8.0000e-01) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AnonymousMutableDenseHashTable", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), empty_key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), deleted_key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "key_dtype", key_dtype);
    TFE_OpSetAttrType(op.get(), "value_dtype", value_dtype);
    
    TFE_OpSetAttrShape(op.get(), "value_shape", value_shape.data(), static_cast<int>(value_shape.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "initial_num_buckets", initial_num_buckets);
    TFE_OpSetAttrFloat(op.get(), "max_load_factor", max_load_factor);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AnonymousMutableHashTable
# Inputs:
*    
# Attributes:
*    key_dtype
*    value_dtype

# Outputs:
*    table_handle

*/
inline tensor anonymous_mutable_hash_table(datatype key_dtype, datatype value_dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AnonymousMutableHashTable", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "key_dtype", key_dtype);
    TFE_OpSetAttrType(op.get(), "value_dtype", value_dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AnonymousMutableHashTableOfTensors
# Inputs:
*    
# Attributes:
*    key_dtype
*    value_dtype
*    value_shape

# Outputs:
*    table_handle

*/
inline tensor anonymous_mutable_hash_table_of_tensors(datatype key_dtype, datatype value_dtype, const std::vector<int64_t>& value_shape) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AnonymousMutableHashTableOfTensors", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "key_dtype", key_dtype);
    TFE_OpSetAttrType(op.get(), "value_dtype", value_dtype);
    
    TFE_OpSetAttrShape(op.get(), "value_shape", value_shape.data(), static_cast<int>(value_shape.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AnonymousRandomSeedGenerator
# Inputs:
*    seed
*    seed2

# Attributes:
*    
# Outputs:
*    handle
*    deleter

*/
inline std::vector<tensor> anonymous_random_seed_generator(const tensor& seed, const tensor& seed2) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AnonymousRandomSeedGenerator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), seed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # AnonymousSeedGenerator
# Inputs:
*    seed
*    seed2
*    reshuffle

# Attributes:
*    
# Outputs:
*    handle
*    deleter

*/
inline std::vector<tensor> anonymous_seed_generator(const tensor& seed, const tensor& seed2, const tensor& reshuffle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AnonymousSeedGenerator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), seed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reshuffle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # Any
# Inputs:
*    input
*    reduction_indices

# Attributes:
*    keep_dims
*    Tidx

# Outputs:
*    output

*/
inline tensor any(const tensor& input, const tensor& reduction_indices, bool keep_dims=false, datatype Tidx=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Any", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reduction_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "keep_dims", (unsigned char)keep_dims);
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ApplyAdaMax
# Inputs:
*    var
*    m
*    v
*    beta1_power
*    lr
*    beta1
*    beta2
*    epsilon
*    grad

# Attributes:
*    use_locking

# Outputs:
*    out

*/
inline tensor apply_ada_max(const tensor& var, const tensor& m, const tensor& v, const tensor& beta1_power, const tensor& lr, const tensor& beta1, const tensor& beta2, const tensor& epsilon, const tensor& grad, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyAdaMax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta1_power.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ApplyAdadelta
# Inputs:
*    var
*    accum
*    accum_update
*    lr
*    rho
*    epsilon
*    grad

# Attributes:
*    use_locking

# Outputs:
*    out

*/
inline tensor apply_adadelta(const tensor& var, const tensor& accum, const tensor& accum_update, const tensor& lr, const tensor& rho, const tensor& epsilon, const tensor& grad, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyAdadelta", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum_update.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rho.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ApplyAdagrad
# Inputs:
*    var
*    accum
*    lr
*    grad

# Attributes:
*    use_locking
*    update_slots

# Outputs:
*    out

*/
inline tensor apply_adagrad(const tensor& var, const tensor& accum, const tensor& lr, const tensor& grad, bool use_locking=false, bool update_slots=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyAdagrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "update_slots", (unsigned char)update_slots);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ApplyAdagradDA
# Inputs:
*    var
*    gradient_accumulator
*    gradient_squared_accumulator
*    grad
*    lr
*    l1
*    l2
*    global_step

# Attributes:
*    use_locking

# Outputs:
*    out

*/
inline tensor apply_adagrad_d_a(const tensor& var, const tensor& gradient_accumulator, const tensor& gradient_squared_accumulator, const tensor& grad, const tensor& lr, const tensor& l1, const tensor& l2, const tensor& global_step, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyAdagradDA", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_accumulator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_squared_accumulator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), global_step.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ApplyAdagradV2
# Inputs:
*    var
*    accum
*    lr
*    epsilon
*    grad

# Attributes:
*    use_locking
*    update_slots

# Outputs:
*    out

*/
inline tensor apply_adagrad_v2(const tensor& var, const tensor& accum, const tensor& lr, const tensor& epsilon, const tensor& grad, bool use_locking=false, bool update_slots=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyAdagradV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "update_slots", (unsigned char)update_slots);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ApplyAdam
# Inputs:
*    var
*    m
*    v
*    beta1_power
*    beta2_power
*    lr
*    beta1
*    beta2
*    epsilon
*    grad

# Attributes:
*    use_locking
*    use_nesterov

# Outputs:
*    out

*/
inline tensor apply_adam(const tensor& var, const tensor& m, const tensor& v, const tensor& beta1_power, const tensor& beta2_power, const tensor& lr, const tensor& beta1, const tensor& beta2, const tensor& epsilon, const tensor& grad, bool use_locking=false, bool use_nesterov=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyAdam", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta1_power.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta2_power.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "use_nesterov", (unsigned char)use_nesterov);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ApplyAddSign
# Inputs:
*    var
*    m
*    lr
*    alpha
*    sign_decay
*    beta
*    grad

# Attributes:
*    use_locking

# Outputs:
*    out

*/
inline tensor apply_add_sign(const tensor& var, const tensor& m, const tensor& lr, const tensor& alpha, const tensor& sign_decay, const tensor& beta, const tensor& grad, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyAddSign", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alpha.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sign_decay.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ApplyCenteredRMSProp
# Inputs:
*    var
*    mg
*    ms
*    mom
*    lr
*    rho
*    momentum
*    epsilon
*    grad

# Attributes:
*    use_locking

# Outputs:
*    out

*/
inline tensor apply_centered_r_m_s_prop(const tensor& var, const tensor& mg, const tensor& ms, const tensor& mom, const tensor& lr, const tensor& rho, const tensor& momentum, const tensor& epsilon, const tensor& grad, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyCenteredRMSProp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mg.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ms.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mom.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rho.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ApplyFtrl
# Inputs:
*    var
*    accum
*    linear
*    grad
*    lr
*    l1
*    l2
*    lr_power

# Attributes:
*    use_locking
*    multiply_linear_by_lr

# Outputs:
*    out

*/
inline tensor apply_ftrl(const tensor& var, const tensor& accum, const tensor& linear, const tensor& grad, const tensor& lr, const tensor& l1, const tensor& l2, const tensor& lr_power, bool use_locking=false, bool multiply_linear_by_lr=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyFtrl", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), linear.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr_power.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "multiply_linear_by_lr", (unsigned char)multiply_linear_by_lr);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ApplyFtrlV2
# Inputs:
*    var
*    accum
*    linear
*    grad
*    lr
*    l1
*    l2
*    l2_shrinkage
*    lr_power

# Attributes:
*    use_locking
*    multiply_linear_by_lr

# Outputs:
*    out

*/
inline tensor apply_ftrl_v2(const tensor& var, const tensor& accum, const tensor& linear, const tensor& grad, const tensor& lr, const tensor& l1, const tensor& l2, const tensor& l2_shrinkage, const tensor& lr_power, bool use_locking=false, bool multiply_linear_by_lr=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyFtrlV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), linear.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2_shrinkage.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr_power.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "multiply_linear_by_lr", (unsigned char)multiply_linear_by_lr);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ApplyGradientDescent
# Inputs:
*    var
*    alpha
*    delta

# Attributes:
*    use_locking

# Outputs:
*    out

*/
inline tensor apply_gradient_descent(const tensor& var, const tensor& alpha, const tensor& delta, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyGradientDescent", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alpha.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), delta.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ApplyMomentum
# Inputs:
*    var
*    accum
*    lr
*    grad
*    momentum

# Attributes:
*    use_locking
*    use_nesterov

# Outputs:
*    out

*/
inline tensor apply_momentum(const tensor& var, const tensor& accum, const tensor& lr, const tensor& grad, const tensor& momentum, bool use_locking=false, bool use_nesterov=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyMomentum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "use_nesterov", (unsigned char)use_nesterov);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ApplyPowerSign
# Inputs:
*    var
*    m
*    lr
*    logbase
*    sign_decay
*    beta
*    grad

# Attributes:
*    use_locking

# Outputs:
*    out

*/
inline tensor apply_power_sign(const tensor& var, const tensor& m, const tensor& lr, const tensor& logbase, const tensor& sign_decay, const tensor& beta, const tensor& grad, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyPowerSign", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), logbase.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sign_decay.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ApplyProximalAdagrad
# Inputs:
*    var
*    accum
*    lr
*    l1
*    l2
*    grad

# Attributes:
*    use_locking

# Outputs:
*    out

*/
inline tensor apply_proximal_adagrad(const tensor& var, const tensor& accum, const tensor& lr, const tensor& l1, const tensor& l2, const tensor& grad, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyProximalAdagrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ApplyProximalGradientDescent
# Inputs:
*    var
*    alpha
*    l1
*    l2
*    delta

# Attributes:
*    use_locking

# Outputs:
*    out

*/
inline tensor apply_proximal_gradient_descent(const tensor& var, const tensor& alpha, const tensor& l1, const tensor& l2, const tensor& delta, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyProximalGradientDescent", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alpha.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), delta.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ApplyRMSProp
# Inputs:
*    var
*    ms
*    mom
*    lr
*    rho
*    momentum
*    epsilon
*    grad

# Attributes:
*    use_locking

# Outputs:
*    out

*/
inline tensor apply_r_m_s_prop(const tensor& var, const tensor& ms, const tensor& mom, const tensor& lr, const tensor& rho, const tensor& momentum, const tensor& epsilon, const tensor& grad, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyRMSProp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ms.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mom.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rho.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ApproxTopK
# Inputs:
*    input

# Attributes:
*    k
*    reduction_dimension
*    recall_target
*    is_max_k
*    reduction_input_size_override
*    aggregate_to_topk

# Outputs:
*    values
*    indices

*/
inline std::vector<tensor> approx_top_k(const tensor& input, int64_t k, int64_t reduction_dimension=-1, float recall_target=9.5000e-01, bool is_max_k=true, int64_t reduction_input_size_override=-1, bool aggregate_to_topk=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApproxTopK", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "k", k);
    TFE_OpSetAttrInt(op.get(), "reduction_dimension", reduction_dimension);
    TFE_OpSetAttrFloat(op.get(), "recall_target", recall_target);
    TFE_OpSetAttrBool(op.get(), "is_max_k", (unsigned char)is_max_k);
    TFE_OpSetAttrInt(op.get(), "reduction_input_size_override", reduction_input_size_override);
    TFE_OpSetAttrBool(op.get(), "aggregate_to_topk", (unsigned char)aggregate_to_topk);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # ApproximateEqual
# Inputs:
*    x
*    y

# Attributes:
*    tolerance

# Outputs:
*    z

*/
inline tensor approximate_equal(const tensor& x, const tensor& y, float tolerance=1.0000e-05) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApproximateEqual", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "tolerance", tolerance);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ArgMax
# Inputs:
*    input
*    dimension

# Attributes:
*    Tidx
*    output_type

# Outputs:
*    output

*/
inline tensor arg_max(const tensor& input, const tensor& dimension, datatype Tidx=static_cast<datatype>(3), datatype output_type=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ArgMax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dimension.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrType(op.get(), "output_type", output_type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ArgMin
# Inputs:
*    input
*    dimension

# Attributes:
*    Tidx
*    output_type

# Outputs:
*    output

*/
inline tensor arg_min(const tensor& input, const tensor& dimension, datatype Tidx=static_cast<datatype>(3), datatype output_type=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ArgMin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dimension.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrType(op.get(), "output_type", output_type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AsString
# Inputs:
*    input

# Attributes:
*    precision
*    scientific
*    shortest
*    width
*    fill

# Outputs:
*    output

*/
inline tensor as_string(const tensor& input, int64_t precision=-1, bool scientific=false, bool shortest=false, int64_t width=-1, const std::string& fill="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AsString", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "precision", precision);
    TFE_OpSetAttrBool(op.get(), "scientific", (unsigned char)scientific);
    TFE_OpSetAttrBool(op.get(), "shortest", (unsigned char)shortest);
    TFE_OpSetAttrInt(op.get(), "width", width);
    TFE_OpSetAttrString(op.get(), "fill", (void*) fill.c_str(), fill.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Asin
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor asin(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Asin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Asinh
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor asinh(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Asinh", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Assert
# Inputs:
*    condition
*    data

# Attributes:
*    summarize

# Outputs:
*    
*/
inline void tfe_assert(const tensor& condition, const std::vector<tensor>&data, int64_t summarize=3) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Assert", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), condition.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> data_handles; data_handles.reserve(data.size());
    std::transform(data.begin(), data.end(), std::back_inserter(data_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), data_handles.data(), static_cast<int>(data.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "summarize", summarize);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # AssertCardinalityDataset
# Inputs:
*    input_dataset
*    cardinality

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor assert_cardinality_dataset(const tensor& input_dataset, const tensor& cardinality, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AssertCardinalityDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cardinality.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AssertNextDataset
# Inputs:
*    input_dataset
*    transformations

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor assert_next_dataset(const tensor& input_dataset, const tensor& transformations, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AssertNextDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), transformations.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AssertPrevDataset
# Inputs:
*    input_dataset
*    transformations

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor assert_prev_dataset(const tensor& input_dataset, const tensor& transformations, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AssertPrevDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), transformations.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Assign
# Inputs:
*    ref
*    value

# Attributes:
*    validate_shape
*    use_locking

# Outputs:
*    output_ref

*/
inline tensor assign(const tensor& ref, const tensor& value, bool validate_shape=true, bool use_locking=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Assign", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "validate_shape", (unsigned char)validate_shape);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AssignAdd
# Inputs:
*    ref
*    value

# Attributes:
*    use_locking

# Outputs:
*    output_ref

*/
inline tensor assign_add(const tensor& ref, const tensor& value, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AssignAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AssignAddVariableOp
# Inputs:
*    resource
*    value

# Attributes:
*    dtype

# Outputs:
*    
*/
inline void assign_add_variable_op(const tensor& resource, const tensor& value, datatype dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AssignAddVariableOp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # AssignSub
# Inputs:
*    ref
*    value

# Attributes:
*    use_locking

# Outputs:
*    output_ref

*/
inline tensor assign_sub(const tensor& ref, const tensor& value, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AssignSub", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AssignSubVariableOp
# Inputs:
*    resource
*    value

# Attributes:
*    dtype

# Outputs:
*    
*/
inline void assign_sub_variable_op(const tensor& resource, const tensor& value, datatype dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AssignSubVariableOp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # AssignVariableOp
# Inputs:
*    resource
*    value

# Attributes:
*    dtype
*    validate_shape

# Outputs:
*    
*/
inline void assign_variable_op(const tensor& resource, const tensor& value, datatype dtype, bool validate_shape=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AssignVariableOp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrBool(op.get(), "validate_shape", (unsigned char)validate_shape);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # AssignVariableXlaConcatND
# Inputs:
*    resource
*    inputs

# Attributes:
*    N
*    num_concats
*    paddings

# Outputs:
*    
*/
inline void assign_variable_xla_concat_n_d(const tensor& resource, const std::vector<tensor>&inputs, const std::vector<int64_t>& num_concats, const std::vector<int64_t>& paddings) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AssignVariableXlaConcatND", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), static_cast<int>(inputs.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", inputs.size());
    TFE_OpSetAttrIntList(op.get(), "num_concats", num_concats.data(), static_cast<int>(num_concats.size()));
    TFE_OpSetAttrIntList(op.get(), "paddings", paddings.data(), static_cast<int>(paddings.size()));

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # Atan
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor atan(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Atan", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Atan2
# Inputs:
*    y
*    x

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor atan2(const tensor& y, const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Atan2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Atanh
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor atanh(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Atanh", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AudioSpectrogram
# Inputs:
*    input

# Attributes:
*    window_size
*    stride
*    magnitude_squared

# Outputs:
*    spectrogram

*/
inline tensor audio_spectrogram(const tensor& input, int64_t window_size, int64_t stride, bool magnitude_squared=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AudioSpectrogram", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "window_size", window_size);
    TFE_OpSetAttrInt(op.get(), "stride", stride);
    TFE_OpSetAttrBool(op.get(), "magnitude_squared", (unsigned char)magnitude_squared);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AudioSummary
# Inputs:
*    tag
*    tensor

# Attributes:
*    sample_rate
*    max_outputs

# Outputs:
*    summary

*/
inline tensor audio_summary(const tensor& tag, const tensor& input_tensor, float sample_rate, int64_t max_outputs=3) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AudioSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tag.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "sample_rate", sample_rate);
    TFE_OpSetAttrInt(op.get(), "max_outputs", max_outputs);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AudioSummaryV2
# Inputs:
*    tag
*    tensor
*    sample_rate

# Attributes:
*    max_outputs

# Outputs:
*    summary

*/
inline tensor audio_summary_v2(const tensor& tag, const tensor& input_tensor, const tensor& sample_rate, int64_t max_outputs=3) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AudioSummaryV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tag.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sample_rate.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "max_outputs", max_outputs);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AutoShardDataset
# Inputs:
*    input_dataset
*    num_workers
*    index

# Attributes:
*    output_types
*    output_shapes
*    auto_shard_policy
*    num_replicas

# Outputs:
*    handle

*/
inline tensor auto_shard_dataset(const tensor& input_dataset, const tensor& num_workers, const tensor& index, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, int64_t auto_shard_policy=0, int64_t num_replicas=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AutoShardDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_workers.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), index.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "auto_shard_policy", auto_shard_policy);
    TFE_OpSetAttrInt(op.get(), "num_replicas", num_replicas);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AvgPool
# Inputs:
*    value

# Attributes:
*    ksize
*    strides
*    padding
*    data_format

# Outputs:
*    output

*/
inline tensor avg_pool(const tensor& value, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding, const std::string& data_format="NHWC") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AvgPool", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), static_cast<int>(ksize.size()));
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AvgPool3D
# Inputs:
*    input

# Attributes:
*    ksize
*    strides
*    padding
*    data_format

# Outputs:
*    output

*/
inline tensor avg_pool3_d(const tensor& input, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding, const std::string& data_format="NDHWC") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AvgPool3D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), static_cast<int>(ksize.size()));
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AvgPool3DGrad
# Inputs:
*    orig_input_shape
*    grad

# Attributes:
*    ksize
*    strides
*    padding
*    data_format

# Outputs:
*    output

*/
inline tensor avg_pool3_d_grad(const tensor& orig_input_shape, const tensor& grad, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding, const std::string& data_format="NDHWC") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AvgPool3DGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), orig_input_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), static_cast<int>(ksize.size()));
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # AvgPoolGrad
# Inputs:
*    orig_input_shape
*    grad

# Attributes:
*    ksize
*    strides
*    padding
*    data_format

# Outputs:
*    output

*/
inline tensor avg_pool_grad(const tensor& orig_input_shape, const tensor& grad, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding, const std::string& data_format="NHWC") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AvgPoolGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), orig_input_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), static_cast<int>(ksize.size()));
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BandedTriangularSolve
# Inputs:
*    matrix
*    rhs

# Attributes:
*    lower
*    adjoint

# Outputs:
*    output

*/
inline tensor banded_triangular_solve(const tensor& matrix, const tensor& rhs, bool lower=true, bool adjoint=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BandedTriangularSolve", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), matrix.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "lower", (unsigned char)lower);
    TFE_OpSetAttrBool(op.get(), "adjoint", (unsigned char)adjoint);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Barrier
# Inputs:
*    
# Attributes:
*    component_types
*    shapes
*    capacity
*    container
*    shared_name

# Outputs:
*    handle

*/
inline tensor barrier(const std::vector<datatype>& component_types, const std::vector< std::vector<int64_t>>& shapes, int64_t capacity=-1, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Barrier", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), static_cast<int>(component_types.size()));
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), static_cast<int>(shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BarrierClose
# Inputs:
*    handle

# Attributes:
*    cancel_pending_enqueues

# Outputs:
*    
*/
inline void barrier_close(const tensor& handle, bool cancel_pending_enqueues=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BarrierClose", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "cancel_pending_enqueues", (unsigned char)cancel_pending_enqueues);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # BarrierIncompleteSize
# Inputs:
*    handle

# Attributes:
*    
# Outputs:
*    size

*/
inline tensor barrier_incomplete_size(const tensor& handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BarrierIncompleteSize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BarrierInsertMany
# Inputs:
*    handle
*    keys
*    values

# Attributes:
*    component_index

# Outputs:
*    
*/
inline void barrier_insert_many(const tensor& handle, const tensor& keys, const tensor& values, int64_t component_index) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BarrierInsertMany", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), keys.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "component_index", component_index);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # BarrierReadySize
# Inputs:
*    handle

# Attributes:
*    
# Outputs:
*    size

*/
inline tensor barrier_ready_size(const tensor& handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BarrierReadySize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BarrierTakeMany
# Inputs:
*    handle
*    num_elements

# Attributes:
*    component_types
*    allow_small_batch
*    wait_for_incomplete
*    timeout_ms

# Outputs:
*    indices
*    keys
*    values

*/
inline std::vector<tensor> barrier_take_many(const tensor& handle, const tensor& num_elements, const std::vector<datatype>& component_types, bool allow_small_batch=false, bool wait_for_incomplete=false, int64_t timeout_ms=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BarrierTakeMany", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_elements.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), static_cast<int>(component_types.size()));
    TFE_OpSetAttrBool(op.get(), "allow_small_batch", (unsigned char)allow_small_batch);
    TFE_OpSetAttrBool(op.get(), "wait_for_incomplete", (unsigned char)wait_for_incomplete);
    TFE_OpSetAttrInt(op.get(), "timeout_ms", timeout_ms);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # Batch
# Inputs:
*    in_tensors

# Attributes:
*    num_batch_threads
*    max_batch_size
*    batch_timeout_micros
*    allowed_batch_sizes
*    grad_timeout_micros
*    max_enqueued_batches
*    container
*    shared_name
*    batching_queue

# Outputs:
*    batched_tensors
*    batch_index
*    id

*/
inline std::vector<tensor> batch(const std::vector<tensor>&in_tensors, int64_t num_batch_threads, int64_t max_batch_size, int64_t batch_timeout_micros, const std::vector<int64_t>& allowed_batch_sizes, int64_t grad_timeout_micros, int64_t max_enqueued_batches=10, const std::string& container="", const std::string& shared_name="", const std::string& batching_queue="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Batch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> in_tensors_handles; in_tensors_handles.reserve(in_tensors.size());
    std::transform(in_tensors.begin(), in_tensors.end(), std::back_inserter(in_tensors_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), in_tensors_handles.data(), static_cast<int>(in_tensors.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_batch_threads", num_batch_threads);
    TFE_OpSetAttrInt(op.get(), "max_batch_size", max_batch_size);
    TFE_OpSetAttrInt(op.get(), "batch_timeout_micros", batch_timeout_micros);
    TFE_OpSetAttrIntList(op.get(), "allowed_batch_sizes", allowed_batch_sizes.data(), static_cast<int>(allowed_batch_sizes.size()));
    TFE_OpSetAttrInt(op.get(), "grad_timeout_micros", grad_timeout_micros);
    TFE_OpSetAttrInt(op.get(), "max_enqueued_batches", max_enqueued_batches);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrString(op.get(), "batching_queue", (void*) batching_queue.c_str(), batching_queue.size());

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # BatchCholesky
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor batch_cholesky(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchCholesky", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BatchCholeskyGrad
# Inputs:
*    l
*    grad

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor batch_cholesky_grad(const tensor& l, const tensor& grad) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchCholeskyGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), l.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BatchDataset
# Inputs:
*    input_dataset
*    batch_size

# Attributes:
*    output_types
*    output_shapes
*    metadata

# Outputs:
*    handle

*/
inline tensor batch_dataset(const tensor& input_dataset, const tensor& batch_size, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), batch_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BatchDatasetV2
# Inputs:
*    input_dataset
*    batch_size
*    drop_remainder

# Attributes:
*    output_types
*    output_shapes
*    parallel_copy
*    metadata

# Outputs:
*    handle

*/
inline tensor batch_dataset_v2(const tensor& input_dataset, const tensor& batch_size, const tensor& drop_remainder, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool parallel_copy=false, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), batch_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), drop_remainder.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "parallel_copy", (unsigned char)parallel_copy);
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BatchFFT
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor batch_f_f_t(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchFFT", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BatchFFT2D
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor batch_f_f_t2_d(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchFFT2D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BatchFFT3D
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor batch_f_f_t3_d(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchFFT3D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BatchFunction
# Inputs:
*    in_tensors
*    captured_tensors

# Attributes:
*    f
*    num_batch_threads
*    max_batch_size
*    batch_timeout_micros
*    allowed_batch_sizes
*    low_priority_allowed_batch_sizes
*    Tin
*    Tcaptured
*    Tout
*    max_enqueued_batches
*    container
*    shared_name
*    batching_queue
*    low_priority_max_batch_size
*    low_priority_batch_timeout_micros
*    low_priority_max_enqueued_batches
*    mixed_priority_policy
*    enable_large_batch_splitting

# Outputs:
*    out_tensors

*/
inline tensor batch_function(const std::vector<tensor>&in_tensors, const std::vector<tensor>&captured_tensors, int64_t f, int64_t num_batch_threads, int64_t max_batch_size, int64_t batch_timeout_micros, const std::vector<int64_t>& allowed_batch_sizes, const std::vector<int64_t>& low_priority_allowed_batch_sizes, const std::vector<datatype>& Tin, const std::vector<datatype>& Tcaptured, const std::vector<datatype>& Tout, int64_t max_enqueued_batches=10, const std::string& container="", const std::string& shared_name="", const std::string& batching_queue="", int64_t low_priority_max_batch_size=0, int64_t low_priority_batch_timeout_micros=0, int64_t low_priority_max_enqueued_batches=0, const std::string& mixed_priority_policy="low_priority_padding_with_max_batch_size", bool enable_large_batch_splitting=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchFunction", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> in_tensors_handles; in_tensors_handles.reserve(in_tensors.size());
    std::transform(in_tensors.begin(), in_tensors.end(), std::back_inserter(in_tensors_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), in_tensors_handles.data(), static_cast<int>(in_tensors.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> captured_tensors_handles; captured_tensors_handles.reserve(captured_tensors.size());
    std::transform(captured_tensors.begin(), captured_tensors.end(), std::back_inserter(captured_tensors_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), captured_tensors_handles.data(), static_cast<int>(captured_tensors.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "f", f);
    TFE_OpSetAttrInt(op.get(), "num_batch_threads", num_batch_threads);
    TFE_OpSetAttrInt(op.get(), "max_batch_size", max_batch_size);
    TFE_OpSetAttrInt(op.get(), "batch_timeout_micros", batch_timeout_micros);
    TFE_OpSetAttrIntList(op.get(), "allowed_batch_sizes", allowed_batch_sizes.data(), static_cast<int>(allowed_batch_sizes.size()));
    TFE_OpSetAttrIntList(op.get(), "low_priority_allowed_batch_sizes", low_priority_allowed_batch_sizes.data(), static_cast<int>(low_priority_allowed_batch_sizes.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tin", reinterpret_cast<const enum TF_DataType *>(Tin.data()), static_cast<int>(Tin.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tcaptured", reinterpret_cast<const enum TF_DataType *>(Tcaptured.data()), static_cast<int>(Tcaptured.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tout", reinterpret_cast<const enum TF_DataType *>(Tout.data()), static_cast<int>(Tout.size()));
    TFE_OpSetAttrInt(op.get(), "max_enqueued_batches", max_enqueued_batches);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrString(op.get(), "batching_queue", (void*) batching_queue.c_str(), batching_queue.size());
    TFE_OpSetAttrInt(op.get(), "low_priority_max_batch_size", low_priority_max_batch_size);
    TFE_OpSetAttrInt(op.get(), "low_priority_batch_timeout_micros", low_priority_batch_timeout_micros);
    TFE_OpSetAttrInt(op.get(), "low_priority_max_enqueued_batches", low_priority_max_enqueued_batches);
    TFE_OpSetAttrString(op.get(), "mixed_priority_policy", (void*) mixed_priority_policy.c_str(), mixed_priority_policy.size());
    TFE_OpSetAttrBool(op.get(), "enable_large_batch_splitting", (unsigned char)enable_large_batch_splitting);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BatchIFFT
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor batch_i_f_f_t(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchIFFT", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BatchIFFT2D
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor batch_i_f_f_t2_d(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchIFFT2D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BatchIFFT3D
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor batch_i_f_f_t3_d(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchIFFT3D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BatchMatMul
# Inputs:
*    x
*    y

# Attributes:
*    adj_x
*    adj_y
*    grad_x
*    grad_y

# Outputs:
*    output

*/
inline tensor batch_mat_mul(const tensor& x, const tensor& y, bool adj_x=false, bool adj_y=false, bool grad_x=false, bool grad_y=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchMatMul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "adj_x", (unsigned char)adj_x);
    TFE_OpSetAttrBool(op.get(), "adj_y", (unsigned char)adj_y);
    TFE_OpSetAttrBool(op.get(), "grad_x", (unsigned char)grad_x);
    TFE_OpSetAttrBool(op.get(), "grad_y", (unsigned char)grad_y);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BatchMatMulV2
# Inputs:
*    x
*    y

# Attributes:
*    adj_x
*    adj_y
*    grad_x
*    grad_y

# Outputs:
*    output

*/
inline tensor batch_mat_mul_v2(const tensor& x, const tensor& y, bool adj_x=false, bool adj_y=false, bool grad_x=false, bool grad_y=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchMatMulV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "adj_x", (unsigned char)adj_x);
    TFE_OpSetAttrBool(op.get(), "adj_y", (unsigned char)adj_y);
    TFE_OpSetAttrBool(op.get(), "grad_x", (unsigned char)grad_x);
    TFE_OpSetAttrBool(op.get(), "grad_y", (unsigned char)grad_y);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BatchMatMulV3
# Inputs:
*    x
*    y

# Attributes:
*    Ta
*    Tb
*    Tout
*    adj_x
*    adj_y
*    grad_x
*    grad_y

# Outputs:
*    output

*/
inline tensor batch_mat_mul_v3(const tensor& x, const tensor& y, datatype Ta, datatype Tb, datatype Tout, bool adj_x=false, bool adj_y=false, bool grad_x=false, bool grad_y=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchMatMulV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Ta", Ta);
    TFE_OpSetAttrType(op.get(), "Tb", Tb);
    TFE_OpSetAttrType(op.get(), "Tout", Tout);
    TFE_OpSetAttrBool(op.get(), "adj_x", (unsigned char)adj_x);
    TFE_OpSetAttrBool(op.get(), "adj_y", (unsigned char)adj_y);
    TFE_OpSetAttrBool(op.get(), "grad_x", (unsigned char)grad_x);
    TFE_OpSetAttrBool(op.get(), "grad_y", (unsigned char)grad_y);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BatchMatrixBandPart
# Inputs:
*    input
*    num_lower
*    num_upper

# Attributes:
*    
# Outputs:
*    band

*/
inline tensor batch_matrix_band_part(const tensor& input, const tensor& num_lower, const tensor& num_upper) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchMatrixBandPart", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_lower.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_upper.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BatchMatrixDeterminant
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor batch_matrix_determinant(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchMatrixDeterminant", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BatchMatrixDiag
# Inputs:
*    diagonal

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor batch_matrix_diag(const tensor& diagonal) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchMatrixDiag", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), diagonal.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BatchMatrixDiagPart
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    diagonal

*/
inline tensor batch_matrix_diag_part(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchMatrixDiagPart", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BatchMatrixInverse
# Inputs:
*    input

# Attributes:
*    adjoint

# Outputs:
*    output

*/
inline tensor batch_matrix_inverse(const tensor& input, bool adjoint=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchMatrixInverse", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "adjoint", (unsigned char)adjoint);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BatchMatrixSetDiag
# Inputs:
*    input
*    diagonal

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor batch_matrix_set_diag(const tensor& input, const tensor& diagonal) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchMatrixSetDiag", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), diagonal.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BatchMatrixSolve
# Inputs:
*    matrix
*    rhs

# Attributes:
*    adjoint

# Outputs:
*    output

*/
inline tensor batch_matrix_solve(const tensor& matrix, const tensor& rhs, bool adjoint=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchMatrixSolve", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), matrix.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "adjoint", (unsigned char)adjoint);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BatchMatrixSolveLs
# Inputs:
*    matrix
*    rhs
*    l2_regularizer

# Attributes:
*    fast

# Outputs:
*    output

*/
inline tensor batch_matrix_solve_ls(const tensor& matrix, const tensor& rhs, const tensor& l2_regularizer, bool fast=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchMatrixSolveLs", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), matrix.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2_regularizer.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "fast", (unsigned char)fast);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BatchMatrixTriangularSolve
# Inputs:
*    matrix
*    rhs

# Attributes:
*    lower
*    adjoint

# Outputs:
*    output

*/
inline tensor batch_matrix_triangular_solve(const tensor& matrix, const tensor& rhs, bool lower=true, bool adjoint=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchMatrixTriangularSolve", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), matrix.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "lower", (unsigned char)lower);
    TFE_OpSetAttrBool(op.get(), "adjoint", (unsigned char)adjoint);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BatchNormWithGlobalNormalization
# Inputs:
*    t
*    m
*    v
*    beta
*    gamma

# Attributes:
*    variance_epsilon
*    scale_after_normalization

# Outputs:
*    result

*/
inline tensor batch_norm_with_global_normalization(const tensor& t, const tensor& m, const tensor& v, const tensor& beta, const tensor& gamma, float variance_epsilon, bool scale_after_normalization) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchNormWithGlobalNormalization", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), t.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gamma.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "variance_epsilon", variance_epsilon);
    TFE_OpSetAttrBool(op.get(), "scale_after_normalization", (unsigned char)scale_after_normalization);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BatchNormWithGlobalNormalizationGrad
# Inputs:
*    t
*    m
*    v
*    gamma
*    backprop

# Attributes:
*    variance_epsilon
*    scale_after_normalization

# Outputs:
*    dx
*    dm
*    dv
*    db
*    dg

*/
inline std::vector<tensor> batch_norm_with_global_normalization_grad(const tensor& t, const tensor& m, const tensor& v, const tensor& gamma, const tensor& backprop, float variance_epsilon, bool scale_after_normalization) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchNormWithGlobalNormalizationGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), t.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gamma.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "variance_epsilon", variance_epsilon);
    TFE_OpSetAttrBool(op.get(), "scale_after_normalization", (unsigned char)scale_after_normalization);

    // Execute Op
    int num_outputs_op = 5;
    TFE_TensorHandle* res[5] = { nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]), };
}

/* # BatchSelfAdjointEig
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor batch_self_adjoint_eig(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchSelfAdjointEig", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BatchSelfAdjointEigV2
# Inputs:
*    input

# Attributes:
*    compute_v

# Outputs:
*    e
*    v

*/
inline std::vector<tensor> batch_self_adjoint_eig_v2(const tensor& input, bool compute_v=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchSelfAdjointEigV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "compute_v", (unsigned char)compute_v);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # BatchSvd
# Inputs:
*    input

# Attributes:
*    compute_uv
*    full_matrices

# Outputs:
*    s
*    u
*    v

*/
inline std::vector<tensor> batch_svd(const tensor& input, bool compute_uv=true, bool full_matrices=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchSvd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "compute_uv", (unsigned char)compute_uv);
    TFE_OpSetAttrBool(op.get(), "full_matrices", (unsigned char)full_matrices);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # BatchToSpace
# Inputs:
*    input
*    crops

# Attributes:
*    block_size
*    Tidx

# Outputs:
*    output

*/
inline tensor batch_to_space(const tensor& input, const tensor& crops, int64_t block_size, datatype Tidx=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchToSpace", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), crops.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "block_size", block_size);
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BatchToSpaceND
# Inputs:
*    input
*    block_shape
*    crops

# Attributes:
*    Tblock_shape
*    Tcrops

# Outputs:
*    output

*/
inline tensor batch_to_space_n_d(const tensor& input, const tensor& block_shape, const tensor& crops, datatype Tblock_shape=static_cast<datatype>(3), datatype Tcrops=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchToSpaceND", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), block_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), crops.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tblock_shape", Tblock_shape);
    TFE_OpSetAttrType(op.get(), "Tcrops", Tcrops);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BesselI0
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor bessel_i0(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BesselI0", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BesselI0e
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor bessel_i0e(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BesselI0e", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BesselI1
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor bessel_i1(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BesselI1", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BesselI1e
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor bessel_i1e(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BesselI1e", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BesselJ0
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor bessel_j0(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BesselJ0", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BesselJ1
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor bessel_j1(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BesselJ1", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BesselK0
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor bessel_k0(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BesselK0", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BesselK0e
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor bessel_k0e(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BesselK0e", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BesselK1
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor bessel_k1(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BesselK1", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BesselK1e
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor bessel_k1e(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BesselK1e", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BesselY0
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor bessel_y0(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BesselY0", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BesselY1
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor bessel_y1(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BesselY1", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Betainc
# Inputs:
*    a
*    b
*    x

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor betainc(const tensor& a, const tensor& b, const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Betainc", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BiasAdd
# Inputs:
*    value
*    bias

# Attributes:
*    data_format

# Outputs:
*    output

*/
inline tensor bias_add(const tensor& value, const tensor& bias, const std::string& data_format="NHWC") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BiasAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BiasAddGrad
# Inputs:
*    out_backprop

# Attributes:
*    data_format

# Outputs:
*    output

*/
inline tensor bias_add_grad(const tensor& out_backprop, const std::string& data_format="NHWC") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BiasAddGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), out_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BiasAddV1
# Inputs:
*    value
*    bias

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor bias_add_v1(const tensor& value, const tensor& bias) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BiasAddV1", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Bincount
# Inputs:
*    arr
*    size
*    weights

# Attributes:
*    
# Outputs:
*    bins

*/
inline tensor bincount(const tensor& arr, const tensor& size, const tensor& weights) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Bincount", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), arr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), weights.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Bitcast
# Inputs:
*    input

# Attributes:
*    type

# Outputs:
*    output

*/
inline tensor bitcast(const tensor& input, datatype type) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Bitcast", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "type", type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BitwiseAnd
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor bitwise_and(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BitwiseAnd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BitwiseOr
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor bitwise_or(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BitwiseOr", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BitwiseXor
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor bitwise_xor(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BitwiseXor", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BlockLSTM
# Inputs:
*    seq_len_max
*    x
*    cs_prev
*    h_prev
*    w
*    wci
*    wcf
*    wco
*    b

# Attributes:
*    forget_bias
*    cell_clip
*    use_peephole

# Outputs:
*    i
*    cs
*    f
*    o
*    ci
*    co
*    h

*/
inline std::vector<tensor> block_l_s_t_m(const tensor& seq_len_max, const tensor& x, const tensor& cs_prev, const tensor& h_prev, const tensor& w, const tensor& wci, const tensor& wcf, const tensor& wco, const tensor& b, float forget_bias=1.0000e+00, float cell_clip=3.0000e+00, bool use_peephole=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BlockLSTM", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), seq_len_max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cs_prev.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), h_prev.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), w.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wci.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wcf.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wco.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "forget_bias", forget_bias);
    TFE_OpSetAttrFloat(op.get(), "cell_clip", cell_clip);
    TFE_OpSetAttrBool(op.get(), "use_peephole", (unsigned char)use_peephole);

    // Execute Op
    int num_outputs_op = 7;
    TFE_TensorHandle* res[7] = { nullptr,nullptr,nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]),tensor(res[5]),tensor(res[6]), };
}

/* # BlockLSTMGrad
# Inputs:
*    seq_len_max
*    x
*    cs_prev
*    h_prev
*    w
*    wci
*    wcf
*    wco
*    b
*    i
*    cs
*    f
*    o
*    ci
*    co
*    h
*    cs_grad
*    h_grad

# Attributes:
*    use_peephole

# Outputs:
*    x_grad
*    cs_prev_grad
*    h_prev_grad
*    w_grad
*    wci_grad
*    wcf_grad
*    wco_grad
*    b_grad

*/
inline std::vector<tensor> block_l_s_t_m_grad(const tensor& seq_len_max, const tensor& x, const tensor& cs_prev, const tensor& h_prev, const tensor& w, const tensor& wci, const tensor& wcf, const tensor& wco, const tensor& b, const tensor& i, const tensor& cs, const tensor& f, const tensor& o, const tensor& ci, const tensor& co, const tensor& h, const tensor& cs_grad, const tensor& h_grad, bool use_peephole) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BlockLSTMGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), seq_len_max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cs_prev.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), h_prev.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), w.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wci.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wcf.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wco.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), i.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), f.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), o.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ci.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), co.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), h.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cs_grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), h_grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_peephole", (unsigned char)use_peephole);

    // Execute Op
    int num_outputs_op = 8;
    TFE_TensorHandle* res[8] = { nullptr,nullptr,nullptr,nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]),tensor(res[5]),tensor(res[6]),tensor(res[7]), };
}

/* # BlockLSTMGradV2
# Inputs:
*    seq_len_max
*    x
*    cs_prev
*    h_prev
*    w
*    wci
*    wcf
*    wco
*    b
*    i
*    cs
*    f
*    o
*    ci
*    co
*    h
*    cs_grad
*    h_grad

# Attributes:
*    use_peephole

# Outputs:
*    x_grad
*    cs_prev_grad
*    h_prev_grad
*    w_grad
*    wci_grad
*    wcf_grad
*    wco_grad
*    b_grad

*/
inline std::vector<tensor> block_l_s_t_m_grad_v2(const tensor& seq_len_max, const tensor& x, const tensor& cs_prev, const tensor& h_prev, const tensor& w, const tensor& wci, const tensor& wcf, const tensor& wco, const tensor& b, const tensor& i, const tensor& cs, const tensor& f, const tensor& o, const tensor& ci, const tensor& co, const tensor& h, const tensor& cs_grad, const tensor& h_grad, bool use_peephole) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BlockLSTMGradV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), seq_len_max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cs_prev.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), h_prev.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), w.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wci.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wcf.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wco.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), i.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), f.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), o.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ci.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), co.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), h.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cs_grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), h_grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_peephole", (unsigned char)use_peephole);

    // Execute Op
    int num_outputs_op = 8;
    TFE_TensorHandle* res[8] = { nullptr,nullptr,nullptr,nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]),tensor(res[5]),tensor(res[6]),tensor(res[7]), };
}

/* # BlockLSTMV2
# Inputs:
*    seq_len_max
*    x
*    cs_prev
*    h_prev
*    w
*    wci
*    wcf
*    wco
*    b

# Attributes:
*    cell_clip
*    use_peephole

# Outputs:
*    i
*    cs
*    f
*    o
*    ci
*    co
*    h

*/
inline std::vector<tensor> block_l_s_t_m_v2(const tensor& seq_len_max, const tensor& x, const tensor& cs_prev, const tensor& h_prev, const tensor& w, const tensor& wci, const tensor& wcf, const tensor& wco, const tensor& b, float cell_clip=0.0000e+00, bool use_peephole=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BlockLSTMV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), seq_len_max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cs_prev.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), h_prev.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), w.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wci.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wcf.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wco.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "cell_clip", cell_clip);
    TFE_OpSetAttrBool(op.get(), "use_peephole", (unsigned char)use_peephole);

    // Execute Op
    int num_outputs_op = 7;
    TFE_TensorHandle* res[7] = { nullptr,nullptr,nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]),tensor(res[5]),tensor(res[6]), };
}

/* # BoostedTreesAggregateStats
# Inputs:
*    node_ids
*    gradients
*    hessians
*    feature

# Attributes:
*    max_splits
*    num_buckets

# Outputs:
*    stats_summary

*/
inline tensor boosted_trees_aggregate_stats(const tensor& node_ids, const tensor& gradients, const tensor& hessians, const tensor& feature, int64_t max_splits, int64_t num_buckets) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesAggregateStats", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), node_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradients.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), hessians.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), feature.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "max_splits", max_splits);
    TFE_OpSetAttrInt(op.get(), "num_buckets", num_buckets);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BoostedTreesBucketize
# Inputs:
*    float_values
*    bucket_boundaries

# Attributes:
*    num_features

# Outputs:
*    buckets

*/
inline tensor boosted_trees_bucketize(const std::vector<tensor>&float_values, const std::vector<tensor>&bucket_boundaries) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesBucketize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> float_values_handles; float_values_handles.reserve(float_values.size());
    std::transform(float_values.begin(), float_values.end(), std::back_inserter(float_values_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), float_values_handles.data(), static_cast<int>(float_values.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> bucket_boundaries_handles; bucket_boundaries_handles.reserve(bucket_boundaries.size());
    std::transform(bucket_boundaries.begin(), bucket_boundaries.end(), std::back_inserter(bucket_boundaries_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), bucket_boundaries_handles.data(), static_cast<int>(bucket_boundaries.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_features", float_values.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BoostedTreesCalculateBestFeatureSplit
# Inputs:
*    node_id_range
*    stats_summary
*    l1
*    l2
*    tree_complexity
*    min_node_weight

# Attributes:
*    logits_dimension
*    split_type

# Outputs:
*    node_ids
*    gains
*    feature_dimensions
*    thresholds
*    left_node_contribs
*    right_node_contribs
*    split_with_default_directions

*/
inline std::vector<tensor> boosted_trees_calculate_best_feature_split(const tensor& node_id_range, const tensor& stats_summary, const tensor& l1, const tensor& l2, const tensor& tree_complexity, const tensor& min_node_weight, int64_t logits_dimension, const std::string& split_type="inequality") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesCalculateBestFeatureSplit", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), node_id_range.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), stats_summary.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tree_complexity.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_node_weight.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "logits_dimension", logits_dimension);
    TFE_OpSetAttrString(op.get(), "split_type", (void*) split_type.c_str(), split_type.size());

    // Execute Op
    int num_outputs_op = 7;
    TFE_TensorHandle* res[7] = { nullptr,nullptr,nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]),tensor(res[5]),tensor(res[6]), };
}

/* # BoostedTreesCalculateBestFeatureSplitV2
# Inputs:
*    node_id_range
*    stats_summaries_list
*    split_types
*    candidate_feature_ids
*    l1
*    l2
*    tree_complexity
*    min_node_weight

# Attributes:
*    num_features
*    logits_dimension

# Outputs:
*    node_ids
*    gains
*    feature_ids
*    feature_dimensions
*    thresholds
*    left_node_contribs
*    right_node_contribs
*    split_with_default_directions

*/
inline std::vector<tensor> boosted_trees_calculate_best_feature_split_v2(const tensor& node_id_range, const std::vector<tensor>&stats_summaries_list, const tensor& split_types, const tensor& candidate_feature_ids, const tensor& l1, const tensor& l2, const tensor& tree_complexity, const tensor& min_node_weight, int64_t logits_dimension) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesCalculateBestFeatureSplitV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), node_id_range.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> stats_summaries_list_handles; stats_summaries_list_handles.reserve(stats_summaries_list.size());
    std::transform(stats_summaries_list.begin(), stats_summaries_list.end(), std::back_inserter(stats_summaries_list_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), stats_summaries_list_handles.data(), static_cast<int>(stats_summaries_list.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), split_types.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), candidate_feature_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tree_complexity.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_node_weight.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_features", stats_summaries_list.size());
    TFE_OpSetAttrInt(op.get(), "logits_dimension", logits_dimension);

    // Execute Op
    int num_outputs_op = 8;
    TFE_TensorHandle* res[8] = { nullptr,nullptr,nullptr,nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]),tensor(res[5]),tensor(res[6]),tensor(res[7]), };
}

/* # BoostedTreesCalculateBestGainsPerFeature
# Inputs:
*    node_id_range
*    stats_summary_list
*    l1
*    l2
*    tree_complexity
*    min_node_weight

# Attributes:
*    max_splits
*    num_features

# Outputs:
*    node_ids_list
*    gains_list
*    thresholds_list
*    left_node_contribs_list
*    right_node_contribs_list

*/
inline std::vector<tensor> boosted_trees_calculate_best_gains_per_feature(const tensor& node_id_range, const std::vector<tensor>&stats_summary_list, const tensor& l1, const tensor& l2, const tensor& tree_complexity, const tensor& min_node_weight, int64_t max_splits) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesCalculateBestGainsPerFeature", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), node_id_range.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> stats_summary_list_handles; stats_summary_list_handles.reserve(stats_summary_list.size());
    std::transform(stats_summary_list.begin(), stats_summary_list.end(), std::back_inserter(stats_summary_list_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), stats_summary_list_handles.data(), static_cast<int>(stats_summary_list.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tree_complexity.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_node_weight.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "max_splits", max_splits);
    TFE_OpSetAttrInt(op.get(), "num_features", stats_summary_list.size());

    // Execute Op
    int num_outputs_op = 5;
    TFE_TensorHandle* res[5] = { nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]), };
}

/* # BoostedTreesCenterBias
# Inputs:
*    tree_ensemble_handle
*    mean_gradients
*    mean_hessians
*    l1
*    l2

# Attributes:
*    
# Outputs:
*    continue_centering

*/
inline tensor boosted_trees_center_bias(const tensor& tree_ensemble_handle, const tensor& mean_gradients, const tensor& mean_hessians, const tensor& l1, const tensor& l2) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesCenterBias", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tree_ensemble_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mean_gradients.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mean_hessians.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BoostedTreesCreateEnsemble
# Inputs:
*    tree_ensemble_handle
*    stamp_token
*    tree_ensemble_serialized

# Attributes:
*    
# Outputs:
*    
*/
inline void boosted_trees_create_ensemble(const tensor& tree_ensemble_handle, const tensor& stamp_token, const tensor& tree_ensemble_serialized) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesCreateEnsemble", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tree_ensemble_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), stamp_token.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tree_ensemble_serialized.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # BoostedTreesCreateQuantileStreamResource
# Inputs:
*    quantile_stream_resource_handle
*    epsilon
*    num_streams

# Attributes:
*    max_elements

# Outputs:
*    
*/
inline void boosted_trees_create_quantile_stream_resource(const tensor& quantile_stream_resource_handle, const tensor& epsilon, const tensor& num_streams, int64_t max_elements=1099511627776) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesCreateQuantileStreamResource", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), quantile_stream_resource_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_streams.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "max_elements", max_elements);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # BoostedTreesDeserializeEnsemble
# Inputs:
*    tree_ensemble_handle
*    stamp_token
*    tree_ensemble_serialized

# Attributes:
*    
# Outputs:
*    
*/
inline void boosted_trees_deserialize_ensemble(const tensor& tree_ensemble_handle, const tensor& stamp_token, const tensor& tree_ensemble_serialized) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesDeserializeEnsemble", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tree_ensemble_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), stamp_token.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tree_ensemble_serialized.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # BoostedTreesEnsembleResourceHandleOp
# Inputs:
*    
# Attributes:
*    container
*    shared_name

# Outputs:
*    resource

*/
inline tensor boosted_trees_ensemble_resource_handle_op(const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesEnsembleResourceHandleOp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BoostedTreesExampleDebugOutputs
# Inputs:
*    tree_ensemble_handle
*    bucketized_features

# Attributes:
*    num_bucketized_features
*    logits_dimension

# Outputs:
*    examples_debug_outputs_serialized

*/
inline tensor boosted_trees_example_debug_outputs(const tensor& tree_ensemble_handle, const std::vector<tensor>&bucketized_features, int64_t logits_dimension) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesExampleDebugOutputs", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tree_ensemble_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> bucketized_features_handles; bucketized_features_handles.reserve(bucketized_features.size());
    std::transform(bucketized_features.begin(), bucketized_features.end(), std::back_inserter(bucketized_features_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), bucketized_features_handles.data(), static_cast<int>(bucketized_features.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_bucketized_features", bucketized_features.size());
    TFE_OpSetAttrInt(op.get(), "logits_dimension", logits_dimension);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BoostedTreesFlushQuantileSummaries
# Inputs:
*    quantile_stream_resource_handle

# Attributes:
*    num_features

# Outputs:
*    summaries

*/
inline tensor boosted_trees_flush_quantile_summaries(const tensor& quantile_stream_resource_handle, int64_t num_features) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesFlushQuantileSummaries", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), quantile_stream_resource_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_features", num_features);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BoostedTreesGetEnsembleStates
# Inputs:
*    tree_ensemble_handle

# Attributes:
*    
# Outputs:
*    stamp_token
*    num_trees
*    num_finalized_trees
*    num_attempted_layers
*    last_layer_nodes_range

*/
inline std::vector<tensor> boosted_trees_get_ensemble_states(const tensor& tree_ensemble_handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesGetEnsembleStates", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tree_ensemble_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 5;
    TFE_TensorHandle* res[5] = { nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]), };
}

/* # BoostedTreesMakeQuantileSummaries
# Inputs:
*    float_values
*    example_weights
*    epsilon

# Attributes:
*    num_features

# Outputs:
*    summaries

*/
inline tensor boosted_trees_make_quantile_summaries(const std::vector<tensor>&float_values, const tensor& example_weights, const tensor& epsilon) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesMakeQuantileSummaries", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> float_values_handles; float_values_handles.reserve(float_values.size());
    std::transform(float_values.begin(), float_values.end(), std::back_inserter(float_values_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), float_values_handles.data(), static_cast<int>(float_values.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), example_weights.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_features", float_values.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BoostedTreesMakeStatsSummary
# Inputs:
*    node_ids
*    gradients
*    hessians
*    bucketized_features_list

# Attributes:
*    max_splits
*    num_buckets
*    num_features

# Outputs:
*    stats_summary

*/
inline tensor boosted_trees_make_stats_summary(const tensor& node_ids, const tensor& gradients, const tensor& hessians, const std::vector<tensor>&bucketized_features_list, int64_t max_splits, int64_t num_buckets) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesMakeStatsSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), node_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradients.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), hessians.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> bucketized_features_list_handles; bucketized_features_list_handles.reserve(bucketized_features_list.size());
    std::transform(bucketized_features_list.begin(), bucketized_features_list.end(), std::back_inserter(bucketized_features_list_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), bucketized_features_list_handles.data(), static_cast<int>(bucketized_features_list.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "max_splits", max_splits);
    TFE_OpSetAttrInt(op.get(), "num_buckets", num_buckets);
    TFE_OpSetAttrInt(op.get(), "num_features", bucketized_features_list.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BoostedTreesPredict
# Inputs:
*    tree_ensemble_handle
*    bucketized_features

# Attributes:
*    num_bucketized_features
*    logits_dimension

# Outputs:
*    logits

*/
inline tensor boosted_trees_predict(const tensor& tree_ensemble_handle, const std::vector<tensor>&bucketized_features, int64_t logits_dimension) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesPredict", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tree_ensemble_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> bucketized_features_handles; bucketized_features_handles.reserve(bucketized_features.size());
    std::transform(bucketized_features.begin(), bucketized_features.end(), std::back_inserter(bucketized_features_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), bucketized_features_handles.data(), static_cast<int>(bucketized_features.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_bucketized_features", bucketized_features.size());
    TFE_OpSetAttrInt(op.get(), "logits_dimension", logits_dimension);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BoostedTreesQuantileStreamResourceAddSummaries
# Inputs:
*    quantile_stream_resource_handle
*    summaries

# Attributes:
*    num_features

# Outputs:
*    
*/
inline void boosted_trees_quantile_stream_resource_add_summaries(const tensor& quantile_stream_resource_handle, const std::vector<tensor>&summaries) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesQuantileStreamResourceAddSummaries", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), quantile_stream_resource_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> summaries_handles; summaries_handles.reserve(summaries.size());
    std::transform(summaries.begin(), summaries.end(), std::back_inserter(summaries_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), summaries_handles.data(), static_cast<int>(summaries.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_features", summaries.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # BoostedTreesQuantileStreamResourceDeserialize
# Inputs:
*    quantile_stream_resource_handle
*    bucket_boundaries

# Attributes:
*    num_streams

# Outputs:
*    
*/
inline void boosted_trees_quantile_stream_resource_deserialize(const tensor& quantile_stream_resource_handle, const std::vector<tensor>&bucket_boundaries) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesQuantileStreamResourceDeserialize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), quantile_stream_resource_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> bucket_boundaries_handles; bucket_boundaries_handles.reserve(bucket_boundaries.size());
    std::transform(bucket_boundaries.begin(), bucket_boundaries.end(), std::back_inserter(bucket_boundaries_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), bucket_boundaries_handles.data(), static_cast<int>(bucket_boundaries.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_streams", bucket_boundaries.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # BoostedTreesQuantileStreamResourceFlush
# Inputs:
*    quantile_stream_resource_handle
*    num_buckets

# Attributes:
*    generate_quantiles

# Outputs:
*    
*/
inline void boosted_trees_quantile_stream_resource_flush(const tensor& quantile_stream_resource_handle, const tensor& num_buckets, bool generate_quantiles=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesQuantileStreamResourceFlush", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), quantile_stream_resource_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_buckets.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "generate_quantiles", (unsigned char)generate_quantiles);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # BoostedTreesQuantileStreamResourceGetBucketBoundaries
# Inputs:
*    quantile_stream_resource_handle

# Attributes:
*    num_features

# Outputs:
*    bucket_boundaries

*/
inline tensor boosted_trees_quantile_stream_resource_get_bucket_boundaries(const tensor& quantile_stream_resource_handle, int64_t num_features) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesQuantileStreamResourceGetBucketBoundaries", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), quantile_stream_resource_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_features", num_features);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BoostedTreesQuantileStreamResourceHandleOp
# Inputs:
*    
# Attributes:
*    container
*    shared_name

# Outputs:
*    resource

*/
inline tensor boosted_trees_quantile_stream_resource_handle_op(const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesQuantileStreamResourceHandleOp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BoostedTreesSerializeEnsemble
# Inputs:
*    tree_ensemble_handle

# Attributes:
*    
# Outputs:
*    stamp_token
*    tree_ensemble_serialized

*/
inline std::vector<tensor> boosted_trees_serialize_ensemble(const tensor& tree_ensemble_handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesSerializeEnsemble", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tree_ensemble_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # BoostedTreesSparseAggregateStats
# Inputs:
*    node_ids
*    gradients
*    hessians
*    feature_indices
*    feature_values
*    feature_shape

# Attributes:
*    max_splits
*    num_buckets

# Outputs:
*    stats_summary_indices
*    stats_summary_values
*    stats_summary_shape

*/
inline std::vector<tensor> boosted_trees_sparse_aggregate_stats(const tensor& node_ids, const tensor& gradients, const tensor& hessians, const tensor& feature_indices, const tensor& feature_values, const tensor& feature_shape, int64_t max_splits, int64_t num_buckets) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesSparseAggregateStats", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), node_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradients.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), hessians.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), feature_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), feature_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), feature_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "max_splits", max_splits);
    TFE_OpSetAttrInt(op.get(), "num_buckets", num_buckets);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # BoostedTreesSparseCalculateBestFeatureSplit
# Inputs:
*    node_id_range
*    stats_summary_indices
*    stats_summary_values
*    stats_summary_shape
*    l1
*    l2
*    tree_complexity
*    min_node_weight

# Attributes:
*    logits_dimension
*    split_type

# Outputs:
*    node_ids
*    gains
*    feature_dimensions
*    thresholds
*    left_node_contribs
*    right_node_contribs
*    split_with_default_directions

*/
inline std::vector<tensor> boosted_trees_sparse_calculate_best_feature_split(const tensor& node_id_range, const tensor& stats_summary_indices, const tensor& stats_summary_values, const tensor& stats_summary_shape, const tensor& l1, const tensor& l2, const tensor& tree_complexity, const tensor& min_node_weight, int64_t logits_dimension, const std::string& split_type="inequality") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesSparseCalculateBestFeatureSplit", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), node_id_range.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), stats_summary_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), stats_summary_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), stats_summary_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tree_complexity.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_node_weight.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "logits_dimension", logits_dimension);
    TFE_OpSetAttrString(op.get(), "split_type", (void*) split_type.c_str(), split_type.size());

    // Execute Op
    int num_outputs_op = 7;
    TFE_TensorHandle* res[7] = { nullptr,nullptr,nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]),tensor(res[5]),tensor(res[6]), };
}

/* # BoostedTreesTrainingPredict
# Inputs:
*    tree_ensemble_handle
*    cached_tree_ids
*    cached_node_ids
*    bucketized_features

# Attributes:
*    num_bucketized_features
*    logits_dimension

# Outputs:
*    partial_logits
*    tree_ids
*    node_ids

*/
inline std::vector<tensor> boosted_trees_training_predict(const tensor& tree_ensemble_handle, const tensor& cached_tree_ids, const tensor& cached_node_ids, const std::vector<tensor>&bucketized_features, int64_t logits_dimension) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesTrainingPredict", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tree_ensemble_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cached_tree_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cached_node_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> bucketized_features_handles; bucketized_features_handles.reserve(bucketized_features.size());
    std::transform(bucketized_features.begin(), bucketized_features.end(), std::back_inserter(bucketized_features_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), bucketized_features_handles.data(), static_cast<int>(bucketized_features.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_bucketized_features", bucketized_features.size());
    TFE_OpSetAttrInt(op.get(), "logits_dimension", logits_dimension);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # BoostedTreesUpdateEnsemble
# Inputs:
*    tree_ensemble_handle
*    feature_ids
*    node_ids
*    gains
*    thresholds
*    left_node_contribs
*    right_node_contribs
*    max_depth
*    learning_rate

# Attributes:
*    pruning_mode
*    num_features

# Outputs:
*    
*/
inline void boosted_trees_update_ensemble(const tensor& tree_ensemble_handle, const tensor& feature_ids, const std::vector<tensor>&node_ids, const std::vector<tensor>&gains, const std::vector<tensor>&thresholds, const std::vector<tensor>&left_node_contribs, const std::vector<tensor>&right_node_contribs, const tensor& max_depth, const tensor& learning_rate, int64_t pruning_mode) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesUpdateEnsemble", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tree_ensemble_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), feature_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> node_ids_handles; node_ids_handles.reserve(node_ids.size());
    std::transform(node_ids.begin(), node_ids.end(), std::back_inserter(node_ids_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), node_ids_handles.data(), static_cast<int>(node_ids.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> gains_handles; gains_handles.reserve(gains.size());
    std::transform(gains.begin(), gains.end(), std::back_inserter(gains_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), gains_handles.data(), static_cast<int>(gains.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> thresholds_handles; thresholds_handles.reserve(thresholds.size());
    std::transform(thresholds.begin(), thresholds.end(), std::back_inserter(thresholds_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), thresholds_handles.data(), static_cast<int>(thresholds.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> left_node_contribs_handles; left_node_contribs_handles.reserve(left_node_contribs.size());
    std::transform(left_node_contribs.begin(), left_node_contribs.end(), std::back_inserter(left_node_contribs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), left_node_contribs_handles.data(), static_cast<int>(left_node_contribs.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> right_node_contribs_handles; right_node_contribs_handles.reserve(right_node_contribs.size());
    std::transform(right_node_contribs.begin(), right_node_contribs.end(), std::back_inserter(right_node_contribs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), right_node_contribs_handles.data(), static_cast<int>(right_node_contribs.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_depth.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), learning_rate.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "pruning_mode", pruning_mode);
    TFE_OpSetAttrInt(op.get(), "num_features", node_ids.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # BoostedTreesUpdateEnsembleV2
# Inputs:
*    tree_ensemble_handle
*    feature_ids
*    dimension_ids
*    node_ids
*    gains
*    thresholds
*    left_node_contribs
*    right_node_contribs
*    split_types
*    max_depth
*    learning_rate
*    pruning_mode

# Attributes:
*    num_features
*    logits_dimension
*    num_groups

# Outputs:
*    
*/
inline void boosted_trees_update_ensemble_v2(const tensor& tree_ensemble_handle, const std::vector<tensor>&feature_ids, const std::vector<tensor>&dimension_ids, const std::vector<tensor>&node_ids, const std::vector<tensor>&gains, const std::vector<tensor>&thresholds, const std::vector<tensor>&left_node_contribs, const std::vector<tensor>&right_node_contribs, const std::vector<tensor>&split_types, const tensor& max_depth, const tensor& learning_rate, const tensor& pruning_mode, int64_t logits_dimension=1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesUpdateEnsembleV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tree_ensemble_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> feature_ids_handles; feature_ids_handles.reserve(feature_ids.size());
    std::transform(feature_ids.begin(), feature_ids.end(), std::back_inserter(feature_ids_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), feature_ids_handles.data(), static_cast<int>(feature_ids.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dimension_ids_handles; dimension_ids_handles.reserve(dimension_ids.size());
    std::transform(dimension_ids.begin(), dimension_ids.end(), std::back_inserter(dimension_ids_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), dimension_ids_handles.data(), static_cast<int>(dimension_ids.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> node_ids_handles; node_ids_handles.reserve(node_ids.size());
    std::transform(node_ids.begin(), node_ids.end(), std::back_inserter(node_ids_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), node_ids_handles.data(), static_cast<int>(node_ids.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> gains_handles; gains_handles.reserve(gains.size());
    std::transform(gains.begin(), gains.end(), std::back_inserter(gains_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), gains_handles.data(), static_cast<int>(gains.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> thresholds_handles; thresholds_handles.reserve(thresholds.size());
    std::transform(thresholds.begin(), thresholds.end(), std::back_inserter(thresholds_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), thresholds_handles.data(), static_cast<int>(thresholds.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> left_node_contribs_handles; left_node_contribs_handles.reserve(left_node_contribs.size());
    std::transform(left_node_contribs.begin(), left_node_contribs.end(), std::back_inserter(left_node_contribs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), left_node_contribs_handles.data(), static_cast<int>(left_node_contribs.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> right_node_contribs_handles; right_node_contribs_handles.reserve(right_node_contribs.size());
    std::transform(right_node_contribs.begin(), right_node_contribs.end(), std::back_inserter(right_node_contribs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), right_node_contribs_handles.data(), static_cast<int>(right_node_contribs.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> split_types_handles; split_types_handles.reserve(split_types.size());
    std::transform(split_types.begin(), split_types.end(), std::back_inserter(split_types_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), split_types_handles.data(), static_cast<int>(split_types.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_depth.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), learning_rate.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), pruning_mode.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_features", dimension_ids.size());
    TFE_OpSetAttrInt(op.get(), "logits_dimension", logits_dimension);
    TFE_OpSetAttrInt(op.get(), "num_groups", feature_ids.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # BroadcastArgs
# Inputs:
*    s0
*    s1

# Attributes:
*    
# Outputs:
*    r0

*/
inline tensor broadcast_args(const tensor& s0, const tensor& s1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BroadcastArgs", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), s0.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), s1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BroadcastGradientArgs
# Inputs:
*    s0
*    s1

# Attributes:
*    
# Outputs:
*    r0
*    r1

*/
inline std::vector<tensor> broadcast_gradient_args(const tensor& s0, const tensor& s1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BroadcastGradientArgs", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), s0.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), s1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # BroadcastTo
# Inputs:
*    input
*    shape

# Attributes:
*    Tidx

# Outputs:
*    output

*/
inline tensor broadcast_to(const tensor& input, const tensor& shape, datatype Tidx=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BroadcastTo", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Bucketize
# Inputs:
*    input

# Attributes:
*    boundaries

# Outputs:
*    output

*/
inline tensor bucketize(const tensor& input, const std::vector<float>& boundaries) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Bucketize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloatList(op.get(), "boundaries", boundaries.data(), static_cast<int>(boundaries.size()));

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # BytesProducedStatsDataset
# Inputs:
*    input_dataset
*    tag

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor bytes_produced_stats_dataset(const tensor& input_dataset, const tensor& tag, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BytesProducedStatsDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tag.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CSRSparseMatrixComponents
# Inputs:
*    csr_sparse_matrix
*    index

# Attributes:
*    type

# Outputs:
*    row_ptrs
*    col_inds
*    values

*/
inline std::vector<tensor> c_s_r_sparse_matrix_components(const tensor& csr_sparse_matrix, const tensor& index, datatype type) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CSRSparseMatrixComponents", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), csr_sparse_matrix.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), index.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "type", type);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # CSRSparseMatrixToDense
# Inputs:
*    sparse_input

# Attributes:
*    type

# Outputs:
*    dense_output

*/
inline tensor c_s_r_sparse_matrix_to_dense(const tensor& sparse_input, datatype type) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CSRSparseMatrixToDense", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sparse_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "type", type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CSRSparseMatrixToSparseTensor
# Inputs:
*    sparse_matrix

# Attributes:
*    type

# Outputs:
*    indices
*    values
*    dense_shape

*/
inline std::vector<tensor> c_s_r_sparse_matrix_to_sparse_tensor(const tensor& sparse_matrix, datatype type) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CSRSparseMatrixToSparseTensor", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sparse_matrix.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "type", type);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # CSVDataset
# Inputs:
*    filenames
*    compression_type
*    buffer_size
*    header
*    field_delim
*    use_quote_delim
*    na_value
*    select_cols
*    record_defaults

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor c_s_v_dataset(const tensor& filenames, const tensor& compression_type, const tensor& buffer_size, const tensor& header, const tensor& field_delim, const tensor& use_quote_delim, const tensor& na_value, const tensor& select_cols, const std::vector<tensor>&record_defaults, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CSVDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filenames.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), compression_type.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), header.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), field_delim.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), use_quote_delim.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), na_value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), select_cols.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> record_defaults_handles; record_defaults_handles.reserve(record_defaults.size());
    std::transform(record_defaults.begin(), record_defaults.end(), std::back_inserter(record_defaults_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), record_defaults_handles.data(), static_cast<int>(record_defaults.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CSVDatasetV2
# Inputs:
*    filenames
*    compression_type
*    buffer_size
*    header
*    field_delim
*    use_quote_delim
*    na_value
*    select_cols
*    record_defaults
*    exclude_cols

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor c_s_v_dataset_v2(const tensor& filenames, const tensor& compression_type, const tensor& buffer_size, const tensor& header, const tensor& field_delim, const tensor& use_quote_delim, const tensor& na_value, const tensor& select_cols, const std::vector<tensor>&record_defaults, const tensor& exclude_cols, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CSVDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filenames.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), compression_type.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), header.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), field_delim.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), use_quote_delim.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), na_value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), select_cols.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> record_defaults_handles; record_defaults_handles.reserve(record_defaults.size());
    std::transform(record_defaults.begin(), record_defaults.end(), std::back_inserter(record_defaults_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), record_defaults_handles.data(), static_cast<int>(record_defaults.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), exclude_cols.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CTCBeamSearchDecoder
# Inputs:
*    inputs
*    sequence_length

# Attributes:
*    beam_width
*    top_paths
*    merge_repeated

# Outputs:
*    decoded_indices
*    decoded_values
*    decoded_shape
*    log_probability

*/
inline std::vector<tensor> c_t_c_beam_search_decoder(const tensor& inputs, const tensor& sequence_length, int64_t beam_width, int64_t top_paths, bool merge_repeated=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CTCBeamSearchDecoder", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), inputs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sequence_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "beam_width", beam_width);
    TFE_OpSetAttrInt(op.get(), "top_paths", top_paths);
    TFE_OpSetAttrBool(op.get(), "merge_repeated", (unsigned char)merge_repeated);

    // Execute Op
    int num_outputs_op = 4;
    TFE_TensorHandle* res[4] = { nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]), };
}

/* # CTCGreedyDecoder
# Inputs:
*    inputs
*    sequence_length

# Attributes:
*    merge_repeated
*    blank_index

# Outputs:
*    decoded_indices
*    decoded_values
*    decoded_shape
*    log_probability

*/
inline std::vector<tensor> c_t_c_greedy_decoder(const tensor& inputs, const tensor& sequence_length, bool merge_repeated=false, int64_t blank_index=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CTCGreedyDecoder", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), inputs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sequence_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "merge_repeated", (unsigned char)merge_repeated);
    TFE_OpSetAttrInt(op.get(), "blank_index", blank_index);

    // Execute Op
    int num_outputs_op = 4;
    TFE_TensorHandle* res[4] = { nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]), };
}

/* # CTCLoss
# Inputs:
*    inputs
*    labels_indices
*    labels_values
*    sequence_length

# Attributes:
*    preprocess_collapse_repeated
*    ctc_merge_repeated
*    ignore_longer_outputs_than_inputs

# Outputs:
*    loss
*    gradient

*/
inline std::vector<tensor> c_t_c_loss(const tensor& inputs, const tensor& labels_indices, const tensor& labels_values, const tensor& sequence_length, bool preprocess_collapse_repeated=false, bool ctc_merge_repeated=true, bool ignore_longer_outputs_than_inputs=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CTCLoss", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), inputs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), labels_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), labels_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sequence_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "preprocess_collapse_repeated", (unsigned char)preprocess_collapse_repeated);
    TFE_OpSetAttrBool(op.get(), "ctc_merge_repeated", (unsigned char)ctc_merge_repeated);
    TFE_OpSetAttrBool(op.get(), "ignore_longer_outputs_than_inputs", (unsigned char)ignore_longer_outputs_than_inputs);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # CTCLossV2
# Inputs:
*    inputs
*    labels_indices
*    labels_values
*    sequence_length

# Attributes:
*    preprocess_collapse_repeated
*    ctc_merge_repeated
*    ignore_longer_outputs_than_inputs

# Outputs:
*    loss
*    gradient

*/
inline std::vector<tensor> c_t_c_loss_v2(const tensor& inputs, const tensor& labels_indices, const tensor& labels_values, const tensor& sequence_length, bool preprocess_collapse_repeated=false, bool ctc_merge_repeated=true, bool ignore_longer_outputs_than_inputs=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CTCLossV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), inputs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), labels_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), labels_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sequence_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "preprocess_collapse_repeated", (unsigned char)preprocess_collapse_repeated);
    TFE_OpSetAttrBool(op.get(), "ctc_merge_repeated", (unsigned char)ctc_merge_repeated);
    TFE_OpSetAttrBool(op.get(), "ignore_longer_outputs_than_inputs", (unsigned char)ignore_longer_outputs_than_inputs);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # CacheDataset
# Inputs:
*    input_dataset
*    filename

# Attributes:
*    output_types
*    output_shapes
*    metadata

# Outputs:
*    handle

*/
inline tensor cache_dataset(const tensor& input_dataset, const tensor& filename, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CacheDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filename.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CacheDatasetV2
# Inputs:
*    input_dataset
*    filename
*    cache

# Attributes:
*    output_types
*    output_shapes
*    metadata

# Outputs:
*    handle

*/
inline tensor cache_dataset_v2(const tensor& input_dataset, const tensor& filename, const tensor& cache, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CacheDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filename.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cache.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Case
# Inputs:
*    branch_index
*    input

# Attributes:
*    Tin
*    Tout
*    branches
*    output_shapes

# Outputs:
*    output

*/
inline tensor tfe_case(const tensor& branch_index, const std::vector<tensor>&input, const std::vector<datatype>& Tin, const std::vector<datatype>& Tout, const std::vector<int64_t>& branches, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Case", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), branch_index.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> input_handles; input_handles.reserve(input.size());
    std::transform(input.begin(), input.end(), std::back_inserter(input_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), input_handles.data(), static_cast<int>(input.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Tin", reinterpret_cast<const enum TF_DataType *>(Tin.data()), static_cast<int>(Tin.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tout", reinterpret_cast<const enum TF_DataType *>(Tout.data()), static_cast<int>(Tout.size()));
    TFE_OpSetAttrIntList(op.get(), "branches", branches.data(), static_cast<int>(branches.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Cast
# Inputs:
*    x

# Attributes:
*    SrcT
*    DstT
*    Truncate

# Outputs:
*    y

*/
inline tensor cast(const tensor& x, datatype SrcT, datatype DstT, bool Truncate=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Cast", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "SrcT", SrcT);
    TFE_OpSetAttrType(op.get(), "DstT", DstT);
    TFE_OpSetAttrBool(op.get(), "Truncate", (unsigned char)Truncate);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Ceil
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor ceil(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Ceil", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CheckNumerics
# Inputs:
*    tensor

# Attributes:
*    message

# Outputs:
*    output

*/
inline tensor check_numerics(const tensor& input_tensor, const std::string& message) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CheckNumerics", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "message", (void*) message.c_str(), message.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CheckNumericsV2
# Inputs:
*    tensor

# Attributes:
*    message

# Outputs:
*    output

*/
inline tensor check_numerics_v2(const tensor& input_tensor, const std::string& message) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CheckNumericsV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "message", (void*) message.c_str(), message.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Cholesky
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor cholesky(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Cholesky", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CholeskyGrad
# Inputs:
*    l
*    grad

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor cholesky_grad(const tensor& l, const tensor& grad) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CholeskyGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), l.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ChooseFastestBranchDataset
# Inputs:
*    input_dataset
*    ratio_numerator
*    ratio_denominator
*    other_arguments

# Attributes:
*    Targuments
*    num_elements_per_branch
*    branches
*    other_arguments_lengths
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor choose_fastest_branch_dataset(const tensor& input_dataset, const tensor& ratio_numerator, const tensor& ratio_denominator, const std::vector<tensor>&other_arguments, const std::vector<datatype>& Targuments, int64_t num_elements_per_branch, const std::vector<int64_t>& branches, const std::vector<int64_t>& other_arguments_lengths, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ChooseFastestBranchDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ratio_numerator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ratio_denominator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> other_arguments_handles; other_arguments_handles.reserve(other_arguments.size());
    std::transform(other_arguments.begin(), other_arguments.end(), std::back_inserter(other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), other_arguments_handles.data(), static_cast<int>(other_arguments.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Targuments", reinterpret_cast<const enum TF_DataType *>(Targuments.data()), static_cast<int>(Targuments.size()));
    TFE_OpSetAttrInt(op.get(), "num_elements_per_branch", num_elements_per_branch);
    TFE_OpSetAttrIntList(op.get(), "branches", branches.data(), static_cast<int>(branches.size()));
    TFE_OpSetAttrIntList(op.get(), "other_arguments_lengths", other_arguments_lengths.data(), static_cast<int>(other_arguments_lengths.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ChooseFastestDataset
# Inputs:
*    input_datasets

# Attributes:
*    N
*    num_experiments
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor choose_fastest_dataset(const std::vector<tensor>&input_datasets, int64_t num_experiments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ChooseFastestDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> input_datasets_handles; input_datasets_handles.reserve(input_datasets.size());
    std::transform(input_datasets.begin(), input_datasets.end(), std::back_inserter(input_datasets_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), input_datasets_handles.data(), static_cast<int>(input_datasets.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", input_datasets.size());
    TFE_OpSetAttrInt(op.get(), "num_experiments", num_experiments);
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ClipByValue
# Inputs:
*    t
*    clip_value_min
*    clip_value_max

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor clip_by_value(const tensor& t, const tensor& clip_value_min, const tensor& clip_value_max) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ClipByValue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), t.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), clip_value_min.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), clip_value_max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CloseSummaryWriter
# Inputs:
*    writer

# Attributes:
*    
# Outputs:
*    
*/
inline void close_summary_writer(const tensor& writer) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CloseSummaryWriter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), writer.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # CollectiveAllToAllV2
# Inputs:
*    input
*    group_size
*    group_key
*    instance_key
*    ordering_token

# Attributes:
*    communication_hint
*    timeout_seconds
*    is_stateless
*    Nordering_token

# Outputs:
*    data

*/
inline tensor collective_all_to_all_v2(const tensor& input, const tensor& group_size, const tensor& group_key, const tensor& instance_key, const std::vector<tensor>&ordering_token, const std::string& communication_hint="auto", float timeout_seconds=0.0000e+00, bool is_stateless=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CollectiveAllToAllV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), group_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), group_key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), instance_key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> ordering_token_handles; ordering_token_handles.reserve(ordering_token.size());
    std::transform(ordering_token.begin(), ordering_token.end(), std::back_inserter(ordering_token_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), ordering_token_handles.data(), static_cast<int>(ordering_token.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "communication_hint", (void*) communication_hint.c_str(), communication_hint.size());
    TFE_OpSetAttrFloat(op.get(), "timeout_seconds", timeout_seconds);
    TFE_OpSetAttrBool(op.get(), "is_stateless", (unsigned char)is_stateless);
    TFE_OpSetAttrInt(op.get(), "Nordering_token", ordering_token.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CollectiveAllToAllV3
# Inputs:
*    input
*    communicator
*    group_assignment

# Attributes:
*    timeout_seconds

# Outputs:
*    data

*/
inline tensor collective_all_to_all_v3(const tensor& input, const tensor& communicator, const tensor& group_assignment, float timeout_seconds=0.0000e+00) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CollectiveAllToAllV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), communicator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), group_assignment.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "timeout_seconds", timeout_seconds);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CollectiveAssignGroupV2
# Inputs:
*    group_assignment
*    device_index
*    base_key

# Attributes:
*    
# Outputs:
*    group_size
*    group_key

*/
inline std::vector<tensor> collective_assign_group_v2(const tensor& group_assignment, const tensor& device_index, const tensor& base_key) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CollectiveAssignGroupV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), group_assignment.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), device_index.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), base_key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # CollectiveBcastRecv
# Inputs:
*    
# Attributes:
*    group_size
*    group_key
*    instance_key
*    shape
*    communication_hint
*    timeout_seconds

# Outputs:
*    data

*/
inline tensor collective_bcast_recv(int64_t group_size, int64_t group_key, int64_t instance_key, const std::vector<int64_t>& shape, const std::string& communication_hint="auto", float timeout_seconds=0.0000e+00) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CollectiveBcastRecv", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "group_size", group_size);
    TFE_OpSetAttrInt(op.get(), "group_key", group_key);
    TFE_OpSetAttrInt(op.get(), "instance_key", instance_key);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), static_cast<int>(shape.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "communication_hint", (void*) communication_hint.c_str(), communication_hint.size());
    TFE_OpSetAttrFloat(op.get(), "timeout_seconds", timeout_seconds);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CollectiveBcastRecvV2
# Inputs:
*    group_size
*    group_key
*    instance_key
*    shape

# Attributes:
*    Tshape
*    communication_hint
*    timeout_seconds

# Outputs:
*    data

*/
inline tensor collective_bcast_recv_v2(const tensor& group_size, const tensor& group_key, const tensor& instance_key, const tensor& shape, datatype Tshape=static_cast<datatype>(3), const std::string& communication_hint="auto", float timeout_seconds=0.0000e+00) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CollectiveBcastRecvV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), group_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), group_key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), instance_key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tshape", Tshape);
    TFE_OpSetAttrString(op.get(), "communication_hint", (void*) communication_hint.c_str(), communication_hint.size());
    TFE_OpSetAttrFloat(op.get(), "timeout_seconds", timeout_seconds);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CollectiveBcastSend
# Inputs:
*    input

# Attributes:
*    group_size
*    group_key
*    instance_key
*    shape
*    communication_hint
*    timeout_seconds

# Outputs:
*    data

*/
inline tensor collective_bcast_send(const tensor& input, int64_t group_size, int64_t group_key, int64_t instance_key, const std::vector<int64_t>& shape, const std::string& communication_hint="auto", float timeout_seconds=0.0000e+00) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CollectiveBcastSend", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "group_size", group_size);
    TFE_OpSetAttrInt(op.get(), "group_key", group_key);
    TFE_OpSetAttrInt(op.get(), "instance_key", instance_key);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), static_cast<int>(shape.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "communication_hint", (void*) communication_hint.c_str(), communication_hint.size());
    TFE_OpSetAttrFloat(op.get(), "timeout_seconds", timeout_seconds);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CollectiveBcastSendV2
# Inputs:
*    input
*    group_size
*    group_key
*    instance_key

# Attributes:
*    communication_hint
*    timeout_seconds

# Outputs:
*    data

*/
inline tensor collective_bcast_send_v2(const tensor& input, const tensor& group_size, const tensor& group_key, const tensor& instance_key, const std::string& communication_hint="auto", float timeout_seconds=0.0000e+00) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CollectiveBcastSendV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), group_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), group_key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), instance_key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "communication_hint", (void*) communication_hint.c_str(), communication_hint.size());
    TFE_OpSetAttrFloat(op.get(), "timeout_seconds", timeout_seconds);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CollectiveGather
# Inputs:
*    input

# Attributes:
*    group_size
*    group_key
*    instance_key
*    shape
*    communication_hint
*    timeout_seconds

# Outputs:
*    data

*/
inline tensor collective_gather(const tensor& input, int64_t group_size, int64_t group_key, int64_t instance_key, const std::vector<int64_t>& shape, const std::string& communication_hint="auto", float timeout_seconds=0.0000e+00) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CollectiveGather", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "group_size", group_size);
    TFE_OpSetAttrInt(op.get(), "group_key", group_key);
    TFE_OpSetAttrInt(op.get(), "instance_key", instance_key);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), static_cast<int>(shape.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "communication_hint", (void*) communication_hint.c_str(), communication_hint.size());
    TFE_OpSetAttrFloat(op.get(), "timeout_seconds", timeout_seconds);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CollectiveGatherV2
# Inputs:
*    input
*    group_size
*    group_key
*    instance_key
*    ordering_token

# Attributes:
*    communication_hint
*    timeout_seconds
*    is_stateless
*    Nordering_token

# Outputs:
*    data

*/
inline tensor collective_gather_v2(const tensor& input, const tensor& group_size, const tensor& group_key, const tensor& instance_key, const std::vector<tensor>&ordering_token, const std::string& communication_hint="auto", float timeout_seconds=0.0000e+00, bool is_stateless=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CollectiveGatherV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), group_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), group_key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), instance_key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> ordering_token_handles; ordering_token_handles.reserve(ordering_token.size());
    std::transform(ordering_token.begin(), ordering_token.end(), std::back_inserter(ordering_token_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), ordering_token_handles.data(), static_cast<int>(ordering_token.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "communication_hint", (void*) communication_hint.c_str(), communication_hint.size());
    TFE_OpSetAttrFloat(op.get(), "timeout_seconds", timeout_seconds);
    TFE_OpSetAttrBool(op.get(), "is_stateless", (unsigned char)is_stateless);
    TFE_OpSetAttrInt(op.get(), "Nordering_token", ordering_token.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CollectiveInitializeCommunicator
# Inputs:
*    group_key
*    rank
*    group_size

# Attributes:
*    communication_hint
*    timeout_seconds

# Outputs:
*    communicator

*/
inline tensor collective_initialize_communicator(const tensor& group_key, const tensor& rank, const tensor& group_size, const std::string& communication_hint="auto", float timeout_seconds=0.0000e+00) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CollectiveInitializeCommunicator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), group_key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rank.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), group_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "communication_hint", (void*) communication_hint.c_str(), communication_hint.size());
    TFE_OpSetAttrFloat(op.get(), "timeout_seconds", timeout_seconds);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CollectivePermute
# Inputs:
*    input
*    source_target_pairs

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor collective_permute(const tensor& input, const tensor& source_target_pairs) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CollectivePermute", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), source_target_pairs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CollectiveReduce
# Inputs:
*    input

# Attributes:
*    group_size
*    group_key
*    instance_key
*    merge_op
*    final_op
*    subdiv_offsets
*    wait_for
*    communication_hint
*    timeout_seconds

# Outputs:
*    data

*/
inline tensor collective_reduce(const tensor& input, int64_t group_size, int64_t group_key, int64_t instance_key, const std::string& merge_op, const std::string& final_op, const std::vector<int64_t>& subdiv_offsets, const std::vector<int64_t>& wait_for, const std::string& communication_hint="auto", float timeout_seconds=0.0000e+00) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CollectiveReduce", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "group_size", group_size);
    TFE_OpSetAttrInt(op.get(), "group_key", group_key);
    TFE_OpSetAttrInt(op.get(), "instance_key", instance_key);
    TFE_OpSetAttrString(op.get(), "merge_op", (void*) merge_op.c_str(), merge_op.size());
    TFE_OpSetAttrString(op.get(), "final_op", (void*) final_op.c_str(), final_op.size());
    TFE_OpSetAttrIntList(op.get(), "subdiv_offsets", subdiv_offsets.data(), static_cast<int>(subdiv_offsets.size()));
    TFE_OpSetAttrIntList(op.get(), "wait_for", wait_for.data(), static_cast<int>(wait_for.size()));
    TFE_OpSetAttrString(op.get(), "communication_hint", (void*) communication_hint.c_str(), communication_hint.size());
    TFE_OpSetAttrFloat(op.get(), "timeout_seconds", timeout_seconds);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CollectiveReduceScatterV2
# Inputs:
*    input
*    group_size
*    group_key
*    instance_key
*    ordering_token

# Attributes:
*    merge_op
*    final_op
*    communication_hint
*    timeout_seconds
*    is_stateless
*    Nordering_token
*    max_subdivs_per_device

# Outputs:
*    data

*/
inline tensor collective_reduce_scatter_v2(const tensor& input, const tensor& group_size, const tensor& group_key, const tensor& instance_key, const std::vector<tensor>&ordering_token, const std::string& merge_op, const std::string& final_op, const std::string& communication_hint="auto", float timeout_seconds=0.0000e+00, bool is_stateless=false, int64_t max_subdivs_per_device=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CollectiveReduceScatterV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), group_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), group_key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), instance_key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> ordering_token_handles; ordering_token_handles.reserve(ordering_token.size());
    std::transform(ordering_token.begin(), ordering_token.end(), std::back_inserter(ordering_token_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), ordering_token_handles.data(), static_cast<int>(ordering_token.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "merge_op", (void*) merge_op.c_str(), merge_op.size());
    TFE_OpSetAttrString(op.get(), "final_op", (void*) final_op.c_str(), final_op.size());
    TFE_OpSetAttrString(op.get(), "communication_hint", (void*) communication_hint.c_str(), communication_hint.size());
    TFE_OpSetAttrFloat(op.get(), "timeout_seconds", timeout_seconds);
    TFE_OpSetAttrBool(op.get(), "is_stateless", (unsigned char)is_stateless);
    TFE_OpSetAttrInt(op.get(), "Nordering_token", ordering_token.size());
    TFE_OpSetAttrInt(op.get(), "max_subdivs_per_device", max_subdivs_per_device);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CollectiveReduceV2
# Inputs:
*    input
*    group_size
*    group_key
*    instance_key
*    ordering_token

# Attributes:
*    merge_op
*    final_op
*    communication_hint
*    timeout_seconds
*    is_stateless
*    Nordering_token
*    max_subdivs_per_device

# Outputs:
*    data

*/
inline tensor collective_reduce_v2(const tensor& input, const tensor& group_size, const tensor& group_key, const tensor& instance_key, const std::vector<tensor>&ordering_token, const std::string& merge_op, const std::string& final_op, const std::string& communication_hint="auto", float timeout_seconds=0.0000e+00, bool is_stateless=false, int64_t max_subdivs_per_device=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CollectiveReduceV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), group_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), group_key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), instance_key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> ordering_token_handles; ordering_token_handles.reserve(ordering_token.size());
    std::transform(ordering_token.begin(), ordering_token.end(), std::back_inserter(ordering_token_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), ordering_token_handles.data(), static_cast<int>(ordering_token.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "merge_op", (void*) merge_op.c_str(), merge_op.size());
    TFE_OpSetAttrString(op.get(), "final_op", (void*) final_op.c_str(), final_op.size());
    TFE_OpSetAttrString(op.get(), "communication_hint", (void*) communication_hint.c_str(), communication_hint.size());
    TFE_OpSetAttrFloat(op.get(), "timeout_seconds", timeout_seconds);
    TFE_OpSetAttrBool(op.get(), "is_stateless", (unsigned char)is_stateless);
    TFE_OpSetAttrInt(op.get(), "Nordering_token", ordering_token.size());
    TFE_OpSetAttrInt(op.get(), "max_subdivs_per_device", max_subdivs_per_device);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CollectiveReduceV3
# Inputs:
*    input
*    communicator
*    group_assignment

# Attributes:
*    reduction
*    timeout_seconds

# Outputs:
*    data

*/
inline tensor collective_reduce_v3(const tensor& input, const tensor& communicator, const tensor& group_assignment, const std::string& reduction, float timeout_seconds=0.0000e+00) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CollectiveReduceV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), communicator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), group_assignment.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "reduction", (void*) reduction.c_str(), reduction.size());
    TFE_OpSetAttrFloat(op.get(), "timeout_seconds", timeout_seconds);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CombinedNonMaxSuppression
# Inputs:
*    boxes
*    scores
*    max_output_size_per_class
*    max_total_size
*    iou_threshold
*    score_threshold

# Attributes:
*    pad_per_class
*    clip_boxes

# Outputs:
*    nmsed_boxes
*    nmsed_scores
*    nmsed_classes
*    valid_detections

*/
inline std::vector<tensor> combined_non_max_suppression(const tensor& boxes, const tensor& scores, const tensor& max_output_size_per_class, const tensor& max_total_size, const tensor& iou_threshold, const tensor& score_threshold, bool pad_per_class=false, bool clip_boxes=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CombinedNonMaxSuppression", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), boxes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scores.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_output_size_per_class.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_total_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), iou_threshold.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), score_threshold.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "pad_per_class", (unsigned char)pad_per_class);
    TFE_OpSetAttrBool(op.get(), "clip_boxes", (unsigned char)clip_boxes);

    // Execute Op
    int num_outputs_op = 4;
    TFE_TensorHandle* res[4] = { nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]), };
}

/* # Complex
# Inputs:
*    real
*    imag

# Attributes:
*    Tout

# Outputs:
*    out

*/
inline tensor complex(const tensor& real, const tensor& imag, datatype Tout=static_cast<datatype>(8)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Complex", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), real.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), imag.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tout", Tout);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ComplexAbs
# Inputs:
*    x

# Attributes:
*    Tout

# Outputs:
*    y

*/
inline tensor complex_abs(const tensor& x, datatype Tout=static_cast<datatype>(1)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ComplexAbs", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tout", Tout);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CompositeTensorVariantFromComponents
# Inputs:
*    components

# Attributes:
*    metadata
*    Tcomponents

# Outputs:
*    encoded

*/
inline tensor composite_tensor_variant_from_components(const std::vector<tensor>&components, const std::string& metadata, const std::vector<datatype>& Tcomponents) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CompositeTensorVariantFromComponents", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> components_handles; components_handles.reserve(components.size());
    std::transform(components.begin(), components.end(), std::back_inserter(components_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), components_handles.data(), static_cast<int>(components.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());
    TFE_OpSetAttrTypeList(op.get(), "Tcomponents", reinterpret_cast<const enum TF_DataType *>(Tcomponents.data()), static_cast<int>(Tcomponents.size()));

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CompositeTensorVariantToComponents
# Inputs:
*    encoded

# Attributes:
*    metadata
*    Tcomponents

# Outputs:
*    components

*/
inline tensor composite_tensor_variant_to_components(const tensor& encoded, const std::string& metadata, const std::vector<datatype>& Tcomponents) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CompositeTensorVariantToComponents", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), encoded.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());
    TFE_OpSetAttrTypeList(op.get(), "Tcomponents", reinterpret_cast<const enum TF_DataType *>(Tcomponents.data()), static_cast<int>(Tcomponents.size()));

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CompressElement
# Inputs:
*    components

# Attributes:
*    input_types

# Outputs:
*    compressed

*/
inline tensor compress_element(const std::vector<tensor>&components, const std::vector<datatype>& input_types) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CompressElement", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> components_handles; components_handles.reserve(components.size());
    std::transform(components.begin(), components.end(), std::back_inserter(components_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), components_handles.data(), static_cast<int>(components.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "input_types", reinterpret_cast<const enum TF_DataType *>(input_types.data()), static_cast<int>(input_types.size()));

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ComputeAccidentalHits
# Inputs:
*    true_classes
*    sampled_candidates

# Attributes:
*    num_true
*    seed
*    seed2

# Outputs:
*    indices
*    ids
*    weights

*/
inline std::vector<tensor> compute_accidental_hits(const tensor& true_classes, const tensor& sampled_candidates, int64_t num_true, int64_t seed=0, int64_t seed2=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ComputeAccidentalHits", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), true_classes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sampled_candidates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_true", num_true);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # ComputeBatchSize
# Inputs:
*    input_dataset

# Attributes:
*    
# Outputs:
*    batch_size

*/
inline tensor compute_batch_size(const tensor& input_dataset) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ComputeBatchSize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Concat
# Inputs:
*    concat_dim
*    values

# Attributes:
*    N

# Outputs:
*    output

*/
inline tensor concat(const tensor& concat_dim, const std::vector<tensor>&values) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Concat", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), concat_dim.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> values_handles; values_handles.reserve(values.size());
    std::transform(values.begin(), values.end(), std::back_inserter(values_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), values_handles.data(), static_cast<int>(values.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", values.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ConcatOffset
# Inputs:
*    concat_dim
*    shape

# Attributes:
*    N
*    shape_type

# Outputs:
*    offset

*/
inline tensor concat_offset(const tensor& concat_dim, const std::vector<tensor>&shape, datatype shape_type=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ConcatOffset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), concat_dim.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> shape_handles; shape_handles.reserve(shape.size());
    std::transform(shape.begin(), shape.end(), std::back_inserter(shape_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), shape_handles.data(), static_cast<int>(shape.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", shape.size());
    TFE_OpSetAttrType(op.get(), "shape_type", shape_type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ConcatV2
# Inputs:
*    values
*    axis

# Attributes:
*    N
*    Tidx

# Outputs:
*    output

*/
inline tensor concat_v2(const std::vector<tensor>&values, const tensor& axis, datatype Tidx=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ConcatV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> values_handles; values_handles.reserve(values.size());
    std::transform(values.begin(), values.end(), std::back_inserter(values_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), values_handles.data(), static_cast<int>(values.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), axis.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", values.size());
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ConcatenateDataset
# Inputs:
*    input_dataset
*    another_dataset

# Attributes:
*    output_types
*    output_shapes
*    metadata

# Outputs:
*    handle

*/
inline tensor concatenate_dataset(const tensor& input_dataset, const tensor& another_dataset, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ConcatenateDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), another_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ConditionalAccumulator
# Inputs:
*    
# Attributes:
*    dtype
*    shape
*    container
*    shared_name
*    reduction_type

# Outputs:
*    handle

*/
inline tensor conditional_accumulator(datatype dtype, const std::vector<int64_t>& shape, const std::string& container="", const std::string& shared_name="", const std::string& reduction_type="MEAN") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ConditionalAccumulator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), static_cast<int>(shape.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrString(op.get(), "reduction_type", (void*) reduction_type.c_str(), reduction_type.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ConfigureDistributedTPU
# Inputs:
*    
# Attributes:
*    embedding_config
*    tpu_embedding_config
*    is_global_init
*    enable_whole_mesh_compilations
*    compilation_failure_closes_chips
*    tpu_cancellation_closes_chips

# Outputs:
*    topology

*/
inline tensor configure_distributed_t_p_u(const std::string& embedding_config="", const std::string& tpu_embedding_config="", bool is_global_init=false, bool enable_whole_mesh_compilations=false, bool compilation_failure_closes_chips=true, int64_t tpu_cancellation_closes_chips=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ConfigureDistributedTPU", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "embedding_config", (void*) embedding_config.c_str(), embedding_config.size());
    TFE_OpSetAttrString(op.get(), "tpu_embedding_config", (void*) tpu_embedding_config.c_str(), tpu_embedding_config.size());
    TFE_OpSetAttrBool(op.get(), "is_global_init", (unsigned char)is_global_init);
    TFE_OpSetAttrBool(op.get(), "enable_whole_mesh_compilations", (unsigned char)enable_whole_mesh_compilations);
    TFE_OpSetAttrBool(op.get(), "compilation_failure_closes_chips", (unsigned char)compilation_failure_closes_chips);
    TFE_OpSetAttrInt(op.get(), "tpu_cancellation_closes_chips", tpu_cancellation_closes_chips);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ConfigureTPUEmbedding
# Inputs:
*    
# Attributes:
*    config

# Outputs:
*    
*/
inline void configure_t_p_u_embedding(const std::string& config) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ConfigureTPUEmbedding", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # Conj
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor conj(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Conj", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ConjugateTranspose
# Inputs:
*    x
*    perm

# Attributes:
*    Tperm

# Outputs:
*    y

*/
inline tensor conjugate_transpose(const tensor& x, const tensor& perm, datatype Tperm=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ConjugateTranspose", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), perm.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tperm", Tperm);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Const
# Inputs:
*    
# Attributes:
*    value
*    dtype

# Outputs:
*    output

*/
inline tensor const_tensor(const tensor& value, datatype dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Const", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    
    TFE_OpSetAttrTensor(op.get(), "value", value.get_tensor().get(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ConsumeMutexLock
# Inputs:
*    mutex_lock

# Attributes:
*    
# Outputs:
*    
*/
inline void consume_mutex_lock(const tensor& mutex_lock) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ConsumeMutexLock", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), mutex_lock.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ControlTrigger
# Inputs:
*    
# Attributes:
*    
# Outputs:
*    
*/
inline void control_trigger() {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ControlTrigger", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # Conv
# Inputs:
*    input
*    filter

# Attributes:
*    strides
*    padding
*    explicit_paddings
*    dilations
*    data_format
*    batch_dims
*    groups

# Outputs:
*    output

*/
inline tensor conv(const tensor& input, const tensor& filter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& explicit_paddings, const std::vector<int64_t>& dilations, const std::string& data_format="CHANNELS_LAST", int64_t batch_dims=1, int64_t groups=1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Conv", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "explicit_paddings", explicit_paddings.data(), static_cast<int>(explicit_paddings.size()));
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());
    TFE_OpSetAttrInt(op.get(), "batch_dims", batch_dims);
    TFE_OpSetAttrInt(op.get(), "groups", groups);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Conv2D
# Inputs:
*    input
*    filter

# Attributes:
*    strides
*    padding
*    explicit_paddings
*    dilations
*    use_cudnn_on_gpu
*    data_format

# Outputs:
*    output

*/
inline tensor conv2_d(const tensor& input, const tensor& filter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& explicit_paddings, const std::vector<int64_t>& dilations, bool use_cudnn_on_gpu=true, const std::string& data_format="NHWC") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Conv2D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "explicit_paddings", explicit_paddings.data(), static_cast<int>(explicit_paddings.size()));
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrBool(op.get(), "use_cudnn_on_gpu", (unsigned char)use_cudnn_on_gpu);
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Conv2DBackpropFilter
# Inputs:
*    input
*    filter_sizes
*    out_backprop

# Attributes:
*    strides
*    padding
*    explicit_paddings
*    dilations
*    use_cudnn_on_gpu
*    data_format

# Outputs:
*    output

*/
inline tensor conv2_d_backprop_filter(const tensor& input, const tensor& filter_sizes, const tensor& out_backprop, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& explicit_paddings, const std::vector<int64_t>& dilations, bool use_cudnn_on_gpu=true, const std::string& data_format="NHWC") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Conv2DBackpropFilter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter_sizes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), out_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "explicit_paddings", explicit_paddings.data(), static_cast<int>(explicit_paddings.size()));
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrBool(op.get(), "use_cudnn_on_gpu", (unsigned char)use_cudnn_on_gpu);
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Conv2DBackpropFilterV2
# Inputs:
*    input
*    filter
*    out_backprop

# Attributes:
*    strides
*    padding
*    explicit_paddings
*    dilations
*    use_cudnn_on_gpu
*    data_format

# Outputs:
*    output

*/
inline tensor conv2_d_backprop_filter_v2(const tensor& input, const tensor& filter, const tensor& out_backprop, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& explicit_paddings, const std::vector<int64_t>& dilations, bool use_cudnn_on_gpu=true, const std::string& data_format="NHWC") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Conv2DBackpropFilterV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), out_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "explicit_paddings", explicit_paddings.data(), static_cast<int>(explicit_paddings.size()));
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrBool(op.get(), "use_cudnn_on_gpu", (unsigned char)use_cudnn_on_gpu);
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Conv2DBackpropInput
# Inputs:
*    input_sizes
*    filter
*    out_backprop

# Attributes:
*    strides
*    padding
*    explicit_paddings
*    dilations
*    use_cudnn_on_gpu
*    data_format

# Outputs:
*    output

*/
inline tensor conv2_d_backprop_input(const tensor& input_sizes, const tensor& filter, const tensor& out_backprop, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& explicit_paddings, const std::vector<int64_t>& dilations, bool use_cudnn_on_gpu=true, const std::string& data_format="NHWC") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Conv2DBackpropInput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_sizes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), out_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "explicit_paddings", explicit_paddings.data(), static_cast<int>(explicit_paddings.size()));
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrBool(op.get(), "use_cudnn_on_gpu", (unsigned char)use_cudnn_on_gpu);
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Conv2DBackpropInputV2
# Inputs:
*    input
*    filter
*    out_backprop

# Attributes:
*    strides
*    padding
*    explicit_paddings
*    dilations
*    use_cudnn_on_gpu
*    data_format

# Outputs:
*    output

*/
inline tensor conv2_d_backprop_input_v2(const tensor& input, const tensor& filter, const tensor& out_backprop, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& explicit_paddings, const std::vector<int64_t>& dilations, bool use_cudnn_on_gpu=true, const std::string& data_format="NHWC") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Conv2DBackpropInputV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), out_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "explicit_paddings", explicit_paddings.data(), static_cast<int>(explicit_paddings.size()));
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrBool(op.get(), "use_cudnn_on_gpu", (unsigned char)use_cudnn_on_gpu);
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Conv3D
# Inputs:
*    input
*    filter

# Attributes:
*    strides
*    padding
*    dilations
*    data_format

# Outputs:
*    output

*/
inline tensor conv3_d(const tensor& input, const tensor& filter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::string& data_format="NDHWC") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Conv3D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Conv3DBackpropFilter
# Inputs:
*    input
*    filter
*    out_backprop

# Attributes:
*    strides
*    padding
*    dilations

# Outputs:
*    output

*/
inline tensor conv3_d_backprop_filter(const tensor& input, const tensor& filter, const tensor& out_backprop, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Conv3DBackpropFilter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), out_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Conv3DBackpropFilterV2
# Inputs:
*    input
*    filter_sizes
*    out_backprop

# Attributes:
*    strides
*    padding
*    dilations
*    data_format

# Outputs:
*    output

*/
inline tensor conv3_d_backprop_filter_v2(const tensor& input, const tensor& filter_sizes, const tensor& out_backprop, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::string& data_format="NDHWC") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Conv3DBackpropFilterV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter_sizes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), out_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Conv3DBackpropInput
# Inputs:
*    input
*    filter
*    out_backprop

# Attributes:
*    strides
*    padding
*    dilations

# Outputs:
*    output

*/
inline tensor conv3_d_backprop_input(const tensor& input, const tensor& filter, const tensor& out_backprop, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Conv3DBackpropInput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), out_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Conv3DBackpropInputV2
# Inputs:
*    input_sizes
*    filter
*    out_backprop

# Attributes:
*    strides
*    padding
*    dilations
*    data_format
*    Tshape

# Outputs:
*    output

*/
inline tensor conv3_d_backprop_input_v2(const tensor& input_sizes, const tensor& filter, const tensor& out_backprop, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::string& data_format="NDHWC", datatype Tshape=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Conv3DBackpropInputV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_sizes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), out_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());
    TFE_OpSetAttrType(op.get(), "Tshape", Tshape);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ConvertToCooTensor
# Inputs:
*    indices_or_row_splits
*    values
*    weights

# Attributes:
*    sample_count
*    combiner

# Outputs:
*    row_ids
*    col_ids
*    gains

*/
inline std::vector<tensor> convert_to_coo_tensor(const tensor& indices_or_row_splits, const tensor& values, const tensor& weights, int64_t sample_count, const std::string& combiner) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ConvertToCooTensor", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), indices_or_row_splits.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), weights.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "sample_count", sample_count);
    TFE_OpSetAttrString(op.get(), "combiner", (void*) combiner.c_str(), combiner.size());

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # Copy
# Inputs:
*    input

# Attributes:
*    debug_ops_spec
*    tensor_name

# Outputs:
*    output

*/
inline tensor copy(const tensor& input, const std::vector< std::string>& debug_ops_spec, const std::string& tensor_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Copy", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> debug_ops_spec_sizes; debug_ops_spec_sizes.reserve(debug_ops_spec.size());
    std::transform(debug_ops_spec.begin(), debug_ops_spec.end(), std::back_inserter(debug_ops_spec_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "debug_ops_spec", reinterpret_cast<const void *const *>(debug_ops_spec.data()), debug_ops_spec_sizes.data(), static_cast<int>(debug_ops_spec.size()));
    
    TFE_OpSetAttrString(op.get(), "tensor_name", (void*) tensor_name.c_str(), tensor_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CopyHost
# Inputs:
*    input

# Attributes:
*    debug_ops_spec
*    tensor_name

# Outputs:
*    output

*/
inline tensor copy_host(const tensor& input, const std::vector< std::string>& debug_ops_spec, const std::string& tensor_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CopyHost", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> debug_ops_spec_sizes; debug_ops_spec_sizes.reserve(debug_ops_spec.size());
    std::transform(debug_ops_spec.begin(), debug_ops_spec.end(), std::back_inserter(debug_ops_spec_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "debug_ops_spec", reinterpret_cast<const void *const *>(debug_ops_spec.data()), debug_ops_spec_sizes.data(), static_cast<int>(debug_ops_spec.size()));
    
    TFE_OpSetAttrString(op.get(), "tensor_name", (void*) tensor_name.c_str(), tensor_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Cos
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor cos(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Cos", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Cosh
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor cosh(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Cosh", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CountUpTo
# Inputs:
*    ref

# Attributes:
*    limit

# Outputs:
*    output

*/
inline tensor count_up_to(const tensor& ref, int64_t limit) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CountUpTo", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "limit", limit);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CreateSummaryDbWriter
# Inputs:
*    writer
*    db_uri
*    experiment_name
*    run_name
*    user_name

# Attributes:
*    
# Outputs:
*    
*/
inline void create_summary_db_writer(const tensor& writer, const tensor& db_uri, const tensor& experiment_name, const tensor& run_name, const tensor& user_name) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CreateSummaryDbWriter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), writer.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), db_uri.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), experiment_name.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), run_name.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), user_name.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # CreateSummaryFileWriter
# Inputs:
*    writer
*    logdir
*    max_queue
*    flush_millis
*    filename_suffix

# Attributes:
*    
# Outputs:
*    
*/
inline void create_summary_file_writer(const tensor& writer, const tensor& logdir, const tensor& max_queue, const tensor& flush_millis, const tensor& filename_suffix) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CreateSummaryFileWriter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), writer.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), logdir.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_queue.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flush_millis.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filename_suffix.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # CropAndResize
# Inputs:
*    image
*    boxes
*    box_ind
*    crop_size

# Attributes:
*    method
*    extrapolation_value

# Outputs:
*    crops

*/
inline tensor crop_and_resize(const tensor& image, const tensor& boxes, const tensor& box_ind, const tensor& crop_size, const std::string& method="bilinear", float extrapolation_value=0.0000e+00) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CropAndResize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), image.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), boxes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), box_ind.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), crop_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "method", (void*) method.c_str(), method.size());
    TFE_OpSetAttrFloat(op.get(), "extrapolation_value", extrapolation_value);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CropAndResizeGradBoxes
# Inputs:
*    grads
*    image
*    boxes
*    box_ind

# Attributes:
*    method

# Outputs:
*    output

*/
inline tensor crop_and_resize_grad_boxes(const tensor& grads, const tensor& image, const tensor& boxes, const tensor& box_ind, const std::string& method="bilinear") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CropAndResizeGradBoxes", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), grads.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), image.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), boxes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), box_ind.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "method", (void*) method.c_str(), method.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CropAndResizeGradImage
# Inputs:
*    grads
*    boxes
*    box_ind
*    image_size

# Attributes:
*    method

# Outputs:
*    output

*/
inline tensor crop_and_resize_grad_image(const tensor& grads, const tensor& boxes, const tensor& box_ind, const tensor& image_size, const std::string& method="bilinear") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CropAndResizeGradImage", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), grads.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), boxes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), box_ind.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), image_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "method", (void*) method.c_str(), method.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Cross
# Inputs:
*    a
*    b

# Attributes:
*    
# Outputs:
*    product

*/
inline tensor cross(const tensor& a, const tensor& b) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Cross", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CrossReplicaSum
# Inputs:
*    input
*    group_assignment

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor cross_replica_sum(const tensor& input, const tensor& group_assignment) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CrossReplicaSum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), group_assignment.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CudnnRNN
# Inputs:
*    input
*    input_h
*    input_c
*    params

# Attributes:
*    rnn_mode
*    input_mode
*    direction
*    dropout
*    seed
*    seed2
*    is_training

# Outputs:
*    output
*    output_h
*    output_c
*    reserve_space

*/
inline std::vector<tensor> cudnn_r_n_n(const tensor& input, const tensor& input_h, const tensor& input_c, const tensor& params, const std::string& rnn_mode="lstm", const std::string& input_mode="linear_input", const std::string& direction="unidirectional", float dropout=0.0000e+00, int64_t seed=0, int64_t seed2=0, bool is_training=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CudnnRNN", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_h.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_c.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), params.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "rnn_mode", (void*) rnn_mode.c_str(), rnn_mode.size());
    TFE_OpSetAttrString(op.get(), "input_mode", (void*) input_mode.c_str(), input_mode.size());
    TFE_OpSetAttrString(op.get(), "direction", (void*) direction.c_str(), direction.size());
    TFE_OpSetAttrFloat(op.get(), "dropout", dropout);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrBool(op.get(), "is_training", (unsigned char)is_training);

    // Execute Op
    int num_outputs_op = 4;
    TFE_TensorHandle* res[4] = { nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]), };
}

/* # CudnnRNNBackprop
# Inputs:
*    input
*    input_h
*    input_c
*    params
*    output
*    output_h
*    output_c
*    output_backprop
*    output_h_backprop
*    output_c_backprop
*    reserve_space

# Attributes:
*    rnn_mode
*    input_mode
*    direction
*    dropout
*    seed
*    seed2

# Outputs:
*    input_backprop
*    input_h_backprop
*    input_c_backprop
*    params_backprop

*/
inline std::vector<tensor> cudnn_r_n_n_backprop(const tensor& input, const tensor& input_h, const tensor& input_c, const tensor& params, const tensor& output, const tensor& output_h, const tensor& output_c, const tensor& output_backprop, const tensor& output_h_backprop, const tensor& output_c_backprop, const tensor& reserve_space, const std::string& rnn_mode="lstm", const std::string& input_mode="linear_input", const std::string& direction="unidirectional", float dropout=0.0000e+00, int64_t seed=0, int64_t seed2=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CudnnRNNBackprop", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_h.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_c.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), params.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_h.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_c.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_h_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_c_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reserve_space.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "rnn_mode", (void*) rnn_mode.c_str(), rnn_mode.size());
    TFE_OpSetAttrString(op.get(), "input_mode", (void*) input_mode.c_str(), input_mode.size());
    TFE_OpSetAttrString(op.get(), "direction", (void*) direction.c_str(), direction.size());
    TFE_OpSetAttrFloat(op.get(), "dropout", dropout);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    int num_outputs_op = 4;
    TFE_TensorHandle* res[4] = { nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]), };
}

/* # CudnnRNNBackpropV2
# Inputs:
*    input
*    input_h
*    input_c
*    params
*    output
*    output_h
*    output_c
*    output_backprop
*    output_h_backprop
*    output_c_backprop
*    reserve_space
*    host_reserved

# Attributes:
*    rnn_mode
*    input_mode
*    direction
*    dropout
*    seed
*    seed2

# Outputs:
*    input_backprop
*    input_h_backprop
*    input_c_backprop
*    params_backprop

*/
inline std::vector<tensor> cudnn_r_n_n_backprop_v2(const tensor& input, const tensor& input_h, const tensor& input_c, const tensor& params, const tensor& output, const tensor& output_h, const tensor& output_c, const tensor& output_backprop, const tensor& output_h_backprop, const tensor& output_c_backprop, const tensor& reserve_space, const tensor& host_reserved, const std::string& rnn_mode="lstm", const std::string& input_mode="linear_input", const std::string& direction="unidirectional", float dropout=0.0000e+00, int64_t seed=0, int64_t seed2=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CudnnRNNBackpropV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_h.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_c.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), params.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_h.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_c.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_h_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_c_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reserve_space.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), host_reserved.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "rnn_mode", (void*) rnn_mode.c_str(), rnn_mode.size());
    TFE_OpSetAttrString(op.get(), "input_mode", (void*) input_mode.c_str(), input_mode.size());
    TFE_OpSetAttrString(op.get(), "direction", (void*) direction.c_str(), direction.size());
    TFE_OpSetAttrFloat(op.get(), "dropout", dropout);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    int num_outputs_op = 4;
    TFE_TensorHandle* res[4] = { nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]), };
}

/* # CudnnRNNBackpropV3
# Inputs:
*    input
*    input_h
*    input_c
*    params
*    sequence_lengths
*    output
*    output_h
*    output_c
*    output_backprop
*    output_h_backprop
*    output_c_backprop
*    reserve_space
*    host_reserved

# Attributes:
*    rnn_mode
*    input_mode
*    direction
*    dropout
*    seed
*    seed2
*    num_proj
*    time_major

# Outputs:
*    input_backprop
*    input_h_backprop
*    input_c_backprop
*    params_backprop

*/
inline std::vector<tensor> cudnn_r_n_n_backprop_v3(const tensor& input, const tensor& input_h, const tensor& input_c, const tensor& params, const tensor& sequence_lengths, const tensor& output, const tensor& output_h, const tensor& output_c, const tensor& output_backprop, const tensor& output_h_backprop, const tensor& output_c_backprop, const tensor& reserve_space, const tensor& host_reserved, const std::string& rnn_mode="lstm", const std::string& input_mode="linear_input", const std::string& direction="unidirectional", float dropout=0.0000e+00, int64_t seed=0, int64_t seed2=0, int64_t num_proj=0, bool time_major=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CudnnRNNBackpropV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_h.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_c.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), params.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sequence_lengths.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_h.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_c.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_h_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_c_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reserve_space.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), host_reserved.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "rnn_mode", (void*) rnn_mode.c_str(), rnn_mode.size());
    TFE_OpSetAttrString(op.get(), "input_mode", (void*) input_mode.c_str(), input_mode.size());
    TFE_OpSetAttrString(op.get(), "direction", (void*) direction.c_str(), direction.size());
    TFE_OpSetAttrFloat(op.get(), "dropout", dropout);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrInt(op.get(), "num_proj", num_proj);
    TFE_OpSetAttrBool(op.get(), "time_major", (unsigned char)time_major);

    // Execute Op
    int num_outputs_op = 4;
    TFE_TensorHandle* res[4] = { nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]), };
}

/* # CudnnRNNCanonicalToParams
# Inputs:
*    num_layers
*    num_units
*    input_size
*    weights
*    biases

# Attributes:
*    num_params
*    rnn_mode
*    input_mode
*    direction
*    dropout
*    seed
*    seed2

# Outputs:
*    params

*/
inline tensor cudnn_r_n_n_canonical_to_params(const tensor& num_layers, const tensor& num_units, const tensor& input_size, const std::vector<tensor>&weights, const std::vector<tensor>&biases, const std::string& rnn_mode="lstm", const std::string& input_mode="linear_input", const std::string& direction="unidirectional", float dropout=0.0000e+00, int64_t seed=0, int64_t seed2=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CudnnRNNCanonicalToParams", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), num_layers.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_units.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> weights_handles; weights_handles.reserve(weights.size());
    std::transform(weights.begin(), weights.end(), std::back_inserter(weights_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), weights_handles.data(), static_cast<int>(weights.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> biases_handles; biases_handles.reserve(biases.size());
    std::transform(biases.begin(), biases.end(), std::back_inserter(biases_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), biases_handles.data(), static_cast<int>(biases.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_params", weights.size());
    TFE_OpSetAttrString(op.get(), "rnn_mode", (void*) rnn_mode.c_str(), rnn_mode.size());
    TFE_OpSetAttrString(op.get(), "input_mode", (void*) input_mode.c_str(), input_mode.size());
    TFE_OpSetAttrString(op.get(), "direction", (void*) direction.c_str(), direction.size());
    TFE_OpSetAttrFloat(op.get(), "dropout", dropout);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CudnnRNNCanonicalToParamsV2
# Inputs:
*    num_layers
*    num_units
*    input_size
*    weights
*    biases

# Attributes:
*    num_params_weights
*    num_params_biases
*    rnn_mode
*    input_mode
*    direction
*    dropout
*    seed
*    seed2
*    num_proj

# Outputs:
*    params

*/
inline tensor cudnn_r_n_n_canonical_to_params_v2(const tensor& num_layers, const tensor& num_units, const tensor& input_size, const std::vector<tensor>&weights, const std::vector<tensor>&biases, const std::string& rnn_mode="lstm", const std::string& input_mode="linear_input", const std::string& direction="unidirectional", float dropout=0.0000e+00, int64_t seed=0, int64_t seed2=0, int64_t num_proj=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CudnnRNNCanonicalToParamsV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), num_layers.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_units.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> weights_handles; weights_handles.reserve(weights.size());
    std::transform(weights.begin(), weights.end(), std::back_inserter(weights_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), weights_handles.data(), static_cast<int>(weights.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> biases_handles; biases_handles.reserve(biases.size());
    std::transform(biases.begin(), biases.end(), std::back_inserter(biases_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), biases_handles.data(), static_cast<int>(biases.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_params_weights", weights.size());
    TFE_OpSetAttrInt(op.get(), "num_params_biases", biases.size());
    TFE_OpSetAttrString(op.get(), "rnn_mode", (void*) rnn_mode.c_str(), rnn_mode.size());
    TFE_OpSetAttrString(op.get(), "input_mode", (void*) input_mode.c_str(), input_mode.size());
    TFE_OpSetAttrString(op.get(), "direction", (void*) direction.c_str(), direction.size());
    TFE_OpSetAttrFloat(op.get(), "dropout", dropout);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrInt(op.get(), "num_proj", num_proj);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CudnnRNNParamsSize
# Inputs:
*    num_layers
*    num_units
*    input_size

# Attributes:
*    S
*    rnn_mode
*    input_mode
*    direction
*    dropout
*    seed
*    seed2
*    num_proj

# Outputs:
*    params_size

*/
inline tensor cudnn_r_n_n_params_size(const tensor& num_layers, const tensor& num_units, const tensor& input_size, datatype S, const std::string& rnn_mode="lstm", const std::string& input_mode="linear_input", const std::string& direction="unidirectional", float dropout=0.0000e+00, int64_t seed=0, int64_t seed2=0, int64_t num_proj=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CudnnRNNParamsSize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), num_layers.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_units.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "S", S);
    TFE_OpSetAttrString(op.get(), "rnn_mode", (void*) rnn_mode.c_str(), rnn_mode.size());
    TFE_OpSetAttrString(op.get(), "input_mode", (void*) input_mode.c_str(), input_mode.size());
    TFE_OpSetAttrString(op.get(), "direction", (void*) direction.c_str(), direction.size());
    TFE_OpSetAttrFloat(op.get(), "dropout", dropout);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrInt(op.get(), "num_proj", num_proj);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CudnnRNNParamsToCanonical
# Inputs:
*    num_layers
*    num_units
*    input_size
*    params

# Attributes:
*    num_params
*    rnn_mode
*    input_mode
*    direction
*    dropout
*    seed
*    seed2

# Outputs:
*    weights
*    biases

*/
inline std::vector<tensor> cudnn_r_n_n_params_to_canonical(const tensor& num_layers, const tensor& num_units, const tensor& input_size, const tensor& params, int64_t num_params, const std::string& rnn_mode="lstm", const std::string& input_mode="linear_input", const std::string& direction="unidirectional", float dropout=0.0000e+00, int64_t seed=0, int64_t seed2=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CudnnRNNParamsToCanonical", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), num_layers.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_units.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), params.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_params", num_params);
    TFE_OpSetAttrString(op.get(), "rnn_mode", (void*) rnn_mode.c_str(), rnn_mode.size());
    TFE_OpSetAttrString(op.get(), "input_mode", (void*) input_mode.c_str(), input_mode.size());
    TFE_OpSetAttrString(op.get(), "direction", (void*) direction.c_str(), direction.size());
    TFE_OpSetAttrFloat(op.get(), "dropout", dropout);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # CudnnRNNParamsToCanonicalV2
# Inputs:
*    num_layers
*    num_units
*    input_size
*    params

# Attributes:
*    num_params_weights
*    num_params_biases
*    rnn_mode
*    input_mode
*    direction
*    dropout
*    seed
*    seed2
*    num_proj

# Outputs:
*    weights
*    biases

*/
inline std::vector<tensor> cudnn_r_n_n_params_to_canonical_v2(const tensor& num_layers, const tensor& num_units, const tensor& input_size, const tensor& params, int64_t num_params_weights, int64_t num_params_biases, const std::string& rnn_mode="lstm", const std::string& input_mode="linear_input", const std::string& direction="unidirectional", float dropout=0.0000e+00, int64_t seed=0, int64_t seed2=0, int64_t num_proj=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CudnnRNNParamsToCanonicalV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), num_layers.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_units.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), params.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_params_weights", num_params_weights);
    TFE_OpSetAttrInt(op.get(), "num_params_biases", num_params_biases);
    TFE_OpSetAttrString(op.get(), "rnn_mode", (void*) rnn_mode.c_str(), rnn_mode.size());
    TFE_OpSetAttrString(op.get(), "input_mode", (void*) input_mode.c_str(), input_mode.size());
    TFE_OpSetAttrString(op.get(), "direction", (void*) direction.c_str(), direction.size());
    TFE_OpSetAttrFloat(op.get(), "dropout", dropout);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrInt(op.get(), "num_proj", num_proj);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # CudnnRNNV2
# Inputs:
*    input
*    input_h
*    input_c
*    params

# Attributes:
*    rnn_mode
*    input_mode
*    direction
*    dropout
*    seed
*    seed2
*    is_training

# Outputs:
*    output
*    output_h
*    output_c
*    reserve_space
*    host_reserved

*/
inline std::vector<tensor> cudnn_r_n_n_v2(const tensor& input, const tensor& input_h, const tensor& input_c, const tensor& params, const std::string& rnn_mode="lstm", const std::string& input_mode="linear_input", const std::string& direction="unidirectional", float dropout=0.0000e+00, int64_t seed=0, int64_t seed2=0, bool is_training=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CudnnRNNV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_h.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_c.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), params.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "rnn_mode", (void*) rnn_mode.c_str(), rnn_mode.size());
    TFE_OpSetAttrString(op.get(), "input_mode", (void*) input_mode.c_str(), input_mode.size());
    TFE_OpSetAttrString(op.get(), "direction", (void*) direction.c_str(), direction.size());
    TFE_OpSetAttrFloat(op.get(), "dropout", dropout);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrBool(op.get(), "is_training", (unsigned char)is_training);

    // Execute Op
    int num_outputs_op = 5;
    TFE_TensorHandle* res[5] = { nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]), };
}

/* # CudnnRNNV3
# Inputs:
*    input
*    input_h
*    input_c
*    params
*    sequence_lengths

# Attributes:
*    rnn_mode
*    input_mode
*    direction
*    dropout
*    seed
*    seed2
*    num_proj
*    is_training
*    time_major

# Outputs:
*    output
*    output_h
*    output_c
*    reserve_space
*    host_reserved

*/
inline std::vector<tensor> cudnn_r_n_n_v3(const tensor& input, const tensor& input_h, const tensor& input_c, const tensor& params, const tensor& sequence_lengths, const std::string& rnn_mode="lstm", const std::string& input_mode="linear_input", const std::string& direction="unidirectional", float dropout=0.0000e+00, int64_t seed=0, int64_t seed2=0, int64_t num_proj=0, bool is_training=true, bool time_major=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CudnnRNNV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_h.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_c.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), params.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sequence_lengths.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "rnn_mode", (void*) rnn_mode.c_str(), rnn_mode.size());
    TFE_OpSetAttrString(op.get(), "input_mode", (void*) input_mode.c_str(), input_mode.size());
    TFE_OpSetAttrString(op.get(), "direction", (void*) direction.c_str(), direction.size());
    TFE_OpSetAttrFloat(op.get(), "dropout", dropout);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrInt(op.get(), "num_proj", num_proj);
    TFE_OpSetAttrBool(op.get(), "is_training", (unsigned char)is_training);
    TFE_OpSetAttrBool(op.get(), "time_major", (unsigned char)time_major);

    // Execute Op
    int num_outputs_op = 5;
    TFE_TensorHandle* res[5] = { nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]), };
}

/* # Cumprod
# Inputs:
*    x
*    axis

# Attributes:
*    exclusive
*    reverse
*    Tidx

# Outputs:
*    out

*/
inline tensor cumprod(const tensor& x, const tensor& axis, bool exclusive=false, bool reverse=false, datatype Tidx=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Cumprod", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), axis.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "exclusive", (unsigned char)exclusive);
    TFE_OpSetAttrBool(op.get(), "reverse", (unsigned char)reverse);
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Cumsum
# Inputs:
*    x
*    axis

# Attributes:
*    exclusive
*    reverse
*    Tidx

# Outputs:
*    out

*/
inline tensor cumsum(const tensor& x, const tensor& axis, bool exclusive=false, bool reverse=false, datatype Tidx=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Cumsum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), axis.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "exclusive", (unsigned char)exclusive);
    TFE_OpSetAttrBool(op.get(), "reverse", (unsigned char)reverse);
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # CumulativeLogsumexp
# Inputs:
*    x
*    axis

# Attributes:
*    exclusive
*    reverse
*    Tidx

# Outputs:
*    out

*/
inline tensor cumulative_logsumexp(const tensor& x, const tensor& axis, bool exclusive=false, bool reverse=false, datatype Tidx=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CumulativeLogsumexp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), axis.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "exclusive", (unsigned char)exclusive);
    TFE_OpSetAttrBool(op.get(), "reverse", (unsigned char)reverse);
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DataFormatDimMap
# Inputs:
*    x

# Attributes:
*    src_format
*    dst_format

# Outputs:
*    y

*/
inline tensor data_format_dim_map(const tensor& x, const std::string& src_format="NHWC", const std::string& dst_format="NCHW") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DataFormatDimMap", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "src_format", (void*) src_format.c_str(), src_format.size());
    TFE_OpSetAttrString(op.get(), "dst_format", (void*) dst_format.c_str(), dst_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DataFormatVecPermute
# Inputs:
*    x

# Attributes:
*    src_format
*    dst_format

# Outputs:
*    y

*/
inline tensor data_format_vec_permute(const tensor& x, const std::string& src_format="NHWC", const std::string& dst_format="NCHW") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DataFormatVecPermute", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "src_format", (void*) src_format.c_str(), src_format.size());
    TFE_OpSetAttrString(op.get(), "dst_format", (void*) dst_format.c_str(), dst_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DataServiceDataset
# Inputs:
*    dataset_id
*    processing_mode
*    address
*    protocol
*    job_name
*    max_outstanding_requests
*    iteration_counter

# Attributes:
*    output_types
*    output_shapes
*    task_refresh_interval_hint_ms
*    data_transfer_protocol
*    target_workers
*    cross_trainer_cache_options

# Outputs:
*    handle

*/
inline tensor data_service_dataset(const tensor& dataset_id, const tensor& processing_mode, const tensor& address, const tensor& protocol, const tensor& job_name, const tensor& max_outstanding_requests, const tensor& iteration_counter, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, int64_t task_refresh_interval_hint_ms=-1, const std::string& data_transfer_protocol="", const std::string& target_workers="AUTO", const std::string& cross_trainer_cache_options="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DataServiceDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), dataset_id.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), processing_mode.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), address.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), protocol.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), job_name.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_outstanding_requests.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), iteration_counter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "task_refresh_interval_hint_ms", task_refresh_interval_hint_ms);
    TFE_OpSetAttrString(op.get(), "data_transfer_protocol", (void*) data_transfer_protocol.c_str(), data_transfer_protocol.size());
    TFE_OpSetAttrString(op.get(), "target_workers", (void*) target_workers.c_str(), target_workers.size());
    TFE_OpSetAttrString(op.get(), "cross_trainer_cache_options", (void*) cross_trainer_cache_options.c_str(), cross_trainer_cache_options.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DataServiceDatasetV2
# Inputs:
*    dataset_id
*    processing_mode
*    address
*    protocol
*    job_name
*    consumer_index
*    num_consumers
*    max_outstanding_requests
*    iteration_counter

# Attributes:
*    output_types
*    output_shapes
*    task_refresh_interval_hint_ms
*    data_transfer_protocol
*    target_workers
*    cross_trainer_cache_options

# Outputs:
*    handle

*/
inline tensor data_service_dataset_v2(const tensor& dataset_id, const tensor& processing_mode, const tensor& address, const tensor& protocol, const tensor& job_name, const tensor& consumer_index, const tensor& num_consumers, const tensor& max_outstanding_requests, const tensor& iteration_counter, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, int64_t task_refresh_interval_hint_ms=-1, const std::string& data_transfer_protocol="", const std::string& target_workers="AUTO", const std::string& cross_trainer_cache_options="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DataServiceDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), dataset_id.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), processing_mode.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), address.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), protocol.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), job_name.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), consumer_index.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_consumers.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_outstanding_requests.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), iteration_counter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "task_refresh_interval_hint_ms", task_refresh_interval_hint_ms);
    TFE_OpSetAttrString(op.get(), "data_transfer_protocol", (void*) data_transfer_protocol.c_str(), data_transfer_protocol.size());
    TFE_OpSetAttrString(op.get(), "target_workers", (void*) target_workers.c_str(), target_workers.size());
    TFE_OpSetAttrString(op.get(), "cross_trainer_cache_options", (void*) cross_trainer_cache_options.c_str(), cross_trainer_cache_options.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DataServiceDatasetV3
# Inputs:
*    dataset_id
*    processing_mode
*    address
*    protocol
*    job_name
*    consumer_index
*    num_consumers
*    max_outstanding_requests
*    iteration_counter

# Attributes:
*    output_types
*    output_shapes
*    uncompress_fn
*    task_refresh_interval_hint_ms
*    data_transfer_protocol
*    target_workers
*    uncompress
*    cross_trainer_cache_options

# Outputs:
*    handle

*/
inline tensor data_service_dataset_v3(const tensor& dataset_id, const tensor& processing_mode, const tensor& address, const tensor& protocol, const tensor& job_name, const tensor& consumer_index, const tensor& num_consumers, const tensor& max_outstanding_requests, const tensor& iteration_counter, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, int64_t uncompress_fn, int64_t task_refresh_interval_hint_ms=-1, const std::string& data_transfer_protocol="", const std::string& target_workers="AUTO", bool uncompress=false, const std::string& cross_trainer_cache_options="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DataServiceDatasetV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), dataset_id.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), processing_mode.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), address.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), protocol.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), job_name.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), consumer_index.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_consumers.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_outstanding_requests.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), iteration_counter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "uncompress_fn", uncompress_fn);
    TFE_OpSetAttrInt(op.get(), "task_refresh_interval_hint_ms", task_refresh_interval_hint_ms);
    TFE_OpSetAttrString(op.get(), "data_transfer_protocol", (void*) data_transfer_protocol.c_str(), data_transfer_protocol.size());
    TFE_OpSetAttrString(op.get(), "target_workers", (void*) target_workers.c_str(), target_workers.size());
    TFE_OpSetAttrBool(op.get(), "uncompress", (unsigned char)uncompress);
    TFE_OpSetAttrString(op.get(), "cross_trainer_cache_options", (void*) cross_trainer_cache_options.c_str(), cross_trainer_cache_options.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DataServiceDatasetV4
# Inputs:
*    dataset_id
*    processing_mode
*    address
*    protocol
*    job_name
*    consumer_index
*    num_consumers
*    max_outstanding_requests
*    iteration_counter

# Attributes:
*    output_types
*    output_shapes
*    uncompress_fn
*    task_refresh_interval_hint_ms
*    data_transfer_protocol
*    target_workers
*    uncompress
*    cross_trainer_cache_options

# Outputs:
*    handle

*/
inline tensor data_service_dataset_v4(const tensor& dataset_id, const tensor& processing_mode, const tensor& address, const tensor& protocol, const tensor& job_name, const tensor& consumer_index, const tensor& num_consumers, const tensor& max_outstanding_requests, const tensor& iteration_counter, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, int64_t uncompress_fn, int64_t task_refresh_interval_hint_ms=-1, const std::string& data_transfer_protocol="", const std::string& target_workers="AUTO", bool uncompress=false, const std::string& cross_trainer_cache_options="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DataServiceDatasetV4", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), dataset_id.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), processing_mode.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), address.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), protocol.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), job_name.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), consumer_index.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_consumers.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_outstanding_requests.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), iteration_counter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "uncompress_fn", uncompress_fn);
    TFE_OpSetAttrInt(op.get(), "task_refresh_interval_hint_ms", task_refresh_interval_hint_ms);
    TFE_OpSetAttrString(op.get(), "data_transfer_protocol", (void*) data_transfer_protocol.c_str(), data_transfer_protocol.size());
    TFE_OpSetAttrString(op.get(), "target_workers", (void*) target_workers.c_str(), target_workers.size());
    TFE_OpSetAttrBool(op.get(), "uncompress", (unsigned char)uncompress);
    TFE_OpSetAttrString(op.get(), "cross_trainer_cache_options", (void*) cross_trainer_cache_options.c_str(), cross_trainer_cache_options.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DatasetCardinality
# Inputs:
*    input_dataset

# Attributes:
*    cardinality_options

# Outputs:
*    cardinality

*/
inline tensor dataset_cardinality(const tensor& input_dataset, const std::string& cardinality_options="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DatasetCardinality", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "cardinality_options", (void*) cardinality_options.c_str(), cardinality_options.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DatasetFingerprint
# Inputs:
*    input_dataset

# Attributes:
*    
# Outputs:
*    fingerprint

*/
inline tensor dataset_fingerprint(const tensor& input_dataset) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DatasetFingerprint", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DatasetFromGraph
# Inputs:
*    graph_def

# Attributes:
*    
# Outputs:
*    handle

*/
inline tensor dataset_from_graph(const tensor& graph_def) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DatasetFromGraph", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), graph_def.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DatasetToGraph
# Inputs:
*    input_dataset

# Attributes:
*    stateful_whitelist
*    allow_stateful
*    strip_device_assignment

# Outputs:
*    graph

*/
inline tensor dataset_to_graph(const tensor& input_dataset, const std::vector< std::string>& stateful_whitelist, bool allow_stateful=false, bool strip_device_assignment=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DatasetToGraph", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> stateful_whitelist_sizes; stateful_whitelist_sizes.reserve(stateful_whitelist.size());
    std::transform(stateful_whitelist.begin(), stateful_whitelist.end(), std::back_inserter(stateful_whitelist_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "stateful_whitelist", reinterpret_cast<const void *const *>(stateful_whitelist.data()), stateful_whitelist_sizes.data(), static_cast<int>(stateful_whitelist.size()));
    
    TFE_OpSetAttrBool(op.get(), "allow_stateful", (unsigned char)allow_stateful);
    TFE_OpSetAttrBool(op.get(), "strip_device_assignment", (unsigned char)strip_device_assignment);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DatasetToGraphV2
# Inputs:
*    input_dataset

# Attributes:
*    external_state_policy
*    strip_device_assignment

# Outputs:
*    graph

*/
inline tensor dataset_to_graph_v2(const tensor& input_dataset, int64_t external_state_policy=0, bool strip_device_assignment=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DatasetToGraphV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "external_state_policy", external_state_policy);
    TFE_OpSetAttrBool(op.get(), "strip_device_assignment", (unsigned char)strip_device_assignment);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DatasetToSingleElement
# Inputs:
*    dataset

# Attributes:
*    output_types
*    output_shapes
*    metadata

# Outputs:
*    components

*/
inline tensor dataset_to_single_element(const tensor& dataset, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DatasetToSingleElement", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DatasetToTFRecord
# Inputs:
*    input_dataset
*    filename
*    compression_type

# Attributes:
*    
# Outputs:
*    
*/
inline void dataset_to_t_f_record(const tensor& input_dataset, const tensor& filename, const tensor& compression_type) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DatasetToTFRecord", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filename.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), compression_type.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # Dawsn
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor dawsn(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Dawsn", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DebugGradientIdentity
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor debug_gradient_identity(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DebugGradientIdentity", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DebugGradientRefIdentity
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor debug_gradient_ref_identity(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DebugGradientRefIdentity", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DebugIdentity
# Inputs:
*    input

# Attributes:
*    debug_urls
*    device_name
*    tensor_name
*    gated_grpc

# Outputs:
*    output

*/
inline tensor debug_identity(const tensor& input, const std::vector< std::string>& debug_urls, const std::string& device_name="", const std::string& tensor_name="", bool gated_grpc=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DebugIdentity", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> debug_urls_sizes; debug_urls_sizes.reserve(debug_urls.size());
    std::transform(debug_urls.begin(), debug_urls.end(), std::back_inserter(debug_urls_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "debug_urls", reinterpret_cast<const void *const *>(debug_urls.data()), debug_urls_sizes.data(), static_cast<int>(debug_urls.size()));
    
    TFE_OpSetAttrString(op.get(), "device_name", (void*) device_name.c_str(), device_name.size());
    TFE_OpSetAttrString(op.get(), "tensor_name", (void*) tensor_name.c_str(), tensor_name.size());
    TFE_OpSetAttrBool(op.get(), "gated_grpc", (unsigned char)gated_grpc);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DebugIdentityV2
# Inputs:
*    input

# Attributes:
*    debug_urls
*    tfdbg_context_id
*    op_name
*    output_slot
*    tensor_debug_mode
*    circular_buffer_size
*    tfdbg_run_id

# Outputs:
*    output

*/
inline tensor debug_identity_v2(const tensor& input, const std::vector< std::string>& debug_urls, const std::string& tfdbg_context_id="", const std::string& op_name="", int64_t output_slot=-1, int64_t tensor_debug_mode=-1, int64_t circular_buffer_size=1000, const std::string& tfdbg_run_id="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DebugIdentityV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> debug_urls_sizes; debug_urls_sizes.reserve(debug_urls.size());
    std::transform(debug_urls.begin(), debug_urls.end(), std::back_inserter(debug_urls_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "debug_urls", reinterpret_cast<const void *const *>(debug_urls.data()), debug_urls_sizes.data(), static_cast<int>(debug_urls.size()));
    
    TFE_OpSetAttrString(op.get(), "tfdbg_context_id", (void*) tfdbg_context_id.c_str(), tfdbg_context_id.size());
    TFE_OpSetAttrString(op.get(), "op_name", (void*) op_name.c_str(), op_name.size());
    TFE_OpSetAttrInt(op.get(), "output_slot", output_slot);
    TFE_OpSetAttrInt(op.get(), "tensor_debug_mode", tensor_debug_mode);
    TFE_OpSetAttrInt(op.get(), "circular_buffer_size", circular_buffer_size);
    TFE_OpSetAttrString(op.get(), "tfdbg_run_id", (void*) tfdbg_run_id.c_str(), tfdbg_run_id.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DebugIdentityV3
# Inputs:
*    input

# Attributes:
*    debug_urls
*    device_name
*    tensor_name
*    io_of_node
*    is_input
*    io_index
*    gated_grpc

# Outputs:
*    output

*/
inline tensor debug_identity_v3(const tensor& input, const std::vector< std::string>& debug_urls, const std::string& device_name="", const std::string& tensor_name="", const std::string& io_of_node="", bool is_input=false, int64_t io_index=-1, bool gated_grpc=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DebugIdentityV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> debug_urls_sizes; debug_urls_sizes.reserve(debug_urls.size());
    std::transform(debug_urls.begin(), debug_urls.end(), std::back_inserter(debug_urls_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "debug_urls", reinterpret_cast<const void *const *>(debug_urls.data()), debug_urls_sizes.data(), static_cast<int>(debug_urls.size()));
    
    TFE_OpSetAttrString(op.get(), "device_name", (void*) device_name.c_str(), device_name.size());
    TFE_OpSetAttrString(op.get(), "tensor_name", (void*) tensor_name.c_str(), tensor_name.size());
    TFE_OpSetAttrString(op.get(), "io_of_node", (void*) io_of_node.c_str(), io_of_node.size());
    TFE_OpSetAttrBool(op.get(), "is_input", (unsigned char)is_input);
    TFE_OpSetAttrInt(op.get(), "io_index", io_index);
    TFE_OpSetAttrBool(op.get(), "gated_grpc", (unsigned char)gated_grpc);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DebugNanCount
# Inputs:
*    input

# Attributes:
*    debug_urls
*    device_name
*    tensor_name
*    gated_grpc

# Outputs:
*    output

*/
inline tensor debug_nan_count(const tensor& input, const std::vector< std::string>& debug_urls, const std::string& device_name="", const std::string& tensor_name="", bool gated_grpc=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DebugNanCount", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> debug_urls_sizes; debug_urls_sizes.reserve(debug_urls.size());
    std::transform(debug_urls.begin(), debug_urls.end(), std::back_inserter(debug_urls_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "debug_urls", reinterpret_cast<const void *const *>(debug_urls.data()), debug_urls_sizes.data(), static_cast<int>(debug_urls.size()));
    
    TFE_OpSetAttrString(op.get(), "device_name", (void*) device_name.c_str(), device_name.size());
    TFE_OpSetAttrString(op.get(), "tensor_name", (void*) tensor_name.c_str(), tensor_name.size());
    TFE_OpSetAttrBool(op.get(), "gated_grpc", (unsigned char)gated_grpc);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DebugNumericSummary
# Inputs:
*    input

# Attributes:
*    debug_urls
*    device_name
*    tensor_name
*    lower_bound
*    upper_bound
*    mute_if_healthy
*    gated_grpc

# Outputs:
*    output

*/
inline tensor debug_numeric_summary(const tensor& input, const std::vector< std::string>& debug_urls, const std::string& device_name="", const std::string& tensor_name="", float lower_bound=-std::numeric_limits<float>::infinity(), float upper_bound=std::numeric_limits<float>::infinity(), bool mute_if_healthy=false, bool gated_grpc=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DebugNumericSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> debug_urls_sizes; debug_urls_sizes.reserve(debug_urls.size());
    std::transform(debug_urls.begin(), debug_urls.end(), std::back_inserter(debug_urls_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "debug_urls", reinterpret_cast<const void *const *>(debug_urls.data()), debug_urls_sizes.data(), static_cast<int>(debug_urls.size()));
    
    TFE_OpSetAttrString(op.get(), "device_name", (void*) device_name.c_str(), device_name.size());
    TFE_OpSetAttrString(op.get(), "tensor_name", (void*) tensor_name.c_str(), tensor_name.size());
    TFE_OpSetAttrFloat(op.get(), "lower_bound", lower_bound);
    TFE_OpSetAttrFloat(op.get(), "upper_bound", upper_bound);
    TFE_OpSetAttrBool(op.get(), "mute_if_healthy", (unsigned char)mute_if_healthy);
    TFE_OpSetAttrBool(op.get(), "gated_grpc", (unsigned char)gated_grpc);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DebugNumericSummaryV2
# Inputs:
*    input

# Attributes:
*    output_dtype
*    tensor_debug_mode
*    tensor_id

# Outputs:
*    output

*/
inline tensor debug_numeric_summary_v2(const tensor& input, datatype output_dtype=static_cast<datatype>(1), int64_t tensor_debug_mode=-1, int64_t tensor_id=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DebugNumericSummaryV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "output_dtype", output_dtype);
    TFE_OpSetAttrInt(op.get(), "tensor_debug_mode", tensor_debug_mode);
    TFE_OpSetAttrInt(op.get(), "tensor_id", tensor_id);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DecodeAndCropJpeg
# Inputs:
*    contents
*    crop_window

# Attributes:
*    channels
*    ratio
*    fancy_upscaling
*    try_recover_truncated
*    acceptable_fraction
*    dct_method

# Outputs:
*    image

*/
inline tensor decode_and_crop_jpeg(const tensor& contents, const tensor& crop_window, int64_t channels=0, int64_t ratio=1, bool fancy_upscaling=true, bool try_recover_truncated=false, float acceptable_fraction=1.0000e+00, const std::string& dct_method="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodeAndCropJpeg", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), contents.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), crop_window.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "channels", channels);
    TFE_OpSetAttrInt(op.get(), "ratio", ratio);
    TFE_OpSetAttrBool(op.get(), "fancy_upscaling", (unsigned char)fancy_upscaling);
    TFE_OpSetAttrBool(op.get(), "try_recover_truncated", (unsigned char)try_recover_truncated);
    TFE_OpSetAttrFloat(op.get(), "acceptable_fraction", acceptable_fraction);
    TFE_OpSetAttrString(op.get(), "dct_method", (void*) dct_method.c_str(), dct_method.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DecodeBase64
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor decode_base64(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodeBase64", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DecodeBmp
# Inputs:
*    contents

# Attributes:
*    channels

# Outputs:
*    image

*/
inline tensor decode_bmp(const tensor& contents, int64_t channels=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodeBmp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), contents.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "channels", channels);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DecodeCSV
# Inputs:
*    records
*    record_defaults

# Attributes:
*    OUT_TYPE
*    select_cols
*    field_delim
*    use_quote_delim
*    na_value

# Outputs:
*    output

*/
inline tensor decode_c_s_v(const tensor& records, const std::vector<tensor>&record_defaults, const std::vector<datatype>& OUT_TYPE, const std::vector<int64_t>& select_cols, const std::string& field_delim=",", bool use_quote_delim=true, const std::string& na_value="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodeCSV", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), records.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> record_defaults_handles; record_defaults_handles.reserve(record_defaults.size());
    std::transform(record_defaults.begin(), record_defaults.end(), std::back_inserter(record_defaults_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), record_defaults_handles.data(), static_cast<int>(record_defaults.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "OUT_TYPE", reinterpret_cast<const enum TF_DataType *>(OUT_TYPE.data()), static_cast<int>(OUT_TYPE.size()));
    TFE_OpSetAttrIntList(op.get(), "select_cols", select_cols.data(), static_cast<int>(select_cols.size()));
    TFE_OpSetAttrString(op.get(), "field_delim", (void*) field_delim.c_str(), field_delim.size());
    TFE_OpSetAttrBool(op.get(), "use_quote_delim", (unsigned char)use_quote_delim);
    TFE_OpSetAttrString(op.get(), "na_value", (void*) na_value.c_str(), na_value.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DecodeCompressed
# Inputs:
*    bytes

# Attributes:
*    compression_type

# Outputs:
*    output

*/
inline tensor decode_compressed(const tensor& bytes, const std::string& compression_type="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodeCompressed", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), bytes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "compression_type", (void*) compression_type.c_str(), compression_type.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DecodeGif
# Inputs:
*    contents

# Attributes:
*    
# Outputs:
*    image

*/
inline tensor decode_gif(const tensor& contents) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodeGif", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), contents.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DecodeImage
# Inputs:
*    contents

# Attributes:
*    channels
*    dtype
*    expand_animations

# Outputs:
*    image

*/
inline tensor decode_image(const tensor& contents, int64_t channels=0, datatype dtype=static_cast<datatype>(4), bool expand_animations=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodeImage", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), contents.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "channels", channels);
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrBool(op.get(), "expand_animations", (unsigned char)expand_animations);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DecodeJSONExample
# Inputs:
*    json_examples

# Attributes:
*    
# Outputs:
*    binary_examples

*/
inline tensor decode_j_s_o_n_example(const tensor& json_examples) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodeJSONExample", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), json_examples.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DecodeJpeg
# Inputs:
*    contents

# Attributes:
*    channels
*    ratio
*    fancy_upscaling
*    try_recover_truncated
*    acceptable_fraction
*    dct_method

# Outputs:
*    image

*/
inline tensor decode_jpeg(const tensor& contents, int64_t channels=0, int64_t ratio=1, bool fancy_upscaling=true, bool try_recover_truncated=false, float acceptable_fraction=1.0000e+00, const std::string& dct_method="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodeJpeg", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), contents.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "channels", channels);
    TFE_OpSetAttrInt(op.get(), "ratio", ratio);
    TFE_OpSetAttrBool(op.get(), "fancy_upscaling", (unsigned char)fancy_upscaling);
    TFE_OpSetAttrBool(op.get(), "try_recover_truncated", (unsigned char)try_recover_truncated);
    TFE_OpSetAttrFloat(op.get(), "acceptable_fraction", acceptable_fraction);
    TFE_OpSetAttrString(op.get(), "dct_method", (void*) dct_method.c_str(), dct_method.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DecodePaddedRaw
# Inputs:
*    input_bytes
*    fixed_length

# Attributes:
*    out_type
*    little_endian

# Outputs:
*    output

*/
inline tensor decode_padded_raw(const tensor& input_bytes, const tensor& fixed_length, datatype out_type, bool little_endian=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodePaddedRaw", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_bytes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), fixed_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_type", out_type);
    TFE_OpSetAttrBool(op.get(), "little_endian", (unsigned char)little_endian);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DecodePng
# Inputs:
*    contents

# Attributes:
*    channels
*    dtype

# Outputs:
*    image

*/
inline tensor decode_png(const tensor& contents, int64_t channels=0, datatype dtype=static_cast<datatype>(4)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodePng", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), contents.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "channels", channels);
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DecodeProtoV2
# Inputs:
*    bytes

# Attributes:
*    message_type
*    field_names
*    output_types
*    descriptor_source
*    message_format
*    sanitize

# Outputs:
*    sizes
*    values

*/
inline std::vector<tensor> decode_proto_v2(const tensor& bytes, const std::string& message_type, const std::vector< std::string>& field_names, const std::vector<datatype>& output_types, const std::string& descriptor_source="local://", const std::string& message_format="binary", bool sanitize=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodeProtoV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), bytes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "message_type", (void*) message_type.c_str(), message_type.size());
    
    std::vector<std::size_t> field_names_sizes; field_names_sizes.reserve(field_names.size());
    std::transform(field_names.begin(), field_names.end(), std::back_inserter(field_names_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "field_names", reinterpret_cast<const void *const *>(field_names.data()), field_names_sizes.data(), static_cast<int>(field_names.size()));
    
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    TFE_OpSetAttrString(op.get(), "descriptor_source", (void*) descriptor_source.c_str(), descriptor_source.size());
    TFE_OpSetAttrString(op.get(), "message_format", (void*) message_format.c_str(), message_format.size());
    TFE_OpSetAttrBool(op.get(), "sanitize", (unsigned char)sanitize);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # DecodeRaw
# Inputs:
*    bytes

# Attributes:
*    out_type
*    little_endian

# Outputs:
*    output

*/
inline tensor decode_raw(const tensor& bytes, datatype out_type, bool little_endian=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodeRaw", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), bytes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_type", out_type);
    TFE_OpSetAttrBool(op.get(), "little_endian", (unsigned char)little_endian);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DecodeWav
# Inputs:
*    contents

# Attributes:
*    desired_channels
*    desired_samples

# Outputs:
*    audio
*    sample_rate

*/
inline std::vector<tensor> decode_wav(const tensor& contents, int64_t desired_channels=-1, int64_t desired_samples=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodeWav", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), contents.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "desired_channels", desired_channels);
    TFE_OpSetAttrInt(op.get(), "desired_samples", desired_samples);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # DeepCopy
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor deep_copy(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DeepCopy", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DeleteIterator
# Inputs:
*    handle
*    deleter

# Attributes:
*    
# Outputs:
*    
*/
inline void delete_iterator(const tensor& handle, const tensor& deleter) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DeleteIterator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), deleter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # DeleteMemoryCache
# Inputs:
*    handle
*    deleter

# Attributes:
*    
# Outputs:
*    
*/
inline void delete_memory_cache(const tensor& handle, const tensor& deleter) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DeleteMemoryCache", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), deleter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # DeleteMultiDeviceIterator
# Inputs:
*    multi_device_iterator
*    iterators
*    deleter

# Attributes:
*    N

# Outputs:
*    
*/
inline void delete_multi_device_iterator(const tensor& multi_device_iterator, const std::vector<tensor>&iterators, const tensor& deleter) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DeleteMultiDeviceIterator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), multi_device_iterator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> iterators_handles; iterators_handles.reserve(iterators.size());
    std::transform(iterators.begin(), iterators.end(), std::back_inserter(iterators_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), iterators_handles.data(), static_cast<int>(iterators.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), deleter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", iterators.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # DeleteRandomSeedGenerator
# Inputs:
*    handle
*    deleter

# Attributes:
*    
# Outputs:
*    
*/
inline void delete_random_seed_generator(const tensor& handle, const tensor& deleter) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DeleteRandomSeedGenerator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), deleter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # DeleteSeedGenerator
# Inputs:
*    handle
*    deleter

# Attributes:
*    
# Outputs:
*    
*/
inline void delete_seed_generator(const tensor& handle, const tensor& deleter) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DeleteSeedGenerator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), deleter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # DeleteSessionTensor
# Inputs:
*    handle

# Attributes:
*    
# Outputs:
*    
*/
inline void delete_session_tensor(const tensor& handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DeleteSessionTensor", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # DenseBincount
# Inputs:
*    input
*    size
*    weights

# Attributes:
*    Tidx
*    binary_output

# Outputs:
*    output

*/
inline tensor dense_bincount(const tensor& input, const tensor& size, const tensor& weights, datatype Tidx, bool binary_output=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DenseBincount", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), weights.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrBool(op.get(), "binary_output", (unsigned char)binary_output);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DenseCountSparseOutput
# Inputs:
*    values
*    weights

# Attributes:
*    binary_output
*    output_type
*    minlength
*    maxlength

# Outputs:
*    output_indices
*    output_values
*    output_dense_shape

*/
inline std::vector<tensor> dense_count_sparse_output(const tensor& values, const tensor& weights, bool binary_output, datatype output_type, int64_t minlength=-1, int64_t maxlength=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DenseCountSparseOutput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), weights.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "binary_output", (unsigned char)binary_output);
    TFE_OpSetAttrType(op.get(), "output_type", output_type);
    TFE_OpSetAttrInt(op.get(), "minlength", minlength);
    TFE_OpSetAttrInt(op.get(), "maxlength", maxlength);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # DenseToCSRSparseMatrix
# Inputs:
*    dense_input
*    indices

# Attributes:
*    
# Outputs:
*    sparse_output

*/
inline tensor dense_to_c_s_r_sparse_matrix(const tensor& dense_input, const tensor& indices) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DenseToCSRSparseMatrix", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), dense_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DenseToDenseSetOperation
# Inputs:
*    set1
*    set2

# Attributes:
*    set_operation
*    validate_indices

# Outputs:
*    result_indices
*    result_values
*    result_shape

*/
inline std::vector<tensor> dense_to_dense_set_operation(const tensor& set1, const tensor& set2, const std::string& set_operation, bool validate_indices=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DenseToDenseSetOperation", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), set1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), set2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "set_operation", (void*) set_operation.c_str(), set_operation.size());
    TFE_OpSetAttrBool(op.get(), "validate_indices", (unsigned char)validate_indices);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # DenseToSparseBatchDataset
# Inputs:
*    input_dataset
*    batch_size
*    row_shape

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor dense_to_sparse_batch_dataset(const tensor& input_dataset, const tensor& batch_size, const tensor& row_shape, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DenseToSparseBatchDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), batch_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), row_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DenseToSparseSetOperation
# Inputs:
*    set1
*    set2_indices
*    set2_values
*    set2_shape

# Attributes:
*    set_operation
*    validate_indices

# Outputs:
*    result_indices
*    result_values
*    result_shape

*/
inline std::vector<tensor> dense_to_sparse_set_operation(const tensor& set1, const tensor& set2_indices, const tensor& set2_values, const tensor& set2_shape, const std::string& set_operation, bool validate_indices=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DenseToSparseSetOperation", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), set1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), set2_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), set2_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), set2_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "set_operation", (void*) set_operation.c_str(), set_operation.size());
    TFE_OpSetAttrBool(op.get(), "validate_indices", (unsigned char)validate_indices);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # DepthToSpace
# Inputs:
*    input

# Attributes:
*    block_size
*    data_format

# Outputs:
*    output

*/
inline tensor depth_to_space(const tensor& input, int64_t block_size, const std::string& data_format="NHWC") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DepthToSpace", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "block_size", block_size);
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DepthwiseConv2dNative
# Inputs:
*    input
*    filter

# Attributes:
*    strides
*    padding
*    explicit_paddings
*    dilations
*    data_format

# Outputs:
*    output

*/
inline tensor depthwise_conv2d_native(const tensor& input, const tensor& filter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& explicit_paddings, const std::vector<int64_t>& dilations, const std::string& data_format="NHWC") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DepthwiseConv2dNative", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "explicit_paddings", explicit_paddings.data(), static_cast<int>(explicit_paddings.size()));
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DepthwiseConv2dNativeBackpropFilter
# Inputs:
*    input
*    filter_sizes
*    out_backprop

# Attributes:
*    strides
*    padding
*    explicit_paddings
*    dilations
*    data_format

# Outputs:
*    output

*/
inline tensor depthwise_conv2d_native_backprop_filter(const tensor& input, const tensor& filter_sizes, const tensor& out_backprop, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& explicit_paddings, const std::vector<int64_t>& dilations, const std::string& data_format="NHWC") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DepthwiseConv2dNativeBackpropFilter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter_sizes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), out_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "explicit_paddings", explicit_paddings.data(), static_cast<int>(explicit_paddings.size()));
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DepthwiseConv2dNativeBackpropInput
# Inputs:
*    input_sizes
*    filter
*    out_backprop

# Attributes:
*    strides
*    padding
*    explicit_paddings
*    dilations
*    data_format

# Outputs:
*    output

*/
inline tensor depthwise_conv2d_native_backprop_input(const tensor& input_sizes, const tensor& filter, const tensor& out_backprop, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& explicit_paddings, const std::vector<int64_t>& dilations, const std::string& data_format="NHWC") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DepthwiseConv2dNativeBackpropInput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_sizes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), out_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "explicit_paddings", explicit_paddings.data(), static_cast<int>(explicit_paddings.size()));
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Dequantize
# Inputs:
*    input
*    min_range
*    max_range

# Attributes:
*    mode
*    narrow_range
*    axis
*    dtype

# Outputs:
*    output

*/
inline tensor dequantize(const tensor& input, const tensor& min_range, const tensor& max_range, const std::string& mode="MIN_COMBINED", bool narrow_range=false, int64_t axis=-1, datatype dtype=static_cast<datatype>(1)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Dequantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_range.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_range.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "mode", (void*) mode.c_str(), mode.size());
    TFE_OpSetAttrBool(op.get(), "narrow_range", (unsigned char)narrow_range);
    TFE_OpSetAttrInt(op.get(), "axis", axis);
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DeserializeIterator
# Inputs:
*    resource_handle
*    serialized

# Attributes:
*    
# Outputs:
*    
*/
inline void deserialize_iterator(const tensor& resource_handle, const tensor& serialized) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DeserializeIterator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), serialized.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # DeserializeManySparse
# Inputs:
*    serialized_sparse

# Attributes:
*    dtype

# Outputs:
*    sparse_indices
*    sparse_values
*    sparse_shape

*/
inline std::vector<tensor> deserialize_many_sparse(const tensor& serialized_sparse, datatype dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DeserializeManySparse", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), serialized_sparse.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # DeserializeSparse
# Inputs:
*    serialized_sparse

# Attributes:
*    dtype
*    Tserialized

# Outputs:
*    sparse_indices
*    sparse_values
*    sparse_shape

*/
inline std::vector<tensor> deserialize_sparse(const tensor& serialized_sparse, datatype dtype, datatype Tserialized=static_cast<datatype>(7)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DeserializeSparse", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), serialized_sparse.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tserialized", Tserialized);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # DestroyResourceOp
# Inputs:
*    resource

# Attributes:
*    ignore_lookup_error

# Outputs:
*    
*/
inline void destroy_resource_op(const tensor& resource, bool ignore_lookup_error=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DestroyResourceOp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "ignore_lookup_error", (unsigned char)ignore_lookup_error);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # DestroyTemporaryVariable
# Inputs:
*    ref

# Attributes:
*    var_name

# Outputs:
*    value

*/
inline tensor destroy_temporary_variable(const tensor& ref, const std::string& var_name) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DestroyTemporaryVariable", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "var_name", (void*) var_name.c_str(), var_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DeviceIndex
# Inputs:
*    
# Attributes:
*    device_names

# Outputs:
*    index

*/
inline tensor device_index(const std::vector< std::string>& device_names) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DeviceIndex", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    
    std::vector<std::size_t> device_names_sizes; device_names_sizes.reserve(device_names.size());
    std::transform(device_names.begin(), device_names.end(), std::back_inserter(device_names_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "device_names", reinterpret_cast<const void *const *>(device_names.data()), device_names_sizes.data(), static_cast<int>(device_names.size()));
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Diag
# Inputs:
*    diagonal

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor diag(const tensor& diagonal) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Diag", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), diagonal.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DiagPart
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    diagonal

*/
inline tensor diag_part(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DiagPart", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Digamma
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor digamma(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Digamma", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Dilation2D
# Inputs:
*    input
*    filter

# Attributes:
*    strides
*    rates
*    padding

# Outputs:
*    output

*/
inline tensor dilation2_d(const tensor& input, const tensor& filter, const std::vector<int64_t>& strides, const std::vector<int64_t>& rates, const std::string& padding) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Dilation2D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrIntList(op.get(), "rates", rates.data(), static_cast<int>(rates.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Dilation2DBackpropFilter
# Inputs:
*    input
*    filter
*    out_backprop

# Attributes:
*    strides
*    rates
*    padding

# Outputs:
*    filter_backprop

*/
inline tensor dilation2_d_backprop_filter(const tensor& input, const tensor& filter, const tensor& out_backprop, const std::vector<int64_t>& strides, const std::vector<int64_t>& rates, const std::string& padding) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Dilation2DBackpropFilter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), out_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrIntList(op.get(), "rates", rates.data(), static_cast<int>(rates.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Dilation2DBackpropInput
# Inputs:
*    input
*    filter
*    out_backprop

# Attributes:
*    strides
*    rates
*    padding

# Outputs:
*    in_backprop

*/
inline tensor dilation2_d_backprop_input(const tensor& input, const tensor& filter, const tensor& out_backprop, const std::vector<int64_t>& strides, const std::vector<int64_t>& rates, const std::string& padding) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Dilation2DBackpropInput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), out_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrIntList(op.get(), "rates", rates.data(), static_cast<int>(rates.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DirectedInterleaveDataset
# Inputs:
*    selector_input_dataset
*    data_input_datasets

# Attributes:
*    output_types
*    output_shapes
*    N
*    stop_on_empty_dataset

# Outputs:
*    handle

*/
inline tensor directed_interleave_dataset(const tensor& selector_input_dataset, const std::vector<tensor>&data_input_datasets, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool stop_on_empty_dataset=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DirectedInterleaveDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), selector_input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> data_input_datasets_handles; data_input_datasets_handles.reserve(data_input_datasets.size());
    std::transform(data_input_datasets.begin(), data_input_datasets.end(), std::back_inserter(data_input_datasets_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), data_input_datasets_handles.data(), static_cast<int>(data_input_datasets.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "N", data_input_datasets.size());
    TFE_OpSetAttrBool(op.get(), "stop_on_empty_dataset", (unsigned char)stop_on_empty_dataset);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DisableCopyOnRead
# Inputs:
*    resource

# Attributes:
*    
# Outputs:
*    
*/
inline void disable_copy_on_read(const tensor& resource) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DisableCopyOnRead", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # DistributedSave
# Inputs:
*    dataset
*    directory
*    address

# Attributes:
*    metadata

# Outputs:
*    
*/
inline void distributed_save(const tensor& dataset, const tensor& directory, const tensor& address, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DistributedSave", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), directory.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), address.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # Div
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor div(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Div", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DivNoNan
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor div_no_nan(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DivNoNan", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DrawBoundingBoxes
# Inputs:
*    images
*    boxes

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor draw_bounding_boxes(const tensor& images, const tensor& boxes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DrawBoundingBoxes", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), boxes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DrawBoundingBoxesV2
# Inputs:
*    images
*    boxes
*    colors

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor draw_bounding_boxes_v2(const tensor& images, const tensor& boxes, const tensor& colors) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DrawBoundingBoxesV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), boxes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), colors.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DummyIterationCounter
# Inputs:
*    
# Attributes:
*    
# Outputs:
*    handle

*/
inline tensor dummy_iteration_counter() {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DummyIterationCounter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DummyMemoryCache
# Inputs:
*    
# Attributes:
*    
# Outputs:
*    handle

*/
inline tensor dummy_memory_cache() {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DummyMemoryCache", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DummySeedGenerator
# Inputs:
*    
# Attributes:
*    
# Outputs:
*    handle

*/
inline tensor dummy_seed_generator() {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DummySeedGenerator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DynamicEnqueueTPUEmbeddingArbitraryTensorBatch
# Inputs:
*    sample_indices_or_row_splits
*    embedding_indices
*    aggregation_weights
*    mode_override
*    device_ordinal

# Attributes:
*    N
*    combiners
*    T1
*    T2
*    T3

# Outputs:
*    
*/
inline void dynamic_enqueue_t_p_u_embedding_arbitrary_tensor_batch(const std::vector<tensor>&sample_indices_or_row_splits, const std::vector<tensor>&embedding_indices, const std::vector<tensor>&aggregation_weights, const tensor& mode_override, const tensor& device_ordinal, const std::vector< std::string>& combiners, datatype T1=static_cast<datatype>(3), datatype T2=static_cast<datatype>(3), datatype T3=static_cast<datatype>(1)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DynamicEnqueueTPUEmbeddingArbitraryTensorBatch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> sample_indices_or_row_splits_handles; sample_indices_or_row_splits_handles.reserve(sample_indices_or_row_splits.size());
    std::transform(sample_indices_or_row_splits.begin(), sample_indices_or_row_splits.end(), std::back_inserter(sample_indices_or_row_splits_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), sample_indices_or_row_splits_handles.data(), static_cast<int>(sample_indices_or_row_splits.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> embedding_indices_handles; embedding_indices_handles.reserve(embedding_indices.size());
    std::transform(embedding_indices.begin(), embedding_indices.end(), std::back_inserter(embedding_indices_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), embedding_indices_handles.data(), static_cast<int>(embedding_indices.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> aggregation_weights_handles; aggregation_weights_handles.reserve(aggregation_weights.size());
    std::transform(aggregation_weights.begin(), aggregation_weights.end(), std::back_inserter(aggregation_weights_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), aggregation_weights_handles.data(), static_cast<int>(aggregation_weights.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mode_override.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), device_ordinal.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", sample_indices_or_row_splits.size());
    
    std::vector<std::size_t> combiners_sizes; combiners_sizes.reserve(combiners.size());
    std::transform(combiners.begin(), combiners.end(), std::back_inserter(combiners_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "combiners", reinterpret_cast<const void *const *>(combiners.data()), combiners_sizes.data(), static_cast<int>(combiners.size()));
    
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "T3", T3);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # DynamicEnqueueTPUEmbeddingRaggedTensorBatch
# Inputs:
*    sample_splits
*    embedding_indices
*    aggregation_weights
*    mode_override
*    device_ordinal

# Attributes:
*    N
*    combiners
*    table_ids
*    max_sequence_lengths
*    num_features
*    T1
*    T2
*    T3

# Outputs:
*    
*/
inline void dynamic_enqueue_t_p_u_embedding_ragged_tensor_batch(const std::vector<tensor>&sample_splits, const std::vector<tensor>&embedding_indices, const std::vector<tensor>&aggregation_weights, const tensor& mode_override, const tensor& device_ordinal, const std::vector< std::string>& combiners, const std::vector<int64_t>& table_ids, const std::vector<int64_t>& max_sequence_lengths, const std::vector<int64_t>& num_features, datatype T1=static_cast<datatype>(3), datatype T2=static_cast<datatype>(3), datatype T3=static_cast<datatype>(1)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DynamicEnqueueTPUEmbeddingRaggedTensorBatch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> sample_splits_handles; sample_splits_handles.reserve(sample_splits.size());
    std::transform(sample_splits.begin(), sample_splits.end(), std::back_inserter(sample_splits_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), sample_splits_handles.data(), static_cast<int>(sample_splits.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> embedding_indices_handles; embedding_indices_handles.reserve(embedding_indices.size());
    std::transform(embedding_indices.begin(), embedding_indices.end(), std::back_inserter(embedding_indices_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), embedding_indices_handles.data(), static_cast<int>(embedding_indices.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> aggregation_weights_handles; aggregation_weights_handles.reserve(aggregation_weights.size());
    std::transform(aggregation_weights.begin(), aggregation_weights.end(), std::back_inserter(aggregation_weights_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), aggregation_weights_handles.data(), static_cast<int>(aggregation_weights.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mode_override.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), device_ordinal.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", sample_splits.size());
    
    std::vector<std::size_t> combiners_sizes; combiners_sizes.reserve(combiners.size());
    std::transform(combiners.begin(), combiners.end(), std::back_inserter(combiners_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "combiners", reinterpret_cast<const void *const *>(combiners.data()), combiners_sizes.data(), static_cast<int>(combiners.size()));
    
    TFE_OpSetAttrIntList(op.get(), "table_ids", table_ids.data(), static_cast<int>(table_ids.size()));
    TFE_OpSetAttrIntList(op.get(), "max_sequence_lengths", max_sequence_lengths.data(), static_cast<int>(max_sequence_lengths.size()));
    TFE_OpSetAttrIntList(op.get(), "num_features", num_features.data(), static_cast<int>(num_features.size()));
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "T3", T3);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # DynamicPartition
# Inputs:
*    data
*    partitions

# Attributes:
*    num_partitions

# Outputs:
*    outputs

*/
inline tensor dynamic_partition(const tensor& data, const tensor& partitions, int64_t num_partitions) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DynamicPartition", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), partitions.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_partitions", num_partitions);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # DynamicStitch
# Inputs:
*    indices
*    data

# Attributes:
*    N

# Outputs:
*    merged

*/
inline tensor dynamic_stitch(const std::vector<tensor>&indices, const std::vector<tensor>&data) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DynamicStitch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> indices_handles; indices_handles.reserve(indices.size());
    std::transform(indices.begin(), indices.end(), std::back_inserter(indices_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), indices_handles.data(), static_cast<int>(indices.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> data_handles; data_handles.reserve(data.size());
    std::transform(data.begin(), data.end(), std::back_inserter(data_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), data_handles.data(), static_cast<int>(data.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", indices.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # EagerPyFunc
# Inputs:
*    input

# Attributes:
*    token
*    Tin
*    Tout
*    is_async

# Outputs:
*    output

*/
inline tensor eager_py_func(const std::vector<tensor>&input, const std::string& token, const std::vector<datatype>& Tin, const std::vector<datatype>& Tout, bool is_async=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EagerPyFunc", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> input_handles; input_handles.reserve(input.size());
    std::transform(input.begin(), input.end(), std::back_inserter(input_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), input_handles.data(), static_cast<int>(input.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "token", (void*) token.c_str(), token.size());
    TFE_OpSetAttrTypeList(op.get(), "Tin", reinterpret_cast<const enum TF_DataType *>(Tin.data()), static_cast<int>(Tin.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tout", reinterpret_cast<const enum TF_DataType *>(Tout.data()), static_cast<int>(Tout.size()));
    TFE_OpSetAttrBool(op.get(), "is_async", (unsigned char)is_async);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # EditDistance
# Inputs:
*    hypothesis_indices
*    hypothesis_values
*    hypothesis_shape
*    truth_indices
*    truth_values
*    truth_shape

# Attributes:
*    normalize

# Outputs:
*    output

*/
inline tensor edit_distance(const tensor& hypothesis_indices, const tensor& hypothesis_values, const tensor& hypothesis_shape, const tensor& truth_indices, const tensor& truth_values, const tensor& truth_shape, bool normalize=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EditDistance", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), hypothesis_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), hypothesis_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), hypothesis_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), truth_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), truth_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), truth_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "normalize", (unsigned char)normalize);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Eig
# Inputs:
*    input

# Attributes:
*    Tout
*    compute_v

# Outputs:
*    e
*    v

*/
inline std::vector<tensor> eig(const tensor& input, datatype Tout, bool compute_v=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Eig", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tout", Tout);
    TFE_OpSetAttrBool(op.get(), "compute_v", (unsigned char)compute_v);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # Einsum
# Inputs:
*    inputs

# Attributes:
*    equation
*    N

# Outputs:
*    output

*/
inline tensor einsum(const std::vector<tensor>&inputs, const std::string& equation) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Einsum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), static_cast<int>(inputs.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "equation", (void*) equation.c_str(), equation.size());
    TFE_OpSetAttrInt(op.get(), "N", inputs.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Elu
# Inputs:
*    features

# Attributes:
*    
# Outputs:
*    activations

*/
inline tensor elu(const tensor& features) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Elu", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), features.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # EluGrad
# Inputs:
*    gradients
*    outputs

# Attributes:
*    
# Outputs:
*    backprops

*/
inline tensor elu_grad(const tensor& gradients, const tensor& outputs) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EluGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), gradients.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), outputs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Empty
# Inputs:
*    shape

# Attributes:
*    dtype
*    init

# Outputs:
*    output

*/
inline tensor empty(const tensor& shape, datatype dtype, bool init=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Empty", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrBool(op.get(), "init", (unsigned char)init);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # EmptyTensorList
# Inputs:
*    element_shape
*    max_num_elements

# Attributes:
*    element_dtype
*    shape_type

# Outputs:
*    handle

*/
inline tensor empty_tensor_list(const tensor& element_shape, const tensor& max_num_elements, datatype element_dtype, datatype shape_type) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EmptyTensorList", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), element_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_num_elements.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);
    TFE_OpSetAttrType(op.get(), "shape_type", shape_type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # EmptyTensorMap
# Inputs:
*    
# Attributes:
*    
# Outputs:
*    handle

*/
inline tensor empty_tensor_map() {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EmptyTensorMap", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # EncodeBase64
# Inputs:
*    input

# Attributes:
*    pad

# Outputs:
*    output

*/
inline tensor encode_base64(const tensor& input, bool pad=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EncodeBase64", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "pad", (unsigned char)pad);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # EncodeJpeg
# Inputs:
*    image

# Attributes:
*    format
*    quality
*    progressive
*    optimize_size
*    chroma_downsampling
*    density_unit
*    x_density
*    y_density
*    xmp_metadata

# Outputs:
*    contents

*/
inline tensor encode_jpeg(const tensor& image, const std::string& format="", int64_t quality=95, bool progressive=false, bool optimize_size=false, bool chroma_downsampling=true, const std::string& density_unit="in", int64_t x_density=300, int64_t y_density=300, const std::string& xmp_metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EncodeJpeg", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), image.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "format", (void*) format.c_str(), format.size());
    TFE_OpSetAttrInt(op.get(), "quality", quality);
    TFE_OpSetAttrBool(op.get(), "progressive", (unsigned char)progressive);
    TFE_OpSetAttrBool(op.get(), "optimize_size", (unsigned char)optimize_size);
    TFE_OpSetAttrBool(op.get(), "chroma_downsampling", (unsigned char)chroma_downsampling);
    TFE_OpSetAttrString(op.get(), "density_unit", (void*) density_unit.c_str(), density_unit.size());
    TFE_OpSetAttrInt(op.get(), "x_density", x_density);
    TFE_OpSetAttrInt(op.get(), "y_density", y_density);
    TFE_OpSetAttrString(op.get(), "xmp_metadata", (void*) xmp_metadata.c_str(), xmp_metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # EncodeJpegVariableQuality
# Inputs:
*    images
*    quality

# Attributes:
*    
# Outputs:
*    contents

*/
inline tensor encode_jpeg_variable_quality(const tensor& images, const tensor& quality) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EncodeJpegVariableQuality", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), quality.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # EncodePng
# Inputs:
*    image

# Attributes:
*    compression

# Outputs:
*    contents

*/
inline tensor encode_png(const tensor& image, int64_t compression=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EncodePng", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), image.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "compression", compression);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # EncodeProto
# Inputs:
*    sizes
*    values

# Attributes:
*    field_names
*    message_type
*    Tinput_types
*    descriptor_source

# Outputs:
*    bytes

*/
inline tensor encode_proto(const tensor& sizes, const std::vector<tensor>&values, const std::vector< std::string>& field_names, const std::string& message_type, const std::vector<datatype>& Tinput_types, const std::string& descriptor_source="local://") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EncodeProto", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sizes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> values_handles; values_handles.reserve(values.size());
    std::transform(values.begin(), values.end(), std::back_inserter(values_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), values_handles.data(), static_cast<int>(values.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> field_names_sizes; field_names_sizes.reserve(field_names.size());
    std::transform(field_names.begin(), field_names.end(), std::back_inserter(field_names_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "field_names", reinterpret_cast<const void *const *>(field_names.data()), field_names_sizes.data(), static_cast<int>(field_names.size()));
    
    TFE_OpSetAttrString(op.get(), "message_type", (void*) message_type.c_str(), message_type.size());
    TFE_OpSetAttrTypeList(op.get(), "Tinput_types", reinterpret_cast<const enum TF_DataType *>(Tinput_types.data()), static_cast<int>(Tinput_types.size()));
    TFE_OpSetAttrString(op.get(), "descriptor_source", (void*) descriptor_source.c_str(), descriptor_source.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # EncodeWav
# Inputs:
*    audio
*    sample_rate

# Attributes:
*    
# Outputs:
*    contents

*/
inline tensor encode_wav(const tensor& audio, const tensor& sample_rate) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EncodeWav", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), audio.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sample_rate.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # EnqueueTPUEmbeddingArbitraryTensorBatch
# Inputs:
*    sample_indices_or_row_splits
*    embedding_indices
*    aggregation_weights
*    mode_override

# Attributes:
*    N
*    combiners
*    T1
*    T2
*    T3
*    device_ordinal

# Outputs:
*    
*/
inline void enqueue_t_p_u_embedding_arbitrary_tensor_batch(const std::vector<tensor>&sample_indices_or_row_splits, const std::vector<tensor>&embedding_indices, const std::vector<tensor>&aggregation_weights, const tensor& mode_override, const std::vector< std::string>& combiners, datatype T1=static_cast<datatype>(3), datatype T2=static_cast<datatype>(3), datatype T3=static_cast<datatype>(1), int64_t device_ordinal=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EnqueueTPUEmbeddingArbitraryTensorBatch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> sample_indices_or_row_splits_handles; sample_indices_or_row_splits_handles.reserve(sample_indices_or_row_splits.size());
    std::transform(sample_indices_or_row_splits.begin(), sample_indices_or_row_splits.end(), std::back_inserter(sample_indices_or_row_splits_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), sample_indices_or_row_splits_handles.data(), static_cast<int>(sample_indices_or_row_splits.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> embedding_indices_handles; embedding_indices_handles.reserve(embedding_indices.size());
    std::transform(embedding_indices.begin(), embedding_indices.end(), std::back_inserter(embedding_indices_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), embedding_indices_handles.data(), static_cast<int>(embedding_indices.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> aggregation_weights_handles; aggregation_weights_handles.reserve(aggregation_weights.size());
    std::transform(aggregation_weights.begin(), aggregation_weights.end(), std::back_inserter(aggregation_weights_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), aggregation_weights_handles.data(), static_cast<int>(aggregation_weights.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mode_override.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", sample_indices_or_row_splits.size());
    
    std::vector<std::size_t> combiners_sizes; combiners_sizes.reserve(combiners.size());
    std::transform(combiners.begin(), combiners.end(), std::back_inserter(combiners_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "combiners", reinterpret_cast<const void *const *>(combiners.data()), combiners_sizes.data(), static_cast<int>(combiners.size()));
    
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "T3", T3);
    TFE_OpSetAttrInt(op.get(), "device_ordinal", device_ordinal);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # EnqueueTPUEmbeddingIntegerBatch
# Inputs:
*    batch
*    mode_override

# Attributes:
*    N
*    device_ordinal

# Outputs:
*    
*/
inline void enqueue_t_p_u_embedding_integer_batch(const std::vector<tensor>&batch, const tensor& mode_override, int64_t device_ordinal=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EnqueueTPUEmbeddingIntegerBatch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> batch_handles; batch_handles.reserve(batch.size());
    std::transform(batch.begin(), batch.end(), std::back_inserter(batch_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), batch_handles.data(), static_cast<int>(batch.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mode_override.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", batch.size());
    TFE_OpSetAttrInt(op.get(), "device_ordinal", device_ordinal);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # EnqueueTPUEmbeddingRaggedTensorBatch
# Inputs:
*    sample_splits
*    embedding_indices
*    aggregation_weights
*    mode_override

# Attributes:
*    N
*    combiners
*    table_ids
*    max_sequence_lengths
*    num_features
*    T1
*    T2
*    T3
*    device_ordinal

# Outputs:
*    
*/
inline void enqueue_t_p_u_embedding_ragged_tensor_batch(const std::vector<tensor>&sample_splits, const std::vector<tensor>&embedding_indices, const std::vector<tensor>&aggregation_weights, const tensor& mode_override, const std::vector< std::string>& combiners, const std::vector<int64_t>& table_ids, const std::vector<int64_t>& max_sequence_lengths, const std::vector<int64_t>& num_features, datatype T1=static_cast<datatype>(3), datatype T2=static_cast<datatype>(3), datatype T3=static_cast<datatype>(1), int64_t device_ordinal=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EnqueueTPUEmbeddingRaggedTensorBatch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> sample_splits_handles; sample_splits_handles.reserve(sample_splits.size());
    std::transform(sample_splits.begin(), sample_splits.end(), std::back_inserter(sample_splits_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), sample_splits_handles.data(), static_cast<int>(sample_splits.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> embedding_indices_handles; embedding_indices_handles.reserve(embedding_indices.size());
    std::transform(embedding_indices.begin(), embedding_indices.end(), std::back_inserter(embedding_indices_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), embedding_indices_handles.data(), static_cast<int>(embedding_indices.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> aggregation_weights_handles; aggregation_weights_handles.reserve(aggregation_weights.size());
    std::transform(aggregation_weights.begin(), aggregation_weights.end(), std::back_inserter(aggregation_weights_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), aggregation_weights_handles.data(), static_cast<int>(aggregation_weights.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mode_override.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", sample_splits.size());
    
    std::vector<std::size_t> combiners_sizes; combiners_sizes.reserve(combiners.size());
    std::transform(combiners.begin(), combiners.end(), std::back_inserter(combiners_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "combiners", reinterpret_cast<const void *const *>(combiners.data()), combiners_sizes.data(), static_cast<int>(combiners.size()));
    
    TFE_OpSetAttrIntList(op.get(), "table_ids", table_ids.data(), static_cast<int>(table_ids.size()));
    TFE_OpSetAttrIntList(op.get(), "max_sequence_lengths", max_sequence_lengths.data(), static_cast<int>(max_sequence_lengths.size()));
    TFE_OpSetAttrIntList(op.get(), "num_features", num_features.data(), static_cast<int>(num_features.size()));
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "T3", T3);
    TFE_OpSetAttrInt(op.get(), "device_ordinal", device_ordinal);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # EnqueueTPUEmbeddingSparseBatch
# Inputs:
*    sample_indices
*    embedding_indices
*    aggregation_weights
*    mode_override

# Attributes:
*    N
*    combiners
*    T1
*    T2
*    T3
*    device_ordinal

# Outputs:
*    
*/
inline void enqueue_t_p_u_embedding_sparse_batch(const std::vector<tensor>&sample_indices, const std::vector<tensor>&embedding_indices, const std::vector<tensor>&aggregation_weights, const tensor& mode_override, const std::vector< std::string>& combiners, datatype T1=static_cast<datatype>(3), datatype T2=static_cast<datatype>(3), datatype T3=static_cast<datatype>(1), int64_t device_ordinal=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EnqueueTPUEmbeddingSparseBatch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> sample_indices_handles; sample_indices_handles.reserve(sample_indices.size());
    std::transform(sample_indices.begin(), sample_indices.end(), std::back_inserter(sample_indices_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), sample_indices_handles.data(), static_cast<int>(sample_indices.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> embedding_indices_handles; embedding_indices_handles.reserve(embedding_indices.size());
    std::transform(embedding_indices.begin(), embedding_indices.end(), std::back_inserter(embedding_indices_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), embedding_indices_handles.data(), static_cast<int>(embedding_indices.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> aggregation_weights_handles; aggregation_weights_handles.reserve(aggregation_weights.size());
    std::transform(aggregation_weights.begin(), aggregation_weights.end(), std::back_inserter(aggregation_weights_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), aggregation_weights_handles.data(), static_cast<int>(aggregation_weights.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mode_override.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", sample_indices.size());
    
    std::vector<std::size_t> combiners_sizes; combiners_sizes.reserve(combiners.size());
    std::transform(combiners.begin(), combiners.end(), std::back_inserter(combiners_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "combiners", reinterpret_cast<const void *const *>(combiners.data()), combiners_sizes.data(), static_cast<int>(combiners.size()));
    
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "T3", T3);
    TFE_OpSetAttrInt(op.get(), "device_ordinal", device_ordinal);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # EnqueueTPUEmbeddingSparseTensorBatch
# Inputs:
*    sample_indices
*    embedding_indices
*    aggregation_weights
*    mode_override

# Attributes:
*    N
*    combiners
*    table_ids
*    max_sequence_lengths
*    num_features
*    T1
*    T2
*    T3
*    device_ordinal

# Outputs:
*    
*/
inline void enqueue_t_p_u_embedding_sparse_tensor_batch(const std::vector<tensor>&sample_indices, const std::vector<tensor>&embedding_indices, const std::vector<tensor>&aggregation_weights, const tensor& mode_override, const std::vector< std::string>& combiners, const std::vector<int64_t>& table_ids, const std::vector<int64_t>& max_sequence_lengths, const std::vector<int64_t>& num_features, datatype T1=static_cast<datatype>(3), datatype T2=static_cast<datatype>(3), datatype T3=static_cast<datatype>(1), int64_t device_ordinal=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EnqueueTPUEmbeddingSparseTensorBatch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> sample_indices_handles; sample_indices_handles.reserve(sample_indices.size());
    std::transform(sample_indices.begin(), sample_indices.end(), std::back_inserter(sample_indices_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), sample_indices_handles.data(), static_cast<int>(sample_indices.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> embedding_indices_handles; embedding_indices_handles.reserve(embedding_indices.size());
    std::transform(embedding_indices.begin(), embedding_indices.end(), std::back_inserter(embedding_indices_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), embedding_indices_handles.data(), static_cast<int>(embedding_indices.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> aggregation_weights_handles; aggregation_weights_handles.reserve(aggregation_weights.size());
    std::transform(aggregation_weights.begin(), aggregation_weights.end(), std::back_inserter(aggregation_weights_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), aggregation_weights_handles.data(), static_cast<int>(aggregation_weights.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mode_override.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", sample_indices.size());
    
    std::vector<std::size_t> combiners_sizes; combiners_sizes.reserve(combiners.size());
    std::transform(combiners.begin(), combiners.end(), std::back_inserter(combiners_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "combiners", reinterpret_cast<const void *const *>(combiners.data()), combiners_sizes.data(), static_cast<int>(combiners.size()));
    
    TFE_OpSetAttrIntList(op.get(), "table_ids", table_ids.data(), static_cast<int>(table_ids.size()));
    TFE_OpSetAttrIntList(op.get(), "max_sequence_lengths", max_sequence_lengths.data(), static_cast<int>(max_sequence_lengths.size()));
    TFE_OpSetAttrIntList(op.get(), "num_features", num_features.data(), static_cast<int>(num_features.size()));
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "T3", T3);
    TFE_OpSetAttrInt(op.get(), "device_ordinal", device_ordinal);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # EnsureShape
# Inputs:
*    input

# Attributes:
*    shape

# Outputs:
*    output

*/
inline tensor ensure_shape(const tensor& input, const std::vector<int64_t>& shape) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EnsureShape", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), static_cast<int>(shape.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Enter
# Inputs:
*    data

# Attributes:
*    frame_name
*    is_constant
*    parallel_iterations

# Outputs:
*    output

*/
inline tensor enter(const tensor& data, const std::string& frame_name, bool is_constant=false, int64_t parallel_iterations=10) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Enter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "frame_name", (void*) frame_name.c_str(), frame_name.size());
    TFE_OpSetAttrBool(op.get(), "is_constant", (unsigned char)is_constant);
    TFE_OpSetAttrInt(op.get(), "parallel_iterations", parallel_iterations);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Equal
# Inputs:
*    x
*    y

# Attributes:
*    incompatible_shape_error

# Outputs:
*    z

*/
inline tensor equal(const tensor& x, const tensor& y, bool incompatible_shape_error=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Equal", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "incompatible_shape_error", (unsigned char)incompatible_shape_error);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Erf
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor erf(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Erf", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Erfc
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor erfc(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Erfc", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Erfinv
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor erfinv(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Erfinv", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # EuclideanNorm
# Inputs:
*    input
*    reduction_indices

# Attributes:
*    keep_dims
*    Tidx

# Outputs:
*    output

*/
inline tensor euclidean_norm(const tensor& input, const tensor& reduction_indices, bool keep_dims=false, datatype Tidx=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EuclideanNorm", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reduction_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "keep_dims", (unsigned char)keep_dims);
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Exit
# Inputs:
*    data

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor exit(const tensor& data) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Exit", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Exp
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor exp(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Exp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExpandDims
# Inputs:
*    input
*    dim

# Attributes:
*    Tdim

# Outputs:
*    output

*/
inline tensor expand_dims(const tensor& input, const tensor& dim, datatype Tdim=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExpandDims", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dim.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tdim", Tdim);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalAssertNextDataset
# Inputs:
*    input_dataset
*    transformations

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor experimental_assert_next_dataset(const tensor& input_dataset, const tensor& transformations, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalAssertNextDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), transformations.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalAutoShardDataset
# Inputs:
*    input_dataset
*    num_workers
*    index

# Attributes:
*    output_types
*    output_shapes
*    auto_shard_policy

# Outputs:
*    handle

*/
inline tensor experimental_auto_shard_dataset(const tensor& input_dataset, const tensor& num_workers, const tensor& index, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, int64_t auto_shard_policy=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalAutoShardDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_workers.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), index.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "auto_shard_policy", auto_shard_policy);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalBytesProducedStatsDataset
# Inputs:
*    input_dataset
*    tag

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor experimental_bytes_produced_stats_dataset(const tensor& input_dataset, const tensor& tag, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalBytesProducedStatsDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tag.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalCSVDataset
# Inputs:
*    filenames
*    compression_type
*    buffer_size
*    header
*    field_delim
*    use_quote_delim
*    na_value
*    select_cols
*    record_defaults

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor experimental_c_s_v_dataset(const tensor& filenames, const tensor& compression_type, const tensor& buffer_size, const tensor& header, const tensor& field_delim, const tensor& use_quote_delim, const tensor& na_value, const tensor& select_cols, const std::vector<tensor>&record_defaults, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalCSVDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filenames.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), compression_type.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), header.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), field_delim.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), use_quote_delim.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), na_value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), select_cols.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> record_defaults_handles; record_defaults_handles.reserve(record_defaults.size());
    std::transform(record_defaults.begin(), record_defaults.end(), std::back_inserter(record_defaults_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), record_defaults_handles.data(), static_cast<int>(record_defaults.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalChooseFastestDataset
# Inputs:
*    input_datasets

# Attributes:
*    N
*    num_experiments
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor experimental_choose_fastest_dataset(const std::vector<tensor>&input_datasets, int64_t num_experiments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalChooseFastestDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> input_datasets_handles; input_datasets_handles.reserve(input_datasets.size());
    std::transform(input_datasets.begin(), input_datasets.end(), std::back_inserter(input_datasets_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), input_datasets_handles.data(), static_cast<int>(input_datasets.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", input_datasets.size());
    TFE_OpSetAttrInt(op.get(), "num_experiments", num_experiments);
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalDatasetCardinality
# Inputs:
*    input_dataset

# Attributes:
*    
# Outputs:
*    cardinality

*/
inline tensor experimental_dataset_cardinality(const tensor& input_dataset) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalDatasetCardinality", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalDatasetToTFRecord
# Inputs:
*    input_dataset
*    filename
*    compression_type

# Attributes:
*    
# Outputs:
*    
*/
inline void experimental_dataset_to_t_f_record(const tensor& input_dataset, const tensor& filename, const tensor& compression_type) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalDatasetToTFRecord", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filename.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), compression_type.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ExperimentalDenseToSparseBatchDataset
# Inputs:
*    input_dataset
*    batch_size
*    row_shape

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor experimental_dense_to_sparse_batch_dataset(const tensor& input_dataset, const tensor& batch_size, const tensor& row_shape, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalDenseToSparseBatchDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), batch_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), row_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalDirectedInterleaveDataset
# Inputs:
*    selector_input_dataset
*    data_input_datasets

# Attributes:
*    output_types
*    output_shapes
*    N

# Outputs:
*    handle

*/
inline tensor experimental_directed_interleave_dataset(const tensor& selector_input_dataset, const std::vector<tensor>&data_input_datasets, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalDirectedInterleaveDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), selector_input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> data_input_datasets_handles; data_input_datasets_handles.reserve(data_input_datasets.size());
    std::transform(data_input_datasets.begin(), data_input_datasets.end(), std::back_inserter(data_input_datasets_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), data_input_datasets_handles.data(), static_cast<int>(data_input_datasets.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "N", data_input_datasets.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalGroupByReducerDataset
# Inputs:
*    input_dataset
*    key_func_other_arguments
*    init_func_other_arguments
*    reduce_func_other_arguments
*    finalize_func_other_arguments

# Attributes:
*    key_func
*    init_func
*    reduce_func
*    finalize_func
*    Tkey_func_other_arguments
*    Tinit_func_other_arguments
*    Treduce_func_other_arguments
*    Tfinalize_func_other_arguments
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor experimental_group_by_reducer_dataset(const tensor& input_dataset, const std::vector<tensor>&key_func_other_arguments, const std::vector<tensor>&init_func_other_arguments, const std::vector<tensor>&reduce_func_other_arguments, const std::vector<tensor>&finalize_func_other_arguments, int64_t key_func, int64_t init_func, int64_t reduce_func, int64_t finalize_func, const std::vector<datatype>& Tkey_func_other_arguments, const std::vector<datatype>& Tinit_func_other_arguments, const std::vector<datatype>& Treduce_func_other_arguments, const std::vector<datatype>& Tfinalize_func_other_arguments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalGroupByReducerDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> key_func_other_arguments_handles; key_func_other_arguments_handles.reserve(key_func_other_arguments.size());
    std::transform(key_func_other_arguments.begin(), key_func_other_arguments.end(), std::back_inserter(key_func_other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), key_func_other_arguments_handles.data(), static_cast<int>(key_func_other_arguments.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> init_func_other_arguments_handles; init_func_other_arguments_handles.reserve(init_func_other_arguments.size());
    std::transform(init_func_other_arguments.begin(), init_func_other_arguments.end(), std::back_inserter(init_func_other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), init_func_other_arguments_handles.data(), static_cast<int>(init_func_other_arguments.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> reduce_func_other_arguments_handles; reduce_func_other_arguments_handles.reserve(reduce_func_other_arguments.size());
    std::transform(reduce_func_other_arguments.begin(), reduce_func_other_arguments.end(), std::back_inserter(reduce_func_other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), reduce_func_other_arguments_handles.data(), static_cast<int>(reduce_func_other_arguments.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> finalize_func_other_arguments_handles; finalize_func_other_arguments_handles.reserve(finalize_func_other_arguments.size());
    std::transform(finalize_func_other_arguments.begin(), finalize_func_other_arguments.end(), std::back_inserter(finalize_func_other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), finalize_func_other_arguments_handles.data(), static_cast<int>(finalize_func_other_arguments.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "key_func", key_func);
    TFE_OpSetAttrInt(op.get(), "init_func", init_func);
    TFE_OpSetAttrInt(op.get(), "reduce_func", reduce_func);
    TFE_OpSetAttrInt(op.get(), "finalize_func", finalize_func);
    TFE_OpSetAttrTypeList(op.get(), "Tkey_func_other_arguments", reinterpret_cast<const enum TF_DataType *>(Tkey_func_other_arguments.data()), static_cast<int>(Tkey_func_other_arguments.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tinit_func_other_arguments", reinterpret_cast<const enum TF_DataType *>(Tinit_func_other_arguments.data()), static_cast<int>(Tinit_func_other_arguments.size()));
    TFE_OpSetAttrTypeList(op.get(), "Treduce_func_other_arguments", reinterpret_cast<const enum TF_DataType *>(Treduce_func_other_arguments.data()), static_cast<int>(Treduce_func_other_arguments.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tfinalize_func_other_arguments", reinterpret_cast<const enum TF_DataType *>(Tfinalize_func_other_arguments.data()), static_cast<int>(Tfinalize_func_other_arguments.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalGroupByWindowDataset
# Inputs:
*    input_dataset
*    key_func_other_arguments
*    reduce_func_other_arguments
*    window_size_func_other_arguments

# Attributes:
*    key_func
*    reduce_func
*    window_size_func
*    Tkey_func_other_arguments
*    Treduce_func_other_arguments
*    Twindow_size_func_other_arguments
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor experimental_group_by_window_dataset(const tensor& input_dataset, const std::vector<tensor>&key_func_other_arguments, const std::vector<tensor>&reduce_func_other_arguments, const std::vector<tensor>&window_size_func_other_arguments, int64_t key_func, int64_t reduce_func, int64_t window_size_func, const std::vector<datatype>& Tkey_func_other_arguments, const std::vector<datatype>& Treduce_func_other_arguments, const std::vector<datatype>& Twindow_size_func_other_arguments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalGroupByWindowDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> key_func_other_arguments_handles; key_func_other_arguments_handles.reserve(key_func_other_arguments.size());
    std::transform(key_func_other_arguments.begin(), key_func_other_arguments.end(), std::back_inserter(key_func_other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), key_func_other_arguments_handles.data(), static_cast<int>(key_func_other_arguments.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> reduce_func_other_arguments_handles; reduce_func_other_arguments_handles.reserve(reduce_func_other_arguments.size());
    std::transform(reduce_func_other_arguments.begin(), reduce_func_other_arguments.end(), std::back_inserter(reduce_func_other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), reduce_func_other_arguments_handles.data(), static_cast<int>(reduce_func_other_arguments.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> window_size_func_other_arguments_handles; window_size_func_other_arguments_handles.reserve(window_size_func_other_arguments.size());
    std::transform(window_size_func_other_arguments.begin(), window_size_func_other_arguments.end(), std::back_inserter(window_size_func_other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), window_size_func_other_arguments_handles.data(), static_cast<int>(window_size_func_other_arguments.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "key_func", key_func);
    TFE_OpSetAttrInt(op.get(), "reduce_func", reduce_func);
    TFE_OpSetAttrInt(op.get(), "window_size_func", window_size_func);
    TFE_OpSetAttrTypeList(op.get(), "Tkey_func_other_arguments", reinterpret_cast<const enum TF_DataType *>(Tkey_func_other_arguments.data()), static_cast<int>(Tkey_func_other_arguments.size()));
    TFE_OpSetAttrTypeList(op.get(), "Treduce_func_other_arguments", reinterpret_cast<const enum TF_DataType *>(Treduce_func_other_arguments.data()), static_cast<int>(Treduce_func_other_arguments.size()));
    TFE_OpSetAttrTypeList(op.get(), "Twindow_size_func_other_arguments", reinterpret_cast<const enum TF_DataType *>(Twindow_size_func_other_arguments.data()), static_cast<int>(Twindow_size_func_other_arguments.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalIgnoreErrorsDataset
# Inputs:
*    input_dataset

# Attributes:
*    output_types
*    output_shapes
*    log_warning

# Outputs:
*    handle

*/
inline tensor experimental_ignore_errors_dataset(const tensor& input_dataset, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool log_warning=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalIgnoreErrorsDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "log_warning", (unsigned char)log_warning);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalIteratorGetDevice
# Inputs:
*    resource

# Attributes:
*    
# Outputs:
*    device

*/
inline tensor experimental_iterator_get_device(const tensor& resource) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalIteratorGetDevice", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalLMDBDataset
# Inputs:
*    filenames

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor experimental_l_m_d_b_dataset(const tensor& filenames, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalLMDBDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filenames.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalLatencyStatsDataset
# Inputs:
*    input_dataset
*    tag

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor experimental_latency_stats_dataset(const tensor& input_dataset, const tensor& tag, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalLatencyStatsDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tag.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalMapAndBatchDataset
# Inputs:
*    input_dataset
*    other_arguments
*    batch_size
*    num_parallel_calls
*    drop_remainder

# Attributes:
*    f
*    Targuments
*    output_types
*    output_shapes
*    preserve_cardinality

# Outputs:
*    handle

*/
inline tensor experimental_map_and_batch_dataset(const tensor& input_dataset, const std::vector<tensor>&other_arguments, const tensor& batch_size, const tensor& num_parallel_calls, const tensor& drop_remainder, int64_t f, const std::vector<datatype>& Targuments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool preserve_cardinality=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalMapAndBatchDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> other_arguments_handles; other_arguments_handles.reserve(other_arguments.size());
    std::transform(other_arguments.begin(), other_arguments.end(), std::back_inserter(other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), other_arguments_handles.data(), static_cast<int>(other_arguments.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), batch_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_parallel_calls.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), drop_remainder.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "f", f);
    TFE_OpSetAttrTypeList(op.get(), "Targuments", reinterpret_cast<const enum TF_DataType *>(Targuments.data()), static_cast<int>(Targuments.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "preserve_cardinality", (unsigned char)preserve_cardinality);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalMapDataset
# Inputs:
*    input_dataset
*    other_arguments

# Attributes:
*    f
*    Targuments
*    output_types
*    output_shapes
*    use_inter_op_parallelism
*    preserve_cardinality

# Outputs:
*    handle

*/
inline tensor experimental_map_dataset(const tensor& input_dataset, const std::vector<tensor>&other_arguments, int64_t f, const std::vector<datatype>& Targuments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool use_inter_op_parallelism=true, bool preserve_cardinality=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalMapDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> other_arguments_handles; other_arguments_handles.reserve(other_arguments.size());
    std::transform(other_arguments.begin(), other_arguments.end(), std::back_inserter(other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), other_arguments_handles.data(), static_cast<int>(other_arguments.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "f", f);
    TFE_OpSetAttrTypeList(op.get(), "Targuments", reinterpret_cast<const enum TF_DataType *>(Targuments.data()), static_cast<int>(Targuments.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "use_inter_op_parallelism", (unsigned char)use_inter_op_parallelism);
    TFE_OpSetAttrBool(op.get(), "preserve_cardinality", (unsigned char)preserve_cardinality);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalMatchingFilesDataset
# Inputs:
*    patterns

# Attributes:
*    
# Outputs:
*    handle

*/
inline tensor experimental_matching_files_dataset(const tensor& patterns) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalMatchingFilesDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), patterns.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalMaxIntraOpParallelismDataset
# Inputs:
*    input_dataset
*    max_intra_op_parallelism

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor experimental_max_intra_op_parallelism_dataset(const tensor& input_dataset, const tensor& max_intra_op_parallelism, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalMaxIntraOpParallelismDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_intra_op_parallelism.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalNonSerializableDataset
# Inputs:
*    input_dataset

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor experimental_non_serializable_dataset(const tensor& input_dataset, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalNonSerializableDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalParallelInterleaveDataset
# Inputs:
*    input_dataset
*    other_arguments
*    cycle_length
*    block_length
*    sloppy
*    buffer_output_elements
*    prefetch_input_elements

# Attributes:
*    f
*    Targuments
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor experimental_parallel_interleave_dataset(const tensor& input_dataset, const std::vector<tensor>&other_arguments, const tensor& cycle_length, const tensor& block_length, const tensor& sloppy, const tensor& buffer_output_elements, const tensor& prefetch_input_elements, int64_t f, const std::vector<datatype>& Targuments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalParallelInterleaveDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> other_arguments_handles; other_arguments_handles.reserve(other_arguments.size());
    std::transform(other_arguments.begin(), other_arguments.end(), std::back_inserter(other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), other_arguments_handles.data(), static_cast<int>(other_arguments.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cycle_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), block_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sloppy.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_output_elements.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), prefetch_input_elements.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "f", f);
    TFE_OpSetAttrTypeList(op.get(), "Targuments", reinterpret_cast<const enum TF_DataType *>(Targuments.data()), static_cast<int>(Targuments.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalParseExampleDataset
# Inputs:
*    input_dataset
*    num_parallel_calls
*    dense_defaults

# Attributes:
*    sparse_keys
*    dense_keys
*    sparse_types
*    Tdense
*    dense_shapes
*    output_types
*    output_shapes
*    sloppy

# Outputs:
*    handle

*/
inline tensor experimental_parse_example_dataset(const tensor& input_dataset, const tensor& num_parallel_calls, const std::vector<tensor>&dense_defaults, const std::vector< std::string>& sparse_keys, const std::vector< std::string>& dense_keys, const std::vector<datatype>& sparse_types, const std::vector<datatype>& Tdense, const std::vector< std::vector<int64_t>>& dense_shapes, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool sloppy=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalParseExampleDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_parallel_calls.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_defaults_handles; dense_defaults_handles.reserve(dense_defaults.size());
    std::transform(dense_defaults.begin(), dense_defaults.end(), std::back_inserter(dense_defaults_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), dense_defaults_handles.data(), static_cast<int>(dense_defaults.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> sparse_keys_sizes; sparse_keys_sizes.reserve(sparse_keys.size());
    std::transform(sparse_keys.begin(), sparse_keys.end(), std::back_inserter(sparse_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "sparse_keys", reinterpret_cast<const void *const *>(sparse_keys.data()), sparse_keys_sizes.data(), static_cast<int>(sparse_keys.size()));
    
    
    std::vector<std::size_t> dense_keys_sizes; dense_keys_sizes.reserve(dense_keys.size());
    std::transform(dense_keys.begin(), dense_keys.end(), std::back_inserter(dense_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "dense_keys", reinterpret_cast<const void *const *>(dense_keys.data()), dense_keys_sizes.data(), static_cast<int>(dense_keys.size()));
    
    TFE_OpSetAttrTypeList(op.get(), "sparse_types", reinterpret_cast<const enum TF_DataType *>(sparse_types.data()), static_cast<int>(sparse_types.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tdense", reinterpret_cast<const enum TF_DataType *>(Tdense.data()), static_cast<int>(Tdense.size()));
    
    std::vector<const int64_t*> dense_shapes_values; dense_shapes_values.reserve(dense_shapes.size());
    std::vector<int> dense_shapes_ndims; dense_shapes_ndims.reserve(dense_shapes.size());
    std::transform(dense_shapes.begin(), dense_shapes.end(), std::back_inserter(dense_shapes_values), [](const auto& v) { return v.data();});
    std::transform(dense_shapes.begin(), dense_shapes.end(), std::back_inserter(dense_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "dense_shapes", dense_shapes_values.data(), dense_shapes_ndims.data(), static_cast<int>(dense_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "sloppy", (unsigned char)sloppy);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalPrivateThreadPoolDataset
# Inputs:
*    input_dataset
*    num_threads

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor experimental_private_thread_pool_dataset(const tensor& input_dataset, const tensor& num_threads, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalPrivateThreadPoolDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_threads.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalRandomDataset
# Inputs:
*    seed
*    seed2

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor experimental_random_dataset(const tensor& seed, const tensor& seed2, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalRandomDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), seed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalRebatchDataset
# Inputs:
*    input_dataset
*    num_replicas

# Attributes:
*    output_types
*    output_shapes
*    use_fallback

# Outputs:
*    handle

*/
inline tensor experimental_rebatch_dataset(const tensor& input_dataset, const tensor& num_replicas, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool use_fallback=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalRebatchDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_replicas.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "use_fallback", (unsigned char)use_fallback);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalScanDataset
# Inputs:
*    input_dataset
*    initial_state
*    other_arguments

# Attributes:
*    f
*    Tstate
*    Targuments
*    output_types
*    output_shapes
*    preserve_cardinality

# Outputs:
*    handle

*/
inline tensor experimental_scan_dataset(const tensor& input_dataset, const std::vector<tensor>&initial_state, const std::vector<tensor>&other_arguments, int64_t f, const std::vector<datatype>& Tstate, const std::vector<datatype>& Targuments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool preserve_cardinality=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalScanDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> initial_state_handles; initial_state_handles.reserve(initial_state.size());
    std::transform(initial_state.begin(), initial_state.end(), std::back_inserter(initial_state_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), initial_state_handles.data(), static_cast<int>(initial_state.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> other_arguments_handles; other_arguments_handles.reserve(other_arguments.size());
    std::transform(other_arguments.begin(), other_arguments.end(), std::back_inserter(other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), other_arguments_handles.data(), static_cast<int>(other_arguments.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "f", f);
    TFE_OpSetAttrTypeList(op.get(), "Tstate", reinterpret_cast<const enum TF_DataType *>(Tstate.data()), static_cast<int>(Tstate.size()));
    TFE_OpSetAttrTypeList(op.get(), "Targuments", reinterpret_cast<const enum TF_DataType *>(Targuments.data()), static_cast<int>(Targuments.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "preserve_cardinality", (unsigned char)preserve_cardinality);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalSetStatsAggregatorDataset
# Inputs:
*    input_dataset
*    stats_aggregator
*    tag
*    counter_prefix

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor experimental_set_stats_aggregator_dataset(const tensor& input_dataset, const tensor& stats_aggregator, const tensor& tag, const tensor& counter_prefix, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalSetStatsAggregatorDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), stats_aggregator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tag.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), counter_prefix.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalSleepDataset
# Inputs:
*    input_dataset
*    sleep_microseconds

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor experimental_sleep_dataset(const tensor& input_dataset, const tensor& sleep_microseconds, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalSleepDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sleep_microseconds.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalSlidingWindowDataset
# Inputs:
*    input_dataset
*    window_size
*    window_shift
*    window_stride

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor experimental_sliding_window_dataset(const tensor& input_dataset, const tensor& window_size, const tensor& window_shift, const tensor& window_stride, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalSlidingWindowDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), window_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), window_shift.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), window_stride.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalSqlDataset
# Inputs:
*    driver_name
*    data_source_name
*    query

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor experimental_sql_dataset(const tensor& driver_name, const tensor& data_source_name, const tensor& query, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalSqlDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), driver_name.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), data_source_name.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), query.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalStatsAggregatorHandle
# Inputs:
*    
# Attributes:
*    container
*    shared_name

# Outputs:
*    handle

*/
inline tensor experimental_stats_aggregator_handle(const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalStatsAggregatorHandle", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalStatsAggregatorSummary
# Inputs:
*    iterator

# Attributes:
*    
# Outputs:
*    summary

*/
inline tensor experimental_stats_aggregator_summary(const tensor& iterator) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalStatsAggregatorSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), iterator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalTakeWhileDataset
# Inputs:
*    input_dataset
*    other_arguments

# Attributes:
*    predicate
*    Targuments
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor experimental_take_while_dataset(const tensor& input_dataset, const std::vector<tensor>&other_arguments, int64_t predicate, const std::vector<datatype>& Targuments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalTakeWhileDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> other_arguments_handles; other_arguments_handles.reserve(other_arguments.size());
    std::transform(other_arguments.begin(), other_arguments.end(), std::back_inserter(other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), other_arguments_handles.data(), static_cast<int>(other_arguments.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "predicate", predicate);
    TFE_OpSetAttrTypeList(op.get(), "Targuments", reinterpret_cast<const enum TF_DataType *>(Targuments.data()), static_cast<int>(Targuments.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalThreadPoolDataset
# Inputs:
*    input_dataset
*    thread_pool

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor experimental_thread_pool_dataset(const tensor& input_dataset, const tensor& thread_pool, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalThreadPoolDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), thread_pool.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalThreadPoolHandle
# Inputs:
*    
# Attributes:
*    num_threads
*    display_name
*    max_intra_op_parallelism
*    container
*    shared_name

# Outputs:
*    handle

*/
inline tensor experimental_thread_pool_handle(int64_t num_threads, const std::string& display_name, int64_t max_intra_op_parallelism=1, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalThreadPoolHandle", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_threads", num_threads);
    TFE_OpSetAttrString(op.get(), "display_name", (void*) display_name.c_str(), display_name.size());
    TFE_OpSetAttrInt(op.get(), "max_intra_op_parallelism", max_intra_op_parallelism);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalUnbatchDataset
# Inputs:
*    input_dataset

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor experimental_unbatch_dataset(const tensor& input_dataset, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalUnbatchDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExperimentalUniqueDataset
# Inputs:
*    input_dataset

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor experimental_unique_dataset(const tensor& input_dataset, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalUniqueDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Expint
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor expint(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Expint", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Expm1
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor expm1(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Expm1", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExtractGlimpse
# Inputs:
*    input
*    size
*    offsets

# Attributes:
*    centered
*    normalized
*    uniform_noise
*    noise

# Outputs:
*    glimpse

*/
inline tensor extract_glimpse(const tensor& input, const tensor& size, const tensor& offsets, bool centered=true, bool normalized=true, bool uniform_noise=true, const std::string& noise="uniform") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExtractGlimpse", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), offsets.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "centered", (unsigned char)centered);
    TFE_OpSetAttrBool(op.get(), "normalized", (unsigned char)normalized);
    TFE_OpSetAttrBool(op.get(), "uniform_noise", (unsigned char)uniform_noise);
    TFE_OpSetAttrString(op.get(), "noise", (void*) noise.c_str(), noise.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExtractGlimpseV2
# Inputs:
*    input
*    size
*    offsets

# Attributes:
*    centered
*    normalized
*    uniform_noise
*    noise

# Outputs:
*    glimpse

*/
inline tensor extract_glimpse_v2(const tensor& input, const tensor& size, const tensor& offsets, bool centered=true, bool normalized=true, bool uniform_noise=true, const std::string& noise="uniform") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExtractGlimpseV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), offsets.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "centered", (unsigned char)centered);
    TFE_OpSetAttrBool(op.get(), "normalized", (unsigned char)normalized);
    TFE_OpSetAttrBool(op.get(), "uniform_noise", (unsigned char)uniform_noise);
    TFE_OpSetAttrString(op.get(), "noise", (void*) noise.c_str(), noise.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExtractImagePatches
# Inputs:
*    images

# Attributes:
*    ksizes
*    strides
*    rates
*    padding

# Outputs:
*    patches

*/
inline tensor extract_image_patches(const tensor& images, const std::vector<int64_t>& ksizes, const std::vector<int64_t>& strides, const std::vector<int64_t>& rates, const std::string& padding) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExtractImagePatches", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksizes", ksizes.data(), static_cast<int>(ksizes.size()));
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrIntList(op.get(), "rates", rates.data(), static_cast<int>(rates.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExtractJpegShape
# Inputs:
*    contents

# Attributes:
*    output_type

# Outputs:
*    image_shape

*/
inline tensor extract_jpeg_shape(const tensor& contents, datatype output_type=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExtractJpegShape", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), contents.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "output_type", output_type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ExtractVolumePatches
# Inputs:
*    input

# Attributes:
*    ksizes
*    strides
*    padding

# Outputs:
*    patches

*/
inline tensor extract_volume_patches(const tensor& input, const std::vector<int64_t>& ksizes, const std::vector<int64_t>& strides, const std::string& padding) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExtractVolumePatches", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksizes", ksizes.data(), static_cast<int>(ksizes.size()));
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FFT
# Inputs:
*    input

# Attributes:
*    Tcomplex

# Outputs:
*    output

*/
inline tensor FFT(const tensor& input, datatype Tcomplex=static_cast<datatype>(8)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FFT", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FFT2D
# Inputs:
*    input

# Attributes:
*    Tcomplex

# Outputs:
*    output

*/
inline tensor FFT2D(const tensor& input, datatype Tcomplex=static_cast<datatype>(8)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FFT2D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FFT3D
# Inputs:
*    input

# Attributes:
*    Tcomplex

# Outputs:
*    output

*/
inline tensor FFT3D(const tensor& input, datatype Tcomplex=static_cast<datatype>(8)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FFT3D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FFTND
# Inputs:
*    input
*    fft_length
*    axes

# Attributes:
*    Tcomplex

# Outputs:
*    output

*/
inline tensor FFTND(const tensor& input, const tensor& fft_length, const tensor& axes, datatype Tcomplex=static_cast<datatype>(8)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FFTND", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), fft_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), axes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FIFOQueue
# Inputs:
*    
# Attributes:
*    component_types
*    shapes
*    capacity
*    container
*    shared_name

# Outputs:
*    handle

*/
inline tensor f_i_f_o_queue(const std::vector<datatype>& component_types, const std::vector< std::vector<int64_t>>& shapes, int64_t capacity=-1, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FIFOQueue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), static_cast<int>(component_types.size()));
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), static_cast<int>(shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FIFOQueueV2
# Inputs:
*    
# Attributes:
*    component_types
*    shapes
*    capacity
*    container
*    shared_name

# Outputs:
*    handle

*/
inline tensor f_i_f_o_queue_v2(const std::vector<datatype>& component_types, const std::vector< std::vector<int64_t>>& shapes, int64_t capacity=-1, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FIFOQueueV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), static_cast<int>(component_types.size()));
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), static_cast<int>(shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Fact
# Inputs:
*    
# Attributes:
*    
# Outputs:
*    fact

*/
inline tensor fact() {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Fact", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FakeParam
# Inputs:
*    
# Attributes:
*    dtype
*    shape

# Outputs:
*    output

*/
inline tensor fake_param(datatype dtype, const std::vector<int64_t>& shape) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FakeParam", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), static_cast<int>(shape.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FakeQuantWithMinMaxArgs
# Inputs:
*    inputs

# Attributes:
*    min
*    max
*    num_bits
*    narrow_range

# Outputs:
*    outputs

*/
inline tensor fake_quant_with_min_max_args(const tensor& inputs, float min=-6.0000e+00, float max=6.0000e+00, int64_t num_bits=8, bool narrow_range=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FakeQuantWithMinMaxArgs", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), inputs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "min", min);
    TFE_OpSetAttrFloat(op.get(), "max", max);
    TFE_OpSetAttrInt(op.get(), "num_bits", num_bits);
    TFE_OpSetAttrBool(op.get(), "narrow_range", (unsigned char)narrow_range);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FakeQuantWithMinMaxArgsGradient
# Inputs:
*    gradients
*    inputs

# Attributes:
*    min
*    max
*    num_bits
*    narrow_range

# Outputs:
*    backprops

*/
inline tensor fake_quant_with_min_max_args_gradient(const tensor& gradients, const tensor& inputs, float min=-6.0000e+00, float max=6.0000e+00, int64_t num_bits=8, bool narrow_range=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FakeQuantWithMinMaxArgsGradient", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), gradients.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), inputs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "min", min);
    TFE_OpSetAttrFloat(op.get(), "max", max);
    TFE_OpSetAttrInt(op.get(), "num_bits", num_bits);
    TFE_OpSetAttrBool(op.get(), "narrow_range", (unsigned char)narrow_range);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FakeQuantWithMinMaxVars
# Inputs:
*    inputs
*    min
*    max

# Attributes:
*    num_bits
*    narrow_range

# Outputs:
*    outputs

*/
inline tensor fake_quant_with_min_max_vars(const tensor& inputs, const tensor& min, const tensor& max, int64_t num_bits=8, bool narrow_range=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FakeQuantWithMinMaxVars", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), inputs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_bits", num_bits);
    TFE_OpSetAttrBool(op.get(), "narrow_range", (unsigned char)narrow_range);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FakeQuantWithMinMaxVarsGradient
# Inputs:
*    gradients
*    inputs
*    min
*    max

# Attributes:
*    num_bits
*    narrow_range

# Outputs:
*    backprops_wrt_input
*    backprop_wrt_min
*    backprop_wrt_max

*/
inline std::vector<tensor> fake_quant_with_min_max_vars_gradient(const tensor& gradients, const tensor& inputs, const tensor& min, const tensor& max, int64_t num_bits=8, bool narrow_range=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FakeQuantWithMinMaxVarsGradient", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), gradients.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), inputs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_bits", num_bits);
    TFE_OpSetAttrBool(op.get(), "narrow_range", (unsigned char)narrow_range);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # FakeQuantWithMinMaxVarsPerChannel
# Inputs:
*    inputs
*    min
*    max

# Attributes:
*    num_bits
*    narrow_range

# Outputs:
*    outputs

*/
inline tensor fake_quant_with_min_max_vars_per_channel(const tensor& inputs, const tensor& min, const tensor& max, int64_t num_bits=8, bool narrow_range=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FakeQuantWithMinMaxVarsPerChannel", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), inputs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_bits", num_bits);
    TFE_OpSetAttrBool(op.get(), "narrow_range", (unsigned char)narrow_range);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FakeQuantWithMinMaxVarsPerChannelGradient
# Inputs:
*    gradients
*    inputs
*    min
*    max

# Attributes:
*    num_bits
*    narrow_range

# Outputs:
*    backprops_wrt_input
*    backprop_wrt_min
*    backprop_wrt_max

*/
inline std::vector<tensor> fake_quant_with_min_max_vars_per_channel_gradient(const tensor& gradients, const tensor& inputs, const tensor& min, const tensor& max, int64_t num_bits=8, bool narrow_range=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FakeQuantWithMinMaxVarsPerChannelGradient", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), gradients.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), inputs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_bits", num_bits);
    TFE_OpSetAttrBool(op.get(), "narrow_range", (unsigned char)narrow_range);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # FakeQueue
# Inputs:
*    resource

# Attributes:
*    
# Outputs:
*    handle

*/
inline tensor fake_queue(const tensor& resource) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FakeQueue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FileSystemSetConfiguration
# Inputs:
*    scheme
*    key
*    value

# Attributes:
*    
# Outputs:
*    
*/
inline void file_system_set_configuration(const tensor& scheme, const tensor& key, const tensor& value) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FileSystemSetConfiguration", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), scheme.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # Fill
# Inputs:
*    dims
*    value

# Attributes:
*    index_type

# Outputs:
*    output

*/
inline tensor fill(const tensor& dims, const tensor& value, datatype index_type=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Fill", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), dims.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "index_type", index_type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FilterByLastComponentDataset
# Inputs:
*    input_dataset

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    output

*/
inline tensor filter_by_last_component_dataset(const tensor& input_dataset, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FilterByLastComponentDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FilterDataset
# Inputs:
*    input_dataset
*    other_arguments

# Attributes:
*    predicate
*    Targuments
*    output_types
*    output_shapes
*    metadata

# Outputs:
*    handle

*/
inline tensor filter_dataset(const tensor& input_dataset, const std::vector<tensor>&other_arguments, int64_t predicate, const std::vector<datatype>& Targuments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FilterDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> other_arguments_handles; other_arguments_handles.reserve(other_arguments.size());
    std::transform(other_arguments.begin(), other_arguments.end(), std::back_inserter(other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), other_arguments_handles.data(), static_cast<int>(other_arguments.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "predicate", predicate);
    TFE_OpSetAttrTypeList(op.get(), "Targuments", reinterpret_cast<const enum TF_DataType *>(Targuments.data()), static_cast<int>(Targuments.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FinalizeDataset
# Inputs:
*    input_dataset

# Attributes:
*    output_types
*    output_shapes
*    has_captured_ref

# Outputs:
*    handle

*/
inline tensor finalize_dataset(const tensor& input_dataset, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool has_captured_ref=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FinalizeDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "has_captured_ref", (unsigned char)has_captured_ref);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Fingerprint
# Inputs:
*    data
*    method

# Attributes:
*    
# Outputs:
*    fingerprint

*/
inline tensor fingerprint(const tensor& data, const tensor& method) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Fingerprint", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), method.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FixedLengthRecordDataset
# Inputs:
*    filenames
*    header_bytes
*    record_bytes
*    footer_bytes
*    buffer_size

# Attributes:
*    metadata

# Outputs:
*    handle

*/
inline tensor fixed_length_record_dataset(const tensor& filenames, const tensor& header_bytes, const tensor& record_bytes, const tensor& footer_bytes, const tensor& buffer_size, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FixedLengthRecordDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filenames.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), header_bytes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), record_bytes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), footer_bytes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FixedLengthRecordDatasetV2
# Inputs:
*    filenames
*    header_bytes
*    record_bytes
*    footer_bytes
*    buffer_size
*    compression_type

# Attributes:
*    metadata

# Outputs:
*    handle

*/
inline tensor fixed_length_record_dataset_v2(const tensor& filenames, const tensor& header_bytes, const tensor& record_bytes, const tensor& footer_bytes, const tensor& buffer_size, const tensor& compression_type, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FixedLengthRecordDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filenames.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), header_bytes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), record_bytes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), footer_bytes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), compression_type.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FixedLengthRecordReader
# Inputs:
*    
# Attributes:
*    record_bytes
*    header_bytes
*    footer_bytes
*    hop_bytes
*    container
*    shared_name

# Outputs:
*    reader_handle

*/
inline tensor fixed_length_record_reader(int64_t record_bytes, int64_t header_bytes=0, int64_t footer_bytes=0, int64_t hop_bytes=0, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FixedLengthRecordReader", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "record_bytes", record_bytes);
    TFE_OpSetAttrInt(op.get(), "header_bytes", header_bytes);
    TFE_OpSetAttrInt(op.get(), "footer_bytes", footer_bytes);
    TFE_OpSetAttrInt(op.get(), "hop_bytes", hop_bytes);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FixedLengthRecordReaderV2
# Inputs:
*    
# Attributes:
*    record_bytes
*    header_bytes
*    footer_bytes
*    hop_bytes
*    container
*    shared_name
*    encoding

# Outputs:
*    reader_handle

*/
inline tensor fixed_length_record_reader_v2(int64_t record_bytes, int64_t header_bytes=0, int64_t footer_bytes=0, int64_t hop_bytes=0, const std::string& container="", const std::string& shared_name="", const std::string& encoding="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FixedLengthRecordReaderV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "record_bytes", record_bytes);
    TFE_OpSetAttrInt(op.get(), "header_bytes", header_bytes);
    TFE_OpSetAttrInt(op.get(), "footer_bytes", footer_bytes);
    TFE_OpSetAttrInt(op.get(), "hop_bytes", hop_bytes);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrString(op.get(), "encoding", (void*) encoding.c_str(), encoding.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FixedUnigramCandidateSampler
# Inputs:
*    true_classes

# Attributes:
*    num_true
*    num_sampled
*    unique
*    range_max
*    unigrams
*    vocab_file
*    distortion
*    num_reserved_ids
*    num_shards
*    shard
*    seed
*    seed2

# Outputs:
*    sampled_candidates
*    true_expected_count
*    sampled_expected_count

*/
inline std::vector<tensor> fixed_unigram_candidate_sampler(const tensor& true_classes, int64_t num_true, int64_t num_sampled, bool unique, int64_t range_max, const std::vector<float>& unigrams, const std::string& vocab_file="", float distortion=1.0000e+00, int64_t num_reserved_ids=0, int64_t num_shards=1, int64_t shard=0, int64_t seed=0, int64_t seed2=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FixedUnigramCandidateSampler", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), true_classes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_true", num_true);
    TFE_OpSetAttrInt(op.get(), "num_sampled", num_sampled);
    TFE_OpSetAttrBool(op.get(), "unique", (unsigned char)unique);
    TFE_OpSetAttrInt(op.get(), "range_max", range_max);
    TFE_OpSetAttrFloatList(op.get(), "unigrams", unigrams.data(), static_cast<int>(unigrams.size()));
    TFE_OpSetAttrString(op.get(), "vocab_file", (void*) vocab_file.c_str(), vocab_file.size());
    TFE_OpSetAttrFloat(op.get(), "distortion", distortion);
    TFE_OpSetAttrInt(op.get(), "num_reserved_ids", num_reserved_ids);
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard", shard);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # FlatMapDataset
# Inputs:
*    input_dataset
*    other_arguments

# Attributes:
*    f
*    Targuments
*    output_types
*    output_shapes
*    metadata

# Outputs:
*    handle

*/
inline tensor flat_map_dataset(const tensor& input_dataset, const std::vector<tensor>&other_arguments, int64_t f, const std::vector<datatype>& Targuments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FlatMapDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> other_arguments_handles; other_arguments_handles.reserve(other_arguments.size());
    std::transform(other_arguments.begin(), other_arguments.end(), std::back_inserter(other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), other_arguments_handles.data(), static_cast<int>(other_arguments.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "f", f);
    TFE_OpSetAttrTypeList(op.get(), "Targuments", reinterpret_cast<const enum TF_DataType *>(Targuments.data()), static_cast<int>(Targuments.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Floor
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor floor(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Floor", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FloorDiv
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor floor_div(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FloorDiv", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FloorMod
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor floor_mod(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FloorMod", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FlushSummaryWriter
# Inputs:
*    writer

# Attributes:
*    
# Outputs:
*    
*/
inline void flush_summary_writer(const tensor& writer) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FlushSummaryWriter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), writer.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # For
# Inputs:
*    start
*    limit
*    delta
*    input

# Attributes:
*    body

# Outputs:
*    output

*/
inline tensor tfe_for(const tensor& start, const tensor& limit, const tensor& delta, const std::vector<tensor>&input, int64_t body) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "For", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), start.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), limit.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), delta.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> input_handles; input_handles.reserve(input.size());
    std::transform(input.begin(), input.end(), std::back_inserter(input_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), input_handles.data(), static_cast<int>(input.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "body", body);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FractionalAvgPool
# Inputs:
*    value

# Attributes:
*    pooling_ratio
*    pseudo_random
*    overlapping
*    deterministic
*    seed
*    seed2

# Outputs:
*    output
*    row_pooling_sequence
*    col_pooling_sequence

*/
inline std::vector<tensor> fractional_avg_pool(const tensor& value, const std::vector<float>& pooling_ratio, bool pseudo_random=false, bool overlapping=false, bool deterministic=false, int64_t seed=0, int64_t seed2=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FractionalAvgPool", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloatList(op.get(), "pooling_ratio", pooling_ratio.data(), static_cast<int>(pooling_ratio.size()));
    TFE_OpSetAttrBool(op.get(), "pseudo_random", (unsigned char)pseudo_random);
    TFE_OpSetAttrBool(op.get(), "overlapping", (unsigned char)overlapping);
    TFE_OpSetAttrBool(op.get(), "deterministic", (unsigned char)deterministic);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # FractionalAvgPoolGrad
# Inputs:
*    orig_input_tensor_shape
*    out_backprop
*    row_pooling_sequence
*    col_pooling_sequence

# Attributes:
*    overlapping

# Outputs:
*    output

*/
inline tensor fractional_avg_pool_grad(const tensor& orig_input_input_tensor_shape, const tensor& out_backprop, const tensor& row_pooling_sequence, const tensor& col_pooling_sequence, bool overlapping=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FractionalAvgPoolGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), orig_input_input_tensor_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), out_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), row_pooling_sequence.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), col_pooling_sequence.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "overlapping", (unsigned char)overlapping);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FractionalMaxPool
# Inputs:
*    value

# Attributes:
*    pooling_ratio
*    pseudo_random
*    overlapping
*    deterministic
*    seed
*    seed2

# Outputs:
*    output
*    row_pooling_sequence
*    col_pooling_sequence

*/
inline std::vector<tensor> fractional_max_pool(const tensor& value, const std::vector<float>& pooling_ratio, bool pseudo_random=false, bool overlapping=false, bool deterministic=false, int64_t seed=0, int64_t seed2=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FractionalMaxPool", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloatList(op.get(), "pooling_ratio", pooling_ratio.data(), static_cast<int>(pooling_ratio.size()));
    TFE_OpSetAttrBool(op.get(), "pseudo_random", (unsigned char)pseudo_random);
    TFE_OpSetAttrBool(op.get(), "overlapping", (unsigned char)overlapping);
    TFE_OpSetAttrBool(op.get(), "deterministic", (unsigned char)deterministic);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # FractionalMaxPoolGrad
# Inputs:
*    orig_input
*    orig_output
*    out_backprop
*    row_pooling_sequence
*    col_pooling_sequence

# Attributes:
*    overlapping

# Outputs:
*    output

*/
inline tensor fractional_max_pool_grad(const tensor& orig_input, const tensor& orig_output, const tensor& out_backprop, const tensor& row_pooling_sequence, const tensor& col_pooling_sequence, bool overlapping=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FractionalMaxPoolGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), orig_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), orig_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), out_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), row_pooling_sequence.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), col_pooling_sequence.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "overlapping", (unsigned char)overlapping);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FresnelCos
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor fresnel_cos(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FresnelCos", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FresnelSin
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor fresnel_sin(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FresnelSin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FusedBatchNorm
# Inputs:
*    x
*    scale
*    offset
*    mean
*    variance

# Attributes:
*    epsilon
*    exponential_avg_factor
*    data_format
*    is_training

# Outputs:
*    y
*    batch_mean
*    batch_variance
*    reserve_space_1
*    reserve_space_2

*/
inline std::vector<tensor> fused_batch_norm(const tensor& x, const tensor& scale, const tensor& offset, const tensor& mean, const tensor& variance, float epsilon=1.0000e-04, float exponential_avg_factor=1.0000e+00, const std::string& data_format="NHWC", bool is_training=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FusedBatchNorm", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scale.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), offset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mean.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), variance.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "epsilon", epsilon);
    TFE_OpSetAttrFloat(op.get(), "exponential_avg_factor", exponential_avg_factor);
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());
    TFE_OpSetAttrBool(op.get(), "is_training", (unsigned char)is_training);

    // Execute Op
    int num_outputs_op = 5;
    TFE_TensorHandle* res[5] = { nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]), };
}

/* # FusedBatchNormGrad
# Inputs:
*    y_backprop
*    x
*    scale
*    reserve_space_1
*    reserve_space_2

# Attributes:
*    epsilon
*    data_format
*    is_training

# Outputs:
*    x_backprop
*    scale_backprop
*    offset_backprop
*    reserve_space_3
*    reserve_space_4

*/
inline std::vector<tensor> fused_batch_norm_grad(const tensor& y_backprop, const tensor& x, const tensor& scale, const tensor& reserve_space_1, const tensor& reserve_space_2, float epsilon=1.0000e-04, const std::string& data_format="NHWC", bool is_training=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FusedBatchNormGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), y_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scale.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reserve_space_1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reserve_space_2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "epsilon", epsilon);
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());
    TFE_OpSetAttrBool(op.get(), "is_training", (unsigned char)is_training);

    // Execute Op
    int num_outputs_op = 5;
    TFE_TensorHandle* res[5] = { nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]), };
}

/* # FusedBatchNormGradV2
# Inputs:
*    y_backprop
*    x
*    scale
*    reserve_space_1
*    reserve_space_2

# Attributes:
*    U
*    epsilon
*    data_format
*    is_training

# Outputs:
*    x_backprop
*    scale_backprop
*    offset_backprop
*    reserve_space_3
*    reserve_space_4

*/
inline std::vector<tensor> fused_batch_norm_grad_v2(const tensor& y_backprop, const tensor& x, const tensor& scale, const tensor& reserve_space_1, const tensor& reserve_space_2, datatype U, float epsilon=1.0000e-04, const std::string& data_format="NHWC", bool is_training=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FusedBatchNormGradV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), y_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scale.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reserve_space_1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reserve_space_2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "U", U);
    TFE_OpSetAttrFloat(op.get(), "epsilon", epsilon);
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());
    TFE_OpSetAttrBool(op.get(), "is_training", (unsigned char)is_training);

    // Execute Op
    int num_outputs_op = 5;
    TFE_TensorHandle* res[5] = { nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]), };
}

/* # FusedBatchNormGradV3
# Inputs:
*    y_backprop
*    x
*    scale
*    reserve_space_1
*    reserve_space_2
*    reserve_space_3

# Attributes:
*    U
*    epsilon
*    data_format
*    is_training

# Outputs:
*    x_backprop
*    scale_backprop
*    offset_backprop
*    reserve_space_4
*    reserve_space_5

*/
inline std::vector<tensor> fused_batch_norm_grad_v3(const tensor& y_backprop, const tensor& x, const tensor& scale, const tensor& reserve_space_1, const tensor& reserve_space_2, const tensor& reserve_space_3, datatype U, float epsilon=1.0000e-04, const std::string& data_format="NHWC", bool is_training=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FusedBatchNormGradV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), y_backprop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scale.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reserve_space_1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reserve_space_2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reserve_space_3.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "U", U);
    TFE_OpSetAttrFloat(op.get(), "epsilon", epsilon);
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());
    TFE_OpSetAttrBool(op.get(), "is_training", (unsigned char)is_training);

    // Execute Op
    int num_outputs_op = 5;
    TFE_TensorHandle* res[5] = { nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]), };
}

/* # FusedBatchNormV2
# Inputs:
*    x
*    scale
*    offset
*    mean
*    variance

# Attributes:
*    U
*    epsilon
*    exponential_avg_factor
*    data_format
*    is_training

# Outputs:
*    y
*    batch_mean
*    batch_variance
*    reserve_space_1
*    reserve_space_2

*/
inline std::vector<tensor> fused_batch_norm_v2(const tensor& x, const tensor& scale, const tensor& offset, const tensor& mean, const tensor& variance, datatype U, float epsilon=1.0000e-04, float exponential_avg_factor=1.0000e+00, const std::string& data_format="NHWC", bool is_training=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FusedBatchNormV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scale.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), offset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mean.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), variance.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "U", U);
    TFE_OpSetAttrFloat(op.get(), "epsilon", epsilon);
    TFE_OpSetAttrFloat(op.get(), "exponential_avg_factor", exponential_avg_factor);
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());
    TFE_OpSetAttrBool(op.get(), "is_training", (unsigned char)is_training);

    // Execute Op
    int num_outputs_op = 5;
    TFE_TensorHandle* res[5] = { nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]), };
}

/* # FusedBatchNormV3
# Inputs:
*    x
*    scale
*    offset
*    mean
*    variance

# Attributes:
*    U
*    epsilon
*    exponential_avg_factor
*    data_format
*    is_training

# Outputs:
*    y
*    batch_mean
*    batch_variance
*    reserve_space_1
*    reserve_space_2
*    reserve_space_3

*/
inline std::vector<tensor> fused_batch_norm_v3(const tensor& x, const tensor& scale, const tensor& offset, const tensor& mean, const tensor& variance, datatype U, float epsilon=1.0000e-04, float exponential_avg_factor=1.0000e+00, const std::string& data_format="NHWC", bool is_training=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FusedBatchNormV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scale.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), offset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mean.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), variance.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "U", U);
    TFE_OpSetAttrFloat(op.get(), "epsilon", epsilon);
    TFE_OpSetAttrFloat(op.get(), "exponential_avg_factor", exponential_avg_factor);
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());
    TFE_OpSetAttrBool(op.get(), "is_training", (unsigned char)is_training);

    // Execute Op
    int num_outputs_op = 6;
    TFE_TensorHandle* res[6] = { nullptr,nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]),tensor(res[5]), };
}

/* # FusedPadConv2D
# Inputs:
*    input
*    paddings
*    filter

# Attributes:
*    mode
*    strides
*    padding

# Outputs:
*    output

*/
inline tensor fused_pad_conv2_d(const tensor& input, const tensor& paddings, const tensor& filter, const std::string& mode, const std::vector<int64_t>& strides, const std::string& padding) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FusedPadConv2D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), paddings.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "mode", (void*) mode.c_str(), mode.size());
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # FusedResizeAndPadConv2D
# Inputs:
*    input
*    size
*    paddings
*    filter

# Attributes:
*    mode
*    strides
*    padding
*    resize_align_corners

# Outputs:
*    output

*/
inline tensor fused_resize_and_pad_conv2_d(const tensor& input, const tensor& size, const tensor& paddings, const tensor& filter, const std::string& mode, const std::vector<int64_t>& strides, const std::string& padding, bool resize_align_corners=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FusedResizeAndPadConv2D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), paddings.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "mode", (void*) mode.c_str(), mode.size());
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrBool(op.get(), "resize_align_corners", (unsigned char)resize_align_corners);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # GRUBlockCell
# Inputs:
*    x
*    h_prev
*    w_ru
*    w_c
*    b_ru
*    b_c

# Attributes:
*    
# Outputs:
*    r
*    u
*    c
*    h

*/
inline std::vector<tensor> g_r_u_block_cell(const tensor& x, const tensor& h_prev, const tensor& w_ru, const tensor& w_c, const tensor& b_ru, const tensor& b_c) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GRUBlockCell", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), h_prev.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), w_ru.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), w_c.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_ru.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_c.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 4;
    TFE_TensorHandle* res[4] = { nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]), };
}

/* # GRUBlockCellGrad
# Inputs:
*    x
*    h_prev
*    w_ru
*    w_c
*    b_ru
*    b_c
*    r
*    u
*    c
*    d_h

# Attributes:
*    
# Outputs:
*    d_x
*    d_h_prev
*    d_c_bar
*    d_r_bar_u_bar

*/
inline std::vector<tensor> g_r_u_block_cell_grad(const tensor& x, const tensor& h_prev, const tensor& w_ru, const tensor& w_c, const tensor& b_ru, const tensor& b_c, const tensor& r, const tensor& u, const tensor& c, const tensor& d_h) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GRUBlockCellGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), h_prev.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), w_ru.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), w_c.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_ru.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_c.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), r.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), u.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), c.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), d_h.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 4;
    TFE_TensorHandle* res[4] = { nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]), };
}

/* # Gather
# Inputs:
*    params
*    indices

# Attributes:
*    Tparams
*    Tindices
*    validate_indices

# Outputs:
*    output

*/
inline tensor gather(const tensor& params, const tensor& indices, datatype Tparams, datatype Tindices, bool validate_indices=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Gather", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), params.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tparams", Tparams);
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "validate_indices", (unsigned char)validate_indices);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # GatherNd
# Inputs:
*    params
*    indices

# Attributes:
*    Tparams
*    Tindices
*    bad_indices_policy

# Outputs:
*    output

*/
inline tensor gather_nd(const tensor& params, const tensor& indices, datatype Tparams, datatype Tindices, const std::string& bad_indices_policy="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GatherNd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), params.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tparams", Tparams);
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrString(op.get(), "bad_indices_policy", (void*) bad_indices_policy.c_str(), bad_indices_policy.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # GatherV2
# Inputs:
*    params
*    indices
*    axis

# Attributes:
*    Tparams
*    Tindices
*    Taxis
*    batch_dims

# Outputs:
*    output

*/
inline tensor gather_v2(const tensor& params, const tensor& indices, const tensor& axis, datatype Tparams, datatype Tindices, datatype Taxis, int64_t batch_dims=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GatherV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), params.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), axis.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tparams", Tparams);
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrType(op.get(), "Taxis", Taxis);
    TFE_OpSetAttrInt(op.get(), "batch_dims", batch_dims);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # GenerateBoundingBoxProposals
# Inputs:
*    scores
*    bbox_deltas
*    image_info
*    anchors
*    nms_threshold
*    pre_nms_topn
*    min_size

# Attributes:
*    post_nms_topn

# Outputs:
*    rois
*    roi_probabilities

*/
inline std::vector<tensor> generate_bounding_box_proposals(const tensor& scores, const tensor& bbox_deltas, const tensor& image_info, const tensor& anchors, const tensor& nms_threshold, const tensor& pre_nms_topn, const tensor& min_size, int64_t post_nms_topn=300) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GenerateBoundingBoxProposals", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), scores.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bbox_deltas.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), image_info.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), anchors.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), nms_threshold.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), pre_nms_topn.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "post_nms_topn", post_nms_topn);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # GenerateVocabRemapping
# Inputs:
*    new_vocab_file
*    old_vocab_file

# Attributes:
*    new_vocab_offset
*    num_new_vocab
*    old_vocab_size

# Outputs:
*    remapping
*    num_present

*/
inline std::vector<tensor> generate_vocab_remapping(const tensor& new_vocab_file, const tensor& old_vocab_file, int64_t new_vocab_offset, int64_t num_new_vocab, int64_t old_vocab_size=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GenerateVocabRemapping", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), new_vocab_file.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), old_vocab_file.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "new_vocab_offset", new_vocab_offset);
    TFE_OpSetAttrInt(op.get(), "num_new_vocab", num_new_vocab);
    TFE_OpSetAttrInt(op.get(), "old_vocab_size", old_vocab_size);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # GeneratorDataset
# Inputs:
*    init_func_other_args
*    next_func_other_args
*    finalize_func_other_args

# Attributes:
*    init_func
*    next_func
*    finalize_func
*    Tinit_func_args
*    Tnext_func_args
*    Tfinalize_func_args
*    output_types
*    output_shapes
*    metadata

# Outputs:
*    handle

*/
inline tensor generator_dataset(const std::vector<tensor>&init_func_other_args, const std::vector<tensor>&next_func_other_args, const std::vector<tensor>&finalize_func_other_args, int64_t init_func, int64_t next_func, int64_t finalize_func, const std::vector<datatype>& Tinit_func_args, const std::vector<datatype>& Tnext_func_args, const std::vector<datatype>& Tfinalize_func_args, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GeneratorDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> init_func_other_args_handles; init_func_other_args_handles.reserve(init_func_other_args.size());
    std::transform(init_func_other_args.begin(), init_func_other_args.end(), std::back_inserter(init_func_other_args_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), init_func_other_args_handles.data(), static_cast<int>(init_func_other_args.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> next_func_other_args_handles; next_func_other_args_handles.reserve(next_func_other_args.size());
    std::transform(next_func_other_args.begin(), next_func_other_args.end(), std::back_inserter(next_func_other_args_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), next_func_other_args_handles.data(), static_cast<int>(next_func_other_args.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> finalize_func_other_args_handles; finalize_func_other_args_handles.reserve(finalize_func_other_args.size());
    std::transform(finalize_func_other_args.begin(), finalize_func_other_args.end(), std::back_inserter(finalize_func_other_args_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), finalize_func_other_args_handles.data(), static_cast<int>(finalize_func_other_args.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "init_func", init_func);
    TFE_OpSetAttrInt(op.get(), "next_func", next_func);
    TFE_OpSetAttrInt(op.get(), "finalize_func", finalize_func);
    TFE_OpSetAttrTypeList(op.get(), "Tinit_func_args", reinterpret_cast<const enum TF_DataType *>(Tinit_func_args.data()), static_cast<int>(Tinit_func_args.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tnext_func_args", reinterpret_cast<const enum TF_DataType *>(Tnext_func_args.data()), static_cast<int>(Tnext_func_args.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tfinalize_func_args", reinterpret_cast<const enum TF_DataType *>(Tfinalize_func_args.data()), static_cast<int>(Tfinalize_func_args.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # GetElementAtIndex
# Inputs:
*    dataset
*    index

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    components

*/
inline tensor get_element_at_index(const tensor& dataset, const tensor& index, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GetElementAtIndex", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), index.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # GetMinibatchSplitsWithPhysicalReplica
# Inputs:
*    program_key
*    row_ids
*    col_ids
*    gains

# Attributes:
*    sample_count
*    num_replica
*    table_vocab_size
*    feature_width
*    num_sc_per_chip
*    table_name
*    mini_batch_splits

# Outputs:
*    sorted_row_ids
*    sorted_col_ids
*    sorted_gains
*    splits
*    id_counts
*    max_ids
*    max_uniques

*/
inline std::vector<tensor> get_minibatch_splits_with_physical_replica(const tensor& program_key, const tensor& row_ids, const tensor& col_ids, const tensor& gains, int64_t sample_count, int64_t num_replica, int64_t table_vocab_size, int64_t feature_width, int64_t num_sc_per_chip, const std::string& table_name, const std::string& mini_batch_splits) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GetMinibatchSplitsWithPhysicalReplica", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), program_key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), row_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), col_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gains.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "sample_count", sample_count);
    TFE_OpSetAttrInt(op.get(), "num_replica", num_replica);
    TFE_OpSetAttrInt(op.get(), "table_vocab_size", table_vocab_size);
    TFE_OpSetAttrInt(op.get(), "feature_width", feature_width);
    TFE_OpSetAttrInt(op.get(), "num_sc_per_chip", num_sc_per_chip);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "mini_batch_splits", (void*) mini_batch_splits.c_str(), mini_batch_splits.size());

    // Execute Op
    int num_outputs_op = 7;
    TFE_TensorHandle* res[7] = { nullptr,nullptr,nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]),tensor(res[5]),tensor(res[6]), };
}

/* # GetMinibatchesInCsrWithPhysicalReplica
# Inputs:
*    program_key
*    row_ids
*    col_ids
*    gains
*    splits
*    id_counts

# Attributes:
*    sample_count
*    num_replica
*    max_minibatches_per_sc
*    max_ids_per_chip_per_sample
*    table_vocab_size
*    feature_width
*    num_sc_per_chip
*    table_name
*    mini_batch_in_csr

# Outputs:
*    row_pointers
*    sorted_sample_ids
*    sorted_token_ids
*    sorted_gains
*    row_pointers_unpadded_size
*    ids_unpadded_size
*    num_minibatches_per_physical_sparse_core

*/
inline std::vector<tensor> get_minibatches_in_csr_with_physical_replica(const tensor& program_key, const tensor& row_ids, const tensor& col_ids, const tensor& gains, const tensor& splits, const tensor& id_counts, int64_t sample_count, int64_t num_replica, int64_t max_minibatches_per_sc, int64_t max_ids_per_chip_per_sample, int64_t table_vocab_size, int64_t feature_width, int64_t num_sc_per_chip, const std::string& table_name, const std::string& mini_batch_in_csr) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GetMinibatchesInCsrWithPhysicalReplica", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), program_key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), row_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), col_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gains.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), splits.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), id_counts.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "sample_count", sample_count);
    TFE_OpSetAttrInt(op.get(), "num_replica", num_replica);
    TFE_OpSetAttrInt(op.get(), "max_minibatches_per_sc", max_minibatches_per_sc);
    TFE_OpSetAttrInt(op.get(), "max_ids_per_chip_per_sample", max_ids_per_chip_per_sample);
    TFE_OpSetAttrInt(op.get(), "table_vocab_size", table_vocab_size);
    TFE_OpSetAttrInt(op.get(), "feature_width", feature_width);
    TFE_OpSetAttrInt(op.get(), "num_sc_per_chip", num_sc_per_chip);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "mini_batch_in_csr", (void*) mini_batch_in_csr.c_str(), mini_batch_in_csr.size());

    // Execute Op
    int num_outputs_op = 7;
    TFE_TensorHandle* res[7] = { nullptr,nullptr,nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]),tensor(res[5]),tensor(res[6]), };
}

/* # GetOptions
# Inputs:
*    input_dataset

# Attributes:
*    
# Outputs:
*    serialized_options

*/
inline tensor get_options(const tensor& input_dataset) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GetOptions", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # GetSessionHandle
# Inputs:
*    value

# Attributes:
*    
# Outputs:
*    handle

*/
inline tensor get_session_handle(const tensor& value) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GetSessionHandle", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # GetSessionHandleV2
# Inputs:
*    value

# Attributes:
*    
# Outputs:
*    handle

*/
inline tensor get_session_handle_v2(const tensor& value) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GetSessionHandleV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # GetSessionTensor
# Inputs:
*    handle

# Attributes:
*    dtype

# Outputs:
*    value

*/
inline tensor get_session_tensor(const tensor& handle, datatype dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GetSessionTensor", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # GlobalIterId
# Inputs:
*    
# Attributes:
*    
# Outputs:
*    iter_id

*/
inline tensor global_iter_id() {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GlobalIterId", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Greater
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor greater(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Greater", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # GreaterEqual
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor greater_equal(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GreaterEqual", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # GroupByReducerDataset
# Inputs:
*    input_dataset
*    key_func_other_arguments
*    init_func_other_arguments
*    reduce_func_other_arguments
*    finalize_func_other_arguments

# Attributes:
*    key_func
*    init_func
*    reduce_func
*    finalize_func
*    Tkey_func_other_arguments
*    Tinit_func_other_arguments
*    Treduce_func_other_arguments
*    Tfinalize_func_other_arguments
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor group_by_reducer_dataset(const tensor& input_dataset, const std::vector<tensor>&key_func_other_arguments, const std::vector<tensor>&init_func_other_arguments, const std::vector<tensor>&reduce_func_other_arguments, const std::vector<tensor>&finalize_func_other_arguments, int64_t key_func, int64_t init_func, int64_t reduce_func, int64_t finalize_func, const std::vector<datatype>& Tkey_func_other_arguments, const std::vector<datatype>& Tinit_func_other_arguments, const std::vector<datatype>& Treduce_func_other_arguments, const std::vector<datatype>& Tfinalize_func_other_arguments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GroupByReducerDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> key_func_other_arguments_handles; key_func_other_arguments_handles.reserve(key_func_other_arguments.size());
    std::transform(key_func_other_arguments.begin(), key_func_other_arguments.end(), std::back_inserter(key_func_other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), key_func_other_arguments_handles.data(), static_cast<int>(key_func_other_arguments.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> init_func_other_arguments_handles; init_func_other_arguments_handles.reserve(init_func_other_arguments.size());
    std::transform(init_func_other_arguments.begin(), init_func_other_arguments.end(), std::back_inserter(init_func_other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), init_func_other_arguments_handles.data(), static_cast<int>(init_func_other_arguments.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> reduce_func_other_arguments_handles; reduce_func_other_arguments_handles.reserve(reduce_func_other_arguments.size());
    std::transform(reduce_func_other_arguments.begin(), reduce_func_other_arguments.end(), std::back_inserter(reduce_func_other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), reduce_func_other_arguments_handles.data(), static_cast<int>(reduce_func_other_arguments.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> finalize_func_other_arguments_handles; finalize_func_other_arguments_handles.reserve(finalize_func_other_arguments.size());
    std::transform(finalize_func_other_arguments.begin(), finalize_func_other_arguments.end(), std::back_inserter(finalize_func_other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), finalize_func_other_arguments_handles.data(), static_cast<int>(finalize_func_other_arguments.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "key_func", key_func);
    TFE_OpSetAttrInt(op.get(), "init_func", init_func);
    TFE_OpSetAttrInt(op.get(), "reduce_func", reduce_func);
    TFE_OpSetAttrInt(op.get(), "finalize_func", finalize_func);
    TFE_OpSetAttrTypeList(op.get(), "Tkey_func_other_arguments", reinterpret_cast<const enum TF_DataType *>(Tkey_func_other_arguments.data()), static_cast<int>(Tkey_func_other_arguments.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tinit_func_other_arguments", reinterpret_cast<const enum TF_DataType *>(Tinit_func_other_arguments.data()), static_cast<int>(Tinit_func_other_arguments.size()));
    TFE_OpSetAttrTypeList(op.get(), "Treduce_func_other_arguments", reinterpret_cast<const enum TF_DataType *>(Treduce_func_other_arguments.data()), static_cast<int>(Treduce_func_other_arguments.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tfinalize_func_other_arguments", reinterpret_cast<const enum TF_DataType *>(Tfinalize_func_other_arguments.data()), static_cast<int>(Tfinalize_func_other_arguments.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # GroupByWindowDataset
# Inputs:
*    input_dataset
*    key_func_other_arguments
*    reduce_func_other_arguments
*    window_size_func_other_arguments

# Attributes:
*    key_func
*    reduce_func
*    window_size_func
*    Tkey_func_other_arguments
*    Treduce_func_other_arguments
*    Twindow_size_func_other_arguments
*    output_types
*    output_shapes
*    metadata

# Outputs:
*    handle

*/
inline tensor group_by_window_dataset(const tensor& input_dataset, const std::vector<tensor>&key_func_other_arguments, const std::vector<tensor>&reduce_func_other_arguments, const std::vector<tensor>&window_size_func_other_arguments, int64_t key_func, int64_t reduce_func, int64_t window_size_func, const std::vector<datatype>& Tkey_func_other_arguments, const std::vector<datatype>& Treduce_func_other_arguments, const std::vector<datatype>& Twindow_size_func_other_arguments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GroupByWindowDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> key_func_other_arguments_handles; key_func_other_arguments_handles.reserve(key_func_other_arguments.size());
    std::transform(key_func_other_arguments.begin(), key_func_other_arguments.end(), std::back_inserter(key_func_other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), key_func_other_arguments_handles.data(), static_cast<int>(key_func_other_arguments.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> reduce_func_other_arguments_handles; reduce_func_other_arguments_handles.reserve(reduce_func_other_arguments.size());
    std::transform(reduce_func_other_arguments.begin(), reduce_func_other_arguments.end(), std::back_inserter(reduce_func_other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), reduce_func_other_arguments_handles.data(), static_cast<int>(reduce_func_other_arguments.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> window_size_func_other_arguments_handles; window_size_func_other_arguments_handles.reserve(window_size_func_other_arguments.size());
    std::transform(window_size_func_other_arguments.begin(), window_size_func_other_arguments.end(), std::back_inserter(window_size_func_other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), window_size_func_other_arguments_handles.data(), static_cast<int>(window_size_func_other_arguments.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "key_func", key_func);
    TFE_OpSetAttrInt(op.get(), "reduce_func", reduce_func);
    TFE_OpSetAttrInt(op.get(), "window_size_func", window_size_func);
    TFE_OpSetAttrTypeList(op.get(), "Tkey_func_other_arguments", reinterpret_cast<const enum TF_DataType *>(Tkey_func_other_arguments.data()), static_cast<int>(Tkey_func_other_arguments.size()));
    TFE_OpSetAttrTypeList(op.get(), "Treduce_func_other_arguments", reinterpret_cast<const enum TF_DataType *>(Treduce_func_other_arguments.data()), static_cast<int>(Treduce_func_other_arguments.size()));
    TFE_OpSetAttrTypeList(op.get(), "Twindow_size_func_other_arguments", reinterpret_cast<const enum TF_DataType *>(Twindow_size_func_other_arguments.data()), static_cast<int>(Twindow_size_func_other_arguments.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # GuaranteeConst
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor guarantee_const_tensor(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GuaranteeConst", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # HSVToRGB
# Inputs:
*    images

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor h_s_v_to_r_g_b(const tensor& images) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "HSVToRGB", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # HashTable
# Inputs:
*    
# Attributes:
*    key_dtype
*    value_dtype
*    container
*    shared_name
*    use_node_name_sharing

# Outputs:
*    table_handle

*/
inline tensor hash_table(datatype key_dtype, datatype value_dtype, const std::string& container="", const std::string& shared_name="", bool use_node_name_sharing=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "HashTable", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "key_dtype", key_dtype);
    TFE_OpSetAttrType(op.get(), "value_dtype", value_dtype);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrBool(op.get(), "use_node_name_sharing", (unsigned char)use_node_name_sharing);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # HashTableV2
# Inputs:
*    
# Attributes:
*    key_dtype
*    value_dtype
*    container
*    shared_name
*    use_node_name_sharing

# Outputs:
*    table_handle

*/
inline tensor hash_table_v2(datatype key_dtype, datatype value_dtype, const std::string& container="", const std::string& shared_name="", bool use_node_name_sharing=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "HashTableV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "key_dtype", key_dtype);
    TFE_OpSetAttrType(op.get(), "value_dtype", value_dtype);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrBool(op.get(), "use_node_name_sharing", (unsigned char)use_node_name_sharing);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # HistogramFixedWidth
# Inputs:
*    values
*    value_range
*    nbins

# Attributes:
*    dtype

# Outputs:
*    out

*/
inline tensor histogram_fixed_width(const tensor& values, const tensor& value_range, const tensor& nbins, datatype dtype=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "HistogramFixedWidth", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value_range.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), nbins.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # HistogramSummary
# Inputs:
*    tag
*    values

# Attributes:
*    
# Outputs:
*    summary

*/
inline tensor histogram_summary(const tensor& tag, const tensor& values) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "HistogramSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tag.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IFFT
# Inputs:
*    input

# Attributes:
*    Tcomplex

# Outputs:
*    output

*/
inline tensor IFFT(const tensor& input, datatype Tcomplex=static_cast<datatype>(8)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IFFT", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IFFT2D
# Inputs:
*    input

# Attributes:
*    Tcomplex

# Outputs:
*    output

*/
inline tensor IFFT2D(const tensor& input, datatype Tcomplex=static_cast<datatype>(8)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IFFT2D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IFFT3D
# Inputs:
*    input

# Attributes:
*    Tcomplex

# Outputs:
*    output

*/
inline tensor IFFT3D(const tensor& input, datatype Tcomplex=static_cast<datatype>(8)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IFFT3D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IFFTND
# Inputs:
*    input
*    fft_length
*    axes

# Attributes:
*    Tcomplex

# Outputs:
*    output

*/
inline tensor IFFTND(const tensor& input, const tensor& fft_length, const tensor& axes, datatype Tcomplex=static_cast<datatype>(8)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IFFTND", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), fft_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), axes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IRFFT
# Inputs:
*    input
*    fft_length

# Attributes:
*    Treal
*    Tcomplex

# Outputs:
*    output

*/
inline tensor IRFFT(const tensor& input, const tensor& fft_length, datatype Treal=static_cast<datatype>(1), datatype Tcomplex=static_cast<datatype>(8)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IRFFT", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), fft_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Treal", Treal);
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IRFFT2D
# Inputs:
*    input
*    fft_length

# Attributes:
*    Treal
*    Tcomplex

# Outputs:
*    output

*/
inline tensor IRFFT2D(const tensor& input, const tensor& fft_length, datatype Treal=static_cast<datatype>(1), datatype Tcomplex=static_cast<datatype>(8)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IRFFT2D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), fft_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Treal", Treal);
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IRFFT3D
# Inputs:
*    input
*    fft_length

# Attributes:
*    Treal
*    Tcomplex

# Outputs:
*    output

*/
inline tensor IRFFT3D(const tensor& input, const tensor& fft_length, datatype Treal=static_cast<datatype>(1), datatype Tcomplex=static_cast<datatype>(8)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IRFFT3D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), fft_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Treal", Treal);
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IRFFTND
# Inputs:
*    input
*    fft_length
*    axes

# Attributes:
*    Treal
*    Tcomplex

# Outputs:
*    output

*/
inline tensor IRFFTND(const tensor& input, const tensor& fft_length, const tensor& axes, datatype Treal=static_cast<datatype>(1), datatype Tcomplex=static_cast<datatype>(8)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IRFFTND", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), fft_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), axes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Treal", Treal);
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Identity
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor identity(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Identity", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IdentityN
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor identity_n(const std::vector<tensor>&input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IdentityN", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> input_handles; input_handles.reserve(input.size());
    std::transform(input.begin(), input.end(), std::back_inserter(input_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), input_handles.data(), static_cast<int>(input.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IdentityReader
# Inputs:
*    
# Attributes:
*    container
*    shared_name

# Outputs:
*    reader_handle

*/
inline tensor identity_reader(const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IdentityReader", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IdentityReaderV2
# Inputs:
*    
# Attributes:
*    container
*    shared_name

# Outputs:
*    reader_handle

*/
inline tensor identity_reader_v2(const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IdentityReaderV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # If
# Inputs:
*    cond
*    input

# Attributes:
*    Tcond
*    Tin
*    Tout
*    then_branch
*    else_branch
*    output_shapes

# Outputs:
*    output

*/
inline tensor tfe_if(const tensor& cond, const std::vector<tensor>&input, datatype Tcond, const std::vector<datatype>& Tin, const std::vector<datatype>& Tout, int64_t then_branch, int64_t else_branch, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "If", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), cond.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> input_handles; input_handles.reserve(input.size());
    std::transform(input.begin(), input.end(), std::back_inserter(input_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), input_handles.data(), static_cast<int>(input.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tcond", Tcond);
    TFE_OpSetAttrTypeList(op.get(), "Tin", reinterpret_cast<const enum TF_DataType *>(Tin.data()), static_cast<int>(Tin.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tout", reinterpret_cast<const enum TF_DataType *>(Tout.data()), static_cast<int>(Tout.size()));
    TFE_OpSetAttrInt(op.get(), "then_branch", then_branch);
    TFE_OpSetAttrInt(op.get(), "else_branch", else_branch);
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Igamma
# Inputs:
*    a
*    x

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor igamma(const tensor& a, const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Igamma", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IgammaGradA
# Inputs:
*    a
*    x

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor igamma_grad_a(const tensor& a, const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IgammaGradA", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Igammac
# Inputs:
*    a
*    x

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor igammac(const tensor& a, const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Igammac", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IgnoreErrorsDataset
# Inputs:
*    input_dataset

# Attributes:
*    output_types
*    output_shapes
*    log_warning

# Outputs:
*    handle

*/
inline tensor ignore_errors_dataset(const tensor& input_dataset, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool log_warning=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IgnoreErrorsDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "log_warning", (unsigned char)log_warning);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Imag
# Inputs:
*    input

# Attributes:
*    Tout

# Outputs:
*    output

*/
inline tensor imag(const tensor& input, datatype Tout=static_cast<datatype>(1)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Imag", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tout", Tout);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ImageProjectiveTransformV2
# Inputs:
*    images
*    transforms
*    output_shape

# Attributes:
*    dtype
*    interpolation
*    fill_mode

# Outputs:
*    transformed_images

*/
inline tensor image_projective_transform_v2(const tensor& images, const tensor& transforms, const tensor& output_shape, datatype dtype, const std::string& interpolation, const std::string& fill_mode="CONSTANT") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ImageProjectiveTransformV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), transforms.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrString(op.get(), "interpolation", (void*) interpolation.c_str(), interpolation.size());
    TFE_OpSetAttrString(op.get(), "fill_mode", (void*) fill_mode.c_str(), fill_mode.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ImageProjectiveTransformV3
# Inputs:
*    images
*    transforms
*    output_shape
*    fill_value

# Attributes:
*    dtype
*    interpolation
*    fill_mode

# Outputs:
*    transformed_images

*/
inline tensor image_projective_transform_v3(const tensor& images, const tensor& transforms, const tensor& output_shape, const tensor& fill_value, datatype dtype, const std::string& interpolation, const std::string& fill_mode="CONSTANT") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ImageProjectiveTransformV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), transforms.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), fill_value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrString(op.get(), "interpolation", (void*) interpolation.c_str(), interpolation.size());
    TFE_OpSetAttrString(op.get(), "fill_mode", (void*) fill_mode.c_str(), fill_mode.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ImageSummary
# Inputs:
*    tag
*    tensor

# Attributes:
*    bad_color
*    max_images

# Outputs:
*    summary

*/
inline tensor image_summary(const tensor& tag, const tensor& input_tensor, const tensor& bad_color, int64_t max_images=3) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ImageSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tag.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    TFE_OpSetAttrTensor(op.get(), "bad_color", bad_color.get_tensor().get(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "max_images", max_images);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ImmutableConst
# Inputs:
*    
# Attributes:
*    dtype
*    shape
*    memory_region_name

# Outputs:
*    tensor

*/
inline tensor immutable_const_tensor(datatype dtype, const std::vector<int64_t>& shape, const std::string& memory_region_name) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ImmutableConst", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), static_cast<int>(shape.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "memory_region_name", (void*) memory_region_name.c_str(), memory_region_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ImportEvent
# Inputs:
*    writer
*    event

# Attributes:
*    
# Outputs:
*    
*/
inline void import_event(const tensor& writer, const tensor& event) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ImportEvent", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), writer.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), event.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # InTopK
# Inputs:
*    predictions
*    targets

# Attributes:
*    k

# Outputs:
*    precision

*/
inline tensor in_top_k(const tensor& predictions, const tensor& targets, int64_t k) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InTopK", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), predictions.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), targets.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "k", k);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # InTopKV2
# Inputs:
*    predictions
*    targets
*    k

# Attributes:
*    
# Outputs:
*    precision

*/
inline tensor in_top_k_v2(const tensor& predictions, const tensor& targets, const tensor& k) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InTopKV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), predictions.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), targets.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), k.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # InfeedDequeue
# Inputs:
*    
# Attributes:
*    dtype
*    shape

# Outputs:
*    output

*/
inline tensor infeed_dequeue(datatype dtype, const std::vector<int64_t>& shape) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InfeedDequeue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), static_cast<int>(shape.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # InfeedDequeueTuple
# Inputs:
*    
# Attributes:
*    dtypes
*    shapes

# Outputs:
*    outputs

*/
inline tensor infeed_dequeue_tuple(const std::vector<datatype>& dtypes, const std::vector< std::vector<int64_t>>& shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InfeedDequeueTuple", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), static_cast<int>(shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # InfeedEnqueue
# Inputs:
*    input

# Attributes:
*    dtype
*    shape
*    layout
*    device_ordinal

# Outputs:
*    
*/
inline void infeed_enqueue(const tensor& input, datatype dtype, const std::vector<int64_t>& shape, const std::vector<int64_t>& layout, int64_t device_ordinal=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InfeedEnqueue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), static_cast<int>(shape.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrIntList(op.get(), "layout", layout.data(), static_cast<int>(layout.size()));
    TFE_OpSetAttrInt(op.get(), "device_ordinal", device_ordinal);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # InfeedEnqueuePrelinearizedBuffer
# Inputs:
*    input

# Attributes:
*    device_ordinal

# Outputs:
*    
*/
inline void infeed_enqueue_prelinearized_buffer(const tensor& input, int64_t device_ordinal=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InfeedEnqueuePrelinearizedBuffer", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "device_ordinal", device_ordinal);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # InfeedEnqueueTuple
# Inputs:
*    inputs

# Attributes:
*    dtypes
*    shapes
*    layouts
*    device_ordinal

# Outputs:
*    
*/
inline void infeed_enqueue_tuple(const std::vector<tensor>&inputs, const std::vector<datatype>& dtypes, const std::vector< std::vector<int64_t>>& shapes, const std::vector<int64_t>& layouts, int64_t device_ordinal=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InfeedEnqueueTuple", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), static_cast<int>(inputs.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), static_cast<int>(shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrIntList(op.get(), "layouts", layouts.data(), static_cast<int>(layouts.size()));
    TFE_OpSetAttrInt(op.get(), "device_ordinal", device_ordinal);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # InitializeTable
# Inputs:
*    table_handle
*    keys
*    values

# Attributes:
*    Tkey
*    Tval

# Outputs:
*    
*/
inline void initialize_table(const tensor& table_handle, const tensor& keys, const tensor& values, datatype Tkey, datatype Tval) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InitializeTable", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), keys.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tkey", Tkey);
    TFE_OpSetAttrType(op.get(), "Tval", Tval);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # InitializeTableFromDataset
# Inputs:
*    table_handle
*    dataset

# Attributes:
*    
# Outputs:
*    
*/
inline void initialize_table_from_dataset(const tensor& table_handle, const tensor& dataset) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InitializeTableFromDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # InitializeTableFromTextFile
# Inputs:
*    table_handle
*    filename

# Attributes:
*    key_index
*    value_index
*    vocab_size
*    delimiter
*    offset

# Outputs:
*    
*/
inline void initialize_table_from_text_file(const tensor& table_handle, const tensor& filename, int64_t key_index, int64_t value_index, int64_t vocab_size=-1, const std::string& delimiter="\t", int64_t offset=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InitializeTableFromTextFile", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filename.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "key_index", key_index);
    TFE_OpSetAttrInt(op.get(), "value_index", value_index);
    TFE_OpSetAttrInt(op.get(), "vocab_size", vocab_size);
    TFE_OpSetAttrString(op.get(), "delimiter", (void*) delimiter.c_str(), delimiter.size());
    TFE_OpSetAttrInt(op.get(), "offset", offset);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # InitializeTableFromTextFileV2
# Inputs:
*    table_handle
*    filename

# Attributes:
*    key_index
*    value_index
*    vocab_size
*    delimiter
*    offset

# Outputs:
*    
*/
inline void initialize_table_from_text_file_v2(const tensor& table_handle, const tensor& filename, int64_t key_index, int64_t value_index, int64_t vocab_size=-1, const std::string& delimiter="\t", int64_t offset=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InitializeTableFromTextFileV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filename.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "key_index", key_index);
    TFE_OpSetAttrInt(op.get(), "value_index", value_index);
    TFE_OpSetAttrInt(op.get(), "vocab_size", vocab_size);
    TFE_OpSetAttrString(op.get(), "delimiter", (void*) delimiter.c_str(), delimiter.size());
    TFE_OpSetAttrInt(op.get(), "offset", offset);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # InitializeTableV2
# Inputs:
*    table_handle
*    keys
*    values

# Attributes:
*    Tkey
*    Tval

# Outputs:
*    
*/
inline void initialize_table_v2(const tensor& table_handle, const tensor& keys, const tensor& values, datatype Tkey, datatype Tval) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InitializeTableV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), keys.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tkey", Tkey);
    TFE_OpSetAttrType(op.get(), "Tval", Tval);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # InplaceAdd
# Inputs:
*    x
*    i
*    v

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor inplace_add(const tensor& x, const tensor& i, const tensor& v) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InplaceAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), i.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # InplaceSub
# Inputs:
*    x
*    i
*    v

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor inplace_sub(const tensor& x, const tensor& i, const tensor& v) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InplaceSub", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), i.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # InplaceUpdate
# Inputs:
*    x
*    i
*    v

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor inplace_update(const tensor& x, const tensor& i, const tensor& v) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InplaceUpdate", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), i.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # InterleaveDataset
# Inputs:
*    input_dataset
*    other_arguments
*    cycle_length
*    block_length

# Attributes:
*    f
*    Targuments
*    output_types
*    output_shapes
*    metadata

# Outputs:
*    handle

*/
inline tensor interleave_dataset(const tensor& input_dataset, const std::vector<tensor>&other_arguments, const tensor& cycle_length, const tensor& block_length, int64_t f, const std::vector<datatype>& Targuments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InterleaveDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> other_arguments_handles; other_arguments_handles.reserve(other_arguments.size());
    std::transform(other_arguments.begin(), other_arguments.end(), std::back_inserter(other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), other_arguments_handles.data(), static_cast<int>(other_arguments.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cycle_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), block_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "f", f);
    TFE_OpSetAttrTypeList(op.get(), "Targuments", reinterpret_cast<const enum TF_DataType *>(Targuments.data()), static_cast<int>(Targuments.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Inv
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor inv(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Inv", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # InvGrad
# Inputs:
*    y
*    dy

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor inv_grad(const tensor& y, const tensor& dy) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InvGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dy.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Invert
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor invert(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Invert", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # InvertPermutation
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor invert_permutation(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InvertPermutation", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IsBoostedTreesEnsembleInitialized
# Inputs:
*    tree_ensemble_handle

# Attributes:
*    
# Outputs:
*    is_initialized

*/
inline tensor is_boosted_trees_ensemble_initialized(const tensor& tree_ensemble_handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IsBoostedTreesEnsembleInitialized", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tree_ensemble_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IsBoostedTreesQuantileStreamResourceInitialized
# Inputs:
*    quantile_stream_resource_handle

# Attributes:
*    
# Outputs:
*    is_initialized

*/
inline tensor is_boosted_trees_quantile_stream_resource_initialized(const tensor& quantile_stream_resource_handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IsBoostedTreesQuantileStreamResourceInitialized", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), quantile_stream_resource_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IsFinite
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor is_finite(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IsFinite", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IsInf
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor is_inf(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IsInf", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IsNan
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor is_nan(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IsNan", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IsTPUEmbeddingInitialized
# Inputs:
*    
# Attributes:
*    config

# Outputs:
*    is_tpu_embedding_initialized

*/
inline tensor is_t_p_u_embedding_initialized(const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IsTPUEmbeddingInitialized", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IsVariableInitialized
# Inputs:
*    ref

# Attributes:
*    dtype

# Outputs:
*    is_initialized

*/
inline tensor is_variable_initialized(const tensor& ref, datatype dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IsVariableInitialized", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IsotonicRegression
# Inputs:
*    input

# Attributes:
*    output_dtype

# Outputs:
*    output
*    segments

*/
inline std::vector<tensor> isotonic_regression(const tensor& input, datatype output_dtype=static_cast<datatype>(1)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IsotonicRegression", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "output_dtype", output_dtype);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # Iterator
# Inputs:
*    
# Attributes:
*    shared_name
*    container
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor iterator(const std::string& shared_name, const std::string& container, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Iterator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IteratorFromStringHandle
# Inputs:
*    string_handle

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    resource_handle

*/
inline tensor iterator_from_string_handle(const tensor& string_handle, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IteratorFromStringHandle", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), string_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IteratorFromStringHandleV2
# Inputs:
*    string_handle

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    resource_handle

*/
inline tensor iterator_from_string_handle_v2(const tensor& string_handle, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IteratorFromStringHandleV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), string_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IteratorGetDevice
# Inputs:
*    resource

# Attributes:
*    
# Outputs:
*    device

*/
inline tensor iterator_get_device(const tensor& resource) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IteratorGetDevice", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IteratorGetNext
# Inputs:
*    iterator

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    components

*/
inline tensor iterator_get_next(const tensor& iterator, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IteratorGetNext", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), iterator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IteratorGetNextAsOptional
# Inputs:
*    iterator

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    optional

*/
inline tensor iterator_get_next_as_optional(const tensor& iterator, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IteratorGetNextAsOptional", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), iterator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IteratorGetNextSync
# Inputs:
*    iterator

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    components

*/
inline tensor iterator_get_next_sync(const tensor& iterator, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IteratorGetNextSync", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), iterator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IteratorToStringHandle
# Inputs:
*    resource_handle

# Attributes:
*    
# Outputs:
*    string_handle

*/
inline tensor iterator_to_string_handle(const tensor& resource_handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IteratorToStringHandle", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # IteratorV2
# Inputs:
*    
# Attributes:
*    shared_name
*    container
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor iterator_v2(const std::string& shared_name, const std::string& container, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IteratorV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # KMC2ChainInitialization
# Inputs:
*    distances
*    seed

# Attributes:
*    
# Outputs:
*    index

*/
inline tensor k_m_c2_chain_initialization(const tensor& distances, const tensor& seed) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "KMC2ChainInitialization", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), distances.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # KmeansPlusPlusInitialization
# Inputs:
*    points
*    num_to_sample
*    seed
*    num_retries_per_sample

# Attributes:
*    
# Outputs:
*    samples

*/
inline tensor kmeans_plus_plus_initialization(const tensor& points, const tensor& num_to_sample, const tensor& seed, const tensor& num_retries_per_sample) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "KmeansPlusPlusInitialization", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), points.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_to_sample.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_retries_per_sample.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # L2Loss
# Inputs:
*    t

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor l2_loss(const tensor& t) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "L2Loss", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), t.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # LMDBDataset
# Inputs:
*    filenames

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor l_m_d_b_dataset(const tensor& filenames, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LMDBDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filenames.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # LMDBReader
# Inputs:
*    
# Attributes:
*    container
*    shared_name

# Outputs:
*    reader_handle

*/
inline tensor l_m_d_b_reader(const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LMDBReader", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # LRN
# Inputs:
*    input

# Attributes:
*    depth_radius
*    bias
*    alpha
*    beta

# Outputs:
*    output

*/
inline tensor LRN(const tensor& input, int64_t depth_radius=5, float bias=1.0000e+00, float alpha=1.0000e+00, float beta=5.0000e-01) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LRN", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "depth_radius", depth_radius);
    TFE_OpSetAttrFloat(op.get(), "bias", bias);
    TFE_OpSetAttrFloat(op.get(), "alpha", alpha);
    TFE_OpSetAttrFloat(op.get(), "beta", beta);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # LRNGrad
# Inputs:
*    input_grads
*    input_image
*    output_image

# Attributes:
*    depth_radius
*    bias
*    alpha
*    beta

# Outputs:
*    output

*/
inline tensor l_r_n_grad(const tensor& input_grads, const tensor& input_image, const tensor& output_image, int64_t depth_radius=5, float bias=1.0000e+00, float alpha=1.0000e+00, float beta=5.0000e-01) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LRNGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_grads.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_image.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_image.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "depth_radius", depth_radius);
    TFE_OpSetAttrFloat(op.get(), "bias", bias);
    TFE_OpSetAttrFloat(op.get(), "alpha", alpha);
    TFE_OpSetAttrFloat(op.get(), "beta", beta);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # LSTMBlockCell
# Inputs:
*    x
*    cs_prev
*    h_prev
*    w
*    wci
*    wcf
*    wco
*    b

# Attributes:
*    forget_bias
*    cell_clip
*    use_peephole

# Outputs:
*    i
*    cs
*    f
*    o
*    ci
*    co
*    h

*/
inline std::vector<tensor> l_s_t_m_block_cell(const tensor& x, const tensor& cs_prev, const tensor& h_prev, const tensor& w, const tensor& wci, const tensor& wcf, const tensor& wco, const tensor& b, float forget_bias=1.0000e+00, float cell_clip=3.0000e+00, bool use_peephole=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LSTMBlockCell", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cs_prev.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), h_prev.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), w.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wci.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wcf.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wco.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "forget_bias", forget_bias);
    TFE_OpSetAttrFloat(op.get(), "cell_clip", cell_clip);
    TFE_OpSetAttrBool(op.get(), "use_peephole", (unsigned char)use_peephole);

    // Execute Op
    int num_outputs_op = 7;
    TFE_TensorHandle* res[7] = { nullptr,nullptr,nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]),tensor(res[5]),tensor(res[6]), };
}

/* # LSTMBlockCellGrad
# Inputs:
*    x
*    cs_prev
*    h_prev
*    w
*    wci
*    wcf
*    wco
*    b
*    i
*    cs
*    f
*    o
*    ci
*    co
*    cs_grad
*    h_grad

# Attributes:
*    use_peephole

# Outputs:
*    cs_prev_grad
*    dicfo
*    wci_grad
*    wcf_grad
*    wco_grad

*/
inline std::vector<tensor> l_s_t_m_block_cell_grad(const tensor& x, const tensor& cs_prev, const tensor& h_prev, const tensor& w, const tensor& wci, const tensor& wcf, const tensor& wco, const tensor& b, const tensor& i, const tensor& cs, const tensor& f, const tensor& o, const tensor& ci, const tensor& co, const tensor& cs_grad, const tensor& h_grad, bool use_peephole) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LSTMBlockCellGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cs_prev.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), h_prev.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), w.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wci.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wcf.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wco.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), i.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), f.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), o.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ci.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), co.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cs_grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), h_grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_peephole", (unsigned char)use_peephole);

    // Execute Op
    int num_outputs_op = 5;
    TFE_TensorHandle* res[5] = { nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]), };
}

/* # LatencyStatsDataset
# Inputs:
*    input_dataset
*    tag

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor latency_stats_dataset(const tensor& input_dataset, const tensor& tag, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LatencyStatsDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tag.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # LeakyRelu
# Inputs:
*    features

# Attributes:
*    alpha

# Outputs:
*    activations

*/
inline tensor leaky_relu(const tensor& features, float alpha=2.0000e-01) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LeakyRelu", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), features.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "alpha", alpha);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # LeakyReluGrad
# Inputs:
*    gradients
*    features

# Attributes:
*    alpha

# Outputs:
*    backprops

*/
inline tensor leaky_relu_grad(const tensor& gradients, const tensor& features, float alpha=2.0000e-01) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LeakyReluGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), gradients.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), features.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "alpha", alpha);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # LearnedUnigramCandidateSampler
# Inputs:
*    true_classes

# Attributes:
*    num_true
*    num_sampled
*    unique
*    range_max
*    seed
*    seed2

# Outputs:
*    sampled_candidates
*    true_expected_count
*    sampled_expected_count

*/
inline std::vector<tensor> learned_unigram_candidate_sampler(const tensor& true_classes, int64_t num_true, int64_t num_sampled, bool unique, int64_t range_max, int64_t seed=0, int64_t seed2=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LearnedUnigramCandidateSampler", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), true_classes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_true", num_true);
    TFE_OpSetAttrInt(op.get(), "num_sampled", num_sampled);
    TFE_OpSetAttrBool(op.get(), "unique", (unsigned char)unique);
    TFE_OpSetAttrInt(op.get(), "range_max", range_max);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # LeftShift
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor left_shift(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LeftShift", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # LegacyParallelInterleaveDatasetV2
# Inputs:
*    input_dataset
*    other_arguments
*    cycle_length
*    block_length
*    buffer_output_elements
*    prefetch_input_elements

# Attributes:
*    f
*    Targuments
*    output_types
*    output_shapes
*    deterministic
*    metadata

# Outputs:
*    handle

*/
inline tensor legacy_parallel_interleave_dataset_v2(const tensor& input_dataset, const std::vector<tensor>&other_arguments, const tensor& cycle_length, const tensor& block_length, const tensor& buffer_output_elements, const tensor& prefetch_input_elements, int64_t f, const std::vector<datatype>& Targuments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& deterministic="default", const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LegacyParallelInterleaveDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> other_arguments_handles; other_arguments_handles.reserve(other_arguments.size());
    std::transform(other_arguments.begin(), other_arguments.end(), std::back_inserter(other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), other_arguments_handles.data(), static_cast<int>(other_arguments.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cycle_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), block_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_output_elements.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), prefetch_input_elements.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "f", f);
    TFE_OpSetAttrTypeList(op.get(), "Targuments", reinterpret_cast<const enum TF_DataType *>(Targuments.data()), static_cast<int>(Targuments.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "deterministic", (void*) deterministic.c_str(), deterministic.size());
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Less
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor less(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Less", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # LessEqual
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor less_equal(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LessEqual", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Lgamma
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor lgamma(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Lgamma", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # LinSpace
# Inputs:
*    start
*    stop
*    num

# Attributes:
*    Tidx

# Outputs:
*    output

*/
inline tensor lin_space(const tensor& start, const tensor& stop, const tensor& num, datatype Tidx=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LinSpace", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), start.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), stop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ListDataset
# Inputs:
*    tensors

# Attributes:
*    Tinput_types
*    output_types
*    output_shapes
*    metadata

# Outputs:
*    handle

*/
inline tensor list_dataset(const std::vector<tensor>&tensors, const std::vector<datatype>& Tinput_types, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ListDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> tensors_handles; tensors_handles.reserve(tensors.size());
    std::transform(tensors.begin(), tensors.end(), std::back_inserter(tensors_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), tensors_handles.data(), static_cast<int>(tensors.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Tinput_types", reinterpret_cast<const enum TF_DataType *>(Tinput_types.data()), static_cast<int>(Tinput_types.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ListDiff
# Inputs:
*    x
*    y

# Attributes:
*    out_idx

# Outputs:
*    out
*    idx

*/
inline std::vector<tensor> list_diff(const tensor& x, const tensor& y, datatype out_idx=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ListDiff", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_idx", out_idx);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # ListSnapshotChunksDataset
# Inputs:
*    snapshot_path

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor list_snapshot_chunks_dataset(const tensor& snapshot_path, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ListSnapshotChunksDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), snapshot_path.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # LoadAndRemapMatrix
# Inputs:
*    ckpt_path
*    old_tensor_name
*    row_remapping
*    col_remapping
*    initializing_values

# Attributes:
*    num_rows
*    num_cols
*    max_rows_in_memory

# Outputs:
*    output_matrix

*/
inline tensor load_and_remap_matrix(const tensor& ckpt_path, const tensor& old_input_tensor_name, const tensor& row_remapping, const tensor& col_remapping, const tensor& initializing_values, int64_t num_rows, int64_t num_cols, int64_t max_rows_in_memory=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadAndRemapMatrix", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ckpt_path.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), old_input_tensor_name.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), row_remapping.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), col_remapping.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), initializing_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_rows", num_rows);
    TFE_OpSetAttrInt(op.get(), "num_cols", num_cols);
    TFE_OpSetAttrInt(op.get(), "max_rows_in_memory", max_rows_in_memory);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # LoadDataset
# Inputs:
*    path
*    reader_func_other_args

# Attributes:
*    output_types
*    output_shapes
*    reader_func
*    Treader_func_args
*    compression

# Outputs:
*    handle

*/
inline tensor load_dataset(const tensor& path, const std::vector<tensor>&reader_func_other_args, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, int64_t reader_func, const std::vector<datatype>& Treader_func_args, const std::string& compression="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), path.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> reader_func_other_args_handles; reader_func_other_args_handles.reserve(reader_func_other_args.size());
    std::transform(reader_func_other_args.begin(), reader_func_other_args.end(), std::back_inserter(reader_func_other_args_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), reader_func_other_args_handles.data(), static_cast<int>(reader_func_other_args.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "reader_func", reader_func);
    TFE_OpSetAttrTypeList(op.get(), "Treader_func_args", reinterpret_cast<const enum TF_DataType *>(Treader_func_args.data()), static_cast<int>(Treader_func_args.size()));
    TFE_OpSetAttrString(op.get(), "compression", (void*) compression.c_str(), compression.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # LoadTPUEmbeddingADAMParameters
# Inputs:
*    parameters
*    momenta
*    velocities

# Attributes:
*    num_shards
*    shard_id
*    table_id
*    table_name
*    config

# Outputs:
*    
*/
inline void load_t_p_u_embedding_a_d_a_m_parameters(const tensor& parameters, const tensor& momenta, const tensor& velocities, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingADAMParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momenta.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), velocities.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # LoadTPUEmbeddingAdadeltaParameters
# Inputs:
*    parameters
*    accumulators
*    updates

# Attributes:
*    num_shards
*    shard_id
*    table_id
*    table_name
*    config

# Outputs:
*    
*/
inline void load_t_p_u_embedding_adadelta_parameters(const tensor& parameters, const tensor& accumulators, const tensor& updates, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingAdadeltaParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accumulators.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # LoadTPUEmbeddingAdagradMomentumParameters
# Inputs:
*    parameters
*    accumulators
*    momenta

# Attributes:
*    num_shards
*    shard_id
*    table_id
*    table_name
*    config

# Outputs:
*    
*/
inline void load_t_p_u_embedding_adagrad_momentum_parameters(const tensor& parameters, const tensor& accumulators, const tensor& momenta, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingAdagradMomentumParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accumulators.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momenta.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # LoadTPUEmbeddingAdagradParameters
# Inputs:
*    parameters
*    accumulators

# Attributes:
*    num_shards
*    shard_id
*    table_id
*    table_name
*    config

# Outputs:
*    
*/
inline void load_t_p_u_embedding_adagrad_parameters(const tensor& parameters, const tensor& accumulators, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingAdagradParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accumulators.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # LoadTPUEmbeddingCenteredRMSPropParameters
# Inputs:
*    parameters
*    ms
*    mom
*    mg

# Attributes:
*    num_shards
*    shard_id
*    table_id
*    table_name
*    config

# Outputs:
*    
*/
inline void load_t_p_u_embedding_centered_r_m_s_prop_parameters(const tensor& parameters, const tensor& ms, const tensor& mom, const tensor& mg, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingCenteredRMSPropParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ms.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mom.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mg.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # LoadTPUEmbeddingFTRLParameters
# Inputs:
*    parameters
*    accumulators
*    linears

# Attributes:
*    num_shards
*    shard_id
*    table_id
*    table_name
*    config

# Outputs:
*    
*/
inline void load_t_p_u_embedding_f_t_r_l_parameters(const tensor& parameters, const tensor& accumulators, const tensor& linears, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingFTRLParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accumulators.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), linears.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # LoadTPUEmbeddingFrequencyEstimatorParameters
# Inputs:
*    parameters
*    last_hit_step

# Attributes:
*    num_shards
*    shard_id
*    table_id
*    table_name
*    config

# Outputs:
*    
*/
inline void load_t_p_u_embedding_frequency_estimator_parameters(const tensor& parameters, const tensor& last_hit_step, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingFrequencyEstimatorParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), last_hit_step.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # LoadTPUEmbeddingMDLAdagradLightParameters
# Inputs:
*    parameters
*    accumulators
*    weights
*    benefits

# Attributes:
*    num_shards
*    shard_id
*    table_id
*    table_name
*    config

# Outputs:
*    
*/
inline void load_t_p_u_embedding_m_d_l_adagrad_light_parameters(const tensor& parameters, const tensor& accumulators, const tensor& weights, const tensor& benefits, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingMDLAdagradLightParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accumulators.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), weights.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), benefits.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # LoadTPUEmbeddingMomentumParameters
# Inputs:
*    parameters
*    momenta

# Attributes:
*    num_shards
*    shard_id
*    table_id
*    table_name
*    config

# Outputs:
*    
*/
inline void load_t_p_u_embedding_momentum_parameters(const tensor& parameters, const tensor& momenta, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingMomentumParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momenta.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # LoadTPUEmbeddingProximalAdagradParameters
# Inputs:
*    parameters
*    accumulators

# Attributes:
*    num_shards
*    shard_id
*    table_id
*    table_name
*    config

# Outputs:
*    
*/
inline void load_t_p_u_embedding_proximal_adagrad_parameters(const tensor& parameters, const tensor& accumulators, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingProximalAdagradParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accumulators.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # LoadTPUEmbeddingProximalYogiParameters
# Inputs:
*    parameters
*    v
*    m

# Attributes:
*    num_shards
*    shard_id
*    table_id
*    table_name
*    config

# Outputs:
*    
*/
inline void load_t_p_u_embedding_proximal_yogi_parameters(const tensor& parameters, const tensor& v, const tensor& m, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingProximalYogiParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # LoadTPUEmbeddingRMSPropParameters
# Inputs:
*    parameters
*    ms
*    mom

# Attributes:
*    num_shards
*    shard_id
*    table_id
*    table_name
*    config

# Outputs:
*    
*/
inline void load_t_p_u_embedding_r_m_s_prop_parameters(const tensor& parameters, const tensor& ms, const tensor& mom, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingRMSPropParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ms.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mom.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # LoadTPUEmbeddingStochasticGradientDescentParameters
# Inputs:
*    parameters

# Attributes:
*    num_shards
*    shard_id
*    table_id
*    table_name
*    config

# Outputs:
*    
*/
inline void load_t_p_u_embedding_stochastic_gradient_descent_parameters(const tensor& parameters, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingStochasticGradientDescentParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # Log
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor log(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Log", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Log1p
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor log1p(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Log1p", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # LogMatrixDeterminant
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    sign
*    log_abs_determinant

*/
inline std::vector<tensor> log_matrix_determinant(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LogMatrixDeterminant", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # LogSoftmax
# Inputs:
*    logits

# Attributes:
*    
# Outputs:
*    logsoftmax

*/
inline tensor log_softmax(const tensor& logits) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LogSoftmax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), logits.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # LogUniformCandidateSampler
# Inputs:
*    true_classes

# Attributes:
*    num_true
*    num_sampled
*    unique
*    range_max
*    seed
*    seed2

# Outputs:
*    sampled_candidates
*    true_expected_count
*    sampled_expected_count

*/
inline std::vector<tensor> log_uniform_candidate_sampler(const tensor& true_classes, int64_t num_true, int64_t num_sampled, bool unique, int64_t range_max, int64_t seed=0, int64_t seed2=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LogUniformCandidateSampler", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), true_classes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_true", num_true);
    TFE_OpSetAttrInt(op.get(), "num_sampled", num_sampled);
    TFE_OpSetAttrBool(op.get(), "unique", (unsigned char)unique);
    TFE_OpSetAttrInt(op.get(), "range_max", range_max);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # LogicalAnd
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor logical_and(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LogicalAnd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # LogicalNot
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor logical_not(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LogicalNot", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # LogicalOr
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor logical_or(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LogicalOr", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # LookupTableExport
# Inputs:
*    table_handle

# Attributes:
*    Tkeys
*    Tvalues

# Outputs:
*    keys
*    values

*/
inline std::vector<tensor> lookup_table_export(const tensor& table_handle, datatype Tkeys, datatype Tvalues) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LookupTableExport", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tkeys", Tkeys);
    TFE_OpSetAttrType(op.get(), "Tvalues", Tvalues);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # LookupTableExportV2
# Inputs:
*    table_handle

# Attributes:
*    Tkeys
*    Tvalues

# Outputs:
*    keys
*    values

*/
inline std::vector<tensor> lookup_table_export_v2(const tensor& table_handle, datatype Tkeys, datatype Tvalues) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LookupTableExportV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tkeys", Tkeys);
    TFE_OpSetAttrType(op.get(), "Tvalues", Tvalues);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # LookupTableFind
# Inputs:
*    table_handle
*    keys
*    default_value

# Attributes:
*    Tin
*    Tout

# Outputs:
*    values

*/
inline tensor lookup_table_find(const tensor& table_handle, const tensor& keys, const tensor& default_value, datatype Tin, datatype Tout) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LookupTableFind", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), keys.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), default_value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tin", Tin);
    TFE_OpSetAttrType(op.get(), "Tout", Tout);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # LookupTableFindV2
# Inputs:
*    table_handle
*    keys
*    default_value

# Attributes:
*    Tin
*    Tout

# Outputs:
*    values

*/
inline tensor lookup_table_find_v2(const tensor& table_handle, const tensor& keys, const tensor& default_value, datatype Tin, datatype Tout) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LookupTableFindV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), keys.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), default_value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tin", Tin);
    TFE_OpSetAttrType(op.get(), "Tout", Tout);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # LookupTableImport
# Inputs:
*    table_handle
*    keys
*    values

# Attributes:
*    Tin
*    Tout

# Outputs:
*    
*/
inline void lookup_table_import(const tensor& table_handle, const tensor& keys, const tensor& values, datatype Tin, datatype Tout) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LookupTableImport", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), keys.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tin", Tin);
    TFE_OpSetAttrType(op.get(), "Tout", Tout);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # LookupTableImportV2
# Inputs:
*    table_handle
*    keys
*    values

# Attributes:
*    Tin
*    Tout

# Outputs:
*    
*/
inline void lookup_table_import_v2(const tensor& table_handle, const tensor& keys, const tensor& values, datatype Tin, datatype Tout) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LookupTableImportV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), keys.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tin", Tin);
    TFE_OpSetAttrType(op.get(), "Tout", Tout);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # LookupTableInsert
# Inputs:
*    table_handle
*    keys
*    values

# Attributes:
*    Tin
*    Tout

# Outputs:
*    
*/
inline void lookup_table_insert(const tensor& table_handle, const tensor& keys, const tensor& values, datatype Tin, datatype Tout) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LookupTableInsert", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), keys.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tin", Tin);
    TFE_OpSetAttrType(op.get(), "Tout", Tout);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # LookupTableInsertV2
# Inputs:
*    table_handle
*    keys
*    values

# Attributes:
*    Tin
*    Tout

# Outputs:
*    
*/
inline void lookup_table_insert_v2(const tensor& table_handle, const tensor& keys, const tensor& values, datatype Tin, datatype Tout) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LookupTableInsertV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), keys.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tin", Tin);
    TFE_OpSetAttrType(op.get(), "Tout", Tout);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # LookupTableRemoveV2
# Inputs:
*    table_handle
*    keys

# Attributes:
*    Tin

# Outputs:
*    
*/
inline void lookup_table_remove_v2(const tensor& table_handle, const tensor& keys, datatype Tin) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LookupTableRemoveV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), keys.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tin", Tin);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # LookupTableSize
# Inputs:
*    table_handle

# Attributes:
*    
# Outputs:
*    size

*/
inline tensor lookup_table_size(const tensor& table_handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LookupTableSize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # LookupTableSizeV2
# Inputs:
*    table_handle

# Attributes:
*    
# Outputs:
*    size

*/
inline tensor lookup_table_size_v2(const tensor& table_handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LookupTableSizeV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # LoopCond
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor loop_cond(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoopCond", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # LowerBound
# Inputs:
*    sorted_inputs
*    values

# Attributes:
*    out_type

# Outputs:
*    output

*/
inline tensor lower_bound(const tensor& sorted_inputs, const tensor& values, datatype out_type=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LowerBound", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sorted_inputs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Lu
# Inputs:
*    input

# Attributes:
*    output_idx_type

# Outputs:
*    lu
*    p

*/
inline std::vector<tensor> lu(const tensor& input, datatype output_idx_type=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Lu", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "output_idx_type", output_idx_type);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # MakeIterator
# Inputs:
*    dataset
*    iterator

# Attributes:
*    
# Outputs:
*    
*/
inline void make_iterator(const tensor& dataset, const tensor& iterator) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MakeIterator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), iterator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # MapAndBatchDataset
# Inputs:
*    input_dataset
*    other_arguments
*    batch_size
*    num_parallel_calls
*    drop_remainder

# Attributes:
*    f
*    Targuments
*    output_types
*    output_shapes
*    preserve_cardinality
*    metadata

# Outputs:
*    handle

*/
inline tensor map_and_batch_dataset(const tensor& input_dataset, const std::vector<tensor>&other_arguments, const tensor& batch_size, const tensor& num_parallel_calls, const tensor& drop_remainder, int64_t f, const std::vector<datatype>& Targuments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool preserve_cardinality=false, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MapAndBatchDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> other_arguments_handles; other_arguments_handles.reserve(other_arguments.size());
    std::transform(other_arguments.begin(), other_arguments.end(), std::back_inserter(other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), other_arguments_handles.data(), static_cast<int>(other_arguments.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), batch_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_parallel_calls.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), drop_remainder.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "f", f);
    TFE_OpSetAttrTypeList(op.get(), "Targuments", reinterpret_cast<const enum TF_DataType *>(Targuments.data()), static_cast<int>(Targuments.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "preserve_cardinality", (unsigned char)preserve_cardinality);
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MapClear
# Inputs:
*    
# Attributes:
*    dtypes
*    capacity
*    memory_limit
*    container
*    shared_name

# Outputs:
*    
*/
inline void map_clear(const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MapClear", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # MapDataset
# Inputs:
*    input_dataset
*    other_arguments

# Attributes:
*    f
*    Targuments
*    output_types
*    output_shapes
*    use_inter_op_parallelism
*    preserve_cardinality
*    metadata

# Outputs:
*    handle

*/
inline tensor map_dataset(const tensor& input_dataset, const std::vector<tensor>&other_arguments, int64_t f, const std::vector<datatype>& Targuments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool use_inter_op_parallelism=true, bool preserve_cardinality=false, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MapDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> other_arguments_handles; other_arguments_handles.reserve(other_arguments.size());
    std::transform(other_arguments.begin(), other_arguments.end(), std::back_inserter(other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), other_arguments_handles.data(), static_cast<int>(other_arguments.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "f", f);
    TFE_OpSetAttrTypeList(op.get(), "Targuments", reinterpret_cast<const enum TF_DataType *>(Targuments.data()), static_cast<int>(Targuments.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "use_inter_op_parallelism", (unsigned char)use_inter_op_parallelism);
    TFE_OpSetAttrBool(op.get(), "preserve_cardinality", (unsigned char)preserve_cardinality);
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MapDefun
# Inputs:
*    arguments
*    captured_inputs

# Attributes:
*    Targuments
*    Tcaptured
*    output_types
*    output_shapes
*    f
*    max_intra_op_parallelism

# Outputs:
*    output

*/
inline tensor map_defun(const std::vector<tensor>&arguments, const std::vector<tensor>&captured_inputs, const std::vector<datatype>& Targuments, const std::vector<datatype>& Tcaptured, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, int64_t f, int64_t max_intra_op_parallelism=1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MapDefun", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> arguments_handles; arguments_handles.reserve(arguments.size());
    std::transform(arguments.begin(), arguments.end(), std::back_inserter(arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), arguments_handles.data(), static_cast<int>(arguments.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> captured_inputs_handles; captured_inputs_handles.reserve(captured_inputs.size());
    std::transform(captured_inputs.begin(), captured_inputs.end(), std::back_inserter(captured_inputs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), captured_inputs_handles.data(), static_cast<int>(captured_inputs.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Targuments", reinterpret_cast<const enum TF_DataType *>(Targuments.data()), static_cast<int>(Targuments.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tcaptured", reinterpret_cast<const enum TF_DataType *>(Tcaptured.data()), static_cast<int>(Tcaptured.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "f", f);
    TFE_OpSetAttrInt(op.get(), "max_intra_op_parallelism", max_intra_op_parallelism);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MapIncompleteSize
# Inputs:
*    
# Attributes:
*    dtypes
*    capacity
*    memory_limit
*    container
*    shared_name

# Outputs:
*    size

*/
inline tensor map_incomplete_size(const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MapIncompleteSize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MapPeek
# Inputs:
*    key
*    indices

# Attributes:
*    dtypes
*    capacity
*    memory_limit
*    container
*    shared_name

# Outputs:
*    values

*/
inline tensor map_peek(const tensor& key, const tensor& indices, const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MapPeek", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MapSize
# Inputs:
*    
# Attributes:
*    dtypes
*    capacity
*    memory_limit
*    container
*    shared_name

# Outputs:
*    size

*/
inline tensor map_size(const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MapSize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MapStage
# Inputs:
*    key
*    indices
*    values

# Attributes:
*    dtypes
*    fake_dtypes
*    capacity
*    memory_limit
*    container
*    shared_name

# Outputs:
*    
*/
inline void map_stage(const tensor& key, const tensor& indices, const std::vector<tensor>&values, const std::vector<datatype>& dtypes, const std::vector<datatype>& fake_dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MapStage", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> values_handles; values_handles.reserve(values.size());
    std::transform(values.begin(), values.end(), std::back_inserter(values_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), values_handles.data(), static_cast<int>(values.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));
    TFE_OpSetAttrTypeList(op.get(), "fake_dtypes", reinterpret_cast<const enum TF_DataType *>(fake_dtypes.data()), static_cast<int>(fake_dtypes.size()));
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # MapUnstage
# Inputs:
*    key
*    indices

# Attributes:
*    dtypes
*    capacity
*    memory_limit
*    container
*    shared_name

# Outputs:
*    values

*/
inline tensor map_unstage(const tensor& key, const tensor& indices, const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MapUnstage", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MapUnstageNoKey
# Inputs:
*    indices

# Attributes:
*    dtypes
*    capacity
*    memory_limit
*    container
*    shared_name

# Outputs:
*    key
*    values

*/
inline std::vector<tensor> map_unstage_no_key(const tensor& indices, const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MapUnstageNoKey", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # MatMul
# Inputs:
*    a
*    b

# Attributes:
*    transpose_a
*    transpose_b
*    grad_a
*    grad_b

# Outputs:
*    product

*/
inline tensor mat_mul(const tensor& a, const tensor& b, bool transpose_a=false, bool transpose_b=false, bool grad_a=false, bool grad_b=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatMul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "transpose_a", (unsigned char)transpose_a);
    TFE_OpSetAttrBool(op.get(), "transpose_b", (unsigned char)transpose_b);
    TFE_OpSetAttrBool(op.get(), "grad_a", (unsigned char)grad_a);
    TFE_OpSetAttrBool(op.get(), "grad_b", (unsigned char)grad_b);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MatchingFiles
# Inputs:
*    pattern

# Attributes:
*    
# Outputs:
*    filenames

*/
inline tensor matching_files(const tensor& pattern) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatchingFiles", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), pattern.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MatchingFilesDataset
# Inputs:
*    patterns

# Attributes:
*    
# Outputs:
*    handle

*/
inline tensor matching_files_dataset(const tensor& patterns) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatchingFilesDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), patterns.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MatrixBandPart
# Inputs:
*    input
*    num_lower
*    num_upper

# Attributes:
*    Tindex

# Outputs:
*    band

*/
inline tensor matrix_band_part(const tensor& input, const tensor& num_lower, const tensor& num_upper, datatype Tindex=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixBandPart", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_lower.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_upper.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindex", Tindex);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MatrixDeterminant
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor matrix_determinant(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixDeterminant", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MatrixDiag
# Inputs:
*    diagonal

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor matrix_diag(const tensor& diagonal) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixDiag", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), diagonal.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MatrixDiagPart
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    diagonal

*/
inline tensor matrix_diag_part(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixDiagPart", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MatrixDiagPartV2
# Inputs:
*    input
*    k
*    padding_value

# Attributes:
*    
# Outputs:
*    diagonal

*/
inline tensor matrix_diag_part_v2(const tensor& input, const tensor& k, const tensor& padding_value) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixDiagPartV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), k.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), padding_value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MatrixDiagPartV3
# Inputs:
*    input
*    k
*    padding_value

# Attributes:
*    align

# Outputs:
*    diagonal

*/
inline tensor matrix_diag_part_v3(const tensor& input, const tensor& k, const tensor& padding_value, const std::string& align="RIGHT_LEFT") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixDiagPartV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), k.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), padding_value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "align", (void*) align.c_str(), align.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MatrixDiagV2
# Inputs:
*    diagonal
*    k
*    num_rows
*    num_cols
*    padding_value

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor matrix_diag_v2(const tensor& diagonal, const tensor& k, const tensor& num_rows, const tensor& num_cols, const tensor& padding_value) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixDiagV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), diagonal.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), k.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_rows.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_cols.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), padding_value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MatrixDiagV3
# Inputs:
*    diagonal
*    k
*    num_rows
*    num_cols
*    padding_value

# Attributes:
*    align

# Outputs:
*    output

*/
inline tensor matrix_diag_v3(const tensor& diagonal, const tensor& k, const tensor& num_rows, const tensor& num_cols, const tensor& padding_value, const std::string& align="RIGHT_LEFT") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixDiagV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), diagonal.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), k.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_rows.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_cols.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), padding_value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "align", (void*) align.c_str(), align.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MatrixExponential
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor matrix_exponential(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixExponential", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MatrixInverse
# Inputs:
*    input

# Attributes:
*    adjoint

# Outputs:
*    output

*/
inline tensor matrix_inverse(const tensor& input, bool adjoint=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixInverse", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "adjoint", (unsigned char)adjoint);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MatrixLogarithm
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor matrix_logarithm(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixLogarithm", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MatrixSetDiag
# Inputs:
*    input
*    diagonal

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor matrix_set_diag(const tensor& input, const tensor& diagonal) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixSetDiag", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), diagonal.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MatrixSetDiagV2
# Inputs:
*    input
*    diagonal
*    k

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor matrix_set_diag_v2(const tensor& input, const tensor& diagonal, const tensor& k) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixSetDiagV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), diagonal.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), k.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MatrixSetDiagV3
# Inputs:
*    input
*    diagonal
*    k

# Attributes:
*    align

# Outputs:
*    output

*/
inline tensor matrix_set_diag_v3(const tensor& input, const tensor& diagonal, const tensor& k, const std::string& align="RIGHT_LEFT") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixSetDiagV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), diagonal.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), k.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "align", (void*) align.c_str(), align.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MatrixSolve
# Inputs:
*    matrix
*    rhs

# Attributes:
*    adjoint

# Outputs:
*    output

*/
inline tensor matrix_solve(const tensor& matrix, const tensor& rhs, bool adjoint=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixSolve", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), matrix.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "adjoint", (unsigned char)adjoint);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MatrixSolveLs
# Inputs:
*    matrix
*    rhs
*    l2_regularizer

# Attributes:
*    fast

# Outputs:
*    output

*/
inline tensor matrix_solve_ls(const tensor& matrix, const tensor& rhs, const tensor& l2_regularizer, bool fast=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixSolveLs", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), matrix.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2_regularizer.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "fast", (unsigned char)fast);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MatrixSquareRoot
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor matrix_square_root(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixSquareRoot", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MatrixTriangularSolve
# Inputs:
*    matrix
*    rhs

# Attributes:
*    lower
*    adjoint

# Outputs:
*    output

*/
inline tensor matrix_triangular_solve(const tensor& matrix, const tensor& rhs, bool lower=true, bool adjoint=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixTriangularSolve", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), matrix.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "lower", (unsigned char)lower);
    TFE_OpSetAttrBool(op.get(), "adjoint", (unsigned char)adjoint);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Max
# Inputs:
*    input
*    reduction_indices

# Attributes:
*    keep_dims
*    Tidx

# Outputs:
*    output

*/
inline tensor max(const tensor& input, const tensor& reduction_indices, bool keep_dims=false, datatype Tidx=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Max", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reduction_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "keep_dims", (unsigned char)keep_dims);
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MaxIntraOpParallelismDataset
# Inputs:
*    input_dataset
*    max_intra_op_parallelism

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor max_intra_op_parallelism_dataset(const tensor& input_dataset, const tensor& max_intra_op_parallelism, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MaxIntraOpParallelismDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_intra_op_parallelism.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MaxPool
# Inputs:
*    input

# Attributes:
*    ksize
*    strides
*    padding
*    explicit_paddings
*    data_format

# Outputs:
*    output

*/
inline tensor max_pool(const tensor& input, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& explicit_paddings, const std::string& data_format="NHWC") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MaxPool", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), static_cast<int>(ksize.size()));
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "explicit_paddings", explicit_paddings.data(), static_cast<int>(explicit_paddings.size()));
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MaxPool3D
# Inputs:
*    input

# Attributes:
*    ksize
*    strides
*    padding
*    data_format

# Outputs:
*    output

*/
inline tensor max_pool3_d(const tensor& input, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding, const std::string& data_format="NDHWC") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MaxPool3D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), static_cast<int>(ksize.size()));
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MaxPool3DGrad
# Inputs:
*    orig_input
*    orig_output
*    grad

# Attributes:
*    ksize
*    strides
*    padding
*    data_format
*    TInput

# Outputs:
*    output

*/
inline tensor max_pool3_d_grad(const tensor& orig_input, const tensor& orig_output, const tensor& grad, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding, const std::string& data_format="NDHWC", datatype TInput=static_cast<datatype>(1)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MaxPool3DGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), orig_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), orig_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), static_cast<int>(ksize.size()));
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());
    TFE_OpSetAttrType(op.get(), "TInput", TInput);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MaxPool3DGradGrad
# Inputs:
*    orig_input
*    orig_output
*    grad

# Attributes:
*    ksize
*    strides
*    padding
*    data_format

# Outputs:
*    output

*/
inline tensor max_pool3_d_grad_grad(const tensor& orig_input, const tensor& orig_output, const tensor& grad, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding, const std::string& data_format="NDHWC") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MaxPool3DGradGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), orig_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), orig_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), static_cast<int>(ksize.size()));
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MaxPoolGrad
# Inputs:
*    orig_input
*    orig_output
*    grad

# Attributes:
*    ksize
*    strides
*    padding
*    explicit_paddings
*    data_format

# Outputs:
*    output

*/
inline tensor max_pool_grad(const tensor& orig_input, const tensor& orig_output, const tensor& grad, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& explicit_paddings, const std::string& data_format="NHWC") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MaxPoolGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), orig_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), orig_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), static_cast<int>(ksize.size()));
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "explicit_paddings", explicit_paddings.data(), static_cast<int>(explicit_paddings.size()));
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MaxPoolGradGrad
# Inputs:
*    orig_input
*    orig_output
*    grad

# Attributes:
*    ksize
*    strides
*    padding
*    data_format

# Outputs:
*    output

*/
inline tensor max_pool_grad_grad(const tensor& orig_input, const tensor& orig_output, const tensor& grad, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding, const std::string& data_format="NHWC") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MaxPoolGradGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), orig_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), orig_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), static_cast<int>(ksize.size()));
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MaxPoolGradGradV2
# Inputs:
*    orig_input
*    orig_output
*    grad
*    ksize
*    strides

# Attributes:
*    padding
*    data_format

# Outputs:
*    output

*/
inline tensor max_pool_grad_grad_v2(const tensor& orig_input, const tensor& orig_output, const tensor& grad, const tensor& ksize, const tensor& strides, const std::string& padding, const std::string& data_format="NHWC") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MaxPoolGradGradV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), orig_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), orig_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ksize.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), strides.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MaxPoolGradGradWithArgmax
# Inputs:
*    input
*    grad
*    argmax

# Attributes:
*    ksize
*    strides
*    padding
*    Targmax
*    include_batch_in_index

# Outputs:
*    output

*/
inline tensor max_pool_grad_grad_with_argmax(const tensor& input, const tensor& grad, const tensor& argmax, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding, datatype Targmax, bool include_batch_in_index=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MaxPoolGradGradWithArgmax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), argmax.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), static_cast<int>(ksize.size()));
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrType(op.get(), "Targmax", Targmax);
    TFE_OpSetAttrBool(op.get(), "include_batch_in_index", (unsigned char)include_batch_in_index);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MaxPoolGradV2
# Inputs:
*    orig_input
*    orig_output
*    grad
*    ksize
*    strides

# Attributes:
*    padding
*    data_format

# Outputs:
*    output

*/
inline tensor max_pool_grad_v2(const tensor& orig_input, const tensor& orig_output, const tensor& grad, const tensor& ksize, const tensor& strides, const std::string& padding, const std::string& data_format="NHWC") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MaxPoolGradV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), orig_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), orig_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ksize.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), strides.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MaxPoolGradWithArgmax
# Inputs:
*    input
*    grad
*    argmax

# Attributes:
*    ksize
*    strides
*    padding
*    Targmax
*    include_batch_in_index

# Outputs:
*    output

*/
inline tensor max_pool_grad_with_argmax(const tensor& input, const tensor& grad, const tensor& argmax, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding, datatype Targmax, bool include_batch_in_index=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MaxPoolGradWithArgmax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), argmax.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), static_cast<int>(ksize.size()));
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrType(op.get(), "Targmax", Targmax);
    TFE_OpSetAttrBool(op.get(), "include_batch_in_index", (unsigned char)include_batch_in_index);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MaxPoolV2
# Inputs:
*    input
*    ksize
*    strides

# Attributes:
*    padding
*    data_format

# Outputs:
*    output

*/
inline tensor max_pool_v2(const tensor& input, const tensor& ksize, const tensor& strides, const std::string& padding, const std::string& data_format="NHWC") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MaxPoolV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ksize.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), strides.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MaxPoolWithArgmax
# Inputs:
*    input

# Attributes:
*    ksize
*    strides
*    padding
*    Targmax
*    include_batch_in_index

# Outputs:
*    output
*    argmax

*/
inline std::vector<tensor> max_pool_with_argmax(const tensor& input, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding, datatype Targmax=static_cast<datatype>(9), bool include_batch_in_index=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MaxPoolWithArgmax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), static_cast<int>(ksize.size()));
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrType(op.get(), "Targmax", Targmax);
    TFE_OpSetAttrBool(op.get(), "include_batch_in_index", (unsigned char)include_batch_in_index);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # Maximum
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor maximum(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Maximum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Mean
# Inputs:
*    input
*    reduction_indices

# Attributes:
*    keep_dims
*    Tidx

# Outputs:
*    output

*/
inline tensor mean(const tensor& input, const tensor& reduction_indices, bool keep_dims=false, datatype Tidx=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Mean", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reduction_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "keep_dims", (unsigned char)keep_dims);
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Merge
# Inputs:
*    inputs

# Attributes:
*    N

# Outputs:
*    output
*    value_index

*/
inline std::vector<tensor> merge(const std::vector<tensor>&inputs) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Merge", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), static_cast<int>(inputs.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", inputs.size());

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # MergeSummary
# Inputs:
*    inputs

# Attributes:
*    N

# Outputs:
*    summary

*/
inline tensor merge_summary(const std::vector<tensor>&inputs) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MergeSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), static_cast<int>(inputs.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", inputs.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MergeV2Checkpoints
# Inputs:
*    checkpoint_prefixes
*    destination_prefix

# Attributes:
*    delete_old_dirs
*    allow_missing_files

# Outputs:
*    
*/
inline void merge_v2_checkpoints(const tensor& checkpoint_prefixes, const tensor& destination_prefix, bool delete_old_dirs=true, bool allow_missing_files=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MergeV2Checkpoints", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), checkpoint_prefixes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), destination_prefix.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "delete_old_dirs", (unsigned char)delete_old_dirs);
    TFE_OpSetAttrBool(op.get(), "allow_missing_files", (unsigned char)allow_missing_files);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # Mfcc
# Inputs:
*    spectrogram
*    sample_rate

# Attributes:
*    upper_frequency_limit
*    lower_frequency_limit
*    filterbank_channel_count
*    dct_coefficient_count

# Outputs:
*    output

*/
inline tensor mfcc(const tensor& spectrogram, const tensor& sample_rate, float upper_frequency_limit=4.0000e+03, float lower_frequency_limit=2.0000e+01, int64_t filterbank_channel_count=40, int64_t dct_coefficient_count=13) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Mfcc", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), spectrogram.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sample_rate.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "upper_frequency_limit", upper_frequency_limit);
    TFE_OpSetAttrFloat(op.get(), "lower_frequency_limit", lower_frequency_limit);
    TFE_OpSetAttrInt(op.get(), "filterbank_channel_count", filterbank_channel_count);
    TFE_OpSetAttrInt(op.get(), "dct_coefficient_count", dct_coefficient_count);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Min
# Inputs:
*    input
*    reduction_indices

# Attributes:
*    keep_dims
*    Tidx

# Outputs:
*    output

*/
inline tensor min(const tensor& input, const tensor& reduction_indices, bool keep_dims=false, datatype Tidx=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Min", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reduction_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "keep_dims", (unsigned char)keep_dims);
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Minimum
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor minimum(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Minimum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MirrorPad
# Inputs:
*    input
*    paddings

# Attributes:
*    mode
*    Tpaddings

# Outputs:
*    output

*/
inline tensor mirror_pad(const tensor& input, const tensor& paddings, const std::string& mode, datatype Tpaddings=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MirrorPad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), paddings.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "mode", (void*) mode.c_str(), mode.size());
    TFE_OpSetAttrType(op.get(), "Tpaddings", Tpaddings);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MirrorPadGrad
# Inputs:
*    input
*    paddings

# Attributes:
*    mode
*    Tpaddings

# Outputs:
*    output

*/
inline tensor mirror_pad_grad(const tensor& input, const tensor& paddings, const std::string& mode, datatype Tpaddings=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MirrorPadGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), paddings.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "mode", (void*) mode.c_str(), mode.size());
    TFE_OpSetAttrType(op.get(), "Tpaddings", Tpaddings);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Mod
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor mod(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Mod", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ModelDataset
# Inputs:
*    input_dataset

# Attributes:
*    output_types
*    output_shapes
*    algorithm
*    cpu_budget
*    ram_budget

# Outputs:
*    handle

*/
inline tensor model_dataset(const tensor& input_dataset, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, int64_t algorithm=0, int64_t cpu_budget=0, int64_t ram_budget=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ModelDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "algorithm", algorithm);
    TFE_OpSetAttrInt(op.get(), "cpu_budget", cpu_budget);
    TFE_OpSetAttrInt(op.get(), "ram_budget", ram_budget);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Mul
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor mul(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Mul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MulNoNan
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor mul_no_nan(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MulNoNan", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MultiDeviceIterator
# Inputs:
*    
# Attributes:
*    devices
*    shared_name
*    container
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor multi_device_iterator(const std::vector< std::string>& devices, const std::string& shared_name, const std::string& container, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MultiDeviceIterator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    
    std::vector<std::size_t> devices_sizes; devices_sizes.reserve(devices.size());
    std::transform(devices.begin(), devices.end(), std::back_inserter(devices_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "devices", reinterpret_cast<const void *const *>(devices.data()), devices_sizes.data(), static_cast<int>(devices.size()));
    
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MultiDeviceIteratorFromStringHandle
# Inputs:
*    string_handle

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    multi_device_iterator

*/
inline tensor multi_device_iterator_from_string_handle(const tensor& string_handle, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MultiDeviceIteratorFromStringHandle", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), string_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MultiDeviceIteratorGetNextFromShard
# Inputs:
*    multi_device_iterator
*    shard_num
*    incarnation_id

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    components

*/
inline tensor multi_device_iterator_get_next_from_shard(const tensor& multi_device_iterator, const tensor& shard_num, const tensor& incarnation_id, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MultiDeviceIteratorGetNextFromShard", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), multi_device_iterator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shard_num.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), incarnation_id.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MultiDeviceIteratorInit
# Inputs:
*    dataset
*    multi_device_iterator
*    max_buffer_size

# Attributes:
*    
# Outputs:
*    incarnation_id

*/
inline tensor multi_device_iterator_init(const tensor& dataset, const tensor& multi_device_iterator, const tensor& max_buffer_size) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MultiDeviceIteratorInit", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), multi_device_iterator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_buffer_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MultiDeviceIteratorToStringHandle
# Inputs:
*    multi_device_iterator

# Attributes:
*    
# Outputs:
*    string_handle

*/
inline tensor multi_device_iterator_to_string_handle(const tensor& multi_device_iterator) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MultiDeviceIteratorToStringHandle", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), multi_device_iterator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Multinomial
# Inputs:
*    logits
*    num_samples

# Attributes:
*    seed
*    seed2
*    output_dtype

# Outputs:
*    output

*/
inline tensor multinomial(const tensor& logits, const tensor& num_samples, int64_t seed=0, int64_t seed2=0, datatype output_dtype=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Multinomial", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), logits.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_samples.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrType(op.get(), "output_dtype", output_dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MutableDenseHashTable
# Inputs:
*    empty_key

# Attributes:
*    key_dtype
*    value_dtype
*    value_shape
*    container
*    shared_name
*    use_node_name_sharing
*    initial_num_buckets
*    max_load_factor

# Outputs:
*    table_handle

*/
inline tensor mutable_dense_hash_table(const tensor& empty_key, datatype key_dtype, datatype value_dtype, const std::vector<int64_t>& value_shape, const std::string& container="", const std::string& shared_name="", bool use_node_name_sharing=false, int64_t initial_num_buckets=131072, float max_load_factor=8.0000e-01) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MutableDenseHashTable", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), empty_key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "key_dtype", key_dtype);
    TFE_OpSetAttrType(op.get(), "value_dtype", value_dtype);
    
    TFE_OpSetAttrShape(op.get(), "value_shape", value_shape.data(), static_cast<int>(value_shape.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrBool(op.get(), "use_node_name_sharing", (unsigned char)use_node_name_sharing);
    TFE_OpSetAttrInt(op.get(), "initial_num_buckets", initial_num_buckets);
    TFE_OpSetAttrFloat(op.get(), "max_load_factor", max_load_factor);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MutableDenseHashTableV2
# Inputs:
*    empty_key
*    deleted_key

# Attributes:
*    key_dtype
*    value_dtype
*    value_shape
*    container
*    shared_name
*    use_node_name_sharing
*    initial_num_buckets
*    max_load_factor

# Outputs:
*    table_handle

*/
inline tensor mutable_dense_hash_table_v2(const tensor& empty_key, const tensor& deleted_key, datatype key_dtype, datatype value_dtype, const std::vector<int64_t>& value_shape, const std::string& container="", const std::string& shared_name="", bool use_node_name_sharing=false, int64_t initial_num_buckets=131072, float max_load_factor=8.0000e-01) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MutableDenseHashTableV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), empty_key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), deleted_key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "key_dtype", key_dtype);
    TFE_OpSetAttrType(op.get(), "value_dtype", value_dtype);
    
    TFE_OpSetAttrShape(op.get(), "value_shape", value_shape.data(), static_cast<int>(value_shape.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrBool(op.get(), "use_node_name_sharing", (unsigned char)use_node_name_sharing);
    TFE_OpSetAttrInt(op.get(), "initial_num_buckets", initial_num_buckets);
    TFE_OpSetAttrFloat(op.get(), "max_load_factor", max_load_factor);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MutableHashTable
# Inputs:
*    
# Attributes:
*    key_dtype
*    value_dtype
*    container
*    shared_name
*    use_node_name_sharing

# Outputs:
*    table_handle

*/
inline tensor mutable_hash_table(datatype key_dtype, datatype value_dtype, const std::string& container="", const std::string& shared_name="", bool use_node_name_sharing=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MutableHashTable", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "key_dtype", key_dtype);
    TFE_OpSetAttrType(op.get(), "value_dtype", value_dtype);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrBool(op.get(), "use_node_name_sharing", (unsigned char)use_node_name_sharing);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MutableHashTableOfTensors
# Inputs:
*    
# Attributes:
*    key_dtype
*    value_dtype
*    value_shape
*    container
*    shared_name
*    use_node_name_sharing

# Outputs:
*    table_handle

*/
inline tensor mutable_hash_table_of_tensors(datatype key_dtype, datatype value_dtype, const std::vector<int64_t>& value_shape, const std::string& container="", const std::string& shared_name="", bool use_node_name_sharing=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MutableHashTableOfTensors", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "key_dtype", key_dtype);
    TFE_OpSetAttrType(op.get(), "value_dtype", value_dtype);
    
    TFE_OpSetAttrShape(op.get(), "value_shape", value_shape.data(), static_cast<int>(value_shape.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrBool(op.get(), "use_node_name_sharing", (unsigned char)use_node_name_sharing);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MutableHashTableOfTensorsV2
# Inputs:
*    
# Attributes:
*    key_dtype
*    value_dtype
*    value_shape
*    container
*    shared_name
*    use_node_name_sharing

# Outputs:
*    table_handle

*/
inline tensor mutable_hash_table_of_tensors_v2(datatype key_dtype, datatype value_dtype, const std::vector<int64_t>& value_shape, const std::string& container="", const std::string& shared_name="", bool use_node_name_sharing=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MutableHashTableOfTensorsV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "key_dtype", key_dtype);
    TFE_OpSetAttrType(op.get(), "value_dtype", value_dtype);
    
    TFE_OpSetAttrShape(op.get(), "value_shape", value_shape.data(), static_cast<int>(value_shape.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrBool(op.get(), "use_node_name_sharing", (unsigned char)use_node_name_sharing);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MutableHashTableV2
# Inputs:
*    
# Attributes:
*    key_dtype
*    value_dtype
*    container
*    shared_name
*    use_node_name_sharing

# Outputs:
*    table_handle

*/
inline tensor mutable_hash_table_v2(datatype key_dtype, datatype value_dtype, const std::string& container="", const std::string& shared_name="", bool use_node_name_sharing=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MutableHashTableV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "key_dtype", key_dtype);
    TFE_OpSetAttrType(op.get(), "value_dtype", value_dtype);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrBool(op.get(), "use_node_name_sharing", (unsigned char)use_node_name_sharing);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MutexLock
# Inputs:
*    mutex

# Attributes:
*    
# Outputs:
*    mutex_lock

*/
inline tensor mutex_lock(const tensor& mutex) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MutexLock", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), mutex.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # MutexV2
# Inputs:
*    
# Attributes:
*    container
*    shared_name

# Outputs:
*    resource

*/
inline tensor mutex_v2(const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MutexV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # NcclAllReduce
# Inputs:
*    input

# Attributes:
*    reduction
*    num_devices
*    shared_name

# Outputs:
*    data

*/
inline tensor nccl_all_reduce(const tensor& input, const std::string& reduction, int64_t num_devices, const std::string& shared_name) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NcclAllReduce", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "reduction", (void*) reduction.c_str(), reduction.size());
    TFE_OpSetAttrInt(op.get(), "num_devices", num_devices);
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # NcclBroadcast
# Inputs:
*    input

# Attributes:
*    shape

# Outputs:
*    output

*/
inline tensor nccl_broadcast(const tensor& input, const std::vector<int64_t>& shape) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NcclBroadcast", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), static_cast<int>(shape.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # NcclReduce
# Inputs:
*    input

# Attributes:
*    reduction
*    num_devices

# Outputs:
*    data

*/
inline tensor nccl_reduce(const std::vector<tensor>&input, const std::string& reduction) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NcclReduce", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> input_handles; input_handles.reserve(input.size());
    std::transform(input.begin(), input.end(), std::back_inserter(input_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), input_handles.data(), static_cast<int>(input.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "reduction", (void*) reduction.c_str(), reduction.size());
    TFE_OpSetAttrInt(op.get(), "num_devices", input.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Ndtri
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor ndtri(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Ndtri", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # NearestNeighbors
# Inputs:
*    points
*    centers
*    k

# Attributes:
*    
# Outputs:
*    nearest_center_indices
*    nearest_center_distances

*/
inline std::vector<tensor> nearest_neighbors(const tensor& points, const tensor& centers, const tensor& k) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NearestNeighbors", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), points.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), centers.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), k.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # Neg
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor neg(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Neg", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # NextAfter
# Inputs:
*    x1
*    x2

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor next_after(const tensor& x1, const tensor& x2) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NextAfter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # NextIteration
# Inputs:
*    data

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor next_iteration(const tensor& data) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NextIteration", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # NoOp
# Inputs:
*    
# Attributes:
*    
# Outputs:
*    
*/
inline void no_op() {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NoOp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # NonDeterministicInts
# Inputs:
*    shape

# Attributes:
*    dtype
*    shape_dtype

# Outputs:
*    output

*/
inline tensor non_deterministic_ints(const tensor& shape, datatype dtype=static_cast<datatype>(9), datatype shape_dtype=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NonDeterministicInts", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "shape_dtype", shape_dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # NonMaxSuppression
# Inputs:
*    boxes
*    scores
*    max_output_size

# Attributes:
*    iou_threshold

# Outputs:
*    selected_indices

*/
inline tensor non_max_suppression(const tensor& boxes, const tensor& scores, const tensor& max_output_size, float iou_threshold=5.0000e-01) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NonMaxSuppression", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), boxes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scores.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_output_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "iou_threshold", iou_threshold);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # NonMaxSuppressionV2
# Inputs:
*    boxes
*    scores
*    max_output_size
*    iou_threshold

# Attributes:
*    T_threshold

# Outputs:
*    selected_indices

*/
inline tensor non_max_suppression_v2(const tensor& boxes, const tensor& scores, const tensor& max_output_size, const tensor& iou_threshold, datatype T_threshold=static_cast<datatype>(1)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NonMaxSuppressionV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), boxes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scores.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_output_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), iou_threshold.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "T_threshold", T_threshold);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # NonMaxSuppressionV3
# Inputs:
*    boxes
*    scores
*    max_output_size
*    iou_threshold
*    score_threshold

# Attributes:
*    T_threshold

# Outputs:
*    selected_indices

*/
inline tensor non_max_suppression_v3(const tensor& boxes, const tensor& scores, const tensor& max_output_size, const tensor& iou_threshold, const tensor& score_threshold, datatype T_threshold=static_cast<datatype>(1)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NonMaxSuppressionV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), boxes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scores.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_output_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), iou_threshold.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), score_threshold.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "T_threshold", T_threshold);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # NonMaxSuppressionV4
# Inputs:
*    boxes
*    scores
*    max_output_size
*    iou_threshold
*    score_threshold

# Attributes:
*    T_threshold
*    pad_to_max_output_size

# Outputs:
*    selected_indices
*    valid_outputs

*/
inline std::vector<tensor> non_max_suppression_v4(const tensor& boxes, const tensor& scores, const tensor& max_output_size, const tensor& iou_threshold, const tensor& score_threshold, datatype T_threshold=static_cast<datatype>(1), bool pad_to_max_output_size=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NonMaxSuppressionV4", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), boxes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scores.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_output_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), iou_threshold.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), score_threshold.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "T_threshold", T_threshold);
    TFE_OpSetAttrBool(op.get(), "pad_to_max_output_size", (unsigned char)pad_to_max_output_size);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # NonMaxSuppressionV5
# Inputs:
*    boxes
*    scores
*    max_output_size
*    iou_threshold
*    score_threshold
*    soft_nms_sigma

# Attributes:
*    pad_to_max_output_size

# Outputs:
*    selected_indices
*    selected_scores
*    valid_outputs

*/
inline std::vector<tensor> non_max_suppression_v5(const tensor& boxes, const tensor& scores, const tensor& max_output_size, const tensor& iou_threshold, const tensor& score_threshold, const tensor& soft_nms_sigma, bool pad_to_max_output_size=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NonMaxSuppressionV5", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), boxes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scores.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_output_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), iou_threshold.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), score_threshold.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), soft_nms_sigma.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "pad_to_max_output_size", (unsigned char)pad_to_max_output_size);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # NonMaxSuppressionWithOverlaps
# Inputs:
*    overlaps
*    scores
*    max_output_size
*    overlap_threshold
*    score_threshold

# Attributes:
*    
# Outputs:
*    selected_indices

*/
inline tensor non_max_suppression_with_overlaps(const tensor& overlaps, const tensor& scores, const tensor& max_output_size, const tensor& overlap_threshold, const tensor& score_threshold) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NonMaxSuppressionWithOverlaps", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), overlaps.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scores.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_output_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), overlap_threshold.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), score_threshold.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # NonSerializableDataset
# Inputs:
*    input_dataset

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor non_serializable_dataset(const tensor& input_dataset, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NonSerializableDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # NotEqual
# Inputs:
*    x
*    y

# Attributes:
*    incompatible_shape_error

# Outputs:
*    z

*/
inline tensor not_equal(const tensor& x, const tensor& y, bool incompatible_shape_error=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NotEqual", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "incompatible_shape_error", (unsigned char)incompatible_shape_error);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # NthElement
# Inputs:
*    input
*    n

# Attributes:
*    reverse

# Outputs:
*    values

*/
inline tensor nth_element(const tensor& input, const tensor& n, bool reverse=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NthElement", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), n.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "reverse", (unsigned char)reverse);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # OneHot
# Inputs:
*    indices
*    depth
*    on_value
*    off_value

# Attributes:
*    axis
*    TI

# Outputs:
*    output

*/
inline tensor one_hot(const tensor& indices, const tensor& depth, const tensor& on_value, const tensor& off_value, int64_t axis=-1, datatype TI=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OneHot", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), depth.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), on_value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), off_value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "axis", axis);
    TFE_OpSetAttrType(op.get(), "TI", TI);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # OneShotIterator
# Inputs:
*    
# Attributes:
*    dataset_factory
*    output_types
*    output_shapes
*    container
*    shared_name

# Outputs:
*    handle

*/
inline tensor one_shot_iterator(int64_t dataset_factory, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OneShotIterator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "dataset_factory", dataset_factory);
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # OnesLike
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor ones_like(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OnesLike", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # OptimizeDataset
# Inputs:
*    input_dataset
*    optimizations

# Attributes:
*    output_types
*    output_shapes
*    optimization_configs

# Outputs:
*    handle

*/
inline tensor optimize_dataset(const tensor& input_dataset, const tensor& optimizations, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::vector< std::string>& optimization_configs) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OptimizeDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), optimizations.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<std::size_t> optimization_configs_sizes; optimization_configs_sizes.reserve(optimization_configs.size());
    std::transform(optimization_configs.begin(), optimization_configs.end(), std::back_inserter(optimization_configs_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "optimization_configs", reinterpret_cast<const void *const *>(optimization_configs.data()), optimization_configs_sizes.data(), static_cast<int>(optimization_configs.size()));
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # OptimizeDatasetV2
# Inputs:
*    input_dataset
*    optimizations_enabled
*    optimizations_disabled
*    optimizations_default

# Attributes:
*    output_types
*    output_shapes
*    optimization_configs

# Outputs:
*    handle

*/
inline tensor optimize_dataset_v2(const tensor& input_dataset, const tensor& optimizations_enabled, const tensor& optimizations_disabled, const tensor& optimizations_default, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::vector< std::string>& optimization_configs) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OptimizeDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), optimizations_enabled.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), optimizations_disabled.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), optimizations_default.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<std::size_t> optimization_configs_sizes; optimization_configs_sizes.reserve(optimization_configs.size());
    std::transform(optimization_configs.begin(), optimization_configs.end(), std::back_inserter(optimization_configs_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "optimization_configs", reinterpret_cast<const void *const *>(optimization_configs.data()), optimization_configs_sizes.data(), static_cast<int>(optimization_configs.size()));
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # OptionalFromValue
# Inputs:
*    components

# Attributes:
*    Toutput_types

# Outputs:
*    optional

*/
inline tensor optional_from_value(const std::vector<tensor>&components, const std::vector<datatype>& Toutput_types) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OptionalFromValue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> components_handles; components_handles.reserve(components.size());
    std::transform(components.begin(), components.end(), std::back_inserter(components_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), components_handles.data(), static_cast<int>(components.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Toutput_types", reinterpret_cast<const enum TF_DataType *>(Toutput_types.data()), static_cast<int>(Toutput_types.size()));

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # OptionalGetValue
# Inputs:
*    optional

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    components

*/
inline tensor optional_get_value(const tensor& optional, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OptionalGetValue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), optional.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # OptionalHasValue
# Inputs:
*    optional

# Attributes:
*    
# Outputs:
*    has_value

*/
inline tensor optional_has_value(const tensor& optional) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OptionalHasValue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), optional.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # OptionalNone
# Inputs:
*    
# Attributes:
*    
# Outputs:
*    optional

*/
inline tensor optional_none() {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OptionalNone", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # OptionsDataset
# Inputs:
*    input_dataset

# Attributes:
*    serialized_options
*    output_types
*    output_shapes
*    metadata

# Outputs:
*    handle

*/
inline tensor options_dataset(const tensor& input_dataset, const std::string& serialized_options, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OptionsDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "serialized_options", (void*) serialized_options.c_str(), serialized_options.size());
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # OrderedMapClear
# Inputs:
*    
# Attributes:
*    dtypes
*    capacity
*    memory_limit
*    container
*    shared_name

# Outputs:
*    
*/
inline void ordered_map_clear(const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OrderedMapClear", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # OrderedMapIncompleteSize
# Inputs:
*    
# Attributes:
*    dtypes
*    capacity
*    memory_limit
*    container
*    shared_name

# Outputs:
*    size

*/
inline tensor ordered_map_incomplete_size(const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OrderedMapIncompleteSize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # OrderedMapPeek
# Inputs:
*    key
*    indices

# Attributes:
*    dtypes
*    capacity
*    memory_limit
*    container
*    shared_name

# Outputs:
*    values

*/
inline tensor ordered_map_peek(const tensor& key, const tensor& indices, const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OrderedMapPeek", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # OrderedMapSize
# Inputs:
*    
# Attributes:
*    dtypes
*    capacity
*    memory_limit
*    container
*    shared_name

# Outputs:
*    size

*/
inline tensor ordered_map_size(const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OrderedMapSize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # OrderedMapStage
# Inputs:
*    key
*    indices
*    values

# Attributes:
*    dtypes
*    fake_dtypes
*    capacity
*    memory_limit
*    container
*    shared_name

# Outputs:
*    
*/
inline void ordered_map_stage(const tensor& key, const tensor& indices, const std::vector<tensor>&values, const std::vector<datatype>& dtypes, const std::vector<datatype>& fake_dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OrderedMapStage", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> values_handles; values_handles.reserve(values.size());
    std::transform(values.begin(), values.end(), std::back_inserter(values_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), values_handles.data(), static_cast<int>(values.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));
    TFE_OpSetAttrTypeList(op.get(), "fake_dtypes", reinterpret_cast<const enum TF_DataType *>(fake_dtypes.data()), static_cast<int>(fake_dtypes.size()));
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # OrderedMapUnstage
# Inputs:
*    key
*    indices

# Attributes:
*    dtypes
*    capacity
*    memory_limit
*    container
*    shared_name

# Outputs:
*    values

*/
inline tensor ordered_map_unstage(const tensor& key, const tensor& indices, const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OrderedMapUnstage", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # OrderedMapUnstageNoKey
# Inputs:
*    indices

# Attributes:
*    dtypes
*    capacity
*    memory_limit
*    container
*    shared_name

# Outputs:
*    key
*    values

*/
inline std::vector<tensor> ordered_map_unstage_no_key(const tensor& indices, const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OrderedMapUnstageNoKey", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # OutfeedDequeue
# Inputs:
*    
# Attributes:
*    dtype
*    shape
*    device_ordinal

# Outputs:
*    output

*/
inline tensor outfeed_dequeue(datatype dtype, const std::vector<int64_t>& shape, int64_t device_ordinal=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OutfeedDequeue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), static_cast<int>(shape.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "device_ordinal", device_ordinal);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # OutfeedDequeueTuple
# Inputs:
*    
# Attributes:
*    dtypes
*    shapes
*    device_ordinal

# Outputs:
*    outputs

*/
inline tensor outfeed_dequeue_tuple(const std::vector<datatype>& dtypes, const std::vector< std::vector<int64_t>>& shapes, int64_t device_ordinal=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OutfeedDequeueTuple", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), static_cast<int>(shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "device_ordinal", device_ordinal);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # OutfeedDequeueTupleV2
# Inputs:
*    device_ordinal

# Attributes:
*    dtypes
*    shapes

# Outputs:
*    outputs

*/
inline tensor outfeed_dequeue_tuple_v2(const tensor& device_ordinal, const std::vector<datatype>& dtypes, const std::vector< std::vector<int64_t>>& shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OutfeedDequeueTupleV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), device_ordinal.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), static_cast<int>(shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # OutfeedDequeueV2
# Inputs:
*    device_ordinal

# Attributes:
*    dtype
*    shape

# Outputs:
*    output

*/
inline tensor outfeed_dequeue_v2(const tensor& device_ordinal, datatype dtype, const std::vector<int64_t>& shape) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OutfeedDequeueV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), device_ordinal.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), static_cast<int>(shape.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # OutfeedEnqueue
# Inputs:
*    input

# Attributes:
*    dtype

# Outputs:
*    
*/
inline void outfeed_enqueue(const tensor& input, datatype dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OutfeedEnqueue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # OutfeedEnqueueTuple
# Inputs:
*    inputs

# Attributes:
*    dtypes

# Outputs:
*    
*/
inline void outfeed_enqueue_tuple(const std::vector<tensor>&inputs, const std::vector<datatype>& dtypes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OutfeedEnqueueTuple", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), static_cast<int>(inputs.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # Pack
# Inputs:
*    values

# Attributes:
*    N
*    axis

# Outputs:
*    output

*/
inline tensor pack(const std::vector<tensor>&values, int64_t axis=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Pack", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> values_handles; values_handles.reserve(values.size());
    std::transform(values.begin(), values.end(), std::back_inserter(values_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), values_handles.data(), static_cast<int>(values.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", values.size());
    TFE_OpSetAttrInt(op.get(), "axis", axis);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Pad
# Inputs:
*    input
*    paddings

# Attributes:
*    Tpaddings

# Outputs:
*    output

*/
inline tensor pad(const tensor& input, const tensor& paddings, datatype Tpaddings=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Pad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), paddings.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tpaddings", Tpaddings);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # PadV2
# Inputs:
*    input
*    paddings
*    constant_values

# Attributes:
*    Tpaddings

# Outputs:
*    output

*/
inline tensor pad_v2(const tensor& input, const tensor& paddings, const tensor& constant_values, datatype Tpaddings=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PadV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), paddings.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), constant_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tpaddings", Tpaddings);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # PaddedBatchDataset
# Inputs:
*    input_dataset
*    batch_size
*    padded_shapes
*    padding_values

# Attributes:
*    Toutput_types
*    output_shapes
*    N
*    metadata

# Outputs:
*    handle

*/
inline tensor padded_batch_dataset(const tensor& input_dataset, const tensor& batch_size, const std::vector<tensor>&padded_shapes, const std::vector<tensor>&padding_values, const std::vector<datatype>& Toutput_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PaddedBatchDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), batch_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> padded_shapes_handles; padded_shapes_handles.reserve(padded_shapes.size());
    std::transform(padded_shapes.begin(), padded_shapes.end(), std::back_inserter(padded_shapes_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), padded_shapes_handles.data(), static_cast<int>(padded_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> padding_values_handles; padding_values_handles.reserve(padding_values.size());
    std::transform(padding_values.begin(), padding_values.end(), std::back_inserter(padding_values_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), padding_values_handles.data(), static_cast<int>(padding_values.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Toutput_types", reinterpret_cast<const enum TF_DataType *>(Toutput_types.data()), static_cast<int>(Toutput_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "N", padded_shapes.size());
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # PaddedBatchDatasetV2
# Inputs:
*    input_dataset
*    batch_size
*    padded_shapes
*    padding_values
*    drop_remainder

# Attributes:
*    Toutput_types
*    output_shapes
*    N
*    parallel_copy
*    metadata

# Outputs:
*    handle

*/
inline tensor padded_batch_dataset_v2(const tensor& input_dataset, const tensor& batch_size, const std::vector<tensor>&padded_shapes, const std::vector<tensor>&padding_values, const tensor& drop_remainder, const std::vector<datatype>& Toutput_types, const std::vector< std::vector<int64_t>>& output_shapes, bool parallel_copy=false, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PaddedBatchDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), batch_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> padded_shapes_handles; padded_shapes_handles.reserve(padded_shapes.size());
    std::transform(padded_shapes.begin(), padded_shapes.end(), std::back_inserter(padded_shapes_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), padded_shapes_handles.data(), static_cast<int>(padded_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> padding_values_handles; padding_values_handles.reserve(padding_values.size());
    std::transform(padding_values.begin(), padding_values.end(), std::back_inserter(padding_values_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), padding_values_handles.data(), static_cast<int>(padding_values.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), drop_remainder.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Toutput_types", reinterpret_cast<const enum TF_DataType *>(Toutput_types.data()), static_cast<int>(Toutput_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "N", padded_shapes.size());
    TFE_OpSetAttrBool(op.get(), "parallel_copy", (unsigned char)parallel_copy);
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # PaddingFIFOQueue
# Inputs:
*    
# Attributes:
*    component_types
*    shapes
*    capacity
*    container
*    shared_name

# Outputs:
*    handle

*/
inline tensor padding_f_i_f_o_queue(const std::vector<datatype>& component_types, const std::vector< std::vector<int64_t>>& shapes, int64_t capacity=-1, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PaddingFIFOQueue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), static_cast<int>(component_types.size()));
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), static_cast<int>(shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # PaddingFIFOQueueV2
# Inputs:
*    
# Attributes:
*    component_types
*    shapes
*    capacity
*    container
*    shared_name

# Outputs:
*    handle

*/
inline tensor padding_f_i_f_o_queue_v2(const std::vector<datatype>& component_types, const std::vector< std::vector<int64_t>>& shapes, int64_t capacity=-1, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PaddingFIFOQueueV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), static_cast<int>(component_types.size()));
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), static_cast<int>(shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ParallelBatchDataset
# Inputs:
*    input_dataset
*    batch_size
*    num_parallel_calls
*    drop_remainder

# Attributes:
*    output_types
*    output_shapes
*    parallel_copy
*    deterministic
*    metadata

# Outputs:
*    handle

*/
inline tensor parallel_batch_dataset(const tensor& input_dataset, const tensor& batch_size, const tensor& num_parallel_calls, const tensor& drop_remainder, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool parallel_copy=false, const std::string& deterministic="default", const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParallelBatchDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), batch_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_parallel_calls.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), drop_remainder.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "parallel_copy", (unsigned char)parallel_copy);
    TFE_OpSetAttrString(op.get(), "deterministic", (void*) deterministic.c_str(), deterministic.size());
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ParallelConcat
# Inputs:
*    values

# Attributes:
*    N
*    shape

# Outputs:
*    output

*/
inline tensor parallel_concat(const std::vector<tensor>&values, const std::vector<int64_t>& shape) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParallelConcat", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> values_handles; values_handles.reserve(values.size());
    std::transform(values.begin(), values.end(), std::back_inserter(values_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), values_handles.data(), static_cast<int>(values.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", values.size());
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), static_cast<int>(shape.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ParallelDynamicStitch
# Inputs:
*    indices
*    data

# Attributes:
*    N

# Outputs:
*    merged

*/
inline tensor parallel_dynamic_stitch(const std::vector<tensor>&indices, const std::vector<tensor>&data) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParallelDynamicStitch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> indices_handles; indices_handles.reserve(indices.size());
    std::transform(indices.begin(), indices.end(), std::back_inserter(indices_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), indices_handles.data(), static_cast<int>(indices.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> data_handles; data_handles.reserve(data.size());
    std::transform(data.begin(), data.end(), std::back_inserter(data_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), data_handles.data(), static_cast<int>(data.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", indices.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ParallelFilterDataset
# Inputs:
*    input_dataset
*    other_arguments
*    num_parallel_calls

# Attributes:
*    predicate
*    Targuments
*    output_types
*    output_shapes
*    deterministic
*    metadata

# Outputs:
*    handle

*/
inline tensor parallel_filter_dataset(const tensor& input_dataset, const std::vector<tensor>&other_arguments, const tensor& num_parallel_calls, int64_t predicate, const std::vector<datatype>& Targuments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& deterministic="default", const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParallelFilterDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> other_arguments_handles; other_arguments_handles.reserve(other_arguments.size());
    std::transform(other_arguments.begin(), other_arguments.end(), std::back_inserter(other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), other_arguments_handles.data(), static_cast<int>(other_arguments.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_parallel_calls.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "predicate", predicate);
    TFE_OpSetAttrTypeList(op.get(), "Targuments", reinterpret_cast<const enum TF_DataType *>(Targuments.data()), static_cast<int>(Targuments.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "deterministic", (void*) deterministic.c_str(), deterministic.size());
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ParallelInterleaveDataset
# Inputs:
*    input_dataset
*    other_arguments
*    cycle_length
*    block_length
*    sloppy
*    buffer_output_elements
*    prefetch_input_elements

# Attributes:
*    f
*    Targuments
*    output_types
*    output_shapes
*    metadata

# Outputs:
*    handle

*/
inline tensor parallel_interleave_dataset(const tensor& input_dataset, const std::vector<tensor>&other_arguments, const tensor& cycle_length, const tensor& block_length, const tensor& sloppy, const tensor& buffer_output_elements, const tensor& prefetch_input_elements, int64_t f, const std::vector<datatype>& Targuments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParallelInterleaveDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> other_arguments_handles; other_arguments_handles.reserve(other_arguments.size());
    std::transform(other_arguments.begin(), other_arguments.end(), std::back_inserter(other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), other_arguments_handles.data(), static_cast<int>(other_arguments.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cycle_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), block_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sloppy.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_output_elements.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), prefetch_input_elements.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "f", f);
    TFE_OpSetAttrTypeList(op.get(), "Targuments", reinterpret_cast<const enum TF_DataType *>(Targuments.data()), static_cast<int>(Targuments.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ParallelInterleaveDatasetV2
# Inputs:
*    input_dataset
*    other_arguments
*    cycle_length
*    block_length
*    num_parallel_calls

# Attributes:
*    f
*    Targuments
*    output_types
*    output_shapes
*    sloppy
*    metadata

# Outputs:
*    handle

*/
inline tensor parallel_interleave_dataset_v2(const tensor& input_dataset, const std::vector<tensor>&other_arguments, const tensor& cycle_length, const tensor& block_length, const tensor& num_parallel_calls, int64_t f, const std::vector<datatype>& Targuments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool sloppy=false, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParallelInterleaveDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> other_arguments_handles; other_arguments_handles.reserve(other_arguments.size());
    std::transform(other_arguments.begin(), other_arguments.end(), std::back_inserter(other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), other_arguments_handles.data(), static_cast<int>(other_arguments.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cycle_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), block_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_parallel_calls.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "f", f);
    TFE_OpSetAttrTypeList(op.get(), "Targuments", reinterpret_cast<const enum TF_DataType *>(Targuments.data()), static_cast<int>(Targuments.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "sloppy", (unsigned char)sloppy);
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ParallelInterleaveDatasetV3
# Inputs:
*    input_dataset
*    other_arguments
*    cycle_length
*    block_length
*    num_parallel_calls

# Attributes:
*    f
*    Targuments
*    output_types
*    output_shapes
*    deterministic
*    metadata

# Outputs:
*    handle

*/
inline tensor parallel_interleave_dataset_v3(const tensor& input_dataset, const std::vector<tensor>&other_arguments, const tensor& cycle_length, const tensor& block_length, const tensor& num_parallel_calls, int64_t f, const std::vector<datatype>& Targuments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& deterministic="default", const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParallelInterleaveDatasetV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> other_arguments_handles; other_arguments_handles.reserve(other_arguments.size());
    std::transform(other_arguments.begin(), other_arguments.end(), std::back_inserter(other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), other_arguments_handles.data(), static_cast<int>(other_arguments.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cycle_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), block_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_parallel_calls.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "f", f);
    TFE_OpSetAttrTypeList(op.get(), "Targuments", reinterpret_cast<const enum TF_DataType *>(Targuments.data()), static_cast<int>(Targuments.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "deterministic", (void*) deterministic.c_str(), deterministic.size());
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ParallelInterleaveDatasetV4
# Inputs:
*    input_dataset
*    other_arguments
*    cycle_length
*    block_length
*    buffer_output_elements
*    prefetch_input_elements
*    num_parallel_calls

# Attributes:
*    f
*    Targuments
*    output_types
*    output_shapes
*    deterministic
*    metadata

# Outputs:
*    handle

*/
inline tensor parallel_interleave_dataset_v4(const tensor& input_dataset, const std::vector<tensor>&other_arguments, const tensor& cycle_length, const tensor& block_length, const tensor& buffer_output_elements, const tensor& prefetch_input_elements, const tensor& num_parallel_calls, int64_t f, const std::vector<datatype>& Targuments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& deterministic="default", const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParallelInterleaveDatasetV4", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> other_arguments_handles; other_arguments_handles.reserve(other_arguments.size());
    std::transform(other_arguments.begin(), other_arguments.end(), std::back_inserter(other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), other_arguments_handles.data(), static_cast<int>(other_arguments.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cycle_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), block_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_output_elements.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), prefetch_input_elements.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_parallel_calls.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "f", f);
    TFE_OpSetAttrTypeList(op.get(), "Targuments", reinterpret_cast<const enum TF_DataType *>(Targuments.data()), static_cast<int>(Targuments.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "deterministic", (void*) deterministic.c_str(), deterministic.size());
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ParallelMapDataset
# Inputs:
*    input_dataset
*    other_arguments
*    num_parallel_calls

# Attributes:
*    f
*    Targuments
*    output_types
*    output_shapes
*    use_inter_op_parallelism
*    sloppy
*    preserve_cardinality
*    metadata

# Outputs:
*    handle

*/
inline tensor parallel_map_dataset(const tensor& input_dataset, const std::vector<tensor>&other_arguments, const tensor& num_parallel_calls, int64_t f, const std::vector<datatype>& Targuments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool use_inter_op_parallelism=true, bool sloppy=false, bool preserve_cardinality=false, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParallelMapDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> other_arguments_handles; other_arguments_handles.reserve(other_arguments.size());
    std::transform(other_arguments.begin(), other_arguments.end(), std::back_inserter(other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), other_arguments_handles.data(), static_cast<int>(other_arguments.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_parallel_calls.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "f", f);
    TFE_OpSetAttrTypeList(op.get(), "Targuments", reinterpret_cast<const enum TF_DataType *>(Targuments.data()), static_cast<int>(Targuments.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "use_inter_op_parallelism", (unsigned char)use_inter_op_parallelism);
    TFE_OpSetAttrBool(op.get(), "sloppy", (unsigned char)sloppy);
    TFE_OpSetAttrBool(op.get(), "preserve_cardinality", (unsigned char)preserve_cardinality);
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ParallelMapDatasetV2
# Inputs:
*    input_dataset
*    other_arguments
*    num_parallel_calls

# Attributes:
*    f
*    Targuments
*    output_types
*    output_shapes
*    use_inter_op_parallelism
*    deterministic
*    preserve_cardinality
*    metadata

# Outputs:
*    handle

*/
inline tensor parallel_map_dataset_v2(const tensor& input_dataset, const std::vector<tensor>&other_arguments, const tensor& num_parallel_calls, int64_t f, const std::vector<datatype>& Targuments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool use_inter_op_parallelism=true, const std::string& deterministic="default", bool preserve_cardinality=false, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParallelMapDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> other_arguments_handles; other_arguments_handles.reserve(other_arguments.size());
    std::transform(other_arguments.begin(), other_arguments.end(), std::back_inserter(other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), other_arguments_handles.data(), static_cast<int>(other_arguments.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_parallel_calls.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "f", f);
    TFE_OpSetAttrTypeList(op.get(), "Targuments", reinterpret_cast<const enum TF_DataType *>(Targuments.data()), static_cast<int>(Targuments.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "use_inter_op_parallelism", (unsigned char)use_inter_op_parallelism);
    TFE_OpSetAttrString(op.get(), "deterministic", (void*) deterministic.c_str(), deterministic.size());
    TFE_OpSetAttrBool(op.get(), "preserve_cardinality", (unsigned char)preserve_cardinality);
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ParameterizedTruncatedNormal
# Inputs:
*    shape
*    means
*    stdevs
*    minvals
*    maxvals

# Attributes:
*    dtype
*    seed
*    seed2

# Outputs:
*    output

*/
inline tensor parameterized_truncated_normal(const tensor& shape, const tensor& means, const tensor& stdevs, const tensor& minvals, const tensor& maxvals, datatype dtype, int64_t seed=0, int64_t seed2=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParameterizedTruncatedNormal", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), means.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), stdevs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), minvals.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), maxvals.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ParseExample
# Inputs:
*    serialized
*    names
*    sparse_keys
*    dense_keys
*    dense_defaults

# Attributes:
*    Nsparse
*    Ndense
*    sparse_types
*    Tdense
*    dense_shapes

# Outputs:
*    sparse_indices
*    sparse_values
*    sparse_shapes
*    dense_values

*/
inline std::vector<tensor> parse_example(const tensor& serialized, const tensor& names, const std::vector<tensor>&sparse_keys, const std::vector<tensor>&dense_keys, const std::vector<tensor>&dense_defaults, const std::vector<datatype>& sparse_types, const std::vector<datatype>& Tdense, const std::vector< std::vector<int64_t>>& dense_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParseExample", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), serialized.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), names.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> sparse_keys_handles; sparse_keys_handles.reserve(sparse_keys.size());
    std::transform(sparse_keys.begin(), sparse_keys.end(), std::back_inserter(sparse_keys_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), sparse_keys_handles.data(), static_cast<int>(sparse_keys.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_keys_handles; dense_keys_handles.reserve(dense_keys.size());
    std::transform(dense_keys.begin(), dense_keys.end(), std::back_inserter(dense_keys_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), dense_keys_handles.data(), static_cast<int>(dense_keys.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_defaults_handles; dense_defaults_handles.reserve(dense_defaults.size());
    std::transform(dense_defaults.begin(), dense_defaults.end(), std::back_inserter(dense_defaults_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), dense_defaults_handles.data(), static_cast<int>(dense_defaults.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "Nsparse", sparse_keys.size());
    TFE_OpSetAttrInt(op.get(), "Ndense", dense_keys.size());
    TFE_OpSetAttrTypeList(op.get(), "sparse_types", reinterpret_cast<const enum TF_DataType *>(sparse_types.data()), static_cast<int>(sparse_types.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tdense", reinterpret_cast<const enum TF_DataType *>(Tdense.data()), static_cast<int>(Tdense.size()));
    
    std::vector<const int64_t*> dense_shapes_values; dense_shapes_values.reserve(dense_shapes.size());
    std::vector<int> dense_shapes_ndims; dense_shapes_ndims.reserve(dense_shapes.size());
    std::transform(dense_shapes.begin(), dense_shapes.end(), std::back_inserter(dense_shapes_values), [](const auto& v) { return v.data();});
    std::transform(dense_shapes.begin(), dense_shapes.end(), std::back_inserter(dense_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "dense_shapes", dense_shapes_values.data(), dense_shapes_ndims.data(), static_cast<int>(dense_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 4;
    TFE_TensorHandle* res[4] = { nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]), };
}

/* # ParseExampleDataset
# Inputs:
*    input_dataset
*    num_parallel_calls
*    dense_defaults

# Attributes:
*    sparse_keys
*    dense_keys
*    sparse_types
*    Tdense
*    dense_shapes
*    output_types
*    output_shapes
*    ragged_keys
*    ragged_value_types
*    ragged_split_types
*    sloppy

# Outputs:
*    handle

*/
inline tensor parse_example_dataset(const tensor& input_dataset, const tensor& num_parallel_calls, const std::vector<tensor>&dense_defaults, const std::vector< std::string>& sparse_keys, const std::vector< std::string>& dense_keys, const std::vector<datatype>& sparse_types, const std::vector<datatype>& Tdense, const std::vector< std::vector<int64_t>>& dense_shapes, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::vector< std::string>& ragged_keys, const std::vector<datatype>& ragged_value_types, const std::vector<datatype>& ragged_split_types, bool sloppy=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParseExampleDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_parallel_calls.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_defaults_handles; dense_defaults_handles.reserve(dense_defaults.size());
    std::transform(dense_defaults.begin(), dense_defaults.end(), std::back_inserter(dense_defaults_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), dense_defaults_handles.data(), static_cast<int>(dense_defaults.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> sparse_keys_sizes; sparse_keys_sizes.reserve(sparse_keys.size());
    std::transform(sparse_keys.begin(), sparse_keys.end(), std::back_inserter(sparse_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "sparse_keys", reinterpret_cast<const void *const *>(sparse_keys.data()), sparse_keys_sizes.data(), static_cast<int>(sparse_keys.size()));
    
    
    std::vector<std::size_t> dense_keys_sizes; dense_keys_sizes.reserve(dense_keys.size());
    std::transform(dense_keys.begin(), dense_keys.end(), std::back_inserter(dense_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "dense_keys", reinterpret_cast<const void *const *>(dense_keys.data()), dense_keys_sizes.data(), static_cast<int>(dense_keys.size()));
    
    TFE_OpSetAttrTypeList(op.get(), "sparse_types", reinterpret_cast<const enum TF_DataType *>(sparse_types.data()), static_cast<int>(sparse_types.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tdense", reinterpret_cast<const enum TF_DataType *>(Tdense.data()), static_cast<int>(Tdense.size()));
    
    std::vector<const int64_t*> dense_shapes_values; dense_shapes_values.reserve(dense_shapes.size());
    std::vector<int> dense_shapes_ndims; dense_shapes_ndims.reserve(dense_shapes.size());
    std::transform(dense_shapes.begin(), dense_shapes.end(), std::back_inserter(dense_shapes_values), [](const auto& v) { return v.data();});
    std::transform(dense_shapes.begin(), dense_shapes.end(), std::back_inserter(dense_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "dense_shapes", dense_shapes_values.data(), dense_shapes_ndims.data(), static_cast<int>(dense_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<std::size_t> ragged_keys_sizes; ragged_keys_sizes.reserve(ragged_keys.size());
    std::transform(ragged_keys.begin(), ragged_keys.end(), std::back_inserter(ragged_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "ragged_keys", reinterpret_cast<const void *const *>(ragged_keys.data()), ragged_keys_sizes.data(), static_cast<int>(ragged_keys.size()));
    
    TFE_OpSetAttrTypeList(op.get(), "ragged_value_types", reinterpret_cast<const enum TF_DataType *>(ragged_value_types.data()), static_cast<int>(ragged_value_types.size()));
    TFE_OpSetAttrTypeList(op.get(), "ragged_split_types", reinterpret_cast<const enum TF_DataType *>(ragged_split_types.data()), static_cast<int>(ragged_split_types.size()));
    TFE_OpSetAttrBool(op.get(), "sloppy", (unsigned char)sloppy);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ParseExampleDatasetV2
# Inputs:
*    input_dataset
*    num_parallel_calls
*    dense_defaults

# Attributes:
*    sparse_keys
*    dense_keys
*    sparse_types
*    Tdense
*    dense_shapes
*    output_types
*    output_shapes
*    ragged_keys
*    ragged_value_types
*    ragged_split_types
*    deterministic

# Outputs:
*    handle

*/
inline tensor parse_example_dataset_v2(const tensor& input_dataset, const tensor& num_parallel_calls, const std::vector<tensor>&dense_defaults, const std::vector< std::string>& sparse_keys, const std::vector< std::string>& dense_keys, const std::vector<datatype>& sparse_types, const std::vector<datatype>& Tdense, const std::vector< std::vector<int64_t>>& dense_shapes, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::vector< std::string>& ragged_keys, const std::vector<datatype>& ragged_value_types, const std::vector<datatype>& ragged_split_types, const std::string& deterministic="default") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParseExampleDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_parallel_calls.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_defaults_handles; dense_defaults_handles.reserve(dense_defaults.size());
    std::transform(dense_defaults.begin(), dense_defaults.end(), std::back_inserter(dense_defaults_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), dense_defaults_handles.data(), static_cast<int>(dense_defaults.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> sparse_keys_sizes; sparse_keys_sizes.reserve(sparse_keys.size());
    std::transform(sparse_keys.begin(), sparse_keys.end(), std::back_inserter(sparse_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "sparse_keys", reinterpret_cast<const void *const *>(sparse_keys.data()), sparse_keys_sizes.data(), static_cast<int>(sparse_keys.size()));
    
    
    std::vector<std::size_t> dense_keys_sizes; dense_keys_sizes.reserve(dense_keys.size());
    std::transform(dense_keys.begin(), dense_keys.end(), std::back_inserter(dense_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "dense_keys", reinterpret_cast<const void *const *>(dense_keys.data()), dense_keys_sizes.data(), static_cast<int>(dense_keys.size()));
    
    TFE_OpSetAttrTypeList(op.get(), "sparse_types", reinterpret_cast<const enum TF_DataType *>(sparse_types.data()), static_cast<int>(sparse_types.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tdense", reinterpret_cast<const enum TF_DataType *>(Tdense.data()), static_cast<int>(Tdense.size()));
    
    std::vector<const int64_t*> dense_shapes_values; dense_shapes_values.reserve(dense_shapes.size());
    std::vector<int> dense_shapes_ndims; dense_shapes_ndims.reserve(dense_shapes.size());
    std::transform(dense_shapes.begin(), dense_shapes.end(), std::back_inserter(dense_shapes_values), [](const auto& v) { return v.data();});
    std::transform(dense_shapes.begin(), dense_shapes.end(), std::back_inserter(dense_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "dense_shapes", dense_shapes_values.data(), dense_shapes_ndims.data(), static_cast<int>(dense_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<std::size_t> ragged_keys_sizes; ragged_keys_sizes.reserve(ragged_keys.size());
    std::transform(ragged_keys.begin(), ragged_keys.end(), std::back_inserter(ragged_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "ragged_keys", reinterpret_cast<const void *const *>(ragged_keys.data()), ragged_keys_sizes.data(), static_cast<int>(ragged_keys.size()));
    
    TFE_OpSetAttrTypeList(op.get(), "ragged_value_types", reinterpret_cast<const enum TF_DataType *>(ragged_value_types.data()), static_cast<int>(ragged_value_types.size()));
    TFE_OpSetAttrTypeList(op.get(), "ragged_split_types", reinterpret_cast<const enum TF_DataType *>(ragged_split_types.data()), static_cast<int>(ragged_split_types.size()));
    TFE_OpSetAttrString(op.get(), "deterministic", (void*) deterministic.c_str(), deterministic.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ParseExampleV2
# Inputs:
*    serialized
*    names
*    sparse_keys
*    dense_keys
*    ragged_keys
*    dense_defaults

# Attributes:
*    Tdense
*    num_sparse
*    sparse_types
*    ragged_value_types
*    ragged_split_types
*    dense_shapes

# Outputs:
*    sparse_indices
*    sparse_values
*    sparse_shapes
*    dense_values
*    ragged_values
*    ragged_row_splits

*/
inline std::vector<tensor> parse_example_v2(const tensor& serialized, const tensor& names, const tensor& sparse_keys, const tensor& dense_keys, const tensor& ragged_keys, const std::vector<tensor>&dense_defaults, const std::vector<datatype>& Tdense, int64_t num_sparse, const std::vector<datatype>& sparse_types, const std::vector<datatype>& ragged_value_types, const std::vector<datatype>& ragged_split_types, const std::vector< std::vector<int64_t>>& dense_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParseExampleV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), serialized.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), names.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sparse_keys.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dense_keys.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ragged_keys.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_defaults_handles; dense_defaults_handles.reserve(dense_defaults.size());
    std::transform(dense_defaults.begin(), dense_defaults.end(), std::back_inserter(dense_defaults_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), dense_defaults_handles.data(), static_cast<int>(dense_defaults.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Tdense", reinterpret_cast<const enum TF_DataType *>(Tdense.data()), static_cast<int>(Tdense.size()));
    TFE_OpSetAttrInt(op.get(), "num_sparse", num_sparse);
    TFE_OpSetAttrTypeList(op.get(), "sparse_types", reinterpret_cast<const enum TF_DataType *>(sparse_types.data()), static_cast<int>(sparse_types.size()));
    TFE_OpSetAttrTypeList(op.get(), "ragged_value_types", reinterpret_cast<const enum TF_DataType *>(ragged_value_types.data()), static_cast<int>(ragged_value_types.size()));
    TFE_OpSetAttrTypeList(op.get(), "ragged_split_types", reinterpret_cast<const enum TF_DataType *>(ragged_split_types.data()), static_cast<int>(ragged_split_types.size()));
    
    std::vector<const int64_t*> dense_shapes_values; dense_shapes_values.reserve(dense_shapes.size());
    std::vector<int> dense_shapes_ndims; dense_shapes_ndims.reserve(dense_shapes.size());
    std::transform(dense_shapes.begin(), dense_shapes.end(), std::back_inserter(dense_shapes_values), [](const auto& v) { return v.data();});
    std::transform(dense_shapes.begin(), dense_shapes.end(), std::back_inserter(dense_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "dense_shapes", dense_shapes_values.data(), dense_shapes_ndims.data(), static_cast<int>(dense_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 6;
    TFE_TensorHandle* res[6] = { nullptr,nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]),tensor(res[5]), };
}

/* # ParseSequenceExample
# Inputs:
*    serialized
*    debug_name
*    context_dense_defaults

# Attributes:
*    feature_list_dense_missing_assumed_empty
*    context_sparse_keys
*    context_dense_keys
*    feature_list_sparse_keys
*    feature_list_dense_keys
*    context_sparse_types
*    Tcontext_dense
*    feature_list_dense_types
*    context_dense_shapes
*    feature_list_sparse_types
*    feature_list_dense_shapes
*    Ncontext_sparse
*    Ncontext_dense
*    Nfeature_list_sparse
*    Nfeature_list_dense

# Outputs:
*    context_sparse_indices
*    context_sparse_values
*    context_sparse_shapes
*    context_dense_values
*    feature_list_sparse_indices
*    feature_list_sparse_values
*    feature_list_sparse_shapes
*    feature_list_dense_values
*    feature_list_dense_lengths

*/
inline std::vector<tensor> parse_sequence_example(const tensor& serialized, const tensor& debug_name, const std::vector<tensor>&context_dense_defaults, const std::vector< std::string>& feature_list_dense_missing_assumed_empty, const std::vector< std::string>& context_sparse_keys, const std::vector< std::string>& context_dense_keys, const std::vector< std::string>& feature_list_sparse_keys, const std::vector< std::string>& feature_list_dense_keys, const std::vector<datatype>& context_sparse_types, const std::vector<datatype>& Tcontext_dense, const std::vector<datatype>& feature_list_dense_types, const std::vector< std::vector<int64_t>>& context_dense_shapes, const std::vector<datatype>& feature_list_sparse_types, const std::vector< std::vector<int64_t>>& feature_list_dense_shapes, int64_t Ncontext_sparse=0, int64_t Ncontext_dense=0, int64_t Nfeature_list_sparse=0, int64_t Nfeature_list_dense=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParseSequenceExample", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), serialized.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), debug_name.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> context_dense_defaults_handles; context_dense_defaults_handles.reserve(context_dense_defaults.size());
    std::transform(context_dense_defaults.begin(), context_dense_defaults.end(), std::back_inserter(context_dense_defaults_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), context_dense_defaults_handles.data(), static_cast<int>(context_dense_defaults.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> feature_list_dense_missing_assumed_empty_sizes; feature_list_dense_missing_assumed_empty_sizes.reserve(feature_list_dense_missing_assumed_empty.size());
    std::transform(feature_list_dense_missing_assumed_empty.begin(), feature_list_dense_missing_assumed_empty.end(), std::back_inserter(feature_list_dense_missing_assumed_empty_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "feature_list_dense_missing_assumed_empty", reinterpret_cast<const void *const *>(feature_list_dense_missing_assumed_empty.data()), feature_list_dense_missing_assumed_empty_sizes.data(), static_cast<int>(feature_list_dense_missing_assumed_empty.size()));
    
    
    std::vector<std::size_t> context_sparse_keys_sizes; context_sparse_keys_sizes.reserve(context_sparse_keys.size());
    std::transform(context_sparse_keys.begin(), context_sparse_keys.end(), std::back_inserter(context_sparse_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "context_sparse_keys", reinterpret_cast<const void *const *>(context_sparse_keys.data()), context_sparse_keys_sizes.data(), static_cast<int>(context_sparse_keys.size()));
    
    
    std::vector<std::size_t> context_dense_keys_sizes; context_dense_keys_sizes.reserve(context_dense_keys.size());
    std::transform(context_dense_keys.begin(), context_dense_keys.end(), std::back_inserter(context_dense_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "context_dense_keys", reinterpret_cast<const void *const *>(context_dense_keys.data()), context_dense_keys_sizes.data(), static_cast<int>(context_dense_keys.size()));
    
    
    std::vector<std::size_t> feature_list_sparse_keys_sizes; feature_list_sparse_keys_sizes.reserve(feature_list_sparse_keys.size());
    std::transform(feature_list_sparse_keys.begin(), feature_list_sparse_keys.end(), std::back_inserter(feature_list_sparse_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "feature_list_sparse_keys", reinterpret_cast<const void *const *>(feature_list_sparse_keys.data()), feature_list_sparse_keys_sizes.data(), static_cast<int>(feature_list_sparse_keys.size()));
    
    
    std::vector<std::size_t> feature_list_dense_keys_sizes; feature_list_dense_keys_sizes.reserve(feature_list_dense_keys.size());
    std::transform(feature_list_dense_keys.begin(), feature_list_dense_keys.end(), std::back_inserter(feature_list_dense_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "feature_list_dense_keys", reinterpret_cast<const void *const *>(feature_list_dense_keys.data()), feature_list_dense_keys_sizes.data(), static_cast<int>(feature_list_dense_keys.size()));
    
    TFE_OpSetAttrTypeList(op.get(), "context_sparse_types", reinterpret_cast<const enum TF_DataType *>(context_sparse_types.data()), static_cast<int>(context_sparse_types.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tcontext_dense", reinterpret_cast<const enum TF_DataType *>(Tcontext_dense.data()), static_cast<int>(Tcontext_dense.size()));
    TFE_OpSetAttrTypeList(op.get(), "feature_list_dense_types", reinterpret_cast<const enum TF_DataType *>(feature_list_dense_types.data()), static_cast<int>(feature_list_dense_types.size()));
    
    std::vector<const int64_t*> context_dense_shapes_values; context_dense_shapes_values.reserve(context_dense_shapes.size());
    std::vector<int> context_dense_shapes_ndims; context_dense_shapes_ndims.reserve(context_dense_shapes.size());
    std::transform(context_dense_shapes.begin(), context_dense_shapes.end(), std::back_inserter(context_dense_shapes_values), [](const auto& v) { return v.data();});
    std::transform(context_dense_shapes.begin(), context_dense_shapes.end(), std::back_inserter(context_dense_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "context_dense_shapes", context_dense_shapes_values.data(), context_dense_shapes_ndims.data(), static_cast<int>(context_dense_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrTypeList(op.get(), "feature_list_sparse_types", reinterpret_cast<const enum TF_DataType *>(feature_list_sparse_types.data()), static_cast<int>(feature_list_sparse_types.size()));
    
    std::vector<const int64_t*> feature_list_dense_shapes_values; feature_list_dense_shapes_values.reserve(feature_list_dense_shapes.size());
    std::vector<int> feature_list_dense_shapes_ndims; feature_list_dense_shapes_ndims.reserve(feature_list_dense_shapes.size());
    std::transform(feature_list_dense_shapes.begin(), feature_list_dense_shapes.end(), std::back_inserter(feature_list_dense_shapes_values), [](const auto& v) { return v.data();});
    std::transform(feature_list_dense_shapes.begin(), feature_list_dense_shapes.end(), std::back_inserter(feature_list_dense_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "feature_list_dense_shapes", feature_list_dense_shapes_values.data(), feature_list_dense_shapes_ndims.data(), static_cast<int>(feature_list_dense_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "Ncontext_sparse", Ncontext_sparse);
    TFE_OpSetAttrInt(op.get(), "Ncontext_dense", Ncontext_dense);
    TFE_OpSetAttrInt(op.get(), "Nfeature_list_sparse", Nfeature_list_sparse);
    TFE_OpSetAttrInt(op.get(), "Nfeature_list_dense", Nfeature_list_dense);

    // Execute Op
    int num_outputs_op = 9;
    TFE_TensorHandle* res[9] = { nullptr,nullptr,nullptr,nullptr,nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]),tensor(res[5]),tensor(res[6]),tensor(res[7]),tensor(res[8]), };
}

/* # ParseSequenceExampleV2
# Inputs:
*    serialized
*    debug_name
*    context_sparse_keys
*    context_dense_keys
*    context_ragged_keys
*    feature_list_sparse_keys
*    feature_list_dense_keys
*    feature_list_ragged_keys
*    feature_list_dense_missing_assumed_empty
*    context_dense_defaults

# Attributes:
*    Tcontext_dense
*    context_sparse_types
*    context_ragged_value_types
*    context_ragged_split_types
*    context_dense_shapes
*    feature_list_dense_types
*    feature_list_sparse_types
*    feature_list_ragged_value_types
*    feature_list_ragged_split_types
*    feature_list_dense_shapes
*    Ncontext_sparse
*    Nfeature_list_sparse
*    Nfeature_list_dense

# Outputs:
*    context_sparse_indices
*    context_sparse_values
*    context_sparse_shapes
*    context_dense_values
*    context_ragged_values
*    context_ragged_row_splits
*    feature_list_sparse_indices
*    feature_list_sparse_values
*    feature_list_sparse_shapes
*    feature_list_dense_values
*    feature_list_dense_lengths
*    feature_list_ragged_values
*    feature_list_ragged_outer_splits
*    feature_list_ragged_inner_splits

*/
inline std::vector<tensor> parse_sequence_example_v2(const tensor& serialized, const tensor& debug_name, const tensor& context_sparse_keys, const tensor& context_dense_keys, const tensor& context_ragged_keys, const tensor& feature_list_sparse_keys, const tensor& feature_list_dense_keys, const tensor& feature_list_ragged_keys, const tensor& feature_list_dense_missing_assumed_empty, const std::vector<tensor>&context_dense_defaults, const std::vector<datatype>& Tcontext_dense, const std::vector<datatype>& context_sparse_types, const std::vector<datatype>& context_ragged_value_types, const std::vector<datatype>& context_ragged_split_types, const std::vector< std::vector<int64_t>>& context_dense_shapes, const std::vector<datatype>& feature_list_dense_types, const std::vector<datatype>& feature_list_sparse_types, const std::vector<datatype>& feature_list_ragged_value_types, const std::vector<datatype>& feature_list_ragged_split_types, const std::vector< std::vector<int64_t>>& feature_list_dense_shapes, int64_t Ncontext_sparse=0, int64_t Nfeature_list_sparse=0, int64_t Nfeature_list_dense=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParseSequenceExampleV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), serialized.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), debug_name.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), context_sparse_keys.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), context_dense_keys.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), context_ragged_keys.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), feature_list_sparse_keys.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), feature_list_dense_keys.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), feature_list_ragged_keys.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), feature_list_dense_missing_assumed_empty.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> context_dense_defaults_handles; context_dense_defaults_handles.reserve(context_dense_defaults.size());
    std::transform(context_dense_defaults.begin(), context_dense_defaults.end(), std::back_inserter(context_dense_defaults_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), context_dense_defaults_handles.data(), static_cast<int>(context_dense_defaults.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Tcontext_dense", reinterpret_cast<const enum TF_DataType *>(Tcontext_dense.data()), static_cast<int>(Tcontext_dense.size()));
    TFE_OpSetAttrTypeList(op.get(), "context_sparse_types", reinterpret_cast<const enum TF_DataType *>(context_sparse_types.data()), static_cast<int>(context_sparse_types.size()));
    TFE_OpSetAttrTypeList(op.get(), "context_ragged_value_types", reinterpret_cast<const enum TF_DataType *>(context_ragged_value_types.data()), static_cast<int>(context_ragged_value_types.size()));
    TFE_OpSetAttrTypeList(op.get(), "context_ragged_split_types", reinterpret_cast<const enum TF_DataType *>(context_ragged_split_types.data()), static_cast<int>(context_ragged_split_types.size()));
    
    std::vector<const int64_t*> context_dense_shapes_values; context_dense_shapes_values.reserve(context_dense_shapes.size());
    std::vector<int> context_dense_shapes_ndims; context_dense_shapes_ndims.reserve(context_dense_shapes.size());
    std::transform(context_dense_shapes.begin(), context_dense_shapes.end(), std::back_inserter(context_dense_shapes_values), [](const auto& v) { return v.data();});
    std::transform(context_dense_shapes.begin(), context_dense_shapes.end(), std::back_inserter(context_dense_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "context_dense_shapes", context_dense_shapes_values.data(), context_dense_shapes_ndims.data(), static_cast<int>(context_dense_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrTypeList(op.get(), "feature_list_dense_types", reinterpret_cast<const enum TF_DataType *>(feature_list_dense_types.data()), static_cast<int>(feature_list_dense_types.size()));
    TFE_OpSetAttrTypeList(op.get(), "feature_list_sparse_types", reinterpret_cast<const enum TF_DataType *>(feature_list_sparse_types.data()), static_cast<int>(feature_list_sparse_types.size()));
    TFE_OpSetAttrTypeList(op.get(), "feature_list_ragged_value_types", reinterpret_cast<const enum TF_DataType *>(feature_list_ragged_value_types.data()), static_cast<int>(feature_list_ragged_value_types.size()));
    TFE_OpSetAttrTypeList(op.get(), "feature_list_ragged_split_types", reinterpret_cast<const enum TF_DataType *>(feature_list_ragged_split_types.data()), static_cast<int>(feature_list_ragged_split_types.size()));
    
    std::vector<const int64_t*> feature_list_dense_shapes_values; feature_list_dense_shapes_values.reserve(feature_list_dense_shapes.size());
    std::vector<int> feature_list_dense_shapes_ndims; feature_list_dense_shapes_ndims.reserve(feature_list_dense_shapes.size());
    std::transform(feature_list_dense_shapes.begin(), feature_list_dense_shapes.end(), std::back_inserter(feature_list_dense_shapes_values), [](const auto& v) { return v.data();});
    std::transform(feature_list_dense_shapes.begin(), feature_list_dense_shapes.end(), std::back_inserter(feature_list_dense_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "feature_list_dense_shapes", feature_list_dense_shapes_values.data(), feature_list_dense_shapes_ndims.data(), static_cast<int>(feature_list_dense_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "Ncontext_sparse", Ncontext_sparse);
    TFE_OpSetAttrInt(op.get(), "Nfeature_list_sparse", Nfeature_list_sparse);
    TFE_OpSetAttrInt(op.get(), "Nfeature_list_dense", Nfeature_list_dense);

    // Execute Op
    int num_outputs_op = 14;
    TFE_TensorHandle* res[14] = { nullptr,nullptr,nullptr,nullptr,nullptr,nullptr,nullptr,nullptr,nullptr,nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]),tensor(res[5]),tensor(res[6]),tensor(res[7]),tensor(res[8]),tensor(res[9]),tensor(res[10]),tensor(res[11]),tensor(res[12]),tensor(res[13]), };
}

/* # ParseSingleExample
# Inputs:
*    serialized
*    dense_defaults

# Attributes:
*    num_sparse
*    sparse_keys
*    dense_keys
*    sparse_types
*    Tdense
*    dense_shapes

# Outputs:
*    sparse_indices
*    sparse_values
*    sparse_shapes
*    dense_values

*/
inline std::vector<tensor> parse_single_example(const tensor& serialized, const std::vector<tensor>&dense_defaults, int64_t num_sparse, const std::vector< std::string>& sparse_keys, const std::vector< std::string>& dense_keys, const std::vector<datatype>& sparse_types, const std::vector<datatype>& Tdense, const std::vector< std::vector<int64_t>>& dense_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParseSingleExample", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), serialized.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_defaults_handles; dense_defaults_handles.reserve(dense_defaults.size());
    std::transform(dense_defaults.begin(), dense_defaults.end(), std::back_inserter(dense_defaults_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), dense_defaults_handles.data(), static_cast<int>(dense_defaults.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_sparse", num_sparse);
    
    std::vector<std::size_t> sparse_keys_sizes; sparse_keys_sizes.reserve(sparse_keys.size());
    std::transform(sparse_keys.begin(), sparse_keys.end(), std::back_inserter(sparse_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "sparse_keys", reinterpret_cast<const void *const *>(sparse_keys.data()), sparse_keys_sizes.data(), static_cast<int>(sparse_keys.size()));
    
    
    std::vector<std::size_t> dense_keys_sizes; dense_keys_sizes.reserve(dense_keys.size());
    std::transform(dense_keys.begin(), dense_keys.end(), std::back_inserter(dense_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "dense_keys", reinterpret_cast<const void *const *>(dense_keys.data()), dense_keys_sizes.data(), static_cast<int>(dense_keys.size()));
    
    TFE_OpSetAttrTypeList(op.get(), "sparse_types", reinterpret_cast<const enum TF_DataType *>(sparse_types.data()), static_cast<int>(sparse_types.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tdense", reinterpret_cast<const enum TF_DataType *>(Tdense.data()), static_cast<int>(Tdense.size()));
    
    std::vector<const int64_t*> dense_shapes_values; dense_shapes_values.reserve(dense_shapes.size());
    std::vector<int> dense_shapes_ndims; dense_shapes_ndims.reserve(dense_shapes.size());
    std::transform(dense_shapes.begin(), dense_shapes.end(), std::back_inserter(dense_shapes_values), [](const auto& v) { return v.data();});
    std::transform(dense_shapes.begin(), dense_shapes.end(), std::back_inserter(dense_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "dense_shapes", dense_shapes_values.data(), dense_shapes_ndims.data(), static_cast<int>(dense_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 4;
    TFE_TensorHandle* res[4] = { nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]), };
}

/* # ParseSingleSequenceExample
# Inputs:
*    serialized
*    feature_list_dense_missing_assumed_empty
*    context_sparse_keys
*    context_dense_keys
*    feature_list_sparse_keys
*    feature_list_dense_keys
*    context_dense_defaults
*    debug_name

# Attributes:
*    context_sparse_types
*    Tcontext_dense
*    feature_list_dense_types
*    context_dense_shapes
*    feature_list_sparse_types
*    feature_list_dense_shapes
*    Ncontext_sparse
*    Ncontext_dense
*    Nfeature_list_sparse
*    Nfeature_list_dense

# Outputs:
*    context_sparse_indices
*    context_sparse_values
*    context_sparse_shapes
*    context_dense_values
*    feature_list_sparse_indices
*    feature_list_sparse_values
*    feature_list_sparse_shapes
*    feature_list_dense_values

*/
inline std::vector<tensor> parse_single_sequence_example(const tensor& serialized, const tensor& feature_list_dense_missing_assumed_empty, const std::vector<tensor>&context_sparse_keys, const std::vector<tensor>&context_dense_keys, const std::vector<tensor>&feature_list_sparse_keys, const std::vector<tensor>&feature_list_dense_keys, const std::vector<tensor>&context_dense_defaults, const tensor& debug_name, const std::vector<datatype>& context_sparse_types, const std::vector<datatype>& Tcontext_dense, const std::vector<datatype>& feature_list_dense_types, const std::vector< std::vector<int64_t>>& context_dense_shapes, const std::vector<datatype>& feature_list_sparse_types, const std::vector< std::vector<int64_t>>& feature_list_dense_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParseSingleSequenceExample", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), serialized.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), feature_list_dense_missing_assumed_empty.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> context_sparse_keys_handles; context_sparse_keys_handles.reserve(context_sparse_keys.size());
    std::transform(context_sparse_keys.begin(), context_sparse_keys.end(), std::back_inserter(context_sparse_keys_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), context_sparse_keys_handles.data(), static_cast<int>(context_sparse_keys.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> context_dense_keys_handles; context_dense_keys_handles.reserve(context_dense_keys.size());
    std::transform(context_dense_keys.begin(), context_dense_keys.end(), std::back_inserter(context_dense_keys_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), context_dense_keys_handles.data(), static_cast<int>(context_dense_keys.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> feature_list_sparse_keys_handles; feature_list_sparse_keys_handles.reserve(feature_list_sparse_keys.size());
    std::transform(feature_list_sparse_keys.begin(), feature_list_sparse_keys.end(), std::back_inserter(feature_list_sparse_keys_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), feature_list_sparse_keys_handles.data(), static_cast<int>(feature_list_sparse_keys.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> feature_list_dense_keys_handles; feature_list_dense_keys_handles.reserve(feature_list_dense_keys.size());
    std::transform(feature_list_dense_keys.begin(), feature_list_dense_keys.end(), std::back_inserter(feature_list_dense_keys_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), feature_list_dense_keys_handles.data(), static_cast<int>(feature_list_dense_keys.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> context_dense_defaults_handles; context_dense_defaults_handles.reserve(context_dense_defaults.size());
    std::transform(context_dense_defaults.begin(), context_dense_defaults.end(), std::back_inserter(context_dense_defaults_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), context_dense_defaults_handles.data(), static_cast<int>(context_dense_defaults.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), debug_name.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "context_sparse_types", reinterpret_cast<const enum TF_DataType *>(context_sparse_types.data()), static_cast<int>(context_sparse_types.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tcontext_dense", reinterpret_cast<const enum TF_DataType *>(Tcontext_dense.data()), static_cast<int>(Tcontext_dense.size()));
    TFE_OpSetAttrTypeList(op.get(), "feature_list_dense_types", reinterpret_cast<const enum TF_DataType *>(feature_list_dense_types.data()), static_cast<int>(feature_list_dense_types.size()));
    
    std::vector<const int64_t*> context_dense_shapes_values; context_dense_shapes_values.reserve(context_dense_shapes.size());
    std::vector<int> context_dense_shapes_ndims; context_dense_shapes_ndims.reserve(context_dense_shapes.size());
    std::transform(context_dense_shapes.begin(), context_dense_shapes.end(), std::back_inserter(context_dense_shapes_values), [](const auto& v) { return v.data();});
    std::transform(context_dense_shapes.begin(), context_dense_shapes.end(), std::back_inserter(context_dense_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "context_dense_shapes", context_dense_shapes_values.data(), context_dense_shapes_ndims.data(), static_cast<int>(context_dense_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrTypeList(op.get(), "feature_list_sparse_types", reinterpret_cast<const enum TF_DataType *>(feature_list_sparse_types.data()), static_cast<int>(feature_list_sparse_types.size()));
    
    std::vector<const int64_t*> feature_list_dense_shapes_values; feature_list_dense_shapes_values.reserve(feature_list_dense_shapes.size());
    std::vector<int> feature_list_dense_shapes_ndims; feature_list_dense_shapes_ndims.reserve(feature_list_dense_shapes.size());
    std::transform(feature_list_dense_shapes.begin(), feature_list_dense_shapes.end(), std::back_inserter(feature_list_dense_shapes_values), [](const auto& v) { return v.data();});
    std::transform(feature_list_dense_shapes.begin(), feature_list_dense_shapes.end(), std::back_inserter(feature_list_dense_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "feature_list_dense_shapes", feature_list_dense_shapes_values.data(), feature_list_dense_shapes_ndims.data(), static_cast<int>(feature_list_dense_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "Ncontext_sparse", context_sparse_keys.size());
    TFE_OpSetAttrInt(op.get(), "Ncontext_dense", context_dense_keys.size());
    TFE_OpSetAttrInt(op.get(), "Nfeature_list_sparse", feature_list_sparse_keys.size());
    TFE_OpSetAttrInt(op.get(), "Nfeature_list_dense", feature_list_dense_keys.size());

    // Execute Op
    int num_outputs_op = 8;
    TFE_TensorHandle* res[8] = { nullptr,nullptr,nullptr,nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]),tensor(res[5]),tensor(res[6]),tensor(res[7]), };
}

/* # ParseTensor
# Inputs:
*    serialized

# Attributes:
*    out_type

# Outputs:
*    output

*/
inline tensor parse_tensor(const tensor& serialized, datatype out_type) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParseTensor", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), serialized.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # PartitionedCall
# Inputs:
*    args

# Attributes:
*    Tin
*    Tout
*    f
*    config
*    config_proto
*    executor_type

# Outputs:
*    output

*/
inline tensor partitioned_call(const std::vector<tensor>&args, const std::vector<datatype>& Tin, const std::vector<datatype>& Tout, int64_t f, const std::string& config="", const std::string& config_proto="", const std::string& executor_type="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PartitionedCall", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> args_handles; args_handles.reserve(args.size());
    std::transform(args.begin(), args.end(), std::back_inserter(args_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), args_handles.data(), static_cast<int>(args.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Tin", reinterpret_cast<const enum TF_DataType *>(Tin.data()), static_cast<int>(Tin.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tout", reinterpret_cast<const enum TF_DataType *>(Tout.data()), static_cast<int>(Tout.size()));
    TFE_OpSetAttrInt(op.get(), "f", f);
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());
    TFE_OpSetAttrString(op.get(), "config_proto", (void*) config_proto.c_str(), config_proto.size());
    TFE_OpSetAttrString(op.get(), "executor_type", (void*) executor_type.c_str(), executor_type.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Placeholder
# Inputs:
*    
# Attributes:
*    dtype
*    shape

# Outputs:
*    output

*/
inline tensor placeholder(datatype dtype, const std::vector<int64_t>& shape) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Placeholder", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), static_cast<int>(shape.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # PlaceholderV2
# Inputs:
*    
# Attributes:
*    dtype
*    shape

# Outputs:
*    output

*/
inline tensor placeholder_v2(datatype dtype, const std::vector<int64_t>& shape) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PlaceholderV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), static_cast<int>(shape.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # PlaceholderWithDefault
# Inputs:
*    input

# Attributes:
*    dtype
*    shape

# Outputs:
*    output

*/
inline tensor placeholder_with_default(const tensor& input, datatype dtype, const std::vector<int64_t>& shape) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PlaceholderWithDefault", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), static_cast<int>(shape.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Polygamma
# Inputs:
*    a
*    x

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor polygamma(const tensor& a, const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Polygamma", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # PopulationCount
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor population_count(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PopulationCount", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Pow
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor pow(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Pow", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # PrefetchDataset
# Inputs:
*    input_dataset
*    buffer_size

# Attributes:
*    output_types
*    output_shapes
*    slack_period
*    legacy_autotune
*    buffer_size_min
*    metadata

# Outputs:
*    handle

*/
inline tensor prefetch_dataset(const tensor& input_dataset, const tensor& buffer_size, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, int64_t slack_period=0, bool legacy_autotune=true, int64_t buffer_size_min=0, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PrefetchDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "slack_period", slack_period);
    TFE_OpSetAttrBool(op.get(), "legacy_autotune", (unsigned char)legacy_autotune);
    TFE_OpSetAttrInt(op.get(), "buffer_size_min", buffer_size_min);
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Prelinearize
# Inputs:
*    input

# Attributes:
*    dtype
*    shape
*    layout

# Outputs:
*    output

*/
inline tensor prelinearize(const tensor& input, datatype dtype, const std::vector<int64_t>& shape, const std::vector<int64_t>& layout) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Prelinearize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), static_cast<int>(shape.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrIntList(op.get(), "layout", layout.data(), static_cast<int>(layout.size()));

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # PrelinearizeTuple
# Inputs:
*    inputs

# Attributes:
*    dtypes
*    shapes
*    layouts

# Outputs:
*    output

*/
inline tensor prelinearize_tuple(const std::vector<tensor>&inputs, const std::vector<datatype>& dtypes, const std::vector< std::vector<int64_t>>& shapes, const std::vector<int64_t>& layouts) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PrelinearizeTuple", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), static_cast<int>(inputs.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), static_cast<int>(shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrIntList(op.get(), "layouts", layouts.data(), static_cast<int>(layouts.size()));

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # PreventGradient
# Inputs:
*    input

# Attributes:
*    message

# Outputs:
*    output

*/
inline tensor prevent_gradient(const tensor& input, const std::string& message="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PreventGradient", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "message", (void*) message.c_str(), message.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Print
# Inputs:
*    input
*    data

# Attributes:
*    U
*    message
*    first_n
*    summarize

# Outputs:
*    output

*/
inline tensor print(const tensor& input, const std::vector<tensor>&data, const std::vector<datatype>& U, const std::string& message="", int64_t first_n=-1, int64_t summarize=3) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Print", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> data_handles; data_handles.reserve(data.size());
    std::transform(data.begin(), data.end(), std::back_inserter(data_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), data_handles.data(), static_cast<int>(data.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "U", reinterpret_cast<const enum TF_DataType *>(U.data()), static_cast<int>(U.size()));
    TFE_OpSetAttrString(op.get(), "message", (void*) message.c_str(), message.size());
    TFE_OpSetAttrInt(op.get(), "first_n", first_n);
    TFE_OpSetAttrInt(op.get(), "summarize", summarize);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # PrintV2
# Inputs:
*    input

# Attributes:
*    output_stream
*    end

# Outputs:
*    
*/
inline void print_v2(const tensor& input, const std::string& output_stream="stderr", const std::string& end="\n") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PrintV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "output_stream", (void*) output_stream.c_str(), output_stream.size());
    TFE_OpSetAttrString(op.get(), "end", (void*) end.c_str(), end.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # PriorityQueue
# Inputs:
*    
# Attributes:
*    component_types
*    shapes
*    capacity
*    container
*    shared_name

# Outputs:
*    handle

*/
inline tensor priority_queue(const std::vector<datatype>& component_types, const std::vector< std::vector<int64_t>>& shapes, int64_t capacity=-1, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PriorityQueue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), static_cast<int>(component_types.size()));
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), static_cast<int>(shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # PriorityQueueV2
# Inputs:
*    
# Attributes:
*    component_types
*    shapes
*    capacity
*    container
*    shared_name

# Outputs:
*    handle

*/
inline tensor priority_queue_v2(const std::vector<datatype>& component_types, const std::vector< std::vector<int64_t>>& shapes, int64_t capacity=-1, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PriorityQueueV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), static_cast<int>(component_types.size()));
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), static_cast<int>(shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # PrivateThreadPoolDataset
# Inputs:
*    input_dataset
*    num_threads

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor private_thread_pool_dataset(const tensor& input_dataset, const tensor& num_threads, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PrivateThreadPoolDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_threads.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Prod
# Inputs:
*    input
*    reduction_indices

# Attributes:
*    keep_dims
*    Tidx

# Outputs:
*    output

*/
inline tensor prod(const tensor& input, const tensor& reduction_indices, bool keep_dims=false, datatype Tidx=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Prod", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reduction_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "keep_dims", (unsigned char)keep_dims);
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # PyFunc
# Inputs:
*    input

# Attributes:
*    token
*    Tin
*    Tout

# Outputs:
*    output

*/
inline tensor py_func(const std::vector<tensor>&input, const std::string& token, const std::vector<datatype>& Tin, const std::vector<datatype>& Tout) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PyFunc", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> input_handles; input_handles.reserve(input.size());
    std::transform(input.begin(), input.end(), std::back_inserter(input_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), input_handles.data(), static_cast<int>(input.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "token", (void*) token.c_str(), token.size());
    TFE_OpSetAttrTypeList(op.get(), "Tin", reinterpret_cast<const enum TF_DataType *>(Tin.data()), static_cast<int>(Tin.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tout", reinterpret_cast<const enum TF_DataType *>(Tout.data()), static_cast<int>(Tout.size()));

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # PyFuncStateless
# Inputs:
*    input

# Attributes:
*    token
*    Tin
*    Tout

# Outputs:
*    output

*/
inline tensor py_func_stateless(const std::vector<tensor>&input, const std::string& token, const std::vector<datatype>& Tin, const std::vector<datatype>& Tout) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PyFuncStateless", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> input_handles; input_handles.reserve(input.size());
    std::transform(input.begin(), input.end(), std::back_inserter(input_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), input_handles.data(), static_cast<int>(input.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "token", (void*) token.c_str(), token.size());
    TFE_OpSetAttrTypeList(op.get(), "Tin", reinterpret_cast<const enum TF_DataType *>(Tin.data()), static_cast<int>(Tin.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tout", reinterpret_cast<const enum TF_DataType *>(Tout.data()), static_cast<int>(Tout.size()));

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Qr
# Inputs:
*    input

# Attributes:
*    full_matrices

# Outputs:
*    q
*    r

*/
inline std::vector<tensor> qr(const tensor& input, bool full_matrices=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Qr", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "full_matrices", (unsigned char)full_matrices);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # QuantizeAndDequantize
# Inputs:
*    input

# Attributes:
*    signed_input
*    num_bits
*    range_given
*    input_min
*    input_max

# Outputs:
*    output

*/
inline tensor quantize_and_dequantize(const tensor& input, bool signed_input=true, int64_t num_bits=8, bool range_given=false, float input_min=0.0000e+00, float input_max=0.0000e+00) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizeAndDequantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "signed_input", (unsigned char)signed_input);
    TFE_OpSetAttrInt(op.get(), "num_bits", num_bits);
    TFE_OpSetAttrBool(op.get(), "range_given", (unsigned char)range_given);
    TFE_OpSetAttrFloat(op.get(), "input_min", input_min);
    TFE_OpSetAttrFloat(op.get(), "input_max", input_max);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # QuantizeAndDequantizeV2
# Inputs:
*    input
*    input_min
*    input_max

# Attributes:
*    signed_input
*    num_bits
*    range_given
*    round_mode
*    narrow_range
*    axis

# Outputs:
*    output

*/
inline tensor quantize_and_dequantize_v2(const tensor& input, const tensor& input_min, const tensor& input_max, bool signed_input=true, int64_t num_bits=8, bool range_given=false, const std::string& round_mode="HALF_TO_EVEN", bool narrow_range=false, int64_t axis=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizeAndDequantizeV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_min.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "signed_input", (unsigned char)signed_input);
    TFE_OpSetAttrInt(op.get(), "num_bits", num_bits);
    TFE_OpSetAttrBool(op.get(), "range_given", (unsigned char)range_given);
    TFE_OpSetAttrString(op.get(), "round_mode", (void*) round_mode.c_str(), round_mode.size());
    TFE_OpSetAttrBool(op.get(), "narrow_range", (unsigned char)narrow_range);
    TFE_OpSetAttrInt(op.get(), "axis", axis);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # QuantizeAndDequantizeV3
# Inputs:
*    input
*    input_min
*    input_max
*    num_bits

# Attributes:
*    signed_input
*    range_given
*    narrow_range
*    axis

# Outputs:
*    output

*/
inline tensor quantize_and_dequantize_v3(const tensor& input, const tensor& input_min, const tensor& input_max, const tensor& num_bits, bool signed_input=true, bool range_given=true, bool narrow_range=false, int64_t axis=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizeAndDequantizeV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_min.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_bits.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "signed_input", (unsigned char)signed_input);
    TFE_OpSetAttrBool(op.get(), "range_given", (unsigned char)range_given);
    TFE_OpSetAttrBool(op.get(), "narrow_range", (unsigned char)narrow_range);
    TFE_OpSetAttrInt(op.get(), "axis", axis);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # QuantizeAndDequantizeV4
# Inputs:
*    input
*    input_min
*    input_max

# Attributes:
*    signed_input
*    num_bits
*    range_given
*    round_mode
*    narrow_range
*    axis

# Outputs:
*    output

*/
inline tensor quantize_and_dequantize_v4(const tensor& input, const tensor& input_min, const tensor& input_max, bool signed_input=true, int64_t num_bits=8, bool range_given=false, const std::string& round_mode="HALF_TO_EVEN", bool narrow_range=false, int64_t axis=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizeAndDequantizeV4", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_min.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "signed_input", (unsigned char)signed_input);
    TFE_OpSetAttrInt(op.get(), "num_bits", num_bits);
    TFE_OpSetAttrBool(op.get(), "range_given", (unsigned char)range_given);
    TFE_OpSetAttrString(op.get(), "round_mode", (void*) round_mode.c_str(), round_mode.size());
    TFE_OpSetAttrBool(op.get(), "narrow_range", (unsigned char)narrow_range);
    TFE_OpSetAttrInt(op.get(), "axis", axis);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # QuantizeAndDequantizeV4Grad
# Inputs:
*    gradients
*    input
*    input_min
*    input_max

# Attributes:
*    axis

# Outputs:
*    input_backprop
*    input_min_backprop
*    input_max_backprop

*/
inline std::vector<tensor> quantize_and_dequantize_v4_grad(const tensor& gradients, const tensor& input, const tensor& input_min, const tensor& input_max, int64_t axis=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizeAndDequantizeV4Grad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), gradients.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_min.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "axis", axis);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizeDownAndShrinkRange
# Inputs:
*    input
*    input_min
*    input_max

# Attributes:
*    Tinput
*    out_type

# Outputs:
*    output
*    output_min
*    output_max

*/
inline std::vector<tensor> quantize_down_and_shrink_range(const tensor& input, const tensor& input_min, const tensor& input_max, datatype Tinput, datatype out_type) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizeDownAndShrinkRange", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_min.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizeV2
# Inputs:
*    input
*    min_range
*    max_range

# Attributes:
*    mode
*    round_mode
*    narrow_range
*    axis
*    ensure_minimum_range

# Outputs:
*    output
*    output_min
*    output_max

*/
inline std::vector<tensor> quantize_v2(const tensor& input, const tensor& min_range, const tensor& max_range, const std::string& mode="MIN_COMBINED", const std::string& round_mode="HALF_AWAY_FROM_ZERO", bool narrow_range=false, int64_t axis=-1, float ensure_minimum_range=1.0000e-02) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizeV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_range.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_range.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "mode", (void*) mode.c_str(), mode.size());
    TFE_OpSetAttrString(op.get(), "round_mode", (void*) round_mode.c_str(), round_mode.size());
    TFE_OpSetAttrBool(op.get(), "narrow_range", (unsigned char)narrow_range);
    TFE_OpSetAttrInt(op.get(), "axis", axis);
    TFE_OpSetAttrFloat(op.get(), "ensure_minimum_range", ensure_minimum_range);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedAdd
# Inputs:
*    x
*    y
*    min_x
*    max_x
*    min_y
*    max_y

# Attributes:
*    T1
*    T2
*    Toutput

# Outputs:
*    z
*    min_z
*    max_z

*/
inline std::vector<tensor> quantized_add(const tensor& x, const tensor& y, const tensor& min_x, const tensor& max_x, const tensor& min_y, const tensor& max_y, datatype T1, datatype T2, datatype Toutput=static_cast<datatype>(13)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "Toutput", Toutput);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedAvgPool
# Inputs:
*    input
*    min_input
*    max_input

# Attributes:
*    ksize
*    strides
*    padding

# Outputs:
*    output
*    min_output
*    max_output

*/
inline std::vector<tensor> quantized_avg_pool(const tensor& input, const tensor& min_input, const tensor& max_input, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedAvgPool", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), static_cast<int>(ksize.size()));
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedBatchNormWithGlobalNormalization
# Inputs:
*    t
*    t_min
*    t_max
*    m
*    m_min
*    m_max
*    v
*    v_min
*    v_max
*    beta
*    beta_min
*    beta_max
*    gamma
*    gamma_min
*    gamma_max

# Attributes:
*    Tinput
*    out_type
*    variance_epsilon
*    scale_after_normalization

# Outputs:
*    result
*    result_min
*    result_max

*/
inline std::vector<tensor> quantized_batch_norm_with_global_normalization(const tensor& t, const tensor& t_min, const tensor& t_max, const tensor& m, const tensor& m_min, const tensor& m_max, const tensor& v, const tensor& v_min, const tensor& v_max, const tensor& beta, const tensor& beta_min, const tensor& beta_max, const tensor& gamma, const tensor& gamma_min, const tensor& gamma_max, datatype Tinput, datatype out_type, float variance_epsilon, bool scale_after_normalization) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedBatchNormWithGlobalNormalization", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), t.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), t_min.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), t_max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m_min.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m_max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v_min.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v_max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta_min.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta_max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gamma.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gamma_min.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gamma_max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "out_type", out_type);
    TFE_OpSetAttrFloat(op.get(), "variance_epsilon", variance_epsilon);
    TFE_OpSetAttrBool(op.get(), "scale_after_normalization", (unsigned char)scale_after_normalization);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedBiasAdd
# Inputs:
*    input
*    bias
*    min_input
*    max_input
*    min_bias
*    max_bias

# Attributes:
*    T1
*    T2
*    out_type

# Outputs:
*    output
*    min_out
*    max_out

*/
inline std::vector<tensor> quantized_bias_add(const tensor& input, const tensor& bias, const tensor& min_input, const tensor& max_input, const tensor& min_bias, const tensor& max_bias, datatype T1, datatype T2, datatype out_type) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedBiasAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_bias.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_bias.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedConcat
# Inputs:
*    concat_dim
*    values
*    input_mins
*    input_maxes

# Attributes:
*    N

# Outputs:
*    output
*    output_min
*    output_max

*/
inline std::vector<tensor> quantized_concat(const tensor& concat_dim, const std::vector<tensor>&values, const std::vector<tensor>&input_mins, const std::vector<tensor>&input_maxes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedConcat", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), concat_dim.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> values_handles; values_handles.reserve(values.size());
    std::transform(values.begin(), values.end(), std::back_inserter(values_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), values_handles.data(), static_cast<int>(values.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> input_mins_handles; input_mins_handles.reserve(input_mins.size());
    std::transform(input_mins.begin(), input_mins.end(), std::back_inserter(input_mins_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), input_mins_handles.data(), static_cast<int>(input_mins.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> input_maxes_handles; input_maxes_handles.reserve(input_maxes.size());
    std::transform(input_maxes.begin(), input_maxes.end(), std::back_inserter(input_maxes_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), input_maxes_handles.data(), static_cast<int>(input_maxes.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", values.size());

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedConv2D
# Inputs:
*    input
*    filter
*    min_input
*    max_input
*    min_filter
*    max_filter

# Attributes:
*    Tinput
*    Tfilter
*    strides
*    padding
*    dilations
*    out_type

# Outputs:
*    output
*    min_output
*    max_output

*/
inline std::vector<tensor> quantized_conv2_d(const tensor& input, const tensor& filter, const tensor& min_input, const tensor& max_input, const tensor& min_filter, const tensor& max_filter, datatype Tinput, datatype Tfilter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, datatype out_type=static_cast<datatype>(13)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedConv2D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedConv2DAndRelu
# Inputs:
*    input
*    filter
*    min_input
*    max_input
*    min_filter
*    max_filter

# Attributes:
*    Tinput
*    Tfilter
*    strides
*    padding
*    dilations
*    padding_list
*    out_type

# Outputs:
*    output
*    min_output
*    max_output

*/
inline std::vector<tensor> quantized_conv2_d_and_relu(const tensor& input, const tensor& filter, const tensor& min_input, const tensor& max_input, const tensor& min_filter, const tensor& max_filter, datatype Tinput, datatype Tfilter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::vector<int64_t>& padding_list, datatype out_type=static_cast<datatype>(13)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedConv2DAndRelu", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrIntList(op.get(), "padding_list", padding_list.data(), static_cast<int>(padding_list.size()));
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedConv2DAndReluAndRequantize
# Inputs:
*    input
*    filter
*    min_input
*    max_input
*    min_filter
*    max_filter
*    min_freezed_output
*    max_freezed_output

# Attributes:
*    Tinput
*    Tfilter
*    strides
*    padding
*    dilations
*    padding_list
*    out_type

# Outputs:
*    output
*    min_output
*    max_output

*/
inline std::vector<tensor> quantized_conv2_d_and_relu_and_requantize(const tensor& input, const tensor& filter, const tensor& min_input, const tensor& max_input, const tensor& min_filter, const tensor& max_filter, const tensor& min_freezed_output, const tensor& max_freezed_output, datatype Tinput, datatype Tfilter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::vector<int64_t>& padding_list, datatype out_type=static_cast<datatype>(12)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedConv2DAndReluAndRequantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_freezed_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_freezed_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrIntList(op.get(), "padding_list", padding_list.data(), static_cast<int>(padding_list.size()));
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedConv2DAndRequantize
# Inputs:
*    input
*    filter
*    min_input
*    max_input
*    min_filter
*    max_filter
*    min_freezed_output
*    max_freezed_output

# Attributes:
*    Tinput
*    Tfilter
*    strides
*    padding
*    dilations
*    padding_list
*    out_type

# Outputs:
*    output
*    min_output
*    max_output

*/
inline std::vector<tensor> quantized_conv2_d_and_requantize(const tensor& input, const tensor& filter, const tensor& min_input, const tensor& max_input, const tensor& min_filter, const tensor& max_filter, const tensor& min_freezed_output, const tensor& max_freezed_output, datatype Tinput, datatype Tfilter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::vector<int64_t>& padding_list, datatype out_type=static_cast<datatype>(11)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedConv2DAndRequantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_freezed_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_freezed_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrIntList(op.get(), "padding_list", padding_list.data(), static_cast<int>(padding_list.size()));
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedConv2DPerChannel
# Inputs:
*    input
*    filter
*    min_input
*    max_input
*    min_filter
*    max_filter

# Attributes:
*    Tinput
*    Tfilter
*    strides
*    padding
*    dilations
*    out_type

# Outputs:
*    output
*    min_output
*    max_output

*/
inline std::vector<tensor> quantized_conv2_d_per_channel(const tensor& input, const tensor& filter, const tensor& min_input, const tensor& max_input, const tensor& min_filter, const tensor& max_filter, datatype Tinput, datatype Tfilter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, datatype out_type=static_cast<datatype>(13)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedConv2DPerChannel", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedConv2DWithBias
# Inputs:
*    input
*    filter
*    bias
*    min_input
*    max_input
*    min_filter
*    max_filter

# Attributes:
*    Tinput
*    Tfilter
*    strides
*    padding
*    dilations
*    padding_list
*    out_type

# Outputs:
*    output
*    min_output
*    max_output

*/
inline std::vector<tensor> quantized_conv2_d_with_bias(const tensor& input, const tensor& filter, const tensor& bias, const tensor& min_input, const tensor& max_input, const tensor& min_filter, const tensor& max_filter, datatype Tinput, datatype Tfilter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::vector<int64_t>& padding_list, datatype out_type=static_cast<datatype>(13)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedConv2DWithBias", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrIntList(op.get(), "padding_list", padding_list.data(), static_cast<int>(padding_list.size()));
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedConv2DWithBiasAndRelu
# Inputs:
*    input
*    filter
*    bias
*    min_input
*    max_input
*    min_filter
*    max_filter

# Attributes:
*    Tinput
*    Tfilter
*    strides
*    padding
*    dilations
*    padding_list
*    out_type

# Outputs:
*    output
*    min_output
*    max_output

*/
inline std::vector<tensor> quantized_conv2_d_with_bias_and_relu(const tensor& input, const tensor& filter, const tensor& bias, const tensor& min_input, const tensor& max_input, const tensor& min_filter, const tensor& max_filter, datatype Tinput, datatype Tfilter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::vector<int64_t>& padding_list, datatype out_type=static_cast<datatype>(13)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedConv2DWithBiasAndRelu", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrIntList(op.get(), "padding_list", padding_list.data(), static_cast<int>(padding_list.size()));
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedConv2DWithBiasAndReluAndRequantize
# Inputs:
*    input
*    filter
*    bias
*    min_input
*    max_input
*    min_filter
*    max_filter
*    min_freezed_output
*    max_freezed_output

# Attributes:
*    Tinput
*    Tfilter
*    Tbias
*    strides
*    padding
*    dilations
*    padding_list
*    out_type

# Outputs:
*    output
*    min_output
*    max_output

*/
inline std::vector<tensor> quantized_conv2_d_with_bias_and_relu_and_requantize(const tensor& input, const tensor& filter, const tensor& bias, const tensor& min_input, const tensor& max_input, const tensor& min_filter, const tensor& max_filter, const tensor& min_freezed_output, const tensor& max_freezed_output, datatype Tinput, datatype Tfilter, datatype Tbias, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::vector<int64_t>& padding_list, datatype out_type=static_cast<datatype>(12)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedConv2DWithBiasAndReluAndRequantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_freezed_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_freezed_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrType(op.get(), "Tbias", Tbias);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrIntList(op.get(), "padding_list", padding_list.data(), static_cast<int>(padding_list.size()));
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedConv2DWithBiasAndRequantize
# Inputs:
*    input
*    filter
*    bias
*    min_input
*    max_input
*    min_filter
*    max_filter
*    min_freezed_output
*    max_freezed_output

# Attributes:
*    Tinput
*    Tfilter
*    Tbias
*    strides
*    padding
*    dilations
*    padding_list
*    out_type

# Outputs:
*    output
*    min_output
*    max_output

*/
inline std::vector<tensor> quantized_conv2_d_with_bias_and_requantize(const tensor& input, const tensor& filter, const tensor& bias, const tensor& min_input, const tensor& max_input, const tensor& min_filter, const tensor& max_filter, const tensor& min_freezed_output, const tensor& max_freezed_output, datatype Tinput, datatype Tfilter, datatype Tbias, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::vector<int64_t>& padding_list, datatype out_type=static_cast<datatype>(11)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedConv2DWithBiasAndRequantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_freezed_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_freezed_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrType(op.get(), "Tbias", Tbias);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrIntList(op.get(), "padding_list", padding_list.data(), static_cast<int>(padding_list.size()));
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedConv2DWithBiasSignedSumAndReluAndRequantize
# Inputs:
*    input
*    filter
*    bias
*    min_input
*    max_input
*    min_filter
*    max_filter
*    min_freezed_output
*    max_freezed_output
*    summand
*    min_summand
*    max_summand

# Attributes:
*    Tinput
*    Tfilter
*    Tbias
*    Tsummand
*    strides
*    padding
*    dilations
*    padding_list
*    out_type

# Outputs:
*    output
*    min_output
*    max_output

*/
inline std::vector<tensor> quantized_conv2_d_with_bias_signed_sum_and_relu_and_requantize(const tensor& input, const tensor& filter, const tensor& bias, const tensor& min_input, const tensor& max_input, const tensor& min_filter, const tensor& max_filter, const tensor& min_freezed_output, const tensor& max_freezed_output, const tensor& summand, const tensor& min_summand, const tensor& max_summand, datatype Tinput, datatype Tfilter, datatype Tbias, datatype Tsummand, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::vector<int64_t>& padding_list, datatype out_type=static_cast<datatype>(12)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedConv2DWithBiasSignedSumAndReluAndRequantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_freezed_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_freezed_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), summand.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_summand.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_summand.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrType(op.get(), "Tbias", Tbias);
    TFE_OpSetAttrType(op.get(), "Tsummand", Tsummand);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrIntList(op.get(), "padding_list", padding_list.data(), static_cast<int>(padding_list.size()));
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedConv2DWithBiasSumAndRelu
# Inputs:
*    input
*    filter
*    bias
*    min_input
*    max_input
*    min_filter
*    max_filter
*    summand

# Attributes:
*    Tinput
*    Tfilter
*    strides
*    padding
*    dilations
*    padding_list
*    out_type

# Outputs:
*    output
*    min_output
*    max_output

*/
inline std::vector<tensor> quantized_conv2_d_with_bias_sum_and_relu(const tensor& input, const tensor& filter, const tensor& bias, const tensor& min_input, const tensor& max_input, const tensor& min_filter, const tensor& max_filter, const tensor& summand, datatype Tinput, datatype Tfilter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::vector<int64_t>& padding_list, datatype out_type=static_cast<datatype>(13)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedConv2DWithBiasSumAndRelu", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), summand.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrIntList(op.get(), "padding_list", padding_list.data(), static_cast<int>(padding_list.size()));
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedConv2DWithBiasSumAndReluAndRequantize
# Inputs:
*    input
*    filter
*    bias
*    min_input
*    max_input
*    min_filter
*    max_filter
*    min_freezed_output
*    max_freezed_output
*    summand
*    min_summand
*    max_summand

# Attributes:
*    Tinput
*    Tfilter
*    Tbias
*    Tsummand
*    strides
*    padding
*    dilations
*    padding_list
*    out_type

# Outputs:
*    output
*    min_output
*    max_output

*/
inline std::vector<tensor> quantized_conv2_d_with_bias_sum_and_relu_and_requantize(const tensor& input, const tensor& filter, const tensor& bias, const tensor& min_input, const tensor& max_input, const tensor& min_filter, const tensor& max_filter, const tensor& min_freezed_output, const tensor& max_freezed_output, const tensor& summand, const tensor& min_summand, const tensor& max_summand, datatype Tinput, datatype Tfilter, datatype Tbias, datatype Tsummand, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::vector<int64_t>& padding_list, datatype out_type=static_cast<datatype>(12)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedConv2DWithBiasSumAndReluAndRequantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_freezed_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_freezed_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), summand.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_summand.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_summand.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrType(op.get(), "Tbias", Tbias);
    TFE_OpSetAttrType(op.get(), "Tsummand", Tsummand);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrIntList(op.get(), "padding_list", padding_list.data(), static_cast<int>(padding_list.size()));
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedDepthwiseConv2D
# Inputs:
*    input
*    filter
*    min_input
*    max_input
*    min_filter
*    max_filter

# Attributes:
*    Tinput
*    Tfilter
*    strides
*    padding
*    dilations
*    out_type

# Outputs:
*    output
*    min_output
*    max_output

*/
inline std::vector<tensor> quantized_depthwise_conv2_d(const tensor& input, const tensor& filter, const tensor& min_input, const tensor& max_input, const tensor& min_filter, const tensor& max_filter, datatype Tinput, datatype Tfilter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, datatype out_type=static_cast<datatype>(13)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedDepthwiseConv2D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedDepthwiseConv2DWithBias
# Inputs:
*    input
*    filter
*    bias
*    min_input
*    max_input
*    min_filter
*    max_filter

# Attributes:
*    Tinput
*    Tfilter
*    strides
*    padding
*    dilations
*    out_type

# Outputs:
*    output
*    min_output
*    max_output

*/
inline std::vector<tensor> quantized_depthwise_conv2_d_with_bias(const tensor& input, const tensor& filter, const tensor& bias, const tensor& min_input, const tensor& max_input, const tensor& min_filter, const tensor& max_filter, datatype Tinput, datatype Tfilter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, datatype out_type=static_cast<datatype>(13)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedDepthwiseConv2DWithBias", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedDepthwiseConv2DWithBiasAndRelu
# Inputs:
*    input
*    filter
*    bias
*    min_input
*    max_input
*    min_filter
*    max_filter

# Attributes:
*    Tinput
*    Tfilter
*    strides
*    padding
*    dilations
*    padding_list
*    out_type

# Outputs:
*    output
*    min_output
*    max_output

*/
inline std::vector<tensor> quantized_depthwise_conv2_d_with_bias_and_relu(const tensor& input, const tensor& filter, const tensor& bias, const tensor& min_input, const tensor& max_input, const tensor& min_filter, const tensor& max_filter, datatype Tinput, datatype Tfilter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::vector<int64_t>& padding_list, datatype out_type=static_cast<datatype>(13)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedDepthwiseConv2DWithBiasAndRelu", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrIntList(op.get(), "padding_list", padding_list.data(), static_cast<int>(padding_list.size()));
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedDepthwiseConv2DWithBiasAndReluAndRequantize
# Inputs:
*    input
*    filter
*    bias
*    min_input
*    max_input
*    min_filter
*    max_filter
*    min_freezed_output
*    max_freezed_output

# Attributes:
*    Tinput
*    Tfilter
*    Tbias
*    strides
*    padding
*    dilations
*    padding_list
*    out_type

# Outputs:
*    output
*    min_output
*    max_output

*/
inline std::vector<tensor> quantized_depthwise_conv2_d_with_bias_and_relu_and_requantize(const tensor& input, const tensor& filter, const tensor& bias, const tensor& min_input, const tensor& max_input, const tensor& min_filter, const tensor& max_filter, const tensor& min_freezed_output, const tensor& max_freezed_output, datatype Tinput, datatype Tfilter, datatype Tbias, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::vector<int64_t>& padding_list, datatype out_type=static_cast<datatype>(12)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedDepthwiseConv2DWithBiasAndReluAndRequantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_freezed_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_freezed_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrType(op.get(), "Tbias", Tbias);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), static_cast<int>(dilations.size()));
    TFE_OpSetAttrIntList(op.get(), "padding_list", padding_list.data(), static_cast<int>(padding_list.size()));
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedInstanceNorm
# Inputs:
*    x
*    x_min
*    x_max

# Attributes:
*    output_range_given
*    given_y_min
*    given_y_max
*    variance_epsilon
*    min_separation

# Outputs:
*    y
*    y_min
*    y_max

*/
inline std::vector<tensor> quantized_instance_norm(const tensor& x, const tensor& x_min, const tensor& x_max, bool output_range_given=false, float given_y_min=0.0000e+00, float given_y_max=0.0000e+00, float variance_epsilon=1.0000e-05, float min_separation=1.0000e-03) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedInstanceNorm", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x_min.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x_max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "output_range_given", (unsigned char)output_range_given);
    TFE_OpSetAttrFloat(op.get(), "given_y_min", given_y_min);
    TFE_OpSetAttrFloat(op.get(), "given_y_max", given_y_max);
    TFE_OpSetAttrFloat(op.get(), "variance_epsilon", variance_epsilon);
    TFE_OpSetAttrFloat(op.get(), "min_separation", min_separation);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedMatMul
# Inputs:
*    a
*    b
*    min_a
*    max_a
*    min_b
*    max_b

# Attributes:
*    T1
*    T2
*    Toutput
*    transpose_a
*    transpose_b
*    Tactivation

# Outputs:
*    out
*    min_out
*    max_out

*/
inline std::vector<tensor> quantized_mat_mul(const tensor& a, const tensor& b, const tensor& min_a, const tensor& max_a, const tensor& min_b, const tensor& max_b, datatype T1, datatype T2, datatype Toutput=static_cast<datatype>(13), bool transpose_a=false, bool transpose_b=false, datatype Tactivation=static_cast<datatype>(12)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedMatMul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "Toutput", Toutput);
    TFE_OpSetAttrBool(op.get(), "transpose_a", (unsigned char)transpose_a);
    TFE_OpSetAttrBool(op.get(), "transpose_b", (unsigned char)transpose_b);
    TFE_OpSetAttrType(op.get(), "Tactivation", Tactivation);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedMatMulWithBias
# Inputs:
*    a
*    b
*    bias
*    min_a
*    max_a
*    min_b
*    max_b

# Attributes:
*    T1
*    T2
*    Tbias
*    Toutput
*    transpose_a
*    transpose_b
*    input_quant_mode

# Outputs:
*    out
*    min_out
*    max_out

*/
inline std::vector<tensor> quantized_mat_mul_with_bias(const tensor& a, const tensor& b, const tensor& bias, const tensor& min_a, const tensor& max_a, const tensor& min_b, const tensor& max_b, datatype T1, datatype T2, datatype Tbias, datatype Toutput=static_cast<datatype>(13), bool transpose_a=false, bool transpose_b=false, const std::string& input_quant_mode="MIN_FIRST") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedMatMulWithBias", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "Tbias", Tbias);
    TFE_OpSetAttrType(op.get(), "Toutput", Toutput);
    TFE_OpSetAttrBool(op.get(), "transpose_a", (unsigned char)transpose_a);
    TFE_OpSetAttrBool(op.get(), "transpose_b", (unsigned char)transpose_b);
    TFE_OpSetAttrString(op.get(), "input_quant_mode", (void*) input_quant_mode.c_str(), input_quant_mode.size());

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedMatMulWithBiasAndDequantize
# Inputs:
*    a
*    b
*    bias
*    min_a
*    max_a
*    min_b
*    max_b
*    min_freezed_output
*    max_freezed_output

# Attributes:
*    T1
*    T2
*    Tbias
*    Toutput
*    transpose_a
*    transpose_b
*    input_quant_mode

# Outputs:
*    out

*/
inline tensor quantized_mat_mul_with_bias_and_dequantize(const tensor& a, const tensor& b, const tensor& bias, const tensor& min_a, const tensor& max_a, const tensor& min_b, const tensor& max_b, const tensor& min_freezed_output, const tensor& max_freezed_output, datatype T1, datatype T2, datatype Tbias, datatype Toutput, bool transpose_a=false, bool transpose_b=false, const std::string& input_quant_mode="MIN_FIRST") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedMatMulWithBiasAndDequantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_freezed_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_freezed_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "Tbias", Tbias);
    TFE_OpSetAttrType(op.get(), "Toutput", Toutput);
    TFE_OpSetAttrBool(op.get(), "transpose_a", (unsigned char)transpose_a);
    TFE_OpSetAttrBool(op.get(), "transpose_b", (unsigned char)transpose_b);
    TFE_OpSetAttrString(op.get(), "input_quant_mode", (void*) input_quant_mode.c_str(), input_quant_mode.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # QuantizedMatMulWithBiasAndRelu
# Inputs:
*    a
*    b
*    bias
*    min_a
*    max_a
*    min_b
*    max_b

# Attributes:
*    T1
*    T2
*    Toutput
*    transpose_a
*    transpose_b
*    input_quant_mode

# Outputs:
*    out
*    min_out
*    max_out

*/
inline std::vector<tensor> quantized_mat_mul_with_bias_and_relu(const tensor& a, const tensor& b, const tensor& bias, const tensor& min_a, const tensor& max_a, const tensor& min_b, const tensor& max_b, datatype T1, datatype T2, datatype Toutput=static_cast<datatype>(13), bool transpose_a=false, bool transpose_b=false, const std::string& input_quant_mode="MIN_FIRST") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedMatMulWithBiasAndRelu", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "Toutput", Toutput);
    TFE_OpSetAttrBool(op.get(), "transpose_a", (unsigned char)transpose_a);
    TFE_OpSetAttrBool(op.get(), "transpose_b", (unsigned char)transpose_b);
    TFE_OpSetAttrString(op.get(), "input_quant_mode", (void*) input_quant_mode.c_str(), input_quant_mode.size());

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedMatMulWithBiasAndReluAndRequantize
# Inputs:
*    a
*    b
*    bias
*    min_a
*    max_a
*    min_b
*    max_b
*    min_freezed_output
*    max_freezed_output

# Attributes:
*    T1
*    T2
*    Tbias
*    Toutput
*    transpose_a
*    transpose_b
*    input_quant_mode

# Outputs:
*    out
*    min_out
*    max_out

*/
inline std::vector<tensor> quantized_mat_mul_with_bias_and_relu_and_requantize(const tensor& a, const tensor& b, const tensor& bias, const tensor& min_a, const tensor& max_a, const tensor& min_b, const tensor& max_b, const tensor& min_freezed_output, const tensor& max_freezed_output, datatype T1, datatype T2, datatype Tbias, datatype Toutput=static_cast<datatype>(12), bool transpose_a=false, bool transpose_b=false, const std::string& input_quant_mode="MIN_FIRST") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedMatMulWithBiasAndReluAndRequantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_freezed_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_freezed_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "Tbias", Tbias);
    TFE_OpSetAttrType(op.get(), "Toutput", Toutput);
    TFE_OpSetAttrBool(op.get(), "transpose_a", (unsigned char)transpose_a);
    TFE_OpSetAttrBool(op.get(), "transpose_b", (unsigned char)transpose_b);
    TFE_OpSetAttrString(op.get(), "input_quant_mode", (void*) input_quant_mode.c_str(), input_quant_mode.size());

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedMatMulWithBiasAndRequantize
# Inputs:
*    a
*    b
*    bias
*    min_a
*    max_a
*    min_b
*    max_b
*    min_freezed_output
*    max_freezed_output

# Attributes:
*    T1
*    T2
*    Tbias
*    Toutput
*    transpose_a
*    transpose_b
*    input_quant_mode

# Outputs:
*    out
*    min_out
*    max_out

*/
inline std::vector<tensor> quantized_mat_mul_with_bias_and_requantize(const tensor& a, const tensor& b, const tensor& bias, const tensor& min_a, const tensor& max_a, const tensor& min_b, const tensor& max_b, const tensor& min_freezed_output, const tensor& max_freezed_output, datatype T1, datatype T2, datatype Tbias, datatype Toutput=static_cast<datatype>(12), bool transpose_a=false, bool transpose_b=false, const std::string& input_quant_mode="MIN_FIRST") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedMatMulWithBiasAndRequantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_freezed_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_freezed_output.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "Tbias", Tbias);
    TFE_OpSetAttrType(op.get(), "Toutput", Toutput);
    TFE_OpSetAttrBool(op.get(), "transpose_a", (unsigned char)transpose_a);
    TFE_OpSetAttrBool(op.get(), "transpose_b", (unsigned char)transpose_b);
    TFE_OpSetAttrString(op.get(), "input_quant_mode", (void*) input_quant_mode.c_str(), input_quant_mode.size());

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedMaxPool
# Inputs:
*    input
*    min_input
*    max_input

# Attributes:
*    ksize
*    strides
*    padding

# Outputs:
*    output
*    min_output
*    max_output

*/
inline std::vector<tensor> quantized_max_pool(const tensor& input, const tensor& min_input, const tensor& max_input, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedMaxPool", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), static_cast<int>(ksize.size()));
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), static_cast<int>(strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedMul
# Inputs:
*    x
*    y
*    min_x
*    max_x
*    min_y
*    max_y

# Attributes:
*    T1
*    T2
*    Toutput

# Outputs:
*    z
*    min_z
*    max_z

*/
inline std::vector<tensor> quantized_mul(const tensor& x, const tensor& y, const tensor& min_x, const tensor& max_x, const tensor& min_y, const tensor& max_y, datatype T1, datatype T2, datatype Toutput=static_cast<datatype>(13)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedMul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "Toutput", Toutput);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedRelu
# Inputs:
*    features
*    min_features
*    max_features

# Attributes:
*    Tinput
*    out_type

# Outputs:
*    activations
*    min_activations
*    max_activations

*/
inline std::vector<tensor> quantized_relu(const tensor& features, const tensor& min_features, const tensor& max_features, datatype Tinput, datatype out_type=static_cast<datatype>(12)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedRelu", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), features.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_features.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_features.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedRelu6
# Inputs:
*    features
*    min_features
*    max_features

# Attributes:
*    Tinput
*    out_type

# Outputs:
*    activations
*    min_activations
*    max_activations

*/
inline std::vector<tensor> quantized_relu6(const tensor& features, const tensor& min_features, const tensor& max_features, datatype Tinput, datatype out_type=static_cast<datatype>(12)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedRelu6", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), features.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_features.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_features.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedReluX
# Inputs:
*    features
*    max_value
*    min_features
*    max_features

# Attributes:
*    Tinput
*    out_type

# Outputs:
*    activations
*    min_activations
*    max_activations

*/
inline std::vector<tensor> quantized_relu_x(const tensor& features, const tensor& max_value, const tensor& min_features, const tensor& max_features, datatype Tinput, datatype out_type=static_cast<datatype>(12)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedReluX", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), features.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_features.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_features.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedReshape
# Inputs:
*    tensor
*    shape
*    input_min
*    input_max

# Attributes:
*    Tshape

# Outputs:
*    output
*    output_min
*    output_max

*/
inline std::vector<tensor> quantized_reshape(const tensor& input_tensor, const tensor& shape, const tensor& input_min, const tensor& input_max, datatype Tshape=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedReshape", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_min.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tshape", Tshape);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QuantizedResizeBilinear
# Inputs:
*    images
*    size
*    min
*    max

# Attributes:
*    align_corners
*    half_pixel_centers

# Outputs:
*    resized_images
*    out_min
*    out_max

*/
inline std::vector<tensor> quantized_resize_bilinear(const tensor& images, const tensor& size, const tensor& min, const tensor& max, bool align_corners=false, bool half_pixel_centers=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedResizeBilinear", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "align_corners", (unsigned char)align_corners);
    TFE_OpSetAttrBool(op.get(), "half_pixel_centers", (unsigned char)half_pixel_centers);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # QueueClose
# Inputs:
*    handle

# Attributes:
*    cancel_pending_enqueues

# Outputs:
*    
*/
inline void queue_close(const tensor& handle, bool cancel_pending_enqueues=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueClose", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "cancel_pending_enqueues", (unsigned char)cancel_pending_enqueues);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # QueueCloseV2
# Inputs:
*    handle

# Attributes:
*    cancel_pending_enqueues

# Outputs:
*    
*/
inline void queue_close_v2(const tensor& handle, bool cancel_pending_enqueues=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueCloseV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "cancel_pending_enqueues", (unsigned char)cancel_pending_enqueues);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # QueueDequeue
# Inputs:
*    handle

# Attributes:
*    component_types
*    timeout_ms

# Outputs:
*    components

*/
inline tensor queue_dequeue(const tensor& handle, const std::vector<datatype>& component_types, int64_t timeout_ms=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueDequeue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), static_cast<int>(component_types.size()));
    TFE_OpSetAttrInt(op.get(), "timeout_ms", timeout_ms);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # QueueDequeueMany
# Inputs:
*    handle
*    n

# Attributes:
*    component_types
*    timeout_ms

# Outputs:
*    components

*/
inline tensor queue_dequeue_many(const tensor& handle, const tensor& n, const std::vector<datatype>& component_types, int64_t timeout_ms=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueDequeueMany", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), n.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), static_cast<int>(component_types.size()));
    TFE_OpSetAttrInt(op.get(), "timeout_ms", timeout_ms);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # QueueDequeueManyV2
# Inputs:
*    handle
*    n

# Attributes:
*    component_types
*    timeout_ms

# Outputs:
*    components

*/
inline tensor queue_dequeue_many_v2(const tensor& handle, const tensor& n, const std::vector<datatype>& component_types, int64_t timeout_ms=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueDequeueManyV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), n.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), static_cast<int>(component_types.size()));
    TFE_OpSetAttrInt(op.get(), "timeout_ms", timeout_ms);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # QueueDequeueUpTo
# Inputs:
*    handle
*    n

# Attributes:
*    component_types
*    timeout_ms

# Outputs:
*    components

*/
inline tensor queue_dequeue_up_to(const tensor& handle, const tensor& n, const std::vector<datatype>& component_types, int64_t timeout_ms=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueDequeueUpTo", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), n.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), static_cast<int>(component_types.size()));
    TFE_OpSetAttrInt(op.get(), "timeout_ms", timeout_ms);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # QueueDequeueUpToV2
# Inputs:
*    handle
*    n

# Attributes:
*    component_types
*    timeout_ms

# Outputs:
*    components

*/
inline tensor queue_dequeue_up_to_v2(const tensor& handle, const tensor& n, const std::vector<datatype>& component_types, int64_t timeout_ms=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueDequeueUpToV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), n.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), static_cast<int>(component_types.size()));
    TFE_OpSetAttrInt(op.get(), "timeout_ms", timeout_ms);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # QueueDequeueV2
# Inputs:
*    handle

# Attributes:
*    component_types
*    timeout_ms

# Outputs:
*    components

*/
inline tensor queue_dequeue_v2(const tensor& handle, const std::vector<datatype>& component_types, int64_t timeout_ms=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueDequeueV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), static_cast<int>(component_types.size()));
    TFE_OpSetAttrInt(op.get(), "timeout_ms", timeout_ms);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # QueueEnqueue
# Inputs:
*    handle
*    components

# Attributes:
*    Tcomponents
*    timeout_ms

# Outputs:
*    
*/
inline void queue_enqueue(const tensor& handle, const std::vector<tensor>&components, const std::vector<datatype>& Tcomponents, int64_t timeout_ms=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueEnqueue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> components_handles; components_handles.reserve(components.size());
    std::transform(components.begin(), components.end(), std::back_inserter(components_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), components_handles.data(), static_cast<int>(components.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Tcomponents", reinterpret_cast<const enum TF_DataType *>(Tcomponents.data()), static_cast<int>(Tcomponents.size()));
    TFE_OpSetAttrInt(op.get(), "timeout_ms", timeout_ms);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # QueueEnqueueMany
# Inputs:
*    handle
*    components

# Attributes:
*    Tcomponents
*    timeout_ms

# Outputs:
*    
*/
inline void queue_enqueue_many(const tensor& handle, const std::vector<tensor>&components, const std::vector<datatype>& Tcomponents, int64_t timeout_ms=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueEnqueueMany", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> components_handles; components_handles.reserve(components.size());
    std::transform(components.begin(), components.end(), std::back_inserter(components_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), components_handles.data(), static_cast<int>(components.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Tcomponents", reinterpret_cast<const enum TF_DataType *>(Tcomponents.data()), static_cast<int>(Tcomponents.size()));
    TFE_OpSetAttrInt(op.get(), "timeout_ms", timeout_ms);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # QueueEnqueueManyV2
# Inputs:
*    handle
*    components

# Attributes:
*    Tcomponents
*    timeout_ms

# Outputs:
*    
*/
inline void queue_enqueue_many_v2(const tensor& handle, const std::vector<tensor>&components, const std::vector<datatype>& Tcomponents, int64_t timeout_ms=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueEnqueueManyV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> components_handles; components_handles.reserve(components.size());
    std::transform(components.begin(), components.end(), std::back_inserter(components_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), components_handles.data(), static_cast<int>(components.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Tcomponents", reinterpret_cast<const enum TF_DataType *>(Tcomponents.data()), static_cast<int>(Tcomponents.size()));
    TFE_OpSetAttrInt(op.get(), "timeout_ms", timeout_ms);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # QueueEnqueueV2
# Inputs:
*    handle
*    components

# Attributes:
*    Tcomponents
*    timeout_ms

# Outputs:
*    
*/
inline void queue_enqueue_v2(const tensor& handle, const std::vector<tensor>&components, const std::vector<datatype>& Tcomponents, int64_t timeout_ms=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueEnqueueV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> components_handles; components_handles.reserve(components.size());
    std::transform(components.begin(), components.end(), std::back_inserter(components_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), components_handles.data(), static_cast<int>(components.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Tcomponents", reinterpret_cast<const enum TF_DataType *>(Tcomponents.data()), static_cast<int>(Tcomponents.size()));
    TFE_OpSetAttrInt(op.get(), "timeout_ms", timeout_ms);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # QueueIsClosed
# Inputs:
*    handle

# Attributes:
*    
# Outputs:
*    is_closed

*/
inline tensor queue_is_closed(const tensor& handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueIsClosed", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # QueueIsClosedV2
# Inputs:
*    handle

# Attributes:
*    
# Outputs:
*    is_closed

*/
inline tensor queue_is_closed_v2(const tensor& handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueIsClosedV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # QueueSize
# Inputs:
*    handle

# Attributes:
*    
# Outputs:
*    size

*/
inline tensor queue_size(const tensor& handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueSize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # QueueSizeV2
# Inputs:
*    handle

# Attributes:
*    
# Outputs:
*    size

*/
inline tensor queue_size_v2(const tensor& handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueSizeV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RFFT
# Inputs:
*    input
*    fft_length

# Attributes:
*    Treal
*    Tcomplex

# Outputs:
*    output

*/
inline tensor RFFT(const tensor& input, const tensor& fft_length, datatype Treal=static_cast<datatype>(1), datatype Tcomplex=static_cast<datatype>(8)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RFFT", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), fft_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Treal", Treal);
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RFFT2D
# Inputs:
*    input
*    fft_length

# Attributes:
*    Treal
*    Tcomplex

# Outputs:
*    output

*/
inline tensor RFFT2D(const tensor& input, const tensor& fft_length, datatype Treal=static_cast<datatype>(1), datatype Tcomplex=static_cast<datatype>(8)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RFFT2D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), fft_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Treal", Treal);
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RFFT3D
# Inputs:
*    input
*    fft_length

# Attributes:
*    Treal
*    Tcomplex

# Outputs:
*    output

*/
inline tensor RFFT3D(const tensor& input, const tensor& fft_length, datatype Treal=static_cast<datatype>(1), datatype Tcomplex=static_cast<datatype>(8)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RFFT3D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), fft_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Treal", Treal);
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RFFTND
# Inputs:
*    input
*    fft_length
*    axes

# Attributes:
*    Treal
*    Tcomplex

# Outputs:
*    output

*/
inline tensor RFFTND(const tensor& input, const tensor& fft_length, const tensor& axes, datatype Treal=static_cast<datatype>(1), datatype Tcomplex=static_cast<datatype>(8)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RFFTND", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), fft_length.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), axes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Treal", Treal);
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RGBToHSV
# Inputs:
*    images

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor r_g_b_to_h_s_v(const tensor& images) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RGBToHSV", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RaggedBincount
# Inputs:
*    splits
*    values
*    size
*    weights

# Attributes:
*    Tidx
*    binary_output

# Outputs:
*    output

*/
inline tensor ragged_bincount(const tensor& splits, const tensor& values, const tensor& size, const tensor& weights, datatype Tidx, bool binary_output=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RaggedBincount", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), splits.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), weights.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrBool(op.get(), "binary_output", (unsigned char)binary_output);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RaggedCountSparseOutput
# Inputs:
*    splits
*    values
*    weights

# Attributes:
*    binary_output
*    output_type
*    minlength
*    maxlength

# Outputs:
*    output_indices
*    output_values
*    output_dense_shape

*/
inline std::vector<tensor> ragged_count_sparse_output(const tensor& splits, const tensor& values, const tensor& weights, bool binary_output, datatype output_type, int64_t minlength=-1, int64_t maxlength=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RaggedCountSparseOutput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), splits.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), weights.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "binary_output", (unsigned char)binary_output);
    TFE_OpSetAttrType(op.get(), "output_type", output_type);
    TFE_OpSetAttrInt(op.get(), "minlength", minlength);
    TFE_OpSetAttrInt(op.get(), "maxlength", maxlength);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # RaggedCross
# Inputs:
*    ragged_values
*    ragged_row_splits
*    sparse_indices
*    sparse_values
*    sparse_shape
*    dense_inputs

# Attributes:
*    Nsparse
*    input_order
*    hashed_output
*    num_buckets
*    hash_key
*    ragged_values_types
*    ragged_splits_types
*    sparse_values_types
*    dense_types
*    out_values_type
*    out_row_splits_type

# Outputs:
*    output_values
*    output_row_splits

*/
inline std::vector<tensor> ragged_cross(const std::vector<tensor>&ragged_values, const std::vector<tensor>&ragged_row_splits, const std::vector<tensor>&sparse_indices, const std::vector<tensor>&sparse_values, const std::vector<tensor>&sparse_shape, const std::vector<tensor>&dense_inputs, const std::string& input_order, bool hashed_output, int64_t num_buckets, int64_t hash_key, const std::vector<datatype>& ragged_values_types, const std::vector<datatype>& ragged_splits_types, const std::vector<datatype>& sparse_values_types, const std::vector<datatype>& dense_types, datatype out_values_type, datatype out_row_splits_type) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RaggedCross", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> ragged_values_handles; ragged_values_handles.reserve(ragged_values.size());
    std::transform(ragged_values.begin(), ragged_values.end(), std::back_inserter(ragged_values_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), ragged_values_handles.data(), static_cast<int>(ragged_values.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> ragged_row_splits_handles; ragged_row_splits_handles.reserve(ragged_row_splits.size());
    std::transform(ragged_row_splits.begin(), ragged_row_splits.end(), std::back_inserter(ragged_row_splits_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), ragged_row_splits_handles.data(), static_cast<int>(ragged_row_splits.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> sparse_indices_handles; sparse_indices_handles.reserve(sparse_indices.size());
    std::transform(sparse_indices.begin(), sparse_indices.end(), std::back_inserter(sparse_indices_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), sparse_indices_handles.data(), static_cast<int>(sparse_indices.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> sparse_values_handles; sparse_values_handles.reserve(sparse_values.size());
    std::transform(sparse_values.begin(), sparse_values.end(), std::back_inserter(sparse_values_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), sparse_values_handles.data(), static_cast<int>(sparse_values.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> sparse_shape_handles; sparse_shape_handles.reserve(sparse_shape.size());
    std::transform(sparse_shape.begin(), sparse_shape.end(), std::back_inserter(sparse_shape_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), sparse_shape_handles.data(), static_cast<int>(sparse_shape.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_inputs_handles; dense_inputs_handles.reserve(dense_inputs.size());
    std::transform(dense_inputs.begin(), dense_inputs.end(), std::back_inserter(dense_inputs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), dense_inputs_handles.data(), static_cast<int>(dense_inputs.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "Nsparse", sparse_indices.size());
    TFE_OpSetAttrString(op.get(), "input_order", (void*) input_order.c_str(), input_order.size());
    TFE_OpSetAttrBool(op.get(), "hashed_output", (unsigned char)hashed_output);
    TFE_OpSetAttrInt(op.get(), "num_buckets", num_buckets);
    TFE_OpSetAttrInt(op.get(), "hash_key", hash_key);
    TFE_OpSetAttrTypeList(op.get(), "ragged_values_types", reinterpret_cast<const enum TF_DataType *>(ragged_values_types.data()), static_cast<int>(ragged_values_types.size()));
    TFE_OpSetAttrTypeList(op.get(), "ragged_splits_types", reinterpret_cast<const enum TF_DataType *>(ragged_splits_types.data()), static_cast<int>(ragged_splits_types.size()));
    TFE_OpSetAttrTypeList(op.get(), "sparse_values_types", reinterpret_cast<const enum TF_DataType *>(sparse_values_types.data()), static_cast<int>(sparse_values_types.size()));
    TFE_OpSetAttrTypeList(op.get(), "dense_types", reinterpret_cast<const enum TF_DataType *>(dense_types.data()), static_cast<int>(dense_types.size()));
    TFE_OpSetAttrType(op.get(), "out_values_type", out_values_type);
    TFE_OpSetAttrType(op.get(), "out_row_splits_type", out_row_splits_type);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # RaggedFillEmptyRows
# Inputs:
*    value_rowids
*    values
*    nrows
*    default_value

# Attributes:
*    
# Outputs:
*    output_value_rowids
*    output_values
*    empty_row_indicator
*    reverse_index_map

*/
inline std::vector<tensor> ragged_fill_empty_rows(const tensor& value_rowids, const tensor& values, const tensor& nrows, const tensor& default_value) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RaggedFillEmptyRows", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), value_rowids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), nrows.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), default_value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 4;
    TFE_TensorHandle* res[4] = { nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]), };
}

/* # RaggedFillEmptyRowsGrad
# Inputs:
*    reverse_index_map
*    grad_values

# Attributes:
*    
# Outputs:
*    d_values
*    d_default_value

*/
inline std::vector<tensor> ragged_fill_empty_rows_grad(const tensor& reverse_index_map, const tensor& grad_values) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RaggedFillEmptyRowsGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reverse_index_map.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # RaggedGather
# Inputs:
*    params_nested_splits
*    params_dense_values
*    indices

# Attributes:
*    Tvalues
*    Tindices
*    PARAMS_RAGGED_RANK
*    OUTPUT_RAGGED_RANK
*    Tsplits

# Outputs:
*    output_nested_splits
*    output_dense_values

*/
inline std::vector<tensor> ragged_gather(const std::vector<tensor>&params_nested_splits, const tensor& params_dense_values, const tensor& indices, datatype Tvalues, datatype Tindices, int64_t OUTPUT_RAGGED_RANK, datatype Tsplits=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RaggedGather", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> params_nested_splits_handles; params_nested_splits_handles.reserve(params_nested_splits.size());
    std::transform(params_nested_splits.begin(), params_nested_splits.end(), std::back_inserter(params_nested_splits_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), params_nested_splits_handles.data(), static_cast<int>(params_nested_splits.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), params_dense_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tvalues", Tvalues);
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrInt(op.get(), "PARAMS_RAGGED_RANK", params_nested_splits.size());
    TFE_OpSetAttrInt(op.get(), "OUTPUT_RAGGED_RANK", OUTPUT_RAGGED_RANK);
    TFE_OpSetAttrType(op.get(), "Tsplits", Tsplits);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # RaggedRange
# Inputs:
*    starts
*    limits
*    deltas

# Attributes:
*    Tsplits

# Outputs:
*    rt_nested_splits
*    rt_dense_values

*/
inline std::vector<tensor> ragged_range(const tensor& starts, const tensor& limits, const tensor& deltas, datatype Tsplits=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RaggedRange", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), starts.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), limits.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), deltas.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tsplits", Tsplits);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # RaggedTensorFromVariant
# Inputs:
*    encoded_ragged

# Attributes:
*    input_ragged_rank
*    output_ragged_rank
*    Tvalues
*    Tsplits

# Outputs:
*    output_nested_splits
*    output_dense_values

*/
inline std::vector<tensor> ragged_tensor_from_variant(const tensor& encoded_ragged, int64_t input_ragged_rank, int64_t output_ragged_rank, datatype Tvalues, datatype Tsplits=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RaggedTensorFromVariant", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), encoded_ragged.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "input_ragged_rank", input_ragged_rank);
    TFE_OpSetAttrInt(op.get(), "output_ragged_rank", output_ragged_rank);
    TFE_OpSetAttrType(op.get(), "Tvalues", Tvalues);
    TFE_OpSetAttrType(op.get(), "Tsplits", Tsplits);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # RaggedTensorToSparse
# Inputs:
*    rt_nested_splits
*    rt_dense_values

# Attributes:
*    RAGGED_RANK
*    Tsplits

# Outputs:
*    sparse_indices
*    sparse_values
*    sparse_dense_shape

*/
inline std::vector<tensor> ragged_tensor_to_sparse(const std::vector<tensor>&rt_nested_splits, const tensor& rt_dense_values, datatype Tsplits=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RaggedTensorToSparse", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> rt_nested_splits_handles; rt_nested_splits_handles.reserve(rt_nested_splits.size());
    std::transform(rt_nested_splits.begin(), rt_nested_splits.end(), std::back_inserter(rt_nested_splits_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), rt_nested_splits_handles.data(), static_cast<int>(rt_nested_splits.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rt_dense_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "RAGGED_RANK", rt_nested_splits.size());
    TFE_OpSetAttrType(op.get(), "Tsplits", Tsplits);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # RaggedTensorToTensor
# Inputs:
*    shape
*    values
*    default_value
*    row_partition_tensors

# Attributes:
*    Tindex
*    Tshape
*    num_row_partition_tensors
*    row_partition_types

# Outputs:
*    result

*/
inline tensor ragged_tensor_to_tensor(const tensor& shape, const tensor& values, const tensor& default_value, const std::vector<tensor>&row_partition_tensors, datatype Tindex, datatype Tshape, const std::vector< std::string>& row_partition_types) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RaggedTensorToTensor", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), default_value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> row_partition_tensors_handles; row_partition_tensors_handles.reserve(row_partition_tensors.size());
    std::transform(row_partition_tensors.begin(), row_partition_tensors.end(), std::back_inserter(row_partition_tensors_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), row_partition_tensors_handles.data(), static_cast<int>(row_partition_tensors.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindex", Tindex);
    TFE_OpSetAttrType(op.get(), "Tshape", Tshape);
    TFE_OpSetAttrInt(op.get(), "num_row_partition_tensors", row_partition_tensors.size());
    
    std::vector<std::size_t> row_partition_types_sizes; row_partition_types_sizes.reserve(row_partition_types.size());
    std::transform(row_partition_types.begin(), row_partition_types.end(), std::back_inserter(row_partition_types_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "row_partition_types", reinterpret_cast<const void *const *>(row_partition_types.data()), row_partition_types_sizes.data(), static_cast<int>(row_partition_types.size()));
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RaggedTensorToVariant
# Inputs:
*    rt_nested_splits
*    rt_dense_values

# Attributes:
*    RAGGED_RANK
*    Tvalues
*    batched_input
*    Tsplits

# Outputs:
*    encoded_ragged

*/
inline tensor ragged_tensor_to_variant(const std::vector<tensor>&rt_nested_splits, const tensor& rt_dense_values, datatype Tvalues, bool batched_input, datatype Tsplits=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RaggedTensorToVariant", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> rt_nested_splits_handles; rt_nested_splits_handles.reserve(rt_nested_splits.size());
    std::transform(rt_nested_splits.begin(), rt_nested_splits.end(), std::back_inserter(rt_nested_splits_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), rt_nested_splits_handles.data(), static_cast<int>(rt_nested_splits.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rt_dense_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "RAGGED_RANK", rt_nested_splits.size());
    TFE_OpSetAttrType(op.get(), "Tvalues", Tvalues);
    TFE_OpSetAttrBool(op.get(), "batched_input", (unsigned char)batched_input);
    TFE_OpSetAttrType(op.get(), "Tsplits", Tsplits);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RaggedTensorToVariantGradient
# Inputs:
*    encoded_ragged_grad
*    row_splits
*    dense_values_shape

# Attributes:
*    Tvalues
*    Tsplits

# Outputs:
*    dense_values_grad

*/
inline tensor ragged_tensor_to_variant_gradient(const tensor& encoded_ragged_grad, const tensor& row_splits, const tensor& dense_values_shape, datatype Tvalues, datatype Tsplits=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RaggedTensorToVariantGradient", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), encoded_ragged_grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), row_splits.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dense_values_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tvalues", Tvalues);
    TFE_OpSetAttrType(op.get(), "Tsplits", Tsplits);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RandomCrop
# Inputs:
*    image
*    size

# Attributes:
*    seed
*    seed2

# Outputs:
*    output

*/
inline tensor random_crop(const tensor& image, const tensor& size, int64_t seed=0, int64_t seed2=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RandomCrop", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), image.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RandomDataset
# Inputs:
*    seed
*    seed2

# Attributes:
*    output_types
*    output_shapes
*    metadata

# Outputs:
*    handle

*/
inline tensor random_dataset(const tensor& seed, const tensor& seed2, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RandomDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), seed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RandomDatasetV2
# Inputs:
*    seed
*    seed2
*    seed_generator

# Attributes:
*    output_types
*    output_shapes
*    rerandomize_each_iteration
*    metadata

# Outputs:
*    handle

*/
inline tensor random_dataset_v2(const tensor& seed, const tensor& seed2, const tensor& seed_generator, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool rerandomize_each_iteration=false, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RandomDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), seed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed_generator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "rerandomize_each_iteration", (unsigned char)rerandomize_each_iteration);
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RandomGamma
# Inputs:
*    shape
*    alpha

# Attributes:
*    S
*    seed
*    seed2

# Outputs:
*    output

*/
inline tensor random_gamma(const tensor& shape, const tensor& alpha, datatype S, int64_t seed=0, int64_t seed2=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RandomGamma", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alpha.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "S", S);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RandomGammaGrad
# Inputs:
*    alpha
*    sample

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor random_gamma_grad(const tensor& alpha, const tensor& sample) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RandomGammaGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), alpha.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sample.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RandomIndexShuffle
# Inputs:
*    index
*    seed
*    max_index

# Attributes:
*    dtype
*    Tseed
*    rounds

# Outputs:
*    output

*/
inline tensor random_index_shuffle(const tensor& index, const tensor& seed, const tensor& max_index, datatype dtype, datatype Tseed, int64_t rounds=4) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RandomIndexShuffle", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), index.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_index.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);
    TFE_OpSetAttrInt(op.get(), "rounds", rounds);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RandomPoisson
# Inputs:
*    shape
*    rate

# Attributes:
*    S
*    dtype
*    seed
*    seed2

# Outputs:
*    output

*/
inline tensor random_poisson(const tensor& shape, const tensor& rate, datatype S, datatype dtype, int64_t seed=0, int64_t seed2=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RandomPoisson", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rate.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "S", S);
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RandomPoissonV2
# Inputs:
*    shape
*    rate

# Attributes:
*    S
*    seed
*    seed2
*    R
*    dtype

# Outputs:
*    output

*/
inline tensor random_poisson_v2(const tensor& shape, const tensor& rate, datatype S, int64_t seed=0, int64_t seed2=0, datatype R=static_cast<datatype>(2), datatype dtype=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RandomPoissonV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rate.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "S", S);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrType(op.get(), "R", R);
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RandomShuffle
# Inputs:
*    value

# Attributes:
*    seed
*    seed2

# Outputs:
*    output

*/
inline tensor random_shuffle(const tensor& value, int64_t seed=0, int64_t seed2=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RandomShuffle", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RandomShuffleQueue
# Inputs:
*    
# Attributes:
*    component_types
*    shapes
*    capacity
*    min_after_dequeue
*    seed
*    seed2
*    container
*    shared_name

# Outputs:
*    handle

*/
inline tensor random_shuffle_queue(const std::vector<datatype>& component_types, const std::vector< std::vector<int64_t>>& shapes, int64_t capacity=-1, int64_t min_after_dequeue=0, int64_t seed=0, int64_t seed2=0, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RandomShuffleQueue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), static_cast<int>(component_types.size()));
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), static_cast<int>(shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "min_after_dequeue", min_after_dequeue);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RandomShuffleQueueV2
# Inputs:
*    
# Attributes:
*    component_types
*    shapes
*    capacity
*    min_after_dequeue
*    seed
*    seed2
*    container
*    shared_name

# Outputs:
*    handle

*/
inline tensor random_shuffle_queue_v2(const std::vector<datatype>& component_types, const std::vector< std::vector<int64_t>>& shapes, int64_t capacity=-1, int64_t min_after_dequeue=0, int64_t seed=0, int64_t seed2=0, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RandomShuffleQueueV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), static_cast<int>(component_types.size()));
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), static_cast<int>(shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "min_after_dequeue", min_after_dequeue);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RandomStandardNormal
# Inputs:
*    shape

# Attributes:
*    dtype
*    seed
*    seed2

# Outputs:
*    output

*/
inline tensor random_standard_normal(const tensor& shape, datatype dtype, int64_t seed=0, int64_t seed2=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RandomStandardNormal", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RandomUniform
# Inputs:
*    shape

# Attributes:
*    dtype
*    seed
*    seed2

# Outputs:
*    output

*/
inline tensor random_uniform(const tensor& shape, datatype dtype, int64_t seed=0, int64_t seed2=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RandomUniform", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RandomUniformInt
# Inputs:
*    shape
*    minval
*    maxval

# Attributes:
*    Tout
*    seed
*    seed2

# Outputs:
*    output

*/
inline tensor random_uniform_int(const tensor& shape, const tensor& minval, const tensor& maxval, datatype Tout, int64_t seed=0, int64_t seed2=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RandomUniformInt", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), minval.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), maxval.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tout", Tout);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Range
# Inputs:
*    start
*    limit
*    delta

# Attributes:
*    Tidx

# Outputs:
*    output

*/
inline tensor range(const tensor& start, const tensor& limit, const tensor& delta, datatype Tidx=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Range", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), start.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), limit.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), delta.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RangeDataset
# Inputs:
*    start
*    stop
*    step

# Attributes:
*    output_types
*    output_shapes
*    metadata
*    replicate_on_split

# Outputs:
*    handle

*/
inline tensor range_dataset(const tensor& start, const tensor& stop, const tensor& step, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& metadata="", bool replicate_on_split=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RangeDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), start.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), stop.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), step.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());
    TFE_OpSetAttrBool(op.get(), "replicate_on_split", (unsigned char)replicate_on_split);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Rank
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor rank(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Rank", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ReadFile
# Inputs:
*    filename

# Attributes:
*    
# Outputs:
*    contents

*/
inline tensor read_file(const tensor& filename) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReadFile", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filename.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ReadVariableOp
# Inputs:
*    resource

# Attributes:
*    dtype

# Outputs:
*    value

*/
inline tensor read_variable_op(const tensor& resource, datatype dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReadVariableOp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ReadVariableXlaSplitND
# Inputs:
*    resource

# Attributes:
*    N
*    num_splits
*    paddings

# Outputs:
*    outputs

*/
inline tensor read_variable_xla_split_n_d(const tensor& resource, int64_t N, const std::vector<int64_t>& num_splits, const std::vector<int64_t>& paddings) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReadVariableXlaSplitND", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", N);
    TFE_OpSetAttrIntList(op.get(), "num_splits", num_splits.data(), static_cast<int>(num_splits.size()));
    TFE_OpSetAttrIntList(op.get(), "paddings", paddings.data(), static_cast<int>(paddings.size()));

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ReaderNumRecordsProduced
# Inputs:
*    reader_handle

# Attributes:
*    
# Outputs:
*    records_produced

*/
inline tensor reader_num_records_produced(const tensor& reader_handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderNumRecordsProduced", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ReaderNumRecordsProducedV2
# Inputs:
*    reader_handle

# Attributes:
*    
# Outputs:
*    records_produced

*/
inline tensor reader_num_records_produced_v2(const tensor& reader_handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderNumRecordsProducedV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ReaderNumWorkUnitsCompleted
# Inputs:
*    reader_handle

# Attributes:
*    
# Outputs:
*    units_completed

*/
inline tensor reader_num_work_units_completed(const tensor& reader_handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderNumWorkUnitsCompleted", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ReaderNumWorkUnitsCompletedV2
# Inputs:
*    reader_handle

# Attributes:
*    
# Outputs:
*    units_completed

*/
inline tensor reader_num_work_units_completed_v2(const tensor& reader_handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderNumWorkUnitsCompletedV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ReaderRead
# Inputs:
*    reader_handle
*    queue_handle

# Attributes:
*    
# Outputs:
*    key
*    value

*/
inline std::vector<tensor> reader_read(const tensor& reader_handle, const tensor& queue_handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderRead", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), queue_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # ReaderReadUpTo
# Inputs:
*    reader_handle
*    queue_handle
*    num_records

# Attributes:
*    
# Outputs:
*    keys
*    values

*/
inline std::vector<tensor> reader_read_up_to(const tensor& reader_handle, const tensor& queue_handle, const tensor& num_records) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderReadUpTo", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), queue_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_records.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # ReaderReadUpToV2
# Inputs:
*    reader_handle
*    queue_handle
*    num_records

# Attributes:
*    
# Outputs:
*    keys
*    values

*/
inline std::vector<tensor> reader_read_up_to_v2(const tensor& reader_handle, const tensor& queue_handle, const tensor& num_records) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderReadUpToV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), queue_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_records.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # ReaderReadV2
# Inputs:
*    reader_handle
*    queue_handle

# Attributes:
*    
# Outputs:
*    key
*    value

*/
inline std::vector<tensor> reader_read_v2(const tensor& reader_handle, const tensor& queue_handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderReadV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), queue_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # ReaderReset
# Inputs:
*    reader_handle

# Attributes:
*    
# Outputs:
*    
*/
inline void reader_reset(const tensor& reader_handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderReset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ReaderResetV2
# Inputs:
*    reader_handle

# Attributes:
*    
# Outputs:
*    
*/
inline void reader_reset_v2(const tensor& reader_handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderResetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ReaderRestoreState
# Inputs:
*    reader_handle
*    state

# Attributes:
*    
# Outputs:
*    
*/
inline void reader_restore_state(const tensor& reader_handle, const tensor& state) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderRestoreState", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), state.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ReaderRestoreStateV2
# Inputs:
*    reader_handle
*    state

# Attributes:
*    
# Outputs:
*    
*/
inline void reader_restore_state_v2(const tensor& reader_handle, const tensor& state) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderRestoreStateV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), state.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ReaderSerializeState
# Inputs:
*    reader_handle

# Attributes:
*    
# Outputs:
*    state

*/
inline tensor reader_serialize_state(const tensor& reader_handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderSerializeState", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ReaderSerializeStateV2
# Inputs:
*    reader_handle

# Attributes:
*    
# Outputs:
*    state

*/
inline tensor reader_serialize_state_v2(const tensor& reader_handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderSerializeStateV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Real
# Inputs:
*    input

# Attributes:
*    Tout

# Outputs:
*    output

*/
inline tensor real(const tensor& input, datatype Tout=static_cast<datatype>(1)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Real", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tout", Tout);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RealDiv
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor real_div(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RealDiv", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RebatchDataset
# Inputs:
*    input_dataset
*    num_replicas

# Attributes:
*    output_types
*    output_shapes
*    use_fallback

# Outputs:
*    handle

*/
inline tensor rebatch_dataset(const tensor& input_dataset, const tensor& num_replicas, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool use_fallback=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RebatchDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_replicas.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "use_fallback", (unsigned char)use_fallback);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RebatchDatasetV2
# Inputs:
*    input_dataset
*    batch_sizes
*    drop_remainder

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor rebatch_dataset_v2(const tensor& input_dataset, const tensor& batch_sizes, const tensor& drop_remainder, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RebatchDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), batch_sizes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), drop_remainder.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Reciprocal
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor reciprocal(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Reciprocal", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ReciprocalGrad
# Inputs:
*    y
*    dy

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor reciprocal_grad(const tensor& y, const tensor& dy) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReciprocalGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dy.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RecordInput
# Inputs:
*    
# Attributes:
*    file_pattern
*    file_random_seed
*    file_shuffle_shift_ratio
*    file_buffer_size
*    file_parallelism
*    batch_size
*    compression_type

# Outputs:
*    records

*/
inline tensor record_input(const std::string& file_pattern, int64_t file_random_seed=301, float file_shuffle_shift_ratio=0.0000e+00, int64_t file_buffer_size=10000, int64_t file_parallelism=16, int64_t batch_size=32, const std::string& compression_type="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RecordInput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "file_pattern", (void*) file_pattern.c_str(), file_pattern.size());
    TFE_OpSetAttrInt(op.get(), "file_random_seed", file_random_seed);
    TFE_OpSetAttrFloat(op.get(), "file_shuffle_shift_ratio", file_shuffle_shift_ratio);
    TFE_OpSetAttrInt(op.get(), "file_buffer_size", file_buffer_size);
    TFE_OpSetAttrInt(op.get(), "file_parallelism", file_parallelism);
    TFE_OpSetAttrInt(op.get(), "batch_size", batch_size);
    TFE_OpSetAttrString(op.get(), "compression_type", (void*) compression_type.c_str(), compression_type.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Recv
# Inputs:
*    
# Attributes:
*    tensor_type
*    tensor_name
*    send_device
*    send_device_incarnation
*    recv_device
*    client_terminated

# Outputs:
*    tensor

*/
inline tensor recv(datatype tensor_type, const std::string& tensor_name, const std::string& send_device, int64_t send_device_incarnation, const std::string& recv_device, bool client_terminated=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Recv", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "tensor_type", tensor_type);
    TFE_OpSetAttrString(op.get(), "tensor_name", (void*) tensor_name.c_str(), tensor_name.size());
    TFE_OpSetAttrString(op.get(), "send_device", (void*) send_device.c_str(), send_device.size());
    TFE_OpSetAttrInt(op.get(), "send_device_incarnation", send_device_incarnation);
    TFE_OpSetAttrString(op.get(), "recv_device", (void*) recv_device.c_str(), recv_device.size());
    TFE_OpSetAttrBool(op.get(), "client_terminated", (unsigned char)client_terminated);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RecvTPUEmbeddingActivations
# Inputs:
*    
# Attributes:
*    num_outputs
*    config

# Outputs:
*    outputs

*/
inline tensor recv_t_p_u_embedding_activations(int64_t num_outputs, const std::string& config) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RecvTPUEmbeddingActivations", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_outputs", num_outputs);
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ReduceDataset
# Inputs:
*    input_dataset
*    initial_state
*    other_arguments

# Attributes:
*    f
*    Tstate
*    Targuments
*    output_types
*    output_shapes
*    use_inter_op_parallelism
*    metadata

# Outputs:
*    components

*/
inline tensor reduce_dataset(const tensor& input_dataset, const std::vector<tensor>&initial_state, const std::vector<tensor>&other_arguments, int64_t f, const std::vector<datatype>& Tstate, const std::vector<datatype>& Targuments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool use_inter_op_parallelism=true, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReduceDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> initial_state_handles; initial_state_handles.reserve(initial_state.size());
    std::transform(initial_state.begin(), initial_state.end(), std::back_inserter(initial_state_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), initial_state_handles.data(), static_cast<int>(initial_state.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> other_arguments_handles; other_arguments_handles.reserve(other_arguments.size());
    std::transform(other_arguments.begin(), other_arguments.end(), std::back_inserter(other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), other_arguments_handles.data(), static_cast<int>(other_arguments.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "f", f);
    TFE_OpSetAttrTypeList(op.get(), "Tstate", reinterpret_cast<const enum TF_DataType *>(Tstate.data()), static_cast<int>(Tstate.size()));
    TFE_OpSetAttrTypeList(op.get(), "Targuments", reinterpret_cast<const enum TF_DataType *>(Targuments.data()), static_cast<int>(Targuments.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "use_inter_op_parallelism", (unsigned char)use_inter_op_parallelism);
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ReduceJoin
# Inputs:
*    inputs
*    reduction_indices

# Attributes:
*    keep_dims
*    separator

# Outputs:
*    output

*/
inline tensor reduce_join(const tensor& inputs, const tensor& reduction_indices, bool keep_dims=false, const std::string& separator="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReduceJoin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), inputs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reduction_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "keep_dims", (unsigned char)keep_dims);
    TFE_OpSetAttrString(op.get(), "separator", (void*) separator.c_str(), separator.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RefEnter
# Inputs:
*    data

# Attributes:
*    frame_name
*    is_constant
*    parallel_iterations

# Outputs:
*    output

*/
inline tensor ref_enter(const tensor& data, const std::string& frame_name, bool is_constant=false, int64_t parallel_iterations=10) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RefEnter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "frame_name", (void*) frame_name.c_str(), frame_name.size());
    TFE_OpSetAttrBool(op.get(), "is_constant", (unsigned char)is_constant);
    TFE_OpSetAttrInt(op.get(), "parallel_iterations", parallel_iterations);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RefExit
# Inputs:
*    data

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor ref_exit(const tensor& data) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RefExit", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RefIdentity
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor ref_identity(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RefIdentity", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RefMerge
# Inputs:
*    inputs

# Attributes:
*    N

# Outputs:
*    output
*    value_index

*/
inline std::vector<tensor> ref_merge(const std::vector<tensor>&inputs) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RefMerge", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), static_cast<int>(inputs.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", inputs.size());

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # RefNextIteration
# Inputs:
*    data

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor ref_next_iteration(const tensor& data) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RefNextIteration", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RefSelect
# Inputs:
*    index
*    inputs

# Attributes:
*    N

# Outputs:
*    output

*/
inline tensor ref_select(const tensor& index, const std::vector<tensor>&inputs) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RefSelect", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), index.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), static_cast<int>(inputs.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", inputs.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RefSwitch
# Inputs:
*    data
*    pred

# Attributes:
*    
# Outputs:
*    output_false
*    output_true

*/
inline std::vector<tensor> ref_switch(const tensor& data, const tensor& pred) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RefSwitch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), pred.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # RegexFullMatch
# Inputs:
*    input
*    pattern

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor regex_full_match(const tensor& input, const tensor& pattern) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RegexFullMatch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), pattern.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RegexReplace
# Inputs:
*    input
*    pattern
*    rewrite

# Attributes:
*    replace_global

# Outputs:
*    output

*/
inline tensor regex_replace(const tensor& input, const tensor& pattern, const tensor& rewrite, bool replace_global=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RegexReplace", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), pattern.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rewrite.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "replace_global", (unsigned char)replace_global);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RegisterDataset
# Inputs:
*    dataset
*    address
*    protocol

# Attributes:
*    external_state_policy
*    element_spec
*    metadata

# Outputs:
*    dataset_id

*/
inline tensor register_dataset(const tensor& dataset, const tensor& address, const tensor& protocol, int64_t external_state_policy, const std::string& element_spec="", const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RegisterDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), address.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), protocol.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "external_state_policy", external_state_policy);
    TFE_OpSetAttrString(op.get(), "element_spec", (void*) element_spec.c_str(), element_spec.size());
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RegisterDatasetV2
# Inputs:
*    dataset
*    address
*    protocol

# Attributes:
*    external_state_policy
*    element_spec
*    requested_dataset_id
*    metadata

# Outputs:
*    dataset_id

*/
inline tensor register_dataset_v2(const tensor& dataset, const tensor& address, const tensor& protocol, int64_t external_state_policy, const std::string& element_spec="", const std::string& requested_dataset_id="", const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RegisterDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), address.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), protocol.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "external_state_policy", external_state_policy);
    TFE_OpSetAttrString(op.get(), "element_spec", (void*) element_spec.c_str(), element_spec.size());
    TFE_OpSetAttrString(op.get(), "requested_dataset_id", (void*) requested_dataset_id.c_str(), requested_dataset_id.size());
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Relu
# Inputs:
*    features

# Attributes:
*    
# Outputs:
*    activations

*/
inline tensor relu(const tensor& features) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Relu", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), features.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Relu6
# Inputs:
*    features

# Attributes:
*    
# Outputs:
*    activations

*/
inline tensor relu6(const tensor& features) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Relu6", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), features.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Relu6Grad
# Inputs:
*    gradients
*    features

# Attributes:
*    
# Outputs:
*    backprops

*/
inline tensor relu6_grad(const tensor& gradients, const tensor& features) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Relu6Grad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), gradients.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), features.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ReluGrad
# Inputs:
*    gradients
*    features

# Attributes:
*    
# Outputs:
*    backprops

*/
inline tensor relu_grad(const tensor& gradients, const tensor& features) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReluGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), gradients.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), features.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RemoteCall
# Inputs:
*    target
*    args

# Attributes:
*    Tin
*    Tout
*    f

# Outputs:
*    output

*/
inline tensor remote_call(const tensor& target, const std::vector<tensor>&args, const std::vector<datatype>& Tin, const std::vector<datatype>& Tout, int64_t f) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RemoteCall", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), target.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> args_handles; args_handles.reserve(args.size());
    std::transform(args.begin(), args.end(), std::back_inserter(args_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), args_handles.data(), static_cast<int>(args.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Tin", reinterpret_cast<const enum TF_DataType *>(Tin.data()), static_cast<int>(Tin.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tout", reinterpret_cast<const enum TF_DataType *>(Tout.data()), static_cast<int>(Tout.size()));
    TFE_OpSetAttrInt(op.get(), "f", f);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RepeatDataset
# Inputs:
*    input_dataset
*    count

# Attributes:
*    output_types
*    output_shapes
*    metadata

# Outputs:
*    handle

*/
inline tensor repeat_dataset(const tensor& input_dataset, const tensor& count, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RepeatDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), count.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RequantizationRange
# Inputs:
*    input
*    input_min
*    input_max

# Attributes:
*    Tinput

# Outputs:
*    output_min
*    output_max

*/
inline std::vector<tensor> requantization_range(const tensor& input, const tensor& input_min, const tensor& input_max, datatype Tinput) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RequantizationRange", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_min.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # RequantizationRangePerChannel
# Inputs:
*    input
*    input_min
*    input_max

# Attributes:
*    clip_value_max

# Outputs:
*    output_min
*    output_max

*/
inline std::vector<tensor> requantization_range_per_channel(const tensor& input, const tensor& input_min, const tensor& input_max, float clip_value_max) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RequantizationRangePerChannel", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_min.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "clip_value_max", clip_value_max);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # Requantize
# Inputs:
*    input
*    input_min
*    input_max
*    requested_output_min
*    requested_output_max

# Attributes:
*    Tinput
*    out_type

# Outputs:
*    output
*    output_min
*    output_max

*/
inline std::vector<tensor> requantize(const tensor& input, const tensor& input_min, const tensor& input_max, const tensor& requested_output_min, const tensor& requested_output_max, datatype Tinput, datatype out_type) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Requantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_min.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), requested_output_min.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), requested_output_max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # RequantizePerChannel
# Inputs:
*    input
*    input_min
*    input_max
*    requested_output_min
*    requested_output_max

# Attributes:
*    out_type

# Outputs:
*    output
*    output_min
*    output_max

*/
inline std::vector<tensor> requantize_per_channel(const tensor& input, const tensor& input_min, const tensor& input_max, const tensor& requested_output_min, const tensor& requested_output_max, datatype out_type=static_cast<datatype>(12)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RequantizePerChannel", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_min.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), requested_output_min.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), requested_output_max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # Reshape
# Inputs:
*    tensor
*    shape

# Attributes:
*    Tshape

# Outputs:
*    output

*/
inline tensor reshape(const tensor& input_tensor, const tensor& shape, datatype Tshape=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Reshape", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tshape", Tshape);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ResizeArea
# Inputs:
*    images
*    size

# Attributes:
*    align_corners

# Outputs:
*    resized_images

*/
inline tensor resize_area(const tensor& images, const tensor& size, bool align_corners=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResizeArea", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "align_corners", (unsigned char)align_corners);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ResizeBicubic
# Inputs:
*    images
*    size

# Attributes:
*    align_corners
*    half_pixel_centers

# Outputs:
*    resized_images

*/
inline tensor resize_bicubic(const tensor& images, const tensor& size, bool align_corners=false, bool half_pixel_centers=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResizeBicubic", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "align_corners", (unsigned char)align_corners);
    TFE_OpSetAttrBool(op.get(), "half_pixel_centers", (unsigned char)half_pixel_centers);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ResizeBicubicGrad
# Inputs:
*    grads
*    original_image

# Attributes:
*    align_corners
*    half_pixel_centers

# Outputs:
*    output

*/
inline tensor resize_bicubic_grad(const tensor& grads, const tensor& original_image, bool align_corners=false, bool half_pixel_centers=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResizeBicubicGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), grads.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), original_image.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "align_corners", (unsigned char)align_corners);
    TFE_OpSetAttrBool(op.get(), "half_pixel_centers", (unsigned char)half_pixel_centers);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ResizeBilinear
# Inputs:
*    images
*    size

# Attributes:
*    align_corners
*    half_pixel_centers

# Outputs:
*    resized_images

*/
inline tensor resize_bilinear(const tensor& images, const tensor& size, bool align_corners=false, bool half_pixel_centers=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResizeBilinear", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "align_corners", (unsigned char)align_corners);
    TFE_OpSetAttrBool(op.get(), "half_pixel_centers", (unsigned char)half_pixel_centers);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ResizeBilinearGrad
# Inputs:
*    grads
*    original_image

# Attributes:
*    align_corners
*    half_pixel_centers

# Outputs:
*    output

*/
inline tensor resize_bilinear_grad(const tensor& grads, const tensor& original_image, bool align_corners=false, bool half_pixel_centers=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResizeBilinearGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), grads.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), original_image.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "align_corners", (unsigned char)align_corners);
    TFE_OpSetAttrBool(op.get(), "half_pixel_centers", (unsigned char)half_pixel_centers);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ResizeNearestNeighbor
# Inputs:
*    images
*    size

# Attributes:
*    align_corners
*    half_pixel_centers

# Outputs:
*    resized_images

*/
inline tensor resize_nearest_neighbor(const tensor& images, const tensor& size, bool align_corners=false, bool half_pixel_centers=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResizeNearestNeighbor", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "align_corners", (unsigned char)align_corners);
    TFE_OpSetAttrBool(op.get(), "half_pixel_centers", (unsigned char)half_pixel_centers);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ResizeNearestNeighborGrad
# Inputs:
*    grads
*    size

# Attributes:
*    align_corners
*    half_pixel_centers

# Outputs:
*    output

*/
inline tensor resize_nearest_neighbor_grad(const tensor& grads, const tensor& size, bool align_corners=false, bool half_pixel_centers=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResizeNearestNeighborGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), grads.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "align_corners", (unsigned char)align_corners);
    TFE_OpSetAttrBool(op.get(), "half_pixel_centers", (unsigned char)half_pixel_centers);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ResourceAccumulatorApplyGradient
# Inputs:
*    handle
*    local_step
*    gradient

# Attributes:
*    dtype

# Outputs:
*    
*/
inline void resource_accumulator_apply_gradient(const tensor& handle, const tensor& local_step, const tensor& gradient, datatype dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceAccumulatorApplyGradient", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), local_step.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceAccumulatorNumAccumulated
# Inputs:
*    handle

# Attributes:
*    
# Outputs:
*    num_accumulated

*/
inline tensor resource_accumulator_num_accumulated(const tensor& handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceAccumulatorNumAccumulated", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ResourceAccumulatorSetGlobalStep
# Inputs:
*    handle
*    new_global_step

# Attributes:
*    
# Outputs:
*    
*/
inline void resource_accumulator_set_global_step(const tensor& handle, const tensor& new_global_step) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceAccumulatorSetGlobalStep", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), new_global_step.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceAccumulatorTakeGradient
# Inputs:
*    handle
*    num_required

# Attributes:
*    dtype

# Outputs:
*    average

*/
inline tensor resource_accumulator_take_gradient(const tensor& handle, const tensor& num_required, datatype dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceAccumulatorTakeGradient", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_required.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ResourceApplyAdaMax
# Inputs:
*    var
*    m
*    v
*    beta1_power
*    lr
*    beta1
*    beta2
*    epsilon
*    grad

# Attributes:
*    use_locking

# Outputs:
*    
*/
inline void resource_apply_ada_max(const tensor& var, const tensor& m, const tensor& v, const tensor& beta1_power, const tensor& lr, const tensor& beta1, const tensor& beta2, const tensor& epsilon, const tensor& grad, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyAdaMax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta1_power.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceApplyAdadelta
# Inputs:
*    var
*    accum
*    accum_update
*    lr
*    rho
*    epsilon
*    grad

# Attributes:
*    use_locking

# Outputs:
*    
*/
inline void resource_apply_adadelta(const tensor& var, const tensor& accum, const tensor& accum_update, const tensor& lr, const tensor& rho, const tensor& epsilon, const tensor& grad, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyAdadelta", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum_update.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rho.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceApplyAdagrad
# Inputs:
*    var
*    accum
*    lr
*    grad

# Attributes:
*    use_locking
*    update_slots

# Outputs:
*    
*/
inline void resource_apply_adagrad(const tensor& var, const tensor& accum, const tensor& lr, const tensor& grad, bool use_locking=false, bool update_slots=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyAdagrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "update_slots", (unsigned char)update_slots);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceApplyAdagradDA
# Inputs:
*    var
*    gradient_accumulator
*    gradient_squared_accumulator
*    grad
*    lr
*    l1
*    l2
*    global_step

# Attributes:
*    use_locking

# Outputs:
*    
*/
inline void resource_apply_adagrad_d_a(const tensor& var, const tensor& gradient_accumulator, const tensor& gradient_squared_accumulator, const tensor& grad, const tensor& lr, const tensor& l1, const tensor& l2, const tensor& global_step, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyAdagradDA", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_accumulator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_squared_accumulator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), global_step.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceApplyAdagradV2
# Inputs:
*    var
*    accum
*    lr
*    epsilon
*    grad

# Attributes:
*    use_locking
*    update_slots

# Outputs:
*    
*/
inline void resource_apply_adagrad_v2(const tensor& var, const tensor& accum, const tensor& lr, const tensor& epsilon, const tensor& grad, bool use_locking=false, bool update_slots=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyAdagradV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "update_slots", (unsigned char)update_slots);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceApplyAdam
# Inputs:
*    var
*    m
*    v
*    beta1_power
*    beta2_power
*    lr
*    beta1
*    beta2
*    epsilon
*    grad

# Attributes:
*    use_locking
*    use_nesterov

# Outputs:
*    
*/
inline void resource_apply_adam(const tensor& var, const tensor& m, const tensor& v, const tensor& beta1_power, const tensor& beta2_power, const tensor& lr, const tensor& beta1, const tensor& beta2, const tensor& epsilon, const tensor& grad, bool use_locking=false, bool use_nesterov=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyAdam", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta1_power.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta2_power.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "use_nesterov", (unsigned char)use_nesterov);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceApplyAdamWithAmsgrad
# Inputs:
*    var
*    m
*    v
*    vhat
*    beta1_power
*    beta2_power
*    lr
*    beta1
*    beta2
*    epsilon
*    grad

# Attributes:
*    use_locking

# Outputs:
*    
*/
inline void resource_apply_adam_with_amsgrad(const tensor& var, const tensor& m, const tensor& v, const tensor& vhat, const tensor& beta1_power, const tensor& beta2_power, const tensor& lr, const tensor& beta1, const tensor& beta2, const tensor& epsilon, const tensor& grad, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyAdamWithAmsgrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), vhat.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta1_power.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta2_power.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceApplyAddSign
# Inputs:
*    var
*    m
*    lr
*    alpha
*    sign_decay
*    beta
*    grad

# Attributes:
*    use_locking

# Outputs:
*    
*/
inline void resource_apply_add_sign(const tensor& var, const tensor& m, const tensor& lr, const tensor& alpha, const tensor& sign_decay, const tensor& beta, const tensor& grad, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyAddSign", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alpha.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sign_decay.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceApplyCenteredRMSProp
# Inputs:
*    var
*    mg
*    ms
*    mom
*    lr
*    rho
*    momentum
*    epsilon
*    grad

# Attributes:
*    use_locking

# Outputs:
*    
*/
inline void resource_apply_centered_r_m_s_prop(const tensor& var, const tensor& mg, const tensor& ms, const tensor& mom, const tensor& lr, const tensor& rho, const tensor& momentum, const tensor& epsilon, const tensor& grad, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyCenteredRMSProp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mg.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ms.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mom.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rho.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceApplyFtrl
# Inputs:
*    var
*    accum
*    linear
*    grad
*    lr
*    l1
*    l2
*    lr_power

# Attributes:
*    use_locking
*    multiply_linear_by_lr

# Outputs:
*    
*/
inline void resource_apply_ftrl(const tensor& var, const tensor& accum, const tensor& linear, const tensor& grad, const tensor& lr, const tensor& l1, const tensor& l2, const tensor& lr_power, bool use_locking=false, bool multiply_linear_by_lr=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyFtrl", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), linear.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr_power.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "multiply_linear_by_lr", (unsigned char)multiply_linear_by_lr);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceApplyFtrlV2
# Inputs:
*    var
*    accum
*    linear
*    grad
*    lr
*    l1
*    l2
*    l2_shrinkage
*    lr_power

# Attributes:
*    use_locking
*    multiply_linear_by_lr

# Outputs:
*    
*/
inline void resource_apply_ftrl_v2(const tensor& var, const tensor& accum, const tensor& linear, const tensor& grad, const tensor& lr, const tensor& l1, const tensor& l2, const tensor& l2_shrinkage, const tensor& lr_power, bool use_locking=false, bool multiply_linear_by_lr=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyFtrlV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), linear.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2_shrinkage.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr_power.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "multiply_linear_by_lr", (unsigned char)multiply_linear_by_lr);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceApplyGradientDescent
# Inputs:
*    var
*    alpha
*    delta

# Attributes:
*    use_locking

# Outputs:
*    
*/
inline void resource_apply_gradient_descent(const tensor& var, const tensor& alpha, const tensor& delta, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyGradientDescent", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alpha.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), delta.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceApplyKerasMomentum
# Inputs:
*    var
*    accum
*    lr
*    grad
*    momentum

# Attributes:
*    use_locking
*    use_nesterov

# Outputs:
*    
*/
inline void resource_apply_keras_momentum(const tensor& var, const tensor& accum, const tensor& lr, const tensor& grad, const tensor& momentum, bool use_locking=false, bool use_nesterov=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyKerasMomentum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "use_nesterov", (unsigned char)use_nesterov);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceApplyMomentum
# Inputs:
*    var
*    accum
*    lr
*    grad
*    momentum

# Attributes:
*    use_locking
*    use_nesterov

# Outputs:
*    
*/
inline void resource_apply_momentum(const tensor& var, const tensor& accum, const tensor& lr, const tensor& grad, const tensor& momentum, bool use_locking=false, bool use_nesterov=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyMomentum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "use_nesterov", (unsigned char)use_nesterov);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceApplyPowerSign
# Inputs:
*    var
*    m
*    lr
*    logbase
*    sign_decay
*    beta
*    grad

# Attributes:
*    use_locking

# Outputs:
*    
*/
inline void resource_apply_power_sign(const tensor& var, const tensor& m, const tensor& lr, const tensor& logbase, const tensor& sign_decay, const tensor& beta, const tensor& grad, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyPowerSign", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), logbase.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sign_decay.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceApplyProximalAdagrad
# Inputs:
*    var
*    accum
*    lr
*    l1
*    l2
*    grad

# Attributes:
*    use_locking

# Outputs:
*    
*/
inline void resource_apply_proximal_adagrad(const tensor& var, const tensor& accum, const tensor& lr, const tensor& l1, const tensor& l2, const tensor& grad, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyProximalAdagrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceApplyProximalGradientDescent
# Inputs:
*    var
*    alpha
*    l1
*    l2
*    delta

# Attributes:
*    use_locking

# Outputs:
*    
*/
inline void resource_apply_proximal_gradient_descent(const tensor& var, const tensor& alpha, const tensor& l1, const tensor& l2, const tensor& delta, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyProximalGradientDescent", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alpha.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), delta.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceApplyRMSProp
# Inputs:
*    var
*    ms
*    mom
*    lr
*    rho
*    momentum
*    epsilon
*    grad

# Attributes:
*    use_locking

# Outputs:
*    
*/
inline void resource_apply_r_m_s_prop(const tensor& var, const tensor& ms, const tensor& mom, const tensor& lr, const tensor& rho, const tensor& momentum, const tensor& epsilon, const tensor& grad, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyRMSProp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ms.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mom.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rho.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceConditionalAccumulator
# Inputs:
*    
# Attributes:
*    dtype
*    shape
*    container
*    shared_name
*    reduction_type

# Outputs:
*    handle

*/
inline tensor resource_conditional_accumulator(datatype dtype, const std::vector<int64_t>& shape, const std::string& container="", const std::string& shared_name="", const std::string& reduction_type="MEAN") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceConditionalAccumulator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), static_cast<int>(shape.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrString(op.get(), "reduction_type", (void*) reduction_type.c_str(), reduction_type.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ResourceCountUpTo
# Inputs:
*    resource

# Attributes:
*    limit

# Outputs:
*    output

*/
inline tensor resource_count_up_to(const tensor& resource, int64_t limit) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceCountUpTo", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "limit", limit);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ResourceGather
# Inputs:
*    resource
*    indices

# Attributes:
*    dtype
*    Tindices
*    batch_dims
*    validate_indices

# Outputs:
*    output

*/
inline tensor resource_gather(const tensor& resource, const tensor& indices, datatype dtype, datatype Tindices, int64_t batch_dims=0, bool validate_indices=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceGather", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrInt(op.get(), "batch_dims", batch_dims);
    TFE_OpSetAttrBool(op.get(), "validate_indices", (unsigned char)validate_indices);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ResourceGatherNd
# Inputs:
*    resource
*    indices

# Attributes:
*    dtype
*    Tindices

# Outputs:
*    output

*/
inline tensor resource_gather_nd(const tensor& resource, const tensor& indices, datatype dtype, datatype Tindices) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceGatherNd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ResourceScatterAdd
# Inputs:
*    resource
*    indices
*    updates

# Attributes:
*    dtype
*    Tindices

# Outputs:
*    
*/
inline void resource_scatter_add(const tensor& resource, const tensor& indices, const tensor& updates, datatype dtype, datatype Tindices) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceScatterAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceScatterDiv
# Inputs:
*    resource
*    indices
*    updates

# Attributes:
*    dtype
*    Tindices

# Outputs:
*    
*/
inline void resource_scatter_div(const tensor& resource, const tensor& indices, const tensor& updates, datatype dtype, datatype Tindices) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceScatterDiv", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceScatterMax
# Inputs:
*    resource
*    indices
*    updates

# Attributes:
*    dtype
*    Tindices

# Outputs:
*    
*/
inline void resource_scatter_max(const tensor& resource, const tensor& indices, const tensor& updates, datatype dtype, datatype Tindices) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceScatterMax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceScatterMin
# Inputs:
*    resource
*    indices
*    updates

# Attributes:
*    dtype
*    Tindices

# Outputs:
*    
*/
inline void resource_scatter_min(const tensor& resource, const tensor& indices, const tensor& updates, datatype dtype, datatype Tindices) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceScatterMin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceScatterMul
# Inputs:
*    resource
*    indices
*    updates

# Attributes:
*    dtype
*    Tindices

# Outputs:
*    
*/
inline void resource_scatter_mul(const tensor& resource, const tensor& indices, const tensor& updates, datatype dtype, datatype Tindices) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceScatterMul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceScatterNdAdd
# Inputs:
*    ref
*    indices
*    updates

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    
*/
inline void resource_scatter_nd_add(const tensor& ref, const tensor& indices, const tensor& updates, datatype Tindices, bool use_locking=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceScatterNdAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceScatterNdMax
# Inputs:
*    ref
*    indices
*    updates

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    
*/
inline void resource_scatter_nd_max(const tensor& ref, const tensor& indices, const tensor& updates, datatype Tindices, bool use_locking=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceScatterNdMax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceScatterNdMin
# Inputs:
*    ref
*    indices
*    updates

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    
*/
inline void resource_scatter_nd_min(const tensor& ref, const tensor& indices, const tensor& updates, datatype Tindices, bool use_locking=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceScatterNdMin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceScatterNdSub
# Inputs:
*    ref
*    indices
*    updates

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    
*/
inline void resource_scatter_nd_sub(const tensor& ref, const tensor& indices, const tensor& updates, datatype Tindices, bool use_locking=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceScatterNdSub", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceScatterNdUpdate
# Inputs:
*    ref
*    indices
*    updates

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    
*/
inline void resource_scatter_nd_update(const tensor& ref, const tensor& indices, const tensor& updates, datatype Tindices, bool use_locking=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceScatterNdUpdate", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceScatterSub
# Inputs:
*    resource
*    indices
*    updates

# Attributes:
*    dtype
*    Tindices

# Outputs:
*    
*/
inline void resource_scatter_sub(const tensor& resource, const tensor& indices, const tensor& updates, datatype dtype, datatype Tindices) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceScatterSub", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceScatterUpdate
# Inputs:
*    resource
*    indices
*    updates

# Attributes:
*    dtype
*    Tindices

# Outputs:
*    
*/
inline void resource_scatter_update(const tensor& resource, const tensor& indices, const tensor& updates, datatype dtype, datatype Tindices) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceScatterUpdate", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceSparseApplyAdadelta
# Inputs:
*    var
*    accum
*    accum_update
*    lr
*    rho
*    epsilon
*    grad
*    indices

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    
*/
inline void resource_sparse_apply_adadelta(const tensor& var, const tensor& accum, const tensor& accum_update, const tensor& lr, const tensor& rho, const tensor& epsilon, const tensor& grad, const tensor& indices, datatype Tindices, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceSparseApplyAdadelta", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum_update.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rho.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceSparseApplyAdagrad
# Inputs:
*    var
*    accum
*    lr
*    grad
*    indices

# Attributes:
*    Tindices
*    use_locking
*    update_slots

# Outputs:
*    
*/
inline void resource_sparse_apply_adagrad(const tensor& var, const tensor& accum, const tensor& lr, const tensor& grad, const tensor& indices, datatype Tindices, bool use_locking=false, bool update_slots=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceSparseApplyAdagrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "update_slots", (unsigned char)update_slots);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceSparseApplyAdagradDA
# Inputs:
*    var
*    gradient_accumulator
*    gradient_squared_accumulator
*    grad
*    indices
*    lr
*    l1
*    l2
*    global_step

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    
*/
inline void resource_sparse_apply_adagrad_d_a(const tensor& var, const tensor& gradient_accumulator, const tensor& gradient_squared_accumulator, const tensor& grad, const tensor& indices, const tensor& lr, const tensor& l1, const tensor& l2, const tensor& global_step, datatype Tindices, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceSparseApplyAdagradDA", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_accumulator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_squared_accumulator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), global_step.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceSparseApplyAdagradV2
# Inputs:
*    var
*    accum
*    lr
*    epsilon
*    grad
*    indices

# Attributes:
*    Tindices
*    use_locking
*    update_slots

# Outputs:
*    
*/
inline void resource_sparse_apply_adagrad_v2(const tensor& var, const tensor& accum, const tensor& lr, const tensor& epsilon, const tensor& grad, const tensor& indices, datatype Tindices, bool use_locking=false, bool update_slots=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceSparseApplyAdagradV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "update_slots", (unsigned char)update_slots);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceSparseApplyCenteredRMSProp
# Inputs:
*    var
*    mg
*    ms
*    mom
*    lr
*    rho
*    momentum
*    epsilon
*    grad
*    indices

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    
*/
inline void resource_sparse_apply_centered_r_m_s_prop(const tensor& var, const tensor& mg, const tensor& ms, const tensor& mom, const tensor& lr, const tensor& rho, const tensor& momentum, const tensor& epsilon, const tensor& grad, const tensor& indices, datatype Tindices, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceSparseApplyCenteredRMSProp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mg.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ms.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mom.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rho.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceSparseApplyFtrl
# Inputs:
*    var
*    accum
*    linear
*    grad
*    indices
*    lr
*    l1
*    l2
*    lr_power

# Attributes:
*    Tindices
*    use_locking
*    multiply_linear_by_lr

# Outputs:
*    
*/
inline void resource_sparse_apply_ftrl(const tensor& var, const tensor& accum, const tensor& linear, const tensor& grad, const tensor& indices, const tensor& lr, const tensor& l1, const tensor& l2, const tensor& lr_power, datatype Tindices, bool use_locking=false, bool multiply_linear_by_lr=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceSparseApplyFtrl", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), linear.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr_power.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "multiply_linear_by_lr", (unsigned char)multiply_linear_by_lr);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceSparseApplyFtrlV2
# Inputs:
*    var
*    accum
*    linear
*    grad
*    indices
*    lr
*    l1
*    l2
*    l2_shrinkage
*    lr_power

# Attributes:
*    Tindices
*    use_locking
*    multiply_linear_by_lr

# Outputs:
*    
*/
inline void resource_sparse_apply_ftrl_v2(const tensor& var, const tensor& accum, const tensor& linear, const tensor& grad, const tensor& indices, const tensor& lr, const tensor& l1, const tensor& l2, const tensor& l2_shrinkage, const tensor& lr_power, datatype Tindices, bool use_locking=false, bool multiply_linear_by_lr=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceSparseApplyFtrlV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), linear.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2_shrinkage.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr_power.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "multiply_linear_by_lr", (unsigned char)multiply_linear_by_lr);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceSparseApplyKerasMomentum
# Inputs:
*    var
*    accum
*    lr
*    grad
*    indices
*    momentum

# Attributes:
*    Tindices
*    use_locking
*    use_nesterov

# Outputs:
*    
*/
inline void resource_sparse_apply_keras_momentum(const tensor& var, const tensor& accum, const tensor& lr, const tensor& grad, const tensor& indices, const tensor& momentum, datatype Tindices, bool use_locking=false, bool use_nesterov=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceSparseApplyKerasMomentum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "use_nesterov", (unsigned char)use_nesterov);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceSparseApplyMomentum
# Inputs:
*    var
*    accum
*    lr
*    grad
*    indices
*    momentum

# Attributes:
*    Tindices
*    use_locking
*    use_nesterov

# Outputs:
*    
*/
inline void resource_sparse_apply_momentum(const tensor& var, const tensor& accum, const tensor& lr, const tensor& grad, const tensor& indices, const tensor& momentum, datatype Tindices, bool use_locking=false, bool use_nesterov=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceSparseApplyMomentum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "use_nesterov", (unsigned char)use_nesterov);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceSparseApplyProximalAdagrad
# Inputs:
*    var
*    accum
*    lr
*    l1
*    l2
*    grad
*    indices

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    
*/
inline void resource_sparse_apply_proximal_adagrad(const tensor& var, const tensor& accum, const tensor& lr, const tensor& l1, const tensor& l2, const tensor& grad, const tensor& indices, datatype Tindices, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceSparseApplyProximalAdagrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceSparseApplyProximalGradientDescent
# Inputs:
*    var
*    alpha
*    l1
*    l2
*    grad
*    indices

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    
*/
inline void resource_sparse_apply_proximal_gradient_descent(const tensor& var, const tensor& alpha, const tensor& l1, const tensor& l2, const tensor& grad, const tensor& indices, datatype Tindices, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceSparseApplyProximalGradientDescent", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alpha.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceSparseApplyRMSProp
# Inputs:
*    var
*    ms
*    mom
*    lr
*    rho
*    momentum
*    epsilon
*    grad
*    indices

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    
*/
inline void resource_sparse_apply_r_m_s_prop(const tensor& var, const tensor& ms, const tensor& mom, const tensor& lr, const tensor& rho, const tensor& momentum, const tensor& epsilon, const tensor& grad, const tensor& indices, datatype Tindices, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceSparseApplyRMSProp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ms.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mom.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rho.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ResourceStridedSliceAssign
# Inputs:
*    ref
*    begin
*    end
*    strides
*    value

# Attributes:
*    Index
*    begin_mask
*    end_mask
*    ellipsis_mask
*    new_axis_mask
*    shrink_axis_mask

# Outputs:
*    
*/
inline void resource_strided_slice_assign(const tensor& ref, const tensor& begin, const tensor& end, const tensor& strides, const tensor& value, datatype Index, int64_t begin_mask=0, int64_t end_mask=0, int64_t ellipsis_mask=0, int64_t new_axis_mask=0, int64_t shrink_axis_mask=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceStridedSliceAssign", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), begin.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), end.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), strides.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Index", Index);
    TFE_OpSetAttrInt(op.get(), "begin_mask", begin_mask);
    TFE_OpSetAttrInt(op.get(), "end_mask", end_mask);
    TFE_OpSetAttrInt(op.get(), "ellipsis_mask", ellipsis_mask);
    TFE_OpSetAttrInt(op.get(), "new_axis_mask", new_axis_mask);
    TFE_OpSetAttrInt(op.get(), "shrink_axis_mask", shrink_axis_mask);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # Restore
# Inputs:
*    file_pattern
*    tensor_name

# Attributes:
*    dt
*    preferred_shard

# Outputs:
*    tensor

*/
inline tensor restore(const tensor& file_pattern, const tensor& input_tensor_name, datatype dt, int64_t preferred_shard=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Restore", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), file_pattern.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor_name.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dt", dt);
    TFE_OpSetAttrInt(op.get(), "preferred_shard", preferred_shard);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RestoreSlice
# Inputs:
*    file_pattern
*    tensor_name
*    shape_and_slice

# Attributes:
*    dt
*    preferred_shard

# Outputs:
*    tensor

*/
inline tensor restore_slice(const tensor& file_pattern, const tensor& input_tensor_name, const tensor& shape_and_slice, datatype dt, int64_t preferred_shard=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RestoreSlice", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), file_pattern.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor_name.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape_and_slice.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dt", dt);
    TFE_OpSetAttrInt(op.get(), "preferred_shard", preferred_shard);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RestoreV2
# Inputs:
*    prefix
*    tensor_names
*    shape_and_slices

# Attributes:
*    dtypes

# Outputs:
*    tensors

*/
inline tensor restore_v2(const tensor& prefix, const tensor& input_tensor_names, const tensor& shape_and_slices, const std::vector<datatype>& dtypes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RestoreV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), prefix.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor_names.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape_and_slices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RetrieveTPUEmbeddingADAMParameters
# Inputs:
*    
# Attributes:
*    num_shards
*    shard_id
*    table_id
*    table_name
*    config

# Outputs:
*    parameters
*    momenta
*    velocities

*/
inline std::vector<tensor> retrieve_t_p_u_embedding_a_d_a_m_parameters(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingADAMParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # RetrieveTPUEmbeddingAdadeltaParameters
# Inputs:
*    
# Attributes:
*    num_shards
*    shard_id
*    table_id
*    table_name
*    config

# Outputs:
*    parameters
*    accumulators
*    updates

*/
inline std::vector<tensor> retrieve_t_p_u_embedding_adadelta_parameters(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingAdadeltaParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # RetrieveTPUEmbeddingAdagradMomentumParameters
# Inputs:
*    
# Attributes:
*    num_shards
*    shard_id
*    table_id
*    table_name
*    config

# Outputs:
*    parameters
*    accumulators
*    momenta

*/
inline std::vector<tensor> retrieve_t_p_u_embedding_adagrad_momentum_parameters(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingAdagradMomentumParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # RetrieveTPUEmbeddingAdagradParameters
# Inputs:
*    
# Attributes:
*    num_shards
*    shard_id
*    table_id
*    table_name
*    config

# Outputs:
*    parameters
*    accumulators

*/
inline std::vector<tensor> retrieve_t_p_u_embedding_adagrad_parameters(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingAdagradParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # RetrieveTPUEmbeddingCenteredRMSPropParameters
# Inputs:
*    
# Attributes:
*    num_shards
*    shard_id
*    table_id
*    table_name
*    config

# Outputs:
*    parameters
*    ms
*    mom
*    mg

*/
inline std::vector<tensor> retrieve_t_p_u_embedding_centered_r_m_s_prop_parameters(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingCenteredRMSPropParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 4;
    TFE_TensorHandle* res[4] = { nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]), };
}

/* # RetrieveTPUEmbeddingFTRLParameters
# Inputs:
*    
# Attributes:
*    num_shards
*    shard_id
*    table_id
*    table_name
*    config

# Outputs:
*    parameters
*    accumulators
*    linears

*/
inline std::vector<tensor> retrieve_t_p_u_embedding_f_t_r_l_parameters(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingFTRLParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # RetrieveTPUEmbeddingFrequencyEstimatorParameters
# Inputs:
*    
# Attributes:
*    num_shards
*    shard_id
*    table_id
*    table_name
*    config

# Outputs:
*    parameters
*    last_hit_step

*/
inline std::vector<tensor> retrieve_t_p_u_embedding_frequency_estimator_parameters(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingFrequencyEstimatorParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # RetrieveTPUEmbeddingMDLAdagradLightParameters
# Inputs:
*    
# Attributes:
*    num_shards
*    shard_id
*    table_id
*    table_name
*    config

# Outputs:
*    parameters
*    accumulators
*    weights
*    benefits

*/
inline std::vector<tensor> retrieve_t_p_u_embedding_m_d_l_adagrad_light_parameters(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingMDLAdagradLightParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 4;
    TFE_TensorHandle* res[4] = { nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]), };
}

/* # RetrieveTPUEmbeddingMomentumParameters
# Inputs:
*    
# Attributes:
*    num_shards
*    shard_id
*    table_id
*    table_name
*    config

# Outputs:
*    parameters
*    momenta

*/
inline std::vector<tensor> retrieve_t_p_u_embedding_momentum_parameters(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingMomentumParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # RetrieveTPUEmbeddingProximalAdagradParameters
# Inputs:
*    
# Attributes:
*    num_shards
*    shard_id
*    table_id
*    table_name
*    config

# Outputs:
*    parameters
*    accumulators

*/
inline std::vector<tensor> retrieve_t_p_u_embedding_proximal_adagrad_parameters(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingProximalAdagradParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # RetrieveTPUEmbeddingProximalYogiParameters
# Inputs:
*    
# Attributes:
*    num_shards
*    shard_id
*    table_id
*    table_name
*    config

# Outputs:
*    parameters
*    v
*    m

*/
inline std::vector<tensor> retrieve_t_p_u_embedding_proximal_yogi_parameters(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingProximalYogiParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # RetrieveTPUEmbeddingRMSPropParameters
# Inputs:
*    
# Attributes:
*    num_shards
*    shard_id
*    table_id
*    table_name
*    config

# Outputs:
*    parameters
*    ms
*    mom

*/
inline std::vector<tensor> retrieve_t_p_u_embedding_r_m_s_prop_parameters(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingRMSPropParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # RetrieveTPUEmbeddingStochasticGradientDescentParameters
# Inputs:
*    
# Attributes:
*    num_shards
*    shard_id
*    table_id
*    table_name
*    config

# Outputs:
*    parameters

*/
inline tensor retrieve_t_p_u_embedding_stochastic_gradient_descent_parameters(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingStochasticGradientDescentParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Reverse
# Inputs:
*    tensor
*    dims

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor reverse(const tensor& input_tensor, const tensor& dims) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Reverse", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dims.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ReverseSequence
# Inputs:
*    input
*    seq_lengths

# Attributes:
*    seq_dim
*    batch_dim
*    Tlen

# Outputs:
*    output

*/
inline tensor reverse_sequence(const tensor& input, const tensor& seq_lengths, int64_t seq_dim, int64_t batch_dim=0, datatype Tlen=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReverseSequence", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seq_lengths.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "seq_dim", seq_dim);
    TFE_OpSetAttrInt(op.get(), "batch_dim", batch_dim);
    TFE_OpSetAttrType(op.get(), "Tlen", Tlen);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ReverseV2
# Inputs:
*    tensor
*    axis

# Attributes:
*    Tidx

# Outputs:
*    output

*/
inline tensor reverse_v2(const tensor& input_tensor, const tensor& axis, datatype Tidx=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReverseV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), axis.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RewriteDataset
# Inputs:
*    input_dataset
*    rewrite_name

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor rewrite_dataset(const tensor& input_dataset, const tensor& rewrite_name, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RewriteDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rewrite_name.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RightShift
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor right_shift(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RightShift", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Rint
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor rint(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Rint", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RngReadAndSkip
# Inputs:
*    resource
*    alg
*    delta

# Attributes:
*    
# Outputs:
*    value

*/
inline tensor rng_read_and_skip(const tensor& resource, const tensor& alg, const tensor& delta) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RngReadAndSkip", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alg.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), delta.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RngSkip
# Inputs:
*    resource
*    algorithm
*    delta

# Attributes:
*    
# Outputs:
*    
*/
inline void rng_skip(const tensor& resource, const tensor& algorithm, const tensor& delta) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RngSkip", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), algorithm.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), delta.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # Roll
# Inputs:
*    input
*    shift
*    axis

# Attributes:
*    Tshift
*    Taxis

# Outputs:
*    output

*/
inline tensor roll(const tensor& input, const tensor& shift, const tensor& axis, datatype Tshift, datatype Taxis) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Roll", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shift.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), axis.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tshift", Tshift);
    TFE_OpSetAttrType(op.get(), "Taxis", Taxis);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Round
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor round(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Round", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Rsqrt
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor rsqrt(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Rsqrt", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # RsqrtGrad
# Inputs:
*    y
*    dy

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor rsqrt_grad(const tensor& y, const tensor& dy) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RsqrtGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dy.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SampleDistortedBoundingBox
# Inputs:
*    image_size
*    bounding_boxes

# Attributes:
*    aspect_ratio_range
*    area_range
*    seed
*    seed2
*    min_object_covered
*    max_attempts
*    use_image_if_no_bounding_boxes

# Outputs:
*    begin
*    size
*    bboxes

*/
inline std::vector<tensor> sample_distorted_bounding_box(const tensor& image_size, const tensor& bounding_boxes, const std::vector<float>& aspect_ratio_range, const std::vector<float>& area_range, int64_t seed=0, int64_t seed2=0, float min_object_covered=1.0000e-01, int64_t max_attempts=100, bool use_image_if_no_bounding_boxes=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SampleDistortedBoundingBox", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), image_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bounding_boxes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloatList(op.get(), "aspect_ratio_range", aspect_ratio_range.data(), static_cast<int>(aspect_ratio_range.size()));
    TFE_OpSetAttrFloatList(op.get(), "area_range", area_range.data(), static_cast<int>(area_range.size()));
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrFloat(op.get(), "min_object_covered", min_object_covered);
    TFE_OpSetAttrInt(op.get(), "max_attempts", max_attempts);
    TFE_OpSetAttrBool(op.get(), "use_image_if_no_bounding_boxes", (unsigned char)use_image_if_no_bounding_boxes);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # SampleDistortedBoundingBoxV2
# Inputs:
*    image_size
*    bounding_boxes
*    min_object_covered

# Attributes:
*    aspect_ratio_range
*    area_range
*    seed
*    seed2
*    max_attempts
*    use_image_if_no_bounding_boxes

# Outputs:
*    begin
*    size
*    bboxes

*/
inline std::vector<tensor> sample_distorted_bounding_box_v2(const tensor& image_size, const tensor& bounding_boxes, const tensor& min_object_covered, const std::vector<float>& aspect_ratio_range, const std::vector<float>& area_range, int64_t seed=0, int64_t seed2=0, int64_t max_attempts=100, bool use_image_if_no_bounding_boxes=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SampleDistortedBoundingBoxV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), image_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bounding_boxes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_object_covered.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloatList(op.get(), "aspect_ratio_range", aspect_ratio_range.data(), static_cast<int>(aspect_ratio_range.size()));
    TFE_OpSetAttrFloatList(op.get(), "area_range", area_range.data(), static_cast<int>(area_range.size()));
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrInt(op.get(), "max_attempts", max_attempts);
    TFE_OpSetAttrBool(op.get(), "use_image_if_no_bounding_boxes", (unsigned char)use_image_if_no_bounding_boxes);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # SamplingDataset
# Inputs:
*    input_dataset
*    rate
*    seed
*    seed2

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor sampling_dataset(const tensor& input_dataset, const tensor& rate, const tensor& seed, const tensor& seed2, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SamplingDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rate.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Save
# Inputs:
*    filename
*    tensor_names
*    data

# Attributes:
*    
# Outputs:
*    
*/
inline void save(const tensor& filename, const tensor& input_tensor_names, const std::vector<tensor>&data) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Save", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filename.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor_names.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> data_handles; data_handles.reserve(data.size());
    std::transform(data.begin(), data.end(), std::back_inserter(data_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), data_handles.data(), static_cast<int>(data.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # SaveDataset
# Inputs:
*    input_dataset
*    path
*    shard_func_other_args

# Attributes:
*    shard_func
*    Tshard_func_args
*    compression
*    use_shard_func

# Outputs:
*    
*/
inline void save_dataset(const tensor& input_dataset, const tensor& path, const std::vector<tensor>&shard_func_other_args, int64_t shard_func, const std::vector<datatype>& Tshard_func_args, const std::string& compression="", bool use_shard_func=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SaveDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), path.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> shard_func_other_args_handles; shard_func_other_args_handles.reserve(shard_func_other_args.size());
    std::transform(shard_func_other_args.begin(), shard_func_other_args.end(), std::back_inserter(shard_func_other_args_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), shard_func_other_args_handles.data(), static_cast<int>(shard_func_other_args.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "shard_func", shard_func);
    TFE_OpSetAttrTypeList(op.get(), "Tshard_func_args", reinterpret_cast<const enum TF_DataType *>(Tshard_func_args.data()), static_cast<int>(Tshard_func_args.size()));
    TFE_OpSetAttrString(op.get(), "compression", (void*) compression.c_str(), compression.size());
    TFE_OpSetAttrBool(op.get(), "use_shard_func", (unsigned char)use_shard_func);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # SaveDatasetV2
# Inputs:
*    input_dataset
*    path
*    shard_func_other_args

# Attributes:
*    shard_func
*    Tshard_func_args
*    output_types
*    output_shapes
*    compression
*    use_shard_func

# Outputs:
*    handle

*/
inline tensor save_dataset_v2(const tensor& input_dataset, const tensor& path, const std::vector<tensor>&shard_func_other_args, int64_t shard_func, const std::vector<datatype>& Tshard_func_args, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& compression="", bool use_shard_func=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SaveDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), path.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> shard_func_other_args_handles; shard_func_other_args_handles.reserve(shard_func_other_args.size());
    std::transform(shard_func_other_args.begin(), shard_func_other_args.end(), std::back_inserter(shard_func_other_args_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), shard_func_other_args_handles.data(), static_cast<int>(shard_func_other_args.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "shard_func", shard_func);
    TFE_OpSetAttrTypeList(op.get(), "Tshard_func_args", reinterpret_cast<const enum TF_DataType *>(Tshard_func_args.data()), static_cast<int>(Tshard_func_args.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "compression", (void*) compression.c_str(), compression.size());
    TFE_OpSetAttrBool(op.get(), "use_shard_func", (unsigned char)use_shard_func);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SaveSlices
# Inputs:
*    filename
*    tensor_names
*    shapes_and_slices
*    data

# Attributes:
*    
# Outputs:
*    
*/
inline void save_slices(const tensor& filename, const tensor& input_tensor_names, const tensor& shapes_and_slices, const std::vector<tensor>&data) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SaveSlices", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filename.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor_names.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shapes_and_slices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> data_handles; data_handles.reserve(data.size());
    std::transform(data.begin(), data.end(), std::back_inserter(data_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), data_handles.data(), static_cast<int>(data.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # SaveV2
# Inputs:
*    prefix
*    tensor_names
*    shape_and_slices
*    tensors

# Attributes:
*    dtypes

# Outputs:
*    
*/
inline void save_v2(const tensor& prefix, const tensor& input_tensor_names, const tensor& shape_and_slices, const std::vector<tensor>&tensors, const std::vector<datatype>& dtypes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SaveV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), prefix.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor_names.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape_and_slices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> tensors_handles; tensors_handles.reserve(tensors.size());
    std::transform(tensors.begin(), tensors.end(), std::back_inserter(tensors_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), tensors_handles.data(), static_cast<int>(tensors.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # ScalarSummary
# Inputs:
*    tags
*    values

# Attributes:
*    
# Outputs:
*    summary

*/
inline tensor scalar_summary(const tensor& tags, const tensor& values) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScalarSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tags.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ScaleAndTranslate
# Inputs:
*    images
*    size
*    scale
*    translation

# Attributes:
*    kernel_type
*    antialias

# Outputs:
*    resized_images

*/
inline tensor scale_and_translate(const tensor& images, const tensor& size, const tensor& scale, const tensor& translation, const std::string& kernel_type="lanczos3", bool antialias=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScaleAndTranslate", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scale.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), translation.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "kernel_type", (void*) kernel_type.c_str(), kernel_type.size());
    TFE_OpSetAttrBool(op.get(), "antialias", (unsigned char)antialias);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ScaleAndTranslateGrad
# Inputs:
*    grads
*    original_image
*    scale
*    translation

# Attributes:
*    kernel_type
*    antialias

# Outputs:
*    output

*/
inline tensor scale_and_translate_grad(const tensor& grads, const tensor& original_image, const tensor& scale, const tensor& translation, const std::string& kernel_type="lanczos3", bool antialias=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScaleAndTranslateGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), grads.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), original_image.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scale.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), translation.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "kernel_type", (void*) kernel_type.c_str(), kernel_type.size());
    TFE_OpSetAttrBool(op.get(), "antialias", (unsigned char)antialias);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ScanDataset
# Inputs:
*    input_dataset
*    initial_state
*    other_arguments

# Attributes:
*    f
*    Tstate
*    Targuments
*    output_types
*    output_shapes
*    preserve_cardinality
*    use_default_device
*    metadata

# Outputs:
*    handle

*/
inline tensor scan_dataset(const tensor& input_dataset, const std::vector<tensor>&initial_state, const std::vector<tensor>&other_arguments, int64_t f, const std::vector<datatype>& Tstate, const std::vector<datatype>& Targuments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool preserve_cardinality=false, bool use_default_device=true, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScanDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> initial_state_handles; initial_state_handles.reserve(initial_state.size());
    std::transform(initial_state.begin(), initial_state.end(), std::back_inserter(initial_state_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), initial_state_handles.data(), static_cast<int>(initial_state.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> other_arguments_handles; other_arguments_handles.reserve(other_arguments.size());
    std::transform(other_arguments.begin(), other_arguments.end(), std::back_inserter(other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), other_arguments_handles.data(), static_cast<int>(other_arguments.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "f", f);
    TFE_OpSetAttrTypeList(op.get(), "Tstate", reinterpret_cast<const enum TF_DataType *>(Tstate.data()), static_cast<int>(Tstate.size()));
    TFE_OpSetAttrTypeList(op.get(), "Targuments", reinterpret_cast<const enum TF_DataType *>(Targuments.data()), static_cast<int>(Targuments.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "preserve_cardinality", (unsigned char)preserve_cardinality);
    TFE_OpSetAttrBool(op.get(), "use_default_device", (unsigned char)use_default_device);
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ScatterAdd
# Inputs:
*    ref
*    indices
*    updates

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    output_ref

*/
inline tensor scatter_add(const tensor& ref, const tensor& indices, const tensor& updates, datatype Tindices, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ScatterDiv
# Inputs:
*    ref
*    indices
*    updates

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    output_ref

*/
inline tensor scatter_div(const tensor& ref, const tensor& indices, const tensor& updates, datatype Tindices, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterDiv", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ScatterMax
# Inputs:
*    ref
*    indices
*    updates

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    output_ref

*/
inline tensor scatter_max(const tensor& ref, const tensor& indices, const tensor& updates, datatype Tindices, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterMax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ScatterMin
# Inputs:
*    ref
*    indices
*    updates

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    output_ref

*/
inline tensor scatter_min(const tensor& ref, const tensor& indices, const tensor& updates, datatype Tindices, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterMin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ScatterMul
# Inputs:
*    ref
*    indices
*    updates

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    output_ref

*/
inline tensor scatter_mul(const tensor& ref, const tensor& indices, const tensor& updates, datatype Tindices, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterMul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ScatterNd
# Inputs:
*    indices
*    updates
*    shape

# Attributes:
*    Tindices
*    bad_indices_policy

# Outputs:
*    output

*/
inline tensor scatter_nd(const tensor& indices, const tensor& updates, const tensor& shape, datatype Tindices, const std::string& bad_indices_policy="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterNd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrString(op.get(), "bad_indices_policy", (void*) bad_indices_policy.c_str(), bad_indices_policy.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ScatterNdAdd
# Inputs:
*    ref
*    indices
*    updates

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    output_ref

*/
inline tensor scatter_nd_add(const tensor& ref, const tensor& indices, const tensor& updates, datatype Tindices, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterNdAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ScatterNdMax
# Inputs:
*    ref
*    indices
*    updates

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    output_ref

*/
inline tensor scatter_nd_max(const tensor& ref, const tensor& indices, const tensor& updates, datatype Tindices, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterNdMax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ScatterNdMin
# Inputs:
*    ref
*    indices
*    updates

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    output_ref

*/
inline tensor scatter_nd_min(const tensor& ref, const tensor& indices, const tensor& updates, datatype Tindices, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterNdMin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ScatterNdNonAliasingAdd
# Inputs:
*    input
*    indices
*    updates

# Attributes:
*    Tindices

# Outputs:
*    output

*/
inline tensor scatter_nd_non_aliasing_add(const tensor& input, const tensor& indices, const tensor& updates, datatype Tindices) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterNdNonAliasingAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ScatterNdSub
# Inputs:
*    ref
*    indices
*    updates

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    output_ref

*/
inline tensor scatter_nd_sub(const tensor& ref, const tensor& indices, const tensor& updates, datatype Tindices, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterNdSub", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ScatterNdUpdate
# Inputs:
*    ref
*    indices
*    updates

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    output_ref

*/
inline tensor scatter_nd_update(const tensor& ref, const tensor& indices, const tensor& updates, datatype Tindices, bool use_locking=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterNdUpdate", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ScatterSub
# Inputs:
*    ref
*    indices
*    updates

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    output_ref

*/
inline tensor scatter_sub(const tensor& ref, const tensor& indices, const tensor& updates, datatype Tindices, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterSub", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ScatterUpdate
# Inputs:
*    ref
*    indices
*    updates

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    output_ref

*/
inline tensor scatter_update(const tensor& ref, const tensor& indices, const tensor& updates, datatype Tindices, bool use_locking=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterUpdate", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SdcaFprint
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor sdca_fprint(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SdcaFprint", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SdcaOptimizer
# Inputs:
*    sparse_example_indices
*    sparse_feature_indices
*    sparse_feature_values
*    dense_features
*    example_weights
*    example_labels
*    sparse_indices
*    sparse_weights
*    dense_weights
*    example_state_data

# Attributes:
*    loss_type
*    num_sparse_features
*    num_sparse_features_with_values
*    num_dense_features
*    l1
*    l2
*    num_loss_partitions
*    num_inner_iterations
*    adaptative

# Outputs:
*    out_example_state_data
*    out_delta_sparse_weights
*    out_delta_dense_weights

*/
inline std::vector<tensor> sdca_optimizer(const std::vector<tensor>&sparse_example_indices, const std::vector<tensor>&sparse_feature_indices, const std::vector<tensor>&sparse_feature_values, const std::vector<tensor>&dense_features, const tensor& example_weights, const tensor& example_labels, const std::vector<tensor>&sparse_indices, const std::vector<tensor>&sparse_weights, const std::vector<tensor>&dense_weights, const tensor& example_state_data, const std::string& loss_type, float l1, float l2, int64_t num_loss_partitions, int64_t num_inner_iterations, bool adaptative=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SdcaOptimizer", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> sparse_example_indices_handles; sparse_example_indices_handles.reserve(sparse_example_indices.size());
    std::transform(sparse_example_indices.begin(), sparse_example_indices.end(), std::back_inserter(sparse_example_indices_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), sparse_example_indices_handles.data(), static_cast<int>(sparse_example_indices.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> sparse_feature_indices_handles; sparse_feature_indices_handles.reserve(sparse_feature_indices.size());
    std::transform(sparse_feature_indices.begin(), sparse_feature_indices.end(), std::back_inserter(sparse_feature_indices_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), sparse_feature_indices_handles.data(), static_cast<int>(sparse_feature_indices.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> sparse_feature_values_handles; sparse_feature_values_handles.reserve(sparse_feature_values.size());
    std::transform(sparse_feature_values.begin(), sparse_feature_values.end(), std::back_inserter(sparse_feature_values_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), sparse_feature_values_handles.data(), static_cast<int>(sparse_feature_values.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_features_handles; dense_features_handles.reserve(dense_features.size());
    std::transform(dense_features.begin(), dense_features.end(), std::back_inserter(dense_features_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), dense_features_handles.data(), static_cast<int>(dense_features.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), example_weights.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), example_labels.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> sparse_indices_handles; sparse_indices_handles.reserve(sparse_indices.size());
    std::transform(sparse_indices.begin(), sparse_indices.end(), std::back_inserter(sparse_indices_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), sparse_indices_handles.data(), static_cast<int>(sparse_indices.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> sparse_weights_handles; sparse_weights_handles.reserve(sparse_weights.size());
    std::transform(sparse_weights.begin(), sparse_weights.end(), std::back_inserter(sparse_weights_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), sparse_weights_handles.data(), static_cast<int>(sparse_weights.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_weights_handles; dense_weights_handles.reserve(dense_weights.size());
    std::transform(dense_weights.begin(), dense_weights.end(), std::back_inserter(dense_weights_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), dense_weights_handles.data(), static_cast<int>(dense_weights.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), example_state_data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "loss_type", (void*) loss_type.c_str(), loss_type.size());
    TFE_OpSetAttrInt(op.get(), "num_sparse_features", sparse_example_indices.size());
    TFE_OpSetAttrInt(op.get(), "num_sparse_features_with_values", sparse_feature_values.size());
    TFE_OpSetAttrInt(op.get(), "num_dense_features", dense_features.size());
    TFE_OpSetAttrFloat(op.get(), "l1", l1);
    TFE_OpSetAttrFloat(op.get(), "l2", l2);
    TFE_OpSetAttrInt(op.get(), "num_loss_partitions", num_loss_partitions);
    TFE_OpSetAttrInt(op.get(), "num_inner_iterations", num_inner_iterations);
    TFE_OpSetAttrBool(op.get(), "adaptative", (unsigned char)adaptative);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # SdcaOptimizerV2
# Inputs:
*    sparse_example_indices
*    sparse_feature_indices
*    sparse_feature_values
*    dense_features
*    example_weights
*    example_labels
*    sparse_indices
*    sparse_weights
*    dense_weights
*    example_state_data

# Attributes:
*    loss_type
*    num_sparse_features
*    num_sparse_features_with_values
*    num_dense_features
*    l1
*    l2
*    num_loss_partitions
*    num_inner_iterations
*    adaptive

# Outputs:
*    out_example_state_data
*    out_delta_sparse_weights
*    out_delta_dense_weights

*/
inline std::vector<tensor> sdca_optimizer_v2(const std::vector<tensor>&sparse_example_indices, const std::vector<tensor>&sparse_feature_indices, const std::vector<tensor>&sparse_feature_values, const std::vector<tensor>&dense_features, const tensor& example_weights, const tensor& example_labels, const std::vector<tensor>&sparse_indices, const std::vector<tensor>&sparse_weights, const std::vector<tensor>&dense_weights, const tensor& example_state_data, const std::string& loss_type, float l1, float l2, int64_t num_loss_partitions, int64_t num_inner_iterations, bool adaptive=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SdcaOptimizerV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> sparse_example_indices_handles; sparse_example_indices_handles.reserve(sparse_example_indices.size());
    std::transform(sparse_example_indices.begin(), sparse_example_indices.end(), std::back_inserter(sparse_example_indices_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), sparse_example_indices_handles.data(), static_cast<int>(sparse_example_indices.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> sparse_feature_indices_handles; sparse_feature_indices_handles.reserve(sparse_feature_indices.size());
    std::transform(sparse_feature_indices.begin(), sparse_feature_indices.end(), std::back_inserter(sparse_feature_indices_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), sparse_feature_indices_handles.data(), static_cast<int>(sparse_feature_indices.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> sparse_feature_values_handles; sparse_feature_values_handles.reserve(sparse_feature_values.size());
    std::transform(sparse_feature_values.begin(), sparse_feature_values.end(), std::back_inserter(sparse_feature_values_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), sparse_feature_values_handles.data(), static_cast<int>(sparse_feature_values.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_features_handles; dense_features_handles.reserve(dense_features.size());
    std::transform(dense_features.begin(), dense_features.end(), std::back_inserter(dense_features_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), dense_features_handles.data(), static_cast<int>(dense_features.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), example_weights.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), example_labels.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> sparse_indices_handles; sparse_indices_handles.reserve(sparse_indices.size());
    std::transform(sparse_indices.begin(), sparse_indices.end(), std::back_inserter(sparse_indices_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), sparse_indices_handles.data(), static_cast<int>(sparse_indices.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> sparse_weights_handles; sparse_weights_handles.reserve(sparse_weights.size());
    std::transform(sparse_weights.begin(), sparse_weights.end(), std::back_inserter(sparse_weights_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), sparse_weights_handles.data(), static_cast<int>(sparse_weights.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_weights_handles; dense_weights_handles.reserve(dense_weights.size());
    std::transform(dense_weights.begin(), dense_weights.end(), std::back_inserter(dense_weights_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), dense_weights_handles.data(), static_cast<int>(dense_weights.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), example_state_data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "loss_type", (void*) loss_type.c_str(), loss_type.size());
    TFE_OpSetAttrInt(op.get(), "num_sparse_features", sparse_example_indices.size());
    TFE_OpSetAttrInt(op.get(), "num_sparse_features_with_values", sparse_feature_values.size());
    TFE_OpSetAttrInt(op.get(), "num_dense_features", dense_features.size());
    TFE_OpSetAttrFloat(op.get(), "l1", l1);
    TFE_OpSetAttrFloat(op.get(), "l2", l2);
    TFE_OpSetAttrInt(op.get(), "num_loss_partitions", num_loss_partitions);
    TFE_OpSetAttrInt(op.get(), "num_inner_iterations", num_inner_iterations);
    TFE_OpSetAttrBool(op.get(), "adaptive", (unsigned char)adaptive);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # SdcaShrinkL1
# Inputs:
*    weights

# Attributes:
*    num_features
*    l1
*    l2

# Outputs:
*    
*/
inline void sdca_shrink_l1(const std::vector<tensor>&weights, float l1, float l2) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SdcaShrinkL1", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> weights_handles; weights_handles.reserve(weights.size());
    std::transform(weights.begin(), weights.end(), std::back_inserter(weights_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), weights_handles.data(), static_cast<int>(weights.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_features", weights.size());
    TFE_OpSetAttrFloat(op.get(), "l1", l1);
    TFE_OpSetAttrFloat(op.get(), "l2", l2);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # SegmentMax
# Inputs:
*    data
*    segment_ids

# Attributes:
*    Tindices

# Outputs:
*    output

*/
inline tensor segment_max(const tensor& data, const tensor& segment_ids, datatype Tindices) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SegmentMax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SegmentMaxV2
# Inputs:
*    data
*    segment_ids
*    num_segments

# Attributes:
*    Tindices
*    Tnumsegments

# Outputs:
*    output

*/
inline tensor segment_max_v2(const tensor& data, const tensor& segment_ids, const tensor& num_segments, datatype Tindices, datatype Tnumsegments=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SegmentMaxV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_segments.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrType(op.get(), "Tnumsegments", Tnumsegments);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SegmentMean
# Inputs:
*    data
*    segment_ids

# Attributes:
*    Tindices

# Outputs:
*    output

*/
inline tensor segment_mean(const tensor& data, const tensor& segment_ids, datatype Tindices) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SegmentMean", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SegmentMin
# Inputs:
*    data
*    segment_ids

# Attributes:
*    Tindices

# Outputs:
*    output

*/
inline tensor segment_min(const tensor& data, const tensor& segment_ids, datatype Tindices) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SegmentMin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SegmentMinV2
# Inputs:
*    data
*    segment_ids
*    num_segments

# Attributes:
*    Tindices
*    Tnumsegments

# Outputs:
*    output

*/
inline tensor segment_min_v2(const tensor& data, const tensor& segment_ids, const tensor& num_segments, datatype Tindices, datatype Tnumsegments=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SegmentMinV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_segments.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrType(op.get(), "Tnumsegments", Tnumsegments);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SegmentProd
# Inputs:
*    data
*    segment_ids

# Attributes:
*    Tindices

# Outputs:
*    output

*/
inline tensor segment_prod(const tensor& data, const tensor& segment_ids, datatype Tindices) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SegmentProd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SegmentProdV2
# Inputs:
*    data
*    segment_ids
*    num_segments

# Attributes:
*    Tindices
*    Tnumsegments

# Outputs:
*    output

*/
inline tensor segment_prod_v2(const tensor& data, const tensor& segment_ids, const tensor& num_segments, datatype Tindices, datatype Tnumsegments=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SegmentProdV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_segments.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrType(op.get(), "Tnumsegments", Tnumsegments);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SegmentSum
# Inputs:
*    data
*    segment_ids

# Attributes:
*    Tindices

# Outputs:
*    output

*/
inline tensor segment_sum(const tensor& data, const tensor& segment_ids, datatype Tindices) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SegmentSum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SegmentSumV2
# Inputs:
*    data
*    segment_ids
*    num_segments

# Attributes:
*    Tindices
*    Tnumsegments

# Outputs:
*    output

*/
inline tensor segment_sum_v2(const tensor& data, const tensor& segment_ids, const tensor& num_segments, datatype Tindices, datatype Tnumsegments=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SegmentSumV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_segments.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrType(op.get(), "Tnumsegments", Tnumsegments);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Select
# Inputs:
*    condition
*    t
*    e

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor select(const tensor& condition, const tensor& t, const tensor& e) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Select", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), condition.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), t.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), e.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SelectV2
# Inputs:
*    condition
*    t
*    e

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor select_v2(const tensor& condition, const tensor& t, const tensor& e) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SelectV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), condition.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), t.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), e.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SelfAdjointEig
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor self_adjoint_eig(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SelfAdjointEig", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SelfAdjointEigV2
# Inputs:
*    input

# Attributes:
*    compute_v

# Outputs:
*    e
*    v

*/
inline std::vector<tensor> self_adjoint_eig_v2(const tensor& input, bool compute_v=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SelfAdjointEigV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "compute_v", (unsigned char)compute_v);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # Selu
# Inputs:
*    features

# Attributes:
*    
# Outputs:
*    activations

*/
inline tensor selu(const tensor& features) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Selu", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), features.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SeluGrad
# Inputs:
*    gradients
*    outputs

# Attributes:
*    
# Outputs:
*    backprops

*/
inline tensor selu_grad(const tensor& gradients, const tensor& outputs) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SeluGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), gradients.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), outputs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Send
# Inputs:
*    tensor

# Attributes:
*    tensor_name
*    send_device
*    send_device_incarnation
*    recv_device
*    client_terminated

# Outputs:
*    
*/
inline void send(const tensor& input_tensor, const std::string& tensor_name, const std::string& send_device, int64_t send_device_incarnation, const std::string& recv_device, bool client_terminated=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Send", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "tensor_name", (void*) tensor_name.c_str(), tensor_name.size());
    TFE_OpSetAttrString(op.get(), "send_device", (void*) send_device.c_str(), send_device.size());
    TFE_OpSetAttrInt(op.get(), "send_device_incarnation", send_device_incarnation);
    TFE_OpSetAttrString(op.get(), "recv_device", (void*) recv_device.c_str(), recv_device.size());
    TFE_OpSetAttrBool(op.get(), "client_terminated", (unsigned char)client_terminated);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # SendTPUEmbeddingGradients
# Inputs:
*    inputs
*    learning_rates

# Attributes:
*    N
*    config
*    NN

# Outputs:
*    
*/
inline void send_t_p_u_embedding_gradients(const std::vector<tensor>&inputs, const std::vector<tensor>&learning_rates, const std::string& config) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SendTPUEmbeddingGradients", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), static_cast<int>(inputs.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> learning_rates_handles; learning_rates_handles.reserve(learning_rates.size());
    std::transform(learning_rates.begin(), learning_rates.end(), std::back_inserter(learning_rates_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), learning_rates_handles.data(), static_cast<int>(learning_rates.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", inputs.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());
    TFE_OpSetAttrInt(op.get(), "NN", learning_rates.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # SerializeIterator
# Inputs:
*    resource_handle

# Attributes:
*    external_state_policy

# Outputs:
*    serialized

*/
inline tensor serialize_iterator(const tensor& resource_handle, int64_t external_state_policy=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SerializeIterator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "external_state_policy", external_state_policy);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SerializeManySparse
# Inputs:
*    sparse_indices
*    sparse_values
*    sparse_shape

# Attributes:
*    out_type

# Outputs:
*    serialized_sparse

*/
inline tensor serialize_many_sparse(const tensor& sparse_indices, const tensor& sparse_values, const tensor& sparse_shape, datatype out_type=static_cast<datatype>(7)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SerializeManySparse", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sparse_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sparse_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sparse_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SerializeSparse
# Inputs:
*    sparse_indices
*    sparse_values
*    sparse_shape

# Attributes:
*    out_type

# Outputs:
*    serialized_sparse

*/
inline tensor serialize_sparse(const tensor& sparse_indices, const tensor& sparse_values, const tensor& sparse_shape, datatype out_type=static_cast<datatype>(7)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SerializeSparse", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sparse_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sparse_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sparse_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SerializeTensor
# Inputs:
*    tensor

# Attributes:
*    
# Outputs:
*    serialized

*/
inline tensor serialize_tensor(const tensor& input_tensor) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SerializeTensor", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SetSize
# Inputs:
*    set_indices
*    set_values
*    set_shape

# Attributes:
*    validate_indices

# Outputs:
*    size

*/
inline tensor set_size(const tensor& set_indices, const tensor& set_values, const tensor& set_shape, bool validate_indices=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SetSize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), set_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), set_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), set_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "validate_indices", (unsigned char)validate_indices);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SetStatsAggregatorDataset
# Inputs:
*    input_dataset
*    stats_aggregator
*    tag
*    counter_prefix

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor set_stats_aggregator_dataset(const tensor& input_dataset, const tensor& stats_aggregator, const tensor& tag, const tensor& counter_prefix, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SetStatsAggregatorDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), stats_aggregator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tag.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), counter_prefix.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Shape
# Inputs:
*    input

# Attributes:
*    out_type

# Outputs:
*    output

*/
inline tensor shape(const tensor& input, datatype out_type=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Shape", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ShapeN
# Inputs:
*    input

# Attributes:
*    N
*    out_type

# Outputs:
*    output

*/
inline tensor shape_n(const std::vector<tensor>&input, datatype out_type=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ShapeN", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> input_handles; input_handles.reserve(input.size());
    std::transform(input.begin(), input.end(), std::back_inserter(input_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), input_handles.data(), static_cast<int>(input.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", input.size());
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ShardDataset
# Inputs:
*    input_dataset
*    num_shards
*    index

# Attributes:
*    output_types
*    output_shapes
*    require_non_empty
*    metadata

# Outputs:
*    handle

*/
inline tensor shard_dataset(const tensor& input_dataset, const tensor& num_shards, const tensor& index, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool require_non_empty=false, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ShardDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_shards.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), index.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "require_non_empty", (unsigned char)require_non_empty);
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ShardedFilename
# Inputs:
*    basename
*    shard
*    num_shards

# Attributes:
*    
# Outputs:
*    filename

*/
inline tensor sharded_filename(const tensor& basename, const tensor& shard, const tensor& num_shards) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ShardedFilename", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), basename.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shard.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_shards.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ShardedFilespec
# Inputs:
*    basename
*    num_shards

# Attributes:
*    
# Outputs:
*    filename

*/
inline tensor sharded_filespec(const tensor& basename, const tensor& num_shards) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ShardedFilespec", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), basename.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_shards.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ShuffleAndRepeatDataset
# Inputs:
*    input_dataset
*    buffer_size
*    seed
*    seed2
*    count

# Attributes:
*    output_types
*    output_shapes
*    reshuffle_each_iteration
*    metadata

# Outputs:
*    handle

*/
inline tensor shuffle_and_repeat_dataset(const tensor& input_dataset, const tensor& buffer_size, const tensor& seed, const tensor& seed2, const tensor& count, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool reshuffle_each_iteration=true, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ShuffleAndRepeatDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), count.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "reshuffle_each_iteration", (unsigned char)reshuffle_each_iteration);
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ShuffleAndRepeatDatasetV2
# Inputs:
*    input_dataset
*    buffer_size
*    seed
*    seed2
*    count
*    seed_generator

# Attributes:
*    output_types
*    output_shapes
*    reshuffle_each_iteration
*    metadata

# Outputs:
*    handle

*/
inline tensor shuffle_and_repeat_dataset_v2(const tensor& input_dataset, const tensor& buffer_size, const tensor& seed, const tensor& seed2, const tensor& count, const tensor& seed_generator, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool reshuffle_each_iteration=true, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ShuffleAndRepeatDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), count.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed_generator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "reshuffle_each_iteration", (unsigned char)reshuffle_each_iteration);
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ShuffleDataset
# Inputs:
*    input_dataset
*    buffer_size
*    seed
*    seed2

# Attributes:
*    output_types
*    output_shapes
*    reshuffle_each_iteration
*    metadata

# Outputs:
*    handle

*/
inline tensor shuffle_dataset(const tensor& input_dataset, const tensor& buffer_size, const tensor& seed, const tensor& seed2, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool reshuffle_each_iteration=true, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ShuffleDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "reshuffle_each_iteration", (unsigned char)reshuffle_each_iteration);
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ShuffleDatasetV2
# Inputs:
*    input_dataset
*    buffer_size
*    seed_generator

# Attributes:
*    output_types
*    output_shapes
*    metadata

# Outputs:
*    handle

*/
inline tensor shuffle_dataset_v2(const tensor& input_dataset, const tensor& buffer_size, const tensor& seed_generator, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ShuffleDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed_generator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ShuffleDatasetV3
# Inputs:
*    input_dataset
*    buffer_size
*    seed
*    seed2
*    seed_generator

# Attributes:
*    output_types
*    output_shapes
*    reshuffle_each_iteration
*    metadata

# Outputs:
*    handle

*/
inline tensor shuffle_dataset_v3(const tensor& input_dataset, const tensor& buffer_size, const tensor& seed, const tensor& seed2, const tensor& seed_generator, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool reshuffle_each_iteration=true, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ShuffleDatasetV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed_generator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "reshuffle_each_iteration", (unsigned char)reshuffle_each_iteration);
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ShutdownDistributedTPU
# Inputs:
*    
# Attributes:
*    
# Outputs:
*    
*/
inline void shutdown_distributed_t_p_u() {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ShutdownDistributedTPU", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # Sigmoid
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor sigmoid(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Sigmoid", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SigmoidGrad
# Inputs:
*    y
*    dy

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor sigmoid_grad(const tensor& y, const tensor& dy) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SigmoidGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dy.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Sign
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor sign(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Sign", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Sin
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor sin(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Sin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Sinh
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor sinh(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Sinh", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Size
# Inputs:
*    input

# Attributes:
*    out_type

# Outputs:
*    output

*/
inline tensor size(const tensor& input, datatype out_type=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Size", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SkipDataset
# Inputs:
*    input_dataset
*    count

# Attributes:
*    output_types
*    output_shapes
*    metadata

# Outputs:
*    handle

*/
inline tensor skip_dataset(const tensor& input_dataset, const tensor& count, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SkipDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), count.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SleepDataset
# Inputs:
*    input_dataset
*    sleep_microseconds

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor sleep_dataset(const tensor& input_dataset, const tensor& sleep_microseconds, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SleepDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sleep_microseconds.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Slice
# Inputs:
*    input
*    begin
*    size

# Attributes:
*    Index

# Outputs:
*    output

*/
inline tensor slice(const tensor& input, const tensor& begin, const tensor& size, datatype Index) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Slice", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), begin.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Index", Index);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SlidingWindowDataset
# Inputs:
*    input_dataset
*    window_size
*    window_shift
*    window_stride

# Attributes:
*    output_types
*    output_shapes
*    drop_remainder

# Outputs:
*    handle

*/
inline tensor sliding_window_dataset(const tensor& input_dataset, const tensor& window_size, const tensor& window_shift, const tensor& window_stride, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool drop_remainder=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SlidingWindowDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), window_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), window_shift.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), window_stride.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "drop_remainder", (unsigned char)drop_remainder);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Snapshot
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor snapshot(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Snapshot", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SnapshotChunkDataset
# Inputs:
*    chunk_file

# Attributes:
*    output_types
*    output_shapes
*    compression

# Outputs:
*    handle

*/
inline tensor snapshot_chunk_dataset(const tensor& chunk_file, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& compression="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SnapshotChunkDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), chunk_file.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "compression", (void*) compression.c_str(), compression.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SnapshotDataset
# Inputs:
*    input_dataset
*    path

# Attributes:
*    output_types
*    output_shapes
*    compression
*    reader_path_prefix
*    writer_path_prefix
*    shard_size_bytes
*    pending_snapshot_expiry_seconds
*    num_reader_threads
*    reader_buffer_size
*    num_writer_threads
*    writer_buffer_size
*    shuffle_on_read
*    seed
*    seed2
*    mode
*    snapshot_name

# Outputs:
*    handle

*/
inline tensor snapshot_dataset(const tensor& input_dataset, const tensor& path, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& compression="", const std::string& reader_path_prefix="", const std::string& writer_path_prefix="", int64_t shard_size_bytes=10737418240, int64_t pending_snapshot_expiry_seconds=86400, int64_t num_reader_threads=1, int64_t reader_buffer_size=1, int64_t num_writer_threads=1, int64_t writer_buffer_size=1, bool shuffle_on_read=false, int64_t seed=0, int64_t seed2=0, const std::string& mode="auto", const std::string& snapshot_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SnapshotDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), path.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "compression", (void*) compression.c_str(), compression.size());
    TFE_OpSetAttrString(op.get(), "reader_path_prefix", (void*) reader_path_prefix.c_str(), reader_path_prefix.size());
    TFE_OpSetAttrString(op.get(), "writer_path_prefix", (void*) writer_path_prefix.c_str(), writer_path_prefix.size());
    TFE_OpSetAttrInt(op.get(), "shard_size_bytes", shard_size_bytes);
    TFE_OpSetAttrInt(op.get(), "pending_snapshot_expiry_seconds", pending_snapshot_expiry_seconds);
    TFE_OpSetAttrInt(op.get(), "num_reader_threads", num_reader_threads);
    TFE_OpSetAttrInt(op.get(), "reader_buffer_size", reader_buffer_size);
    TFE_OpSetAttrInt(op.get(), "num_writer_threads", num_writer_threads);
    TFE_OpSetAttrInt(op.get(), "writer_buffer_size", writer_buffer_size);
    TFE_OpSetAttrBool(op.get(), "shuffle_on_read", (unsigned char)shuffle_on_read);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrString(op.get(), "mode", (void*) mode.c_str(), mode.size());
    TFE_OpSetAttrString(op.get(), "snapshot_name", (void*) snapshot_name.c_str(), snapshot_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SnapshotDatasetReader
# Inputs:
*    shard_dir
*    start_index

# Attributes:
*    output_types
*    output_shapes
*    version
*    compression

# Outputs:
*    handle

*/
inline tensor snapshot_dataset_reader(const tensor& shard_dir, const tensor& start_index, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, int64_t version, const std::string& compression="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SnapshotDatasetReader", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shard_dir.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), start_index.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "version", version);
    TFE_OpSetAttrString(op.get(), "compression", (void*) compression.c_str(), compression.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SnapshotDatasetV2
# Inputs:
*    input_dataset
*    path
*    reader_func_other_args
*    shard_func_other_args

# Attributes:
*    output_types
*    output_shapes
*    reader_func
*    shard_func
*    Treader_func_args
*    Tshard_func_args
*    compression
*    reader_prefix
*    writer_prefix
*    hash_valid
*    hash
*    metadata

# Outputs:
*    handle

*/
inline tensor snapshot_dataset_v2(const tensor& input_dataset, const tensor& path, const std::vector<tensor>&reader_func_other_args, const std::vector<tensor>&shard_func_other_args, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, int64_t reader_func, int64_t shard_func, const std::vector<datatype>& Treader_func_args, const std::vector<datatype>& Tshard_func_args, const std::string& compression="", const std::string& reader_prefix="", const std::string& writer_prefix="", bool hash_valid=false, int64_t hash=0, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SnapshotDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), path.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> reader_func_other_args_handles; reader_func_other_args_handles.reserve(reader_func_other_args.size());
    std::transform(reader_func_other_args.begin(), reader_func_other_args.end(), std::back_inserter(reader_func_other_args_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), reader_func_other_args_handles.data(), static_cast<int>(reader_func_other_args.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> shard_func_other_args_handles; shard_func_other_args_handles.reserve(shard_func_other_args.size());
    std::transform(shard_func_other_args.begin(), shard_func_other_args.end(), std::back_inserter(shard_func_other_args_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), shard_func_other_args_handles.data(), static_cast<int>(shard_func_other_args.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "reader_func", reader_func);
    TFE_OpSetAttrInt(op.get(), "shard_func", shard_func);
    TFE_OpSetAttrTypeList(op.get(), "Treader_func_args", reinterpret_cast<const enum TF_DataType *>(Treader_func_args.data()), static_cast<int>(Treader_func_args.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tshard_func_args", reinterpret_cast<const enum TF_DataType *>(Tshard_func_args.data()), static_cast<int>(Tshard_func_args.size()));
    TFE_OpSetAttrString(op.get(), "compression", (void*) compression.c_str(), compression.size());
    TFE_OpSetAttrString(op.get(), "reader_prefix", (void*) reader_prefix.c_str(), reader_prefix.size());
    TFE_OpSetAttrString(op.get(), "writer_prefix", (void*) writer_prefix.c_str(), writer_prefix.size());
    TFE_OpSetAttrBool(op.get(), "hash_valid", (unsigned char)hash_valid);
    TFE_OpSetAttrInt(op.get(), "hash", hash);
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SnapshotNestedDatasetReader
# Inputs:
*    inputs

# Attributes:
*    output_types
*    output_shapes
*    N

# Outputs:
*    handle

*/
inline tensor snapshot_nested_dataset_reader(const std::vector<tensor>&inputs, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SnapshotNestedDatasetReader", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), static_cast<int>(inputs.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "N", inputs.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SobolSample
# Inputs:
*    dim
*    num_results
*    skip

# Attributes:
*    dtype

# Outputs:
*    samples

*/
inline tensor sobol_sample(const tensor& dim, const tensor& num_results, const tensor& skip, datatype dtype=static_cast<datatype>(1)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SobolSample", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), dim.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_results.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), skip.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Softmax
# Inputs:
*    logits

# Attributes:
*    
# Outputs:
*    softmax

*/
inline tensor softmax(const tensor& logits) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Softmax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), logits.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SoftmaxCrossEntropyWithLogits
# Inputs:
*    features
*    labels

# Attributes:
*    
# Outputs:
*    loss
*    backprop

*/
inline std::vector<tensor> softmax_cross_entropy_with_logits(const tensor& features, const tensor& labels) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SoftmaxCrossEntropyWithLogits", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), features.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), labels.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # Softplus
# Inputs:
*    features

# Attributes:
*    
# Outputs:
*    activations

*/
inline tensor softplus(const tensor& features) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Softplus", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), features.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SoftplusGrad
# Inputs:
*    gradients
*    features

# Attributes:
*    
# Outputs:
*    backprops

*/
inline tensor softplus_grad(const tensor& gradients, const tensor& features) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SoftplusGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), gradients.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), features.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Softsign
# Inputs:
*    features

# Attributes:
*    
# Outputs:
*    activations

*/
inline tensor softsign(const tensor& features) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Softsign", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), features.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SoftsignGrad
# Inputs:
*    gradients
*    features

# Attributes:
*    
# Outputs:
*    backprops

*/
inline tensor softsign_grad(const tensor& gradients, const tensor& features) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SoftsignGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), gradients.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), features.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SpaceToBatch
# Inputs:
*    input
*    paddings

# Attributes:
*    block_size
*    Tpaddings

# Outputs:
*    output

*/
inline tensor space_to_batch(const tensor& input, const tensor& paddings, int64_t block_size, datatype Tpaddings=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SpaceToBatch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), paddings.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "block_size", block_size);
    TFE_OpSetAttrType(op.get(), "Tpaddings", Tpaddings);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SpaceToBatchND
# Inputs:
*    input
*    block_shape
*    paddings

# Attributes:
*    Tblock_shape
*    Tpaddings

# Outputs:
*    output

*/
inline tensor space_to_batch_n_d(const tensor& input, const tensor& block_shape, const tensor& paddings, datatype Tblock_shape=static_cast<datatype>(3), datatype Tpaddings=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SpaceToBatchND", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), block_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), paddings.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tblock_shape", Tblock_shape);
    TFE_OpSetAttrType(op.get(), "Tpaddings", Tpaddings);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SpaceToDepth
# Inputs:
*    input

# Attributes:
*    block_size
*    data_format

# Outputs:
*    output

*/
inline tensor space_to_depth(const tensor& input, int64_t block_size, const std::string& data_format="NHWC") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SpaceToDepth", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "block_size", block_size);
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseAccumulatorApplyGradient
# Inputs:
*    handle
*    local_step
*    gradient_indices
*    gradient_values
*    gradient_shape

# Attributes:
*    dtype
*    has_known_shape

# Outputs:
*    
*/
inline void sparse_accumulator_apply_gradient(const tensor& handle, const tensor& local_step, const tensor& gradient_indices, const tensor& gradient_values, const tensor& gradient_shape, datatype dtype, bool has_known_shape) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseAccumulatorApplyGradient", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), local_step.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrBool(op.get(), "has_known_shape", (unsigned char)has_known_shape);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # SparseAccumulatorTakeGradient
# Inputs:
*    handle
*    num_required

# Attributes:
*    dtype

# Outputs:
*    indices
*    values
*    shape

*/
inline std::vector<tensor> sparse_accumulator_take_gradient(const tensor& handle, const tensor& num_required, datatype dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseAccumulatorTakeGradient", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_required.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # SparseAdd
# Inputs:
*    a_indices
*    a_values
*    a_shape
*    b_indices
*    b_values
*    b_shape
*    thresh

# Attributes:
*    Treal

# Outputs:
*    sum_indices
*    sum_values
*    sum_shape

*/
inline std::vector<tensor> sparse_add(const tensor& a_indices, const tensor& a_values, const tensor& a_shape, const tensor& b_indices, const tensor& b_values, const tensor& b_shape, const tensor& thresh, datatype Treal) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), a_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), a_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), thresh.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Treal", Treal);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # SparseAddGrad
# Inputs:
*    backprop_val_grad
*    a_indices
*    b_indices
*    sum_indices

# Attributes:
*    
# Outputs:
*    a_val_grad
*    b_val_grad

*/
inline std::vector<tensor> sparse_add_grad(const tensor& backprop_val_grad, const tensor& a_indices, const tensor& b_indices, const tensor& sum_indices) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseAddGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), backprop_val_grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), a_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sum_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # SparseApplyAdadelta
# Inputs:
*    var
*    accum
*    accum_update
*    lr
*    rho
*    epsilon
*    grad
*    indices

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    out

*/
inline tensor sparse_apply_adadelta(const tensor& var, const tensor& accum, const tensor& accum_update, const tensor& lr, const tensor& rho, const tensor& epsilon, const tensor& grad, const tensor& indices, datatype Tindices, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseApplyAdadelta", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum_update.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rho.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseApplyAdagrad
# Inputs:
*    var
*    accum
*    lr
*    grad
*    indices

# Attributes:
*    Tindices
*    use_locking
*    update_slots

# Outputs:
*    out

*/
inline tensor sparse_apply_adagrad(const tensor& var, const tensor& accum, const tensor& lr, const tensor& grad, const tensor& indices, datatype Tindices, bool use_locking=false, bool update_slots=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseApplyAdagrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "update_slots", (unsigned char)update_slots);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseApplyAdagradDA
# Inputs:
*    var
*    gradient_accumulator
*    gradient_squared_accumulator
*    grad
*    indices
*    lr
*    l1
*    l2
*    global_step

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    out

*/
inline tensor sparse_apply_adagrad_d_a(const tensor& var, const tensor& gradient_accumulator, const tensor& gradient_squared_accumulator, const tensor& grad, const tensor& indices, const tensor& lr, const tensor& l1, const tensor& l2, const tensor& global_step, datatype Tindices, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseApplyAdagradDA", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_accumulator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_squared_accumulator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), global_step.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseApplyAdagradV2
# Inputs:
*    var
*    accum
*    lr
*    epsilon
*    grad
*    indices

# Attributes:
*    Tindices
*    use_locking
*    update_slots

# Outputs:
*    out

*/
inline tensor sparse_apply_adagrad_v2(const tensor& var, const tensor& accum, const tensor& lr, const tensor& epsilon, const tensor& grad, const tensor& indices, datatype Tindices, bool use_locking=false, bool update_slots=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseApplyAdagradV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "update_slots", (unsigned char)update_slots);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseApplyCenteredRMSProp
# Inputs:
*    var
*    mg
*    ms
*    mom
*    lr
*    rho
*    momentum
*    epsilon
*    grad
*    indices

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    out

*/
inline tensor sparse_apply_centered_r_m_s_prop(const tensor& var, const tensor& mg, const tensor& ms, const tensor& mom, const tensor& lr, const tensor& rho, const tensor& momentum, const tensor& epsilon, const tensor& grad, const tensor& indices, datatype Tindices, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseApplyCenteredRMSProp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mg.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ms.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mom.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rho.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseApplyFtrl
# Inputs:
*    var
*    accum
*    linear
*    grad
*    indices
*    lr
*    l1
*    l2
*    lr_power

# Attributes:
*    Tindices
*    use_locking
*    multiply_linear_by_lr

# Outputs:
*    out

*/
inline tensor sparse_apply_ftrl(const tensor& var, const tensor& accum, const tensor& linear, const tensor& grad, const tensor& indices, const tensor& lr, const tensor& l1, const tensor& l2, const tensor& lr_power, datatype Tindices, bool use_locking=false, bool multiply_linear_by_lr=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseApplyFtrl", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), linear.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr_power.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "multiply_linear_by_lr", (unsigned char)multiply_linear_by_lr);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseApplyFtrlV2
# Inputs:
*    var
*    accum
*    linear
*    grad
*    indices
*    lr
*    l1
*    l2
*    l2_shrinkage
*    lr_power

# Attributes:
*    Tindices
*    use_locking
*    multiply_linear_by_lr

# Outputs:
*    out

*/
inline tensor sparse_apply_ftrl_v2(const tensor& var, const tensor& accum, const tensor& linear, const tensor& grad, const tensor& indices, const tensor& lr, const tensor& l1, const tensor& l2, const tensor& l2_shrinkage, const tensor& lr_power, datatype Tindices, bool use_locking=false, bool multiply_linear_by_lr=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseApplyFtrlV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), linear.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2_shrinkage.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr_power.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "multiply_linear_by_lr", (unsigned char)multiply_linear_by_lr);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseApplyMomentum
# Inputs:
*    var
*    accum
*    lr
*    grad
*    indices
*    momentum

# Attributes:
*    Tindices
*    use_locking
*    use_nesterov

# Outputs:
*    out

*/
inline tensor sparse_apply_momentum(const tensor& var, const tensor& accum, const tensor& lr, const tensor& grad, const tensor& indices, const tensor& momentum, datatype Tindices, bool use_locking=false, bool use_nesterov=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseApplyMomentum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "use_nesterov", (unsigned char)use_nesterov);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseApplyProximalAdagrad
# Inputs:
*    var
*    accum
*    lr
*    l1
*    l2
*    grad
*    indices

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    out

*/
inline tensor sparse_apply_proximal_adagrad(const tensor& var, const tensor& accum, const tensor& lr, const tensor& l1, const tensor& l2, const tensor& grad, const tensor& indices, datatype Tindices, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseApplyProximalAdagrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseApplyProximalGradientDescent
# Inputs:
*    var
*    alpha
*    l1
*    l2
*    grad
*    indices

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    out

*/
inline tensor sparse_apply_proximal_gradient_descent(const tensor& var, const tensor& alpha, const tensor& l1, const tensor& l2, const tensor& grad, const tensor& indices, datatype Tindices, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseApplyProximalGradientDescent", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alpha.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseApplyRMSProp
# Inputs:
*    var
*    ms
*    mom
*    lr
*    rho
*    momentum
*    epsilon
*    grad
*    indices

# Attributes:
*    Tindices
*    use_locking

# Outputs:
*    out

*/
inline tensor sparse_apply_r_m_s_prop(const tensor& var, const tensor& ms, const tensor& mom, const tensor& lr, const tensor& rho, const tensor& momentum, const tensor& epsilon, const tensor& grad, const tensor& indices, datatype Tindices, bool use_locking=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseApplyRMSProp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ms.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mom.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rho.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseBincount
# Inputs:
*    indices
*    values
*    dense_shape
*    size
*    weights

# Attributes:
*    Tidx
*    binary_output

# Outputs:
*    output

*/
inline tensor sparse_bincount(const tensor& indices, const tensor& values, const tensor& dense_shape, const tensor& size, const tensor& weights, datatype Tidx, bool binary_output=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseBincount", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dense_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), weights.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrBool(op.get(), "binary_output", (unsigned char)binary_output);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseConcat
# Inputs:
*    indices
*    values
*    shapes

# Attributes:
*    concat_dim
*    N

# Outputs:
*    output_indices
*    output_values
*    output_shape

*/
inline std::vector<tensor> sparse_concat(const std::vector<tensor>&indices, const std::vector<tensor>&values, const std::vector<tensor>&shapes, int64_t concat_dim) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseConcat", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> indices_handles; indices_handles.reserve(indices.size());
    std::transform(indices.begin(), indices.end(), std::back_inserter(indices_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), indices_handles.data(), static_cast<int>(indices.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> values_handles; values_handles.reserve(values.size());
    std::transform(values.begin(), values.end(), std::back_inserter(values_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), values_handles.data(), static_cast<int>(values.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> shapes_handles; shapes_handles.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), shapes_handles.data(), static_cast<int>(shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "concat_dim", concat_dim);
    TFE_OpSetAttrInt(op.get(), "N", indices.size());

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # SparseConditionalAccumulator
# Inputs:
*    
# Attributes:
*    dtype
*    shape
*    container
*    shared_name
*    reduction_type

# Outputs:
*    handle

*/
inline tensor sparse_conditional_accumulator(datatype dtype, const std::vector<int64_t>& shape, const std::string& container="", const std::string& shared_name="", const std::string& reduction_type="MEAN") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseConditionalAccumulator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), static_cast<int>(shape.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrString(op.get(), "reduction_type", (void*) reduction_type.c_str(), reduction_type.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseCountSparseOutput
# Inputs:
*    indices
*    values
*    dense_shape
*    weights

# Attributes:
*    binary_output
*    output_type
*    minlength
*    maxlength

# Outputs:
*    output_indices
*    output_values
*    output_dense_shape

*/
inline std::vector<tensor> sparse_count_sparse_output(const tensor& indices, const tensor& values, const tensor& dense_shape, const tensor& weights, bool binary_output, datatype output_type, int64_t minlength=-1, int64_t maxlength=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseCountSparseOutput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dense_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), weights.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "binary_output", (unsigned char)binary_output);
    TFE_OpSetAttrType(op.get(), "output_type", output_type);
    TFE_OpSetAttrInt(op.get(), "minlength", minlength);
    TFE_OpSetAttrInt(op.get(), "maxlength", maxlength);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # SparseCross
# Inputs:
*    indices
*    values
*    shapes
*    dense_inputs

# Attributes:
*    N
*    hashed_output
*    num_buckets
*    hash_key
*    sparse_types
*    dense_types
*    out_type
*    internal_type

# Outputs:
*    output_indices
*    output_values
*    output_shape

*/
inline std::vector<tensor> sparse_cross(const std::vector<tensor>&indices, const std::vector<tensor>&values, const std::vector<tensor>&shapes, const std::vector<tensor>&dense_inputs, bool hashed_output, int64_t num_buckets, int64_t hash_key, const std::vector<datatype>& sparse_types, const std::vector<datatype>& dense_types, datatype out_type, datatype internal_type) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseCross", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> indices_handles; indices_handles.reserve(indices.size());
    std::transform(indices.begin(), indices.end(), std::back_inserter(indices_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), indices_handles.data(), static_cast<int>(indices.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> values_handles; values_handles.reserve(values.size());
    std::transform(values.begin(), values.end(), std::back_inserter(values_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), values_handles.data(), static_cast<int>(values.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> shapes_handles; shapes_handles.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), shapes_handles.data(), static_cast<int>(shapes.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_inputs_handles; dense_inputs_handles.reserve(dense_inputs.size());
    std::transform(dense_inputs.begin(), dense_inputs.end(), std::back_inserter(dense_inputs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), dense_inputs_handles.data(), static_cast<int>(dense_inputs.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", indices.size());
    TFE_OpSetAttrBool(op.get(), "hashed_output", (unsigned char)hashed_output);
    TFE_OpSetAttrInt(op.get(), "num_buckets", num_buckets);
    TFE_OpSetAttrInt(op.get(), "hash_key", hash_key);
    TFE_OpSetAttrTypeList(op.get(), "sparse_types", reinterpret_cast<const enum TF_DataType *>(sparse_types.data()), static_cast<int>(sparse_types.size()));
    TFE_OpSetAttrTypeList(op.get(), "dense_types", reinterpret_cast<const enum TF_DataType *>(dense_types.data()), static_cast<int>(dense_types.size()));
    TFE_OpSetAttrType(op.get(), "out_type", out_type);
    TFE_OpSetAttrType(op.get(), "internal_type", internal_type);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # SparseCrossHashed
# Inputs:
*    indices
*    values
*    shapes
*    dense_inputs
*    num_buckets
*    strong_hash
*    salt

# Attributes:
*    N
*    sparse_types
*    dense_types

# Outputs:
*    output_indices
*    output_values
*    output_shape

*/
inline std::vector<tensor> sparse_cross_hashed(const std::vector<tensor>&indices, const std::vector<tensor>&values, const std::vector<tensor>&shapes, const std::vector<tensor>&dense_inputs, const tensor& num_buckets, const tensor& strong_hash, const tensor& salt, const std::vector<datatype>& sparse_types, const std::vector<datatype>& dense_types) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseCrossHashed", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> indices_handles; indices_handles.reserve(indices.size());
    std::transform(indices.begin(), indices.end(), std::back_inserter(indices_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), indices_handles.data(), static_cast<int>(indices.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> values_handles; values_handles.reserve(values.size());
    std::transform(values.begin(), values.end(), std::back_inserter(values_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), values_handles.data(), static_cast<int>(values.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> shapes_handles; shapes_handles.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), shapes_handles.data(), static_cast<int>(shapes.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_inputs_handles; dense_inputs_handles.reserve(dense_inputs.size());
    std::transform(dense_inputs.begin(), dense_inputs.end(), std::back_inserter(dense_inputs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), dense_inputs_handles.data(), static_cast<int>(dense_inputs.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_buckets.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), strong_hash.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), salt.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", indices.size());
    TFE_OpSetAttrTypeList(op.get(), "sparse_types", reinterpret_cast<const enum TF_DataType *>(sparse_types.data()), static_cast<int>(sparse_types.size()));
    TFE_OpSetAttrTypeList(op.get(), "dense_types", reinterpret_cast<const enum TF_DataType *>(dense_types.data()), static_cast<int>(dense_types.size()));

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # SparseCrossV2
# Inputs:
*    indices
*    values
*    shapes
*    dense_inputs
*    sep

# Attributes:
*    N
*    sparse_types
*    dense_types

# Outputs:
*    output_indices
*    output_values
*    output_shape

*/
inline std::vector<tensor> sparse_cross_v2(const std::vector<tensor>&indices, const std::vector<tensor>&values, const std::vector<tensor>&shapes, const std::vector<tensor>&dense_inputs, const tensor& sep, const std::vector<datatype>& sparse_types, const std::vector<datatype>& dense_types) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseCrossV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> indices_handles; indices_handles.reserve(indices.size());
    std::transform(indices.begin(), indices.end(), std::back_inserter(indices_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), indices_handles.data(), static_cast<int>(indices.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> values_handles; values_handles.reserve(values.size());
    std::transform(values.begin(), values.end(), std::back_inserter(values_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), values_handles.data(), static_cast<int>(values.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> shapes_handles; shapes_handles.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), shapes_handles.data(), static_cast<int>(shapes.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_inputs_handles; dense_inputs_handles.reserve(dense_inputs.size());
    std::transform(dense_inputs.begin(), dense_inputs.end(), std::back_inserter(dense_inputs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), dense_inputs_handles.data(), static_cast<int>(dense_inputs.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sep.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", indices.size());
    TFE_OpSetAttrTypeList(op.get(), "sparse_types", reinterpret_cast<const enum TF_DataType *>(sparse_types.data()), static_cast<int>(sparse_types.size()));
    TFE_OpSetAttrTypeList(op.get(), "dense_types", reinterpret_cast<const enum TF_DataType *>(dense_types.data()), static_cast<int>(dense_types.size()));

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # SparseDenseCwiseAdd
# Inputs:
*    sp_indices
*    sp_values
*    sp_shape
*    dense

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor sparse_dense_cwise_add(const tensor& sp_indices, const tensor& sp_values, const tensor& sp_shape, const tensor& dense) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseDenseCwiseAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sp_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sp_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sp_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dense.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseDenseCwiseDiv
# Inputs:
*    sp_indices
*    sp_values
*    sp_shape
*    dense

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor sparse_dense_cwise_div(const tensor& sp_indices, const tensor& sp_values, const tensor& sp_shape, const tensor& dense) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseDenseCwiseDiv", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sp_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sp_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sp_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dense.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseDenseCwiseMul
# Inputs:
*    sp_indices
*    sp_values
*    sp_shape
*    dense

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor sparse_dense_cwise_mul(const tensor& sp_indices, const tensor& sp_values, const tensor& sp_shape, const tensor& dense) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseDenseCwiseMul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sp_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sp_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sp_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dense.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseFillEmptyRows
# Inputs:
*    indices
*    values
*    dense_shape
*    default_value

# Attributes:
*    
# Outputs:
*    output_indices
*    output_values
*    empty_row_indicator
*    reverse_index_map

*/
inline std::vector<tensor> sparse_fill_empty_rows(const tensor& indices, const tensor& values, const tensor& dense_shape, const tensor& default_value) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseFillEmptyRows", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dense_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), default_value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 4;
    TFE_TensorHandle* res[4] = { nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]), };
}

/* # SparseFillEmptyRowsGrad
# Inputs:
*    reverse_index_map
*    grad_values

# Attributes:
*    
# Outputs:
*    d_values
*    d_default_value

*/
inline std::vector<tensor> sparse_fill_empty_rows_grad(const tensor& reverse_index_map, const tensor& grad_values) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseFillEmptyRowsGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reverse_index_map.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # SparseMatMul
# Inputs:
*    a
*    b

# Attributes:
*    transpose_a
*    transpose_b
*    a_is_sparse
*    b_is_sparse
*    Ta
*    Tb

# Outputs:
*    product

*/
inline tensor sparse_mat_mul(const tensor& a, const tensor& b, bool transpose_a=false, bool transpose_b=false, bool a_is_sparse=false, bool b_is_sparse=false, datatype Ta=static_cast<datatype>(1), datatype Tb=static_cast<datatype>(1)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseMatMul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "transpose_a", (unsigned char)transpose_a);
    TFE_OpSetAttrBool(op.get(), "transpose_b", (unsigned char)transpose_b);
    TFE_OpSetAttrBool(op.get(), "a_is_sparse", (unsigned char)a_is_sparse);
    TFE_OpSetAttrBool(op.get(), "b_is_sparse", (unsigned char)b_is_sparse);
    TFE_OpSetAttrType(op.get(), "Ta", Ta);
    TFE_OpSetAttrType(op.get(), "Tb", Tb);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseMatrixAdd
# Inputs:
*    a
*    b
*    alpha
*    beta

# Attributes:
*    
# Outputs:
*    c

*/
inline tensor sparse_matrix_add(const tensor& a, const tensor& b, const tensor& alpha, const tensor& beta) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseMatrixAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alpha.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseMatrixMatMul
# Inputs:
*    a
*    b

# Attributes:
*    transpose_a
*    transpose_b
*    adjoint_a
*    adjoint_b
*    transpose_output
*    conjugate_output

# Outputs:
*    output

*/
inline tensor sparse_matrix_mat_mul(const tensor& a, const tensor& b, bool transpose_a=false, bool transpose_b=false, bool adjoint_a=false, bool adjoint_b=false, bool transpose_output=false, bool conjugate_output=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseMatrixMatMul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "transpose_a", (unsigned char)transpose_a);
    TFE_OpSetAttrBool(op.get(), "transpose_b", (unsigned char)transpose_b);
    TFE_OpSetAttrBool(op.get(), "adjoint_a", (unsigned char)adjoint_a);
    TFE_OpSetAttrBool(op.get(), "adjoint_b", (unsigned char)adjoint_b);
    TFE_OpSetAttrBool(op.get(), "transpose_output", (unsigned char)transpose_output);
    TFE_OpSetAttrBool(op.get(), "conjugate_output", (unsigned char)conjugate_output);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseMatrixMul
# Inputs:
*    a
*    b

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor sparse_matrix_mul(const tensor& a, const tensor& b) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseMatrixMul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseMatrixNNZ
# Inputs:
*    sparse_matrix

# Attributes:
*    
# Outputs:
*    nnz

*/
inline tensor sparse_matrix_n_n_z(const tensor& sparse_matrix) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseMatrixNNZ", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sparse_matrix.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseMatrixOrderingAMD
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor sparse_matrix_ordering_a_m_d(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseMatrixOrderingAMD", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseMatrixSoftmax
# Inputs:
*    logits

# Attributes:
*    type

# Outputs:
*    softmax

*/
inline tensor sparse_matrix_softmax(const tensor& logits, datatype type) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseMatrixSoftmax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), logits.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "type", type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseMatrixSoftmaxGrad
# Inputs:
*    softmax
*    grad_softmax

# Attributes:
*    type

# Outputs:
*    gradient

*/
inline tensor sparse_matrix_softmax_grad(const tensor& softmax, const tensor& grad_softmax, datatype type) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseMatrixSoftmaxGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), softmax.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad_softmax.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "type", type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseMatrixSparseCholesky
# Inputs:
*    input
*    permutation

# Attributes:
*    type

# Outputs:
*    output

*/
inline tensor sparse_matrix_sparse_cholesky(const tensor& input, const tensor& permutation, datatype type) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseMatrixSparseCholesky", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), permutation.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "type", type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseMatrixSparseMatMul
# Inputs:
*    a
*    b

# Attributes:
*    type
*    transpose_a
*    transpose_b
*    adjoint_a
*    adjoint_b

# Outputs:
*    c

*/
inline tensor sparse_matrix_sparse_mat_mul(const tensor& a, const tensor& b, datatype type, bool transpose_a=false, bool transpose_b=false, bool adjoint_a=false, bool adjoint_b=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseMatrixSparseMatMul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "type", type);
    TFE_OpSetAttrBool(op.get(), "transpose_a", (unsigned char)transpose_a);
    TFE_OpSetAttrBool(op.get(), "transpose_b", (unsigned char)transpose_b);
    TFE_OpSetAttrBool(op.get(), "adjoint_a", (unsigned char)adjoint_a);
    TFE_OpSetAttrBool(op.get(), "adjoint_b", (unsigned char)adjoint_b);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseMatrixTranspose
# Inputs:
*    input

# Attributes:
*    type
*    conjugate

# Outputs:
*    output

*/
inline tensor sparse_matrix_transpose(const tensor& input, datatype type, bool conjugate=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseMatrixTranspose", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "type", type);
    TFE_OpSetAttrBool(op.get(), "conjugate", (unsigned char)conjugate);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseMatrixZeros
# Inputs:
*    dense_shape

# Attributes:
*    type

# Outputs:
*    sparse_matrix

*/
inline tensor sparse_matrix_zeros(const tensor& dense_shape, datatype type) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseMatrixZeros", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), dense_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "type", type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseReduceMax
# Inputs:
*    input_indices
*    input_values
*    input_shape
*    reduction_axes

# Attributes:
*    keep_dims

# Outputs:
*    output

*/
inline tensor sparse_reduce_max(const tensor& input_indices, const tensor& input_values, const tensor& input_shape, const tensor& reduction_axes, bool keep_dims=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseReduceMax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reduction_axes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "keep_dims", (unsigned char)keep_dims);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseReduceMaxSparse
# Inputs:
*    input_indices
*    input_values
*    input_shape
*    reduction_axes

# Attributes:
*    keep_dims

# Outputs:
*    output_indices
*    output_values
*    output_shape

*/
inline std::vector<tensor> sparse_reduce_max_sparse(const tensor& input_indices, const tensor& input_values, const tensor& input_shape, const tensor& reduction_axes, bool keep_dims=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseReduceMaxSparse", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reduction_axes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "keep_dims", (unsigned char)keep_dims);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # SparseReduceSum
# Inputs:
*    input_indices
*    input_values
*    input_shape
*    reduction_axes

# Attributes:
*    keep_dims

# Outputs:
*    output

*/
inline tensor sparse_reduce_sum(const tensor& input_indices, const tensor& input_values, const tensor& input_shape, const tensor& reduction_axes, bool keep_dims=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseReduceSum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reduction_axes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "keep_dims", (unsigned char)keep_dims);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseReduceSumSparse
# Inputs:
*    input_indices
*    input_values
*    input_shape
*    reduction_axes

# Attributes:
*    keep_dims

# Outputs:
*    output_indices
*    output_values
*    output_shape

*/
inline std::vector<tensor> sparse_reduce_sum_sparse(const tensor& input_indices, const tensor& input_values, const tensor& input_shape, const tensor& reduction_axes, bool keep_dims=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseReduceSumSparse", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reduction_axes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "keep_dims", (unsigned char)keep_dims);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # SparseReorder
# Inputs:
*    input_indices
*    input_values
*    input_shape

# Attributes:
*    
# Outputs:
*    output_indices
*    output_values

*/
inline std::vector<tensor> sparse_reorder(const tensor& input_indices, const tensor& input_values, const tensor& input_shape) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseReorder", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # SparseReshape
# Inputs:
*    input_indices
*    input_shape
*    new_shape

# Attributes:
*    
# Outputs:
*    output_indices
*    output_shape

*/
inline std::vector<tensor> sparse_reshape(const tensor& input_indices, const tensor& input_shape, const tensor& new_shape) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseReshape", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), new_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # SparseSegmentMean
# Inputs:
*    data
*    indices
*    segment_ids

# Attributes:
*    Tidx
*    Tsegmentids
*    sparse_gradient

# Outputs:
*    output

*/
inline tensor sparse_segment_mean(const tensor& data, const tensor& indices, const tensor& segment_ids, datatype Tidx=static_cast<datatype>(3), datatype Tsegmentids=static_cast<datatype>(3), bool sparse_gradient=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSegmentMean", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrType(op.get(), "Tsegmentids", Tsegmentids);
    TFE_OpSetAttrBool(op.get(), "sparse_gradient", (unsigned char)sparse_gradient);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseSegmentMeanGrad
# Inputs:
*    grad
*    indices
*    segment_ids
*    output_dim0

# Attributes:
*    Tidx
*    Tsegmentids

# Outputs:
*    output

*/
inline tensor sparse_segment_mean_grad(const tensor& grad, const tensor& indices, const tensor& segment_ids, const tensor& output_dim0, datatype Tidx=static_cast<datatype>(3), datatype Tsegmentids=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSegmentMeanGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_dim0.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrType(op.get(), "Tsegmentids", Tsegmentids);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseSegmentMeanGradV2
# Inputs:
*    grad
*    indices
*    segment_ids
*    dense_output_dim0

# Attributes:
*    Tidx
*    Tsegmentids

# Outputs:
*    output
*    sorted_unique_indices

*/
inline std::vector<tensor> sparse_segment_mean_grad_v2(const tensor& grad, const tensor& indices, const tensor& segment_ids, const tensor& dense_output_dim0, datatype Tidx=static_cast<datatype>(3), datatype Tsegmentids=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSegmentMeanGradV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dense_output_dim0.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrType(op.get(), "Tsegmentids", Tsegmentids);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # SparseSegmentMeanWithNumSegments
# Inputs:
*    data
*    indices
*    segment_ids
*    num_segments

# Attributes:
*    Tidx
*    Tnumsegments
*    Tsegmentids
*    sparse_gradient

# Outputs:
*    output

*/
inline tensor sparse_segment_mean_with_num_segments(const tensor& data, const tensor& indices, const tensor& segment_ids, const tensor& num_segments, datatype Tidx=static_cast<datatype>(3), datatype Tnumsegments=static_cast<datatype>(3), datatype Tsegmentids=static_cast<datatype>(3), bool sparse_gradient=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSegmentMeanWithNumSegments", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_segments.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrType(op.get(), "Tnumsegments", Tnumsegments);
    TFE_OpSetAttrType(op.get(), "Tsegmentids", Tsegmentids);
    TFE_OpSetAttrBool(op.get(), "sparse_gradient", (unsigned char)sparse_gradient);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseSegmentSqrtN
# Inputs:
*    data
*    indices
*    segment_ids

# Attributes:
*    Tidx
*    Tsegmentids
*    sparse_gradient

# Outputs:
*    output

*/
inline tensor sparse_segment_sqrt_n(const tensor& data, const tensor& indices, const tensor& segment_ids, datatype Tidx=static_cast<datatype>(3), datatype Tsegmentids=static_cast<datatype>(3), bool sparse_gradient=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSegmentSqrtN", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrType(op.get(), "Tsegmentids", Tsegmentids);
    TFE_OpSetAttrBool(op.get(), "sparse_gradient", (unsigned char)sparse_gradient);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseSegmentSqrtNGrad
# Inputs:
*    grad
*    indices
*    segment_ids
*    output_dim0

# Attributes:
*    Tidx
*    Tsegmentids

# Outputs:
*    output

*/
inline tensor sparse_segment_sqrt_n_grad(const tensor& grad, const tensor& indices, const tensor& segment_ids, const tensor& output_dim0, datatype Tidx=static_cast<datatype>(3), datatype Tsegmentids=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSegmentSqrtNGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_dim0.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrType(op.get(), "Tsegmentids", Tsegmentids);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseSegmentSqrtNGradV2
# Inputs:
*    grad
*    indices
*    segment_ids
*    dense_output_dim0

# Attributes:
*    Tidx
*    Tsegmentids

# Outputs:
*    output
*    sorted_unique_indices

*/
inline std::vector<tensor> sparse_segment_sqrt_n_grad_v2(const tensor& grad, const tensor& indices, const tensor& segment_ids, const tensor& dense_output_dim0, datatype Tidx=static_cast<datatype>(3), datatype Tsegmentids=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSegmentSqrtNGradV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dense_output_dim0.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrType(op.get(), "Tsegmentids", Tsegmentids);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # SparseSegmentSqrtNWithNumSegments
# Inputs:
*    data
*    indices
*    segment_ids
*    num_segments

# Attributes:
*    Tidx
*    Tnumsegments
*    Tsegmentids
*    sparse_gradient

# Outputs:
*    output

*/
inline tensor sparse_segment_sqrt_n_with_num_segments(const tensor& data, const tensor& indices, const tensor& segment_ids, const tensor& num_segments, datatype Tidx=static_cast<datatype>(3), datatype Tnumsegments=static_cast<datatype>(3), datatype Tsegmentids=static_cast<datatype>(3), bool sparse_gradient=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSegmentSqrtNWithNumSegments", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_segments.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrType(op.get(), "Tnumsegments", Tnumsegments);
    TFE_OpSetAttrType(op.get(), "Tsegmentids", Tsegmentids);
    TFE_OpSetAttrBool(op.get(), "sparse_gradient", (unsigned char)sparse_gradient);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseSegmentSum
# Inputs:
*    data
*    indices
*    segment_ids

# Attributes:
*    Tidx
*    Tsegmentids
*    sparse_gradient

# Outputs:
*    output

*/
inline tensor sparse_segment_sum(const tensor& data, const tensor& indices, const tensor& segment_ids, datatype Tidx=static_cast<datatype>(3), datatype Tsegmentids=static_cast<datatype>(3), bool sparse_gradient=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSegmentSum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrType(op.get(), "Tsegmentids", Tsegmentids);
    TFE_OpSetAttrBool(op.get(), "sparse_gradient", (unsigned char)sparse_gradient);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseSegmentSumGrad
# Inputs:
*    grad
*    indices
*    segment_ids
*    output_dim0

# Attributes:
*    Tidx
*    Tsegmentids

# Outputs:
*    output

*/
inline tensor sparse_segment_sum_grad(const tensor& grad, const tensor& indices, const tensor& segment_ids, const tensor& output_dim0, datatype Tidx=static_cast<datatype>(3), datatype Tsegmentids=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSegmentSumGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_dim0.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrType(op.get(), "Tsegmentids", Tsegmentids);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseSegmentSumGradV2
# Inputs:
*    grad
*    indices
*    segment_ids
*    dense_output_dim0

# Attributes:
*    Tidx
*    Tsegmentids

# Outputs:
*    output
*    sorted_unique_indices

*/
inline std::vector<tensor> sparse_segment_sum_grad_v2(const tensor& grad, const tensor& indices, const tensor& segment_ids, const tensor& dense_output_dim0, datatype Tidx=static_cast<datatype>(3), datatype Tsegmentids=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSegmentSumGradV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dense_output_dim0.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrType(op.get(), "Tsegmentids", Tsegmentids);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # SparseSegmentSumWithNumSegments
# Inputs:
*    data
*    indices
*    segment_ids
*    num_segments

# Attributes:
*    Tidx
*    Tnumsegments
*    Tsegmentids
*    sparse_gradient

# Outputs:
*    output

*/
inline tensor sparse_segment_sum_with_num_segments(const tensor& data, const tensor& indices, const tensor& segment_ids, const tensor& num_segments, datatype Tidx=static_cast<datatype>(3), datatype Tnumsegments=static_cast<datatype>(3), datatype Tsegmentids=static_cast<datatype>(3), bool sparse_gradient=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSegmentSumWithNumSegments", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_segments.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrType(op.get(), "Tnumsegments", Tnumsegments);
    TFE_OpSetAttrType(op.get(), "Tsegmentids", Tsegmentids);
    TFE_OpSetAttrBool(op.get(), "sparse_gradient", (unsigned char)sparse_gradient);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseSlice
# Inputs:
*    indices
*    values
*    shape
*    start
*    size

# Attributes:
*    
# Outputs:
*    output_indices
*    output_values
*    output_shape

*/
inline std::vector<tensor> sparse_slice(const tensor& indices, const tensor& values, const tensor& shape, const tensor& start, const tensor& size) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSlice", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), start.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # SparseSliceGrad
# Inputs:
*    backprop_val_grad
*    input_indices
*    input_start
*    output_indices

# Attributes:
*    
# Outputs:
*    val_grad

*/
inline tensor sparse_slice_grad(const tensor& backprop_val_grad, const tensor& input_indices, const tensor& input_start, const tensor& output_indices) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSliceGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), backprop_val_grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_start.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseSoftmax
# Inputs:
*    sp_indices
*    sp_values
*    sp_shape

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor sparse_softmax(const tensor& sp_indices, const tensor& sp_values, const tensor& sp_shape) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSoftmax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sp_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sp_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sp_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseSoftmaxCrossEntropyWithLogits
# Inputs:
*    features
*    labels

# Attributes:
*    Tlabels

# Outputs:
*    loss
*    backprop

*/
inline std::vector<tensor> sparse_softmax_cross_entropy_with_logits(const tensor& features, const tensor& labels, datatype Tlabels=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSoftmaxCrossEntropyWithLogits", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), features.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), labels.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tlabels", Tlabels);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # SparseSparseMaximum
# Inputs:
*    a_indices
*    a_values
*    a_shape
*    b_indices
*    b_values
*    b_shape

# Attributes:
*    
# Outputs:
*    output_indices
*    output_values

*/
inline std::vector<tensor> sparse_sparse_maximum(const tensor& a_indices, const tensor& a_values, const tensor& a_shape, const tensor& b_indices, const tensor& b_values, const tensor& b_shape) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSparseMaximum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), a_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), a_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # SparseSparseMinimum
# Inputs:
*    a_indices
*    a_values
*    a_shape
*    b_indices
*    b_values
*    b_shape

# Attributes:
*    
# Outputs:
*    output_indices
*    output_values

*/
inline std::vector<tensor> sparse_sparse_minimum(const tensor& a_indices, const tensor& a_values, const tensor& a_shape, const tensor& b_indices, const tensor& b_values, const tensor& b_shape) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSparseMinimum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), a_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), a_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # SparseSplit
# Inputs:
*    split_dim
*    indices
*    values
*    shape

# Attributes:
*    num_split

# Outputs:
*    output_indices
*    output_values
*    output_shape

*/
inline std::vector<tensor> sparse_split(const tensor& split_dim, const tensor& indices, const tensor& values, const tensor& shape, int64_t num_split) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSplit", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), split_dim.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_split", num_split);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # SparseTensorDenseAdd
# Inputs:
*    a_indices
*    a_values
*    a_shape
*    b

# Attributes:
*    Tindices

# Outputs:
*    output

*/
inline tensor sparse_tensor_dense_add(const tensor& a_indices, const tensor& a_values, const tensor& a_shape, const tensor& b, datatype Tindices) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseTensorDenseAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), a_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), a_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseTensorDenseMatMul
# Inputs:
*    a_indices
*    a_values
*    a_shape
*    b

# Attributes:
*    Tindices
*    adjoint_a
*    adjoint_b

# Outputs:
*    product

*/
inline tensor sparse_tensor_dense_mat_mul(const tensor& a_indices, const tensor& a_values, const tensor& a_shape, const tensor& b, datatype Tindices=static_cast<datatype>(9), bool adjoint_a=false, bool adjoint_b=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseTensorDenseMatMul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), a_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), a_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "adjoint_a", (unsigned char)adjoint_a);
    TFE_OpSetAttrBool(op.get(), "adjoint_b", (unsigned char)adjoint_b);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseTensorSliceDataset
# Inputs:
*    indices
*    values
*    dense_shape

# Attributes:
*    Tvalues

# Outputs:
*    handle

*/
inline tensor sparse_tensor_slice_dataset(const tensor& indices, const tensor& values, const tensor& dense_shape, datatype Tvalues) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseTensorSliceDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dense_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tvalues", Tvalues);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseTensorToCSRSparseMatrix
# Inputs:
*    indices
*    values
*    dense_shape

# Attributes:
*    
# Outputs:
*    sparse_matrix

*/
inline tensor sparse_tensor_to_c_s_r_sparse_matrix(const tensor& indices, const tensor& values, const tensor& dense_shape) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseTensorToCSRSparseMatrix", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dense_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseToDense
# Inputs:
*    sparse_indices
*    output_shape
*    sparse_values
*    default_value

# Attributes:
*    Tindices
*    validate_indices

# Outputs:
*    dense

*/
inline tensor sparse_to_dense(const tensor& sparse_indices, const tensor& output_shape, const tensor& sparse_values, const tensor& default_value, datatype Tindices, bool validate_indices=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseToDense", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sparse_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sparse_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), default_value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "validate_indices", (unsigned char)validate_indices);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SparseToSparseSetOperation
# Inputs:
*    set1_indices
*    set1_values
*    set1_shape
*    set2_indices
*    set2_values
*    set2_shape

# Attributes:
*    set_operation
*    validate_indices

# Outputs:
*    result_indices
*    result_values
*    result_shape

*/
inline std::vector<tensor> sparse_to_sparse_set_operation(const tensor& set1_indices, const tensor& set1_values, const tensor& set1_shape, const tensor& set2_indices, const tensor& set2_values, const tensor& set2_shape, const std::string& set_operation, bool validate_indices=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseToSparseSetOperation", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), set1_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), set1_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), set1_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), set2_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), set2_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), set2_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "set_operation", (void*) set_operation.c_str(), set_operation.size());
    TFE_OpSetAttrBool(op.get(), "validate_indices", (unsigned char)validate_indices);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # Spence
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor spence(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Spence", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Split
# Inputs:
*    split_dim
*    value

# Attributes:
*    num_split

# Outputs:
*    output

*/
inline tensor split(const tensor& split_dim, const tensor& value, int64_t num_split) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Split", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), split_dim.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_split", num_split);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SplitV
# Inputs:
*    value
*    size_splits
*    split_dim

# Attributes:
*    num_split
*    Tlen

# Outputs:
*    output

*/
inline tensor split_v(const tensor& value, const tensor& size_splits, const tensor& split_dim, int64_t num_split, datatype Tlen=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SplitV", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size_splits.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), split_dim.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_split", num_split);
    TFE_OpSetAttrType(op.get(), "Tlen", Tlen);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SqlDataset
# Inputs:
*    driver_name
*    data_source_name
*    query

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor sql_dataset(const tensor& driver_name, const tensor& data_source_name, const tensor& query, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SqlDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), driver_name.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), data_source_name.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), query.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Sqrt
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor sqrt(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Sqrt", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SqrtGrad
# Inputs:
*    y
*    dy

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor sqrt_grad(const tensor& y, const tensor& dy) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SqrtGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dy.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Square
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor square(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Square", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SquaredDifference
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor squared_difference(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SquaredDifference", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Squeeze
# Inputs:
*    input

# Attributes:
*    squeeze_dims

# Outputs:
*    output

*/
inline tensor squeeze(const tensor& input, const std::vector<int64_t>& squeeze_dims) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Squeeze", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "squeeze_dims", squeeze_dims.data(), static_cast<int>(squeeze_dims.size()));

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Stack
# Inputs:
*    
# Attributes:
*    elem_type
*    stack_name

# Outputs:
*    handle

*/
inline tensor stack(datatype elem_type, const std::string& stack_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Stack", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "elem_type", elem_type);
    TFE_OpSetAttrString(op.get(), "stack_name", (void*) stack_name.c_str(), stack_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StackClose
# Inputs:
*    handle

# Attributes:
*    
# Outputs:
*    
*/
inline void stack_close(const tensor& handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StackClose", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # StackCloseV2
# Inputs:
*    handle

# Attributes:
*    
# Outputs:
*    
*/
inline void stack_close_v2(const tensor& handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StackCloseV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # StackPop
# Inputs:
*    handle

# Attributes:
*    elem_type

# Outputs:
*    elem

*/
inline tensor stack_pop(const tensor& handle, datatype elem_type) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StackPop", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "elem_type", elem_type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StackPopV2
# Inputs:
*    handle

# Attributes:
*    elem_type

# Outputs:
*    elem

*/
inline tensor stack_pop_v2(const tensor& handle, datatype elem_type) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StackPopV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "elem_type", elem_type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StackPush
# Inputs:
*    handle
*    elem

# Attributes:
*    swap_memory

# Outputs:
*    output

*/
inline tensor stack_push(const tensor& handle, const tensor& elem, bool swap_memory=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StackPush", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), elem.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "swap_memory", (unsigned char)swap_memory);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StackPushV2
# Inputs:
*    handle
*    elem

# Attributes:
*    swap_memory

# Outputs:
*    output

*/
inline tensor stack_push_v2(const tensor& handle, const tensor& elem, bool swap_memory=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StackPushV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), elem.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "swap_memory", (unsigned char)swap_memory);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StackV2
# Inputs:
*    max_size

# Attributes:
*    elem_type
*    stack_name

# Outputs:
*    handle

*/
inline tensor stack_v2(const tensor& max_size, datatype elem_type, const std::string& stack_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StackV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), max_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "elem_type", elem_type);
    TFE_OpSetAttrString(op.get(), "stack_name", (void*) stack_name.c_str(), stack_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Stage
# Inputs:
*    values

# Attributes:
*    dtypes
*    capacity
*    memory_limit
*    container
*    shared_name

# Outputs:
*    
*/
inline void stage(const std::vector<tensor>&values, const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Stage", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> values_handles; values_handles.reserve(values.size());
    std::transform(values.begin(), values.end(), std::back_inserter(values_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), values_handles.data(), static_cast<int>(values.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # StageClear
# Inputs:
*    
# Attributes:
*    dtypes
*    capacity
*    memory_limit
*    container
*    shared_name

# Outputs:
*    
*/
inline void stage_clear(const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StageClear", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # StagePeek
# Inputs:
*    index

# Attributes:
*    dtypes
*    capacity
*    memory_limit
*    container
*    shared_name

# Outputs:
*    values

*/
inline tensor stage_peek(const tensor& index, const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StagePeek", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), index.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StageSize
# Inputs:
*    
# Attributes:
*    dtypes
*    capacity
*    memory_limit
*    container
*    shared_name

# Outputs:
*    size

*/
inline tensor stage_size(const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StageSize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatefulPartitionedCall
# Inputs:
*    args

# Attributes:
*    Tin
*    Tout
*    f
*    config
*    config_proto
*    executor_type

# Outputs:
*    output

*/
inline tensor stateful_partitioned_call(const std::vector<tensor>&args, const std::vector<datatype>& Tin, const std::vector<datatype>& Tout, int64_t f, const std::string& config="", const std::string& config_proto="", const std::string& executor_type="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatefulPartitionedCall", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> args_handles; args_handles.reserve(args.size());
    std::transform(args.begin(), args.end(), std::back_inserter(args_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), args_handles.data(), static_cast<int>(args.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Tin", reinterpret_cast<const enum TF_DataType *>(Tin.data()), static_cast<int>(Tin.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tout", reinterpret_cast<const enum TF_DataType *>(Tout.data()), static_cast<int>(Tout.size()));
    TFE_OpSetAttrInt(op.get(), "f", f);
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());
    TFE_OpSetAttrString(op.get(), "config_proto", (void*) config_proto.c_str(), config_proto.size());
    TFE_OpSetAttrString(op.get(), "executor_type", (void*) executor_type.c_str(), executor_type.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatefulRandomBinomial
# Inputs:
*    resource
*    algorithm
*    shape
*    counts
*    probs

# Attributes:
*    S
*    dtype

# Outputs:
*    output

*/
inline tensor stateful_random_binomial(const tensor& resource, const tensor& algorithm, const tensor& shape, const tensor& counts, const tensor& probs, datatype S, datatype dtype=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatefulRandomBinomial", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), algorithm.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), counts.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), probs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "S", S);
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatefulStandardNormal
# Inputs:
*    resource
*    shape

# Attributes:
*    dtype
*    shape_dtype

# Outputs:
*    output

*/
inline tensor stateful_standard_normal(const tensor& resource, const tensor& shape, datatype dtype=static_cast<datatype>(1), datatype shape_dtype=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatefulStandardNormal", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "shape_dtype", shape_dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatefulStandardNormalV2
# Inputs:
*    resource
*    algorithm
*    shape

# Attributes:
*    dtype
*    shape_dtype

# Outputs:
*    output

*/
inline tensor stateful_standard_normal_v2(const tensor& resource, const tensor& algorithm, const tensor& shape, datatype dtype=static_cast<datatype>(1), datatype shape_dtype=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatefulStandardNormalV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), algorithm.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "shape_dtype", shape_dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatefulTruncatedNormal
# Inputs:
*    resource
*    algorithm
*    shape

# Attributes:
*    dtype
*    shape_dtype

# Outputs:
*    output

*/
inline tensor stateful_truncated_normal(const tensor& resource, const tensor& algorithm, const tensor& shape, datatype dtype=static_cast<datatype>(1), datatype shape_dtype=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatefulTruncatedNormal", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), algorithm.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "shape_dtype", shape_dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatefulUniform
# Inputs:
*    resource
*    algorithm
*    shape

# Attributes:
*    dtype
*    shape_dtype

# Outputs:
*    output

*/
inline tensor stateful_uniform(const tensor& resource, const tensor& algorithm, const tensor& shape, datatype dtype=static_cast<datatype>(1), datatype shape_dtype=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatefulUniform", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), algorithm.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "shape_dtype", shape_dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatefulUniformFullInt
# Inputs:
*    resource
*    algorithm
*    shape

# Attributes:
*    dtype
*    shape_dtype

# Outputs:
*    output

*/
inline tensor stateful_uniform_full_int(const tensor& resource, const tensor& algorithm, const tensor& shape, datatype dtype=static_cast<datatype>(23), datatype shape_dtype=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatefulUniformFullInt", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), algorithm.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "shape_dtype", shape_dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatefulUniformInt
# Inputs:
*    resource
*    algorithm
*    shape
*    minval
*    maxval

# Attributes:
*    dtype
*    shape_dtype

# Outputs:
*    output

*/
inline tensor stateful_uniform_int(const tensor& resource, const tensor& algorithm, const tensor& shape, const tensor& minval, const tensor& maxval, datatype dtype=static_cast<datatype>(9), datatype shape_dtype=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatefulUniformInt", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), algorithm.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), minval.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), maxval.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "shape_dtype", shape_dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatelessCase
# Inputs:
*    branch_index
*    input

# Attributes:
*    Tin
*    Tout
*    branches
*    output_shapes

# Outputs:
*    output

*/
inline tensor stateless_case(const tensor& branch_index, const std::vector<tensor>&input, const std::vector<datatype>& Tin, const std::vector<datatype>& Tout, const std::vector<int64_t>& branches, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessCase", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), branch_index.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> input_handles; input_handles.reserve(input.size());
    std::transform(input.begin(), input.end(), std::back_inserter(input_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), input_handles.data(), static_cast<int>(input.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Tin", reinterpret_cast<const enum TF_DataType *>(Tin.data()), static_cast<int>(Tin.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tout", reinterpret_cast<const enum TF_DataType *>(Tout.data()), static_cast<int>(Tout.size()));
    TFE_OpSetAttrIntList(op.get(), "branches", branches.data(), static_cast<int>(branches.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatelessIf
# Inputs:
*    cond
*    input

# Attributes:
*    Tcond
*    Tin
*    Tout
*    then_branch
*    else_branch
*    output_shapes

# Outputs:
*    output

*/
inline tensor stateless_if(const tensor& cond, const std::vector<tensor>&input, datatype Tcond, const std::vector<datatype>& Tin, const std::vector<datatype>& Tout, int64_t then_branch, int64_t else_branch, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessIf", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), cond.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> input_handles; input_handles.reserve(input.size());
    std::transform(input.begin(), input.end(), std::back_inserter(input_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), input_handles.data(), static_cast<int>(input.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tcond", Tcond);
    TFE_OpSetAttrTypeList(op.get(), "Tin", reinterpret_cast<const enum TF_DataType *>(Tin.data()), static_cast<int>(Tin.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tout", reinterpret_cast<const enum TF_DataType *>(Tout.data()), static_cast<int>(Tout.size()));
    TFE_OpSetAttrInt(op.get(), "then_branch", then_branch);
    TFE_OpSetAttrInt(op.get(), "else_branch", else_branch);
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatelessMultinomial
# Inputs:
*    logits
*    num_samples
*    seed

# Attributes:
*    Tseed
*    output_dtype

# Outputs:
*    output

*/
inline tensor stateless_multinomial(const tensor& logits, const tensor& num_samples, const tensor& seed, datatype Tseed=static_cast<datatype>(9), datatype output_dtype=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessMultinomial", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), logits.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_samples.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);
    TFE_OpSetAttrType(op.get(), "output_dtype", output_dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatelessParameterizedTruncatedNormal
# Inputs:
*    shape
*    seed
*    means
*    stddevs
*    minvals
*    maxvals

# Attributes:
*    S
*    dtype
*    Tseed

# Outputs:
*    output

*/
inline tensor stateless_parameterized_truncated_normal(const tensor& shape, const tensor& seed, const tensor& means, const tensor& stddevs, const tensor& minvals, const tensor& maxvals, datatype S, datatype dtype, datatype Tseed=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessParameterizedTruncatedNormal", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), means.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), stddevs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), minvals.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), maxvals.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "S", S);
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatelessRandomBinomial
# Inputs:
*    shape
*    seed
*    counts
*    probs

# Attributes:
*    S
*    Tseed
*    dtype

# Outputs:
*    output

*/
inline tensor stateless_random_binomial(const tensor& shape, const tensor& seed, const tensor& counts, const tensor& probs, datatype S, datatype Tseed=static_cast<datatype>(9), datatype dtype=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomBinomial", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), counts.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), probs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "S", S);
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatelessRandomGammaV2
# Inputs:
*    shape
*    seed
*    alpha

# Attributes:
*    dtype
*    Tseed

# Outputs:
*    output

*/
inline tensor stateless_random_gamma_v2(const tensor& shape, const tensor& seed, const tensor& alpha, datatype dtype, datatype Tseed=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomGammaV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alpha.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatelessRandomGammaV3
# Inputs:
*    shape
*    key
*    counter
*    alg
*    alpha

# Attributes:
*    dtype
*    shape_dtype

# Outputs:
*    output

*/
inline tensor stateless_random_gamma_v3(const tensor& shape, const tensor& key, const tensor& counter, const tensor& alg, const tensor& alpha, datatype dtype, datatype shape_dtype=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomGammaV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), counter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alg.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alpha.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "shape_dtype", shape_dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatelessRandomGetAlg
# Inputs:
*    
# Attributes:
*    
# Outputs:
*    alg

*/
inline tensor stateless_random_get_alg() {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomGetAlg", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatelessRandomGetKeyCounter
# Inputs:
*    seed

# Attributes:
*    Tseed

# Outputs:
*    key
*    counter

*/
inline std::vector<tensor> stateless_random_get_key_counter(const tensor& seed, datatype Tseed=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomGetKeyCounter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), seed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # StatelessRandomGetKeyCounterAlg
# Inputs:
*    seed

# Attributes:
*    Tseed

# Outputs:
*    key
*    counter
*    alg

*/
inline std::vector<tensor> stateless_random_get_key_counter_alg(const tensor& seed, datatype Tseed=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomGetKeyCounterAlg", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), seed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # StatelessRandomNormal
# Inputs:
*    shape
*    seed

# Attributes:
*    dtype
*    Tseed

# Outputs:
*    output

*/
inline tensor stateless_random_normal(const tensor& shape, const tensor& seed, datatype dtype=static_cast<datatype>(1), datatype Tseed=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomNormal", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatelessRandomNormalV2
# Inputs:
*    shape
*    key
*    counter
*    alg

# Attributes:
*    dtype
*    Tshape

# Outputs:
*    output

*/
inline tensor stateless_random_normal_v2(const tensor& shape, const tensor& key, const tensor& counter, const tensor& alg, datatype dtype=static_cast<datatype>(1), datatype Tshape=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomNormalV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), counter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alg.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tshape", Tshape);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatelessRandomPoisson
# Inputs:
*    shape
*    seed
*    lam

# Attributes:
*    Rtype
*    dtype
*    Tseed

# Outputs:
*    output

*/
inline tensor stateless_random_poisson(const tensor& shape, const tensor& seed, const tensor& lam, datatype Rtype, datatype dtype, datatype Tseed=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomPoisson", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lam.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Rtype", Rtype);
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatelessRandomUniform
# Inputs:
*    shape
*    seed

# Attributes:
*    dtype
*    Tseed

# Outputs:
*    output

*/
inline tensor stateless_random_uniform(const tensor& shape, const tensor& seed, datatype dtype=static_cast<datatype>(1), datatype Tseed=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomUniform", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatelessRandomUniformFullInt
# Inputs:
*    shape
*    seed

# Attributes:
*    dtype
*    Tseed

# Outputs:
*    output

*/
inline tensor stateless_random_uniform_full_int(const tensor& shape, const tensor& seed, datatype dtype=static_cast<datatype>(23), datatype Tseed=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomUniformFullInt", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatelessRandomUniformFullIntV2
# Inputs:
*    shape
*    key
*    counter
*    alg

# Attributes:
*    dtype
*    Tshape

# Outputs:
*    output

*/
inline tensor stateless_random_uniform_full_int_v2(const tensor& shape, const tensor& key, const tensor& counter, const tensor& alg, datatype dtype=static_cast<datatype>(23), datatype Tshape=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomUniformFullIntV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), counter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alg.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tshape", Tshape);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatelessRandomUniformInt
# Inputs:
*    shape
*    seed
*    minval
*    maxval

# Attributes:
*    dtype
*    Tseed

# Outputs:
*    output

*/
inline tensor stateless_random_uniform_int(const tensor& shape, const tensor& seed, const tensor& minval, const tensor& maxval, datatype dtype, datatype Tseed=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomUniformInt", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), minval.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), maxval.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatelessRandomUniformIntV2
# Inputs:
*    shape
*    key
*    counter
*    alg
*    minval
*    maxval

# Attributes:
*    dtype
*    Tshape

# Outputs:
*    output

*/
inline tensor stateless_random_uniform_int_v2(const tensor& shape, const tensor& key, const tensor& counter, const tensor& alg, const tensor& minval, const tensor& maxval, datatype dtype, datatype Tshape=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomUniformIntV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), counter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alg.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), minval.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), maxval.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tshape", Tshape);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatelessRandomUniformV2
# Inputs:
*    shape
*    key
*    counter
*    alg

# Attributes:
*    dtype
*    Tshape

# Outputs:
*    output

*/
inline tensor stateless_random_uniform_v2(const tensor& shape, const tensor& key, const tensor& counter, const tensor& alg, datatype dtype=static_cast<datatype>(1), datatype Tshape=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomUniformV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), counter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alg.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tshape", Tshape);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatelessSampleDistortedBoundingBox
# Inputs:
*    image_size
*    bounding_boxes
*    min_object_covered
*    seed

# Attributes:
*    Tseed
*    aspect_ratio_range
*    area_range
*    max_attempts
*    use_image_if_no_bounding_boxes

# Outputs:
*    begin
*    size
*    bboxes

*/
inline std::vector<tensor> stateless_sample_distorted_bounding_box(const tensor& image_size, const tensor& bounding_boxes, const tensor& min_object_covered, const tensor& seed, datatype Tseed, const std::vector<float>& aspect_ratio_range, const std::vector<float>& area_range, int64_t max_attempts=100, bool use_image_if_no_bounding_boxes=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessSampleDistortedBoundingBox", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), image_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bounding_boxes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_object_covered.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);
    TFE_OpSetAttrFloatList(op.get(), "aspect_ratio_range", aspect_ratio_range.data(), static_cast<int>(aspect_ratio_range.size()));
    TFE_OpSetAttrFloatList(op.get(), "area_range", area_range.data(), static_cast<int>(area_range.size()));
    TFE_OpSetAttrInt(op.get(), "max_attempts", max_attempts);
    TFE_OpSetAttrBool(op.get(), "use_image_if_no_bounding_boxes", (unsigned char)use_image_if_no_bounding_boxes);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # StatelessShuffle
# Inputs:
*    value
*    key
*    counter
*    alg

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor stateless_shuffle(const tensor& value, const tensor& key, const tensor& counter, const tensor& alg) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessShuffle", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), counter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alg.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatelessTruncatedNormal
# Inputs:
*    shape
*    seed

# Attributes:
*    dtype
*    Tseed

# Outputs:
*    output

*/
inline tensor stateless_truncated_normal(const tensor& shape, const tensor& seed, datatype dtype=static_cast<datatype>(1), datatype Tseed=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessTruncatedNormal", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatelessTruncatedNormalV2
# Inputs:
*    shape
*    key
*    counter
*    alg

# Attributes:
*    dtype
*    Tshape

# Outputs:
*    output

*/
inline tensor stateless_truncated_normal_v2(const tensor& shape, const tensor& key, const tensor& counter, const tensor& alg, datatype dtype=static_cast<datatype>(1), datatype Tshape=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessTruncatedNormalV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), counter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alg.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tshape", Tshape);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatelessWhile
# Inputs:
*    input

# Attributes:
*    cond
*    body
*    output_shapes
*    parallel_iterations

# Outputs:
*    output

*/
inline tensor stateless_while(const std::vector<tensor>&input, int64_t cond, int64_t body, const std::vector< std::vector<int64_t>>& output_shapes, int64_t parallel_iterations=10) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessWhile", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> input_handles; input_handles.reserve(input.size());
    std::transform(input.begin(), input.end(), std::back_inserter(input_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), input_handles.data(), static_cast<int>(input.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "cond", cond);
    TFE_OpSetAttrInt(op.get(), "body", body);
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "parallel_iterations", parallel_iterations);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StaticRegexFullMatch
# Inputs:
*    input

# Attributes:
*    pattern

# Outputs:
*    output

*/
inline tensor static_regex_full_match(const tensor& input, const std::string& pattern) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StaticRegexFullMatch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "pattern", (void*) pattern.c_str(), pattern.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StaticRegexReplace
# Inputs:
*    input

# Attributes:
*    pattern
*    rewrite
*    replace_global

# Outputs:
*    output

*/
inline tensor static_regex_replace(const tensor& input, const std::string& pattern, const std::string& rewrite, bool replace_global=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StaticRegexReplace", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "pattern", (void*) pattern.c_str(), pattern.size());
    TFE_OpSetAttrString(op.get(), "rewrite", (void*) rewrite.c_str(), rewrite.size());
    TFE_OpSetAttrBool(op.get(), "replace_global", (unsigned char)replace_global);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatsAggregatorHandle
# Inputs:
*    
# Attributes:
*    container
*    shared_name

# Outputs:
*    handle

*/
inline tensor stats_aggregator_handle(const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatsAggregatorHandle", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatsAggregatorHandleV2
# Inputs:
*    
# Attributes:
*    container
*    shared_name

# Outputs:
*    handle

*/
inline tensor stats_aggregator_handle_v2(const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatsAggregatorHandleV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StatsAggregatorSetSummaryWriter
# Inputs:
*    stats_aggregator
*    summary

# Attributes:
*    
# Outputs:
*    
*/
inline void stats_aggregator_set_summary_writer(const tensor& stats_aggregator, const tensor& summary) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatsAggregatorSetSummaryWriter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), stats_aggregator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), summary.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # StatsAggregatorSummary
# Inputs:
*    iterator

# Attributes:
*    
# Outputs:
*    summary

*/
inline tensor stats_aggregator_summary(const tensor& iterator) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatsAggregatorSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), iterator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StopGradient
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor stop_gradient(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StopGradient", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StoreMinibatchStatisticsInFdo
# Inputs:
*    program_key
*    max_ids
*    max_uniques

# Attributes:
*    sample_count
*    num_replica
*    feature_width
*    num_sc_per_chip
*    table_name
*    mini_batch_splits

# Outputs:
*    
*/
inline void store_minibatch_statistics_in_fdo(const tensor& program_key, const tensor& max_ids, const tensor& max_uniques, int64_t sample_count, int64_t num_replica, int64_t feature_width, int64_t num_sc_per_chip, const std::string& table_name, const std::string& mini_batch_splits) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StoreMinibatchStatisticsInFdo", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), program_key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_uniques.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "sample_count", sample_count);
    TFE_OpSetAttrInt(op.get(), "num_replica", num_replica);
    TFE_OpSetAttrInt(op.get(), "feature_width", feature_width);
    TFE_OpSetAttrInt(op.get(), "num_sc_per_chip", num_sc_per_chip);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "mini_batch_splits", (void*) mini_batch_splits.c_str(), mini_batch_splits.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # StridedSlice
# Inputs:
*    input
*    begin
*    end
*    strides

# Attributes:
*    Index
*    begin_mask
*    end_mask
*    ellipsis_mask
*    new_axis_mask
*    shrink_axis_mask

# Outputs:
*    output

*/
inline tensor strided_slice(const tensor& input, const tensor& begin, const tensor& end, const tensor& strides, datatype Index, int64_t begin_mask=0, int64_t end_mask=0, int64_t ellipsis_mask=0, int64_t new_axis_mask=0, int64_t shrink_axis_mask=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StridedSlice", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), begin.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), end.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), strides.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Index", Index);
    TFE_OpSetAttrInt(op.get(), "begin_mask", begin_mask);
    TFE_OpSetAttrInt(op.get(), "end_mask", end_mask);
    TFE_OpSetAttrInt(op.get(), "ellipsis_mask", ellipsis_mask);
    TFE_OpSetAttrInt(op.get(), "new_axis_mask", new_axis_mask);
    TFE_OpSetAttrInt(op.get(), "shrink_axis_mask", shrink_axis_mask);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StridedSliceAssign
# Inputs:
*    ref
*    begin
*    end
*    strides
*    value

# Attributes:
*    Index
*    begin_mask
*    end_mask
*    ellipsis_mask
*    new_axis_mask
*    shrink_axis_mask

# Outputs:
*    output_ref

*/
inline tensor strided_slice_assign(const tensor& ref, const tensor& begin, const tensor& end, const tensor& strides, const tensor& value, datatype Index, int64_t begin_mask=0, int64_t end_mask=0, int64_t ellipsis_mask=0, int64_t new_axis_mask=0, int64_t shrink_axis_mask=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StridedSliceAssign", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), begin.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), end.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), strides.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Index", Index);
    TFE_OpSetAttrInt(op.get(), "begin_mask", begin_mask);
    TFE_OpSetAttrInt(op.get(), "end_mask", end_mask);
    TFE_OpSetAttrInt(op.get(), "ellipsis_mask", ellipsis_mask);
    TFE_OpSetAttrInt(op.get(), "new_axis_mask", new_axis_mask);
    TFE_OpSetAttrInt(op.get(), "shrink_axis_mask", shrink_axis_mask);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StridedSliceGrad
# Inputs:
*    shape
*    begin
*    end
*    strides
*    dy

# Attributes:
*    Index
*    begin_mask
*    end_mask
*    ellipsis_mask
*    new_axis_mask
*    shrink_axis_mask

# Outputs:
*    output

*/
inline tensor strided_slice_grad(const tensor& shape, const tensor& begin, const tensor& end, const tensor& strides, const tensor& dy, datatype Index, int64_t begin_mask=0, int64_t end_mask=0, int64_t ellipsis_mask=0, int64_t new_axis_mask=0, int64_t shrink_axis_mask=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StridedSliceGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), begin.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), end.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), strides.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dy.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Index", Index);
    TFE_OpSetAttrInt(op.get(), "begin_mask", begin_mask);
    TFE_OpSetAttrInt(op.get(), "end_mask", end_mask);
    TFE_OpSetAttrInt(op.get(), "ellipsis_mask", ellipsis_mask);
    TFE_OpSetAttrInt(op.get(), "new_axis_mask", new_axis_mask);
    TFE_OpSetAttrInt(op.get(), "shrink_axis_mask", shrink_axis_mask);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StringFormat
# Inputs:
*    inputs

# Attributes:
*    template
*    placeholder
*    summarize

# Outputs:
*    output

*/
inline tensor string_format(const std::vector<tensor>&inputs, const std::string& template_arg="%s", const std::string& placeholder="%s", int64_t summarize=3) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StringFormat", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), static_cast<int>(inputs.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "template", (void*) template_arg.c_str(), template_arg.size());
    TFE_OpSetAttrString(op.get(), "placeholder", (void*) placeholder.c_str(), placeholder.size());
    TFE_OpSetAttrInt(op.get(), "summarize", summarize);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StringJoin
# Inputs:
*    inputs

# Attributes:
*    N
*    separator

# Outputs:
*    output

*/
inline tensor string_join(const std::vector<tensor>&inputs, const std::string& separator="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StringJoin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), static_cast<int>(inputs.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", inputs.size());
    TFE_OpSetAttrString(op.get(), "separator", (void*) separator.c_str(), separator.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StringLength
# Inputs:
*    input

# Attributes:
*    unit

# Outputs:
*    output

*/
inline tensor string_length(const tensor& input, const std::string& unit="BYTE") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StringLength", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "unit", (void*) unit.c_str(), unit.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StringLower
# Inputs:
*    input

# Attributes:
*    encoding

# Outputs:
*    output

*/
inline tensor string_lower(const tensor& input, const std::string& encoding="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StringLower", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "encoding", (void*) encoding.c_str(), encoding.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StringNGrams
# Inputs:
*    data
*    data_splits

# Attributes:
*    separator
*    ngram_widths
*    left_pad
*    right_pad
*    pad_width
*    preserve_short_sequences
*    Tsplits

# Outputs:
*    ngrams
*    ngrams_splits

*/
inline std::vector<tensor> string_n_grams(const tensor& data, const tensor& data_splits, const std::string& separator, const std::vector<int64_t>& ngram_widths, const std::string& left_pad, const std::string& right_pad, int64_t pad_width, bool preserve_short_sequences, datatype Tsplits=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StringNGrams", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), data_splits.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "separator", (void*) separator.c_str(), separator.size());
    TFE_OpSetAttrIntList(op.get(), "ngram_widths", ngram_widths.data(), static_cast<int>(ngram_widths.size()));
    TFE_OpSetAttrString(op.get(), "left_pad", (void*) left_pad.c_str(), left_pad.size());
    TFE_OpSetAttrString(op.get(), "right_pad", (void*) right_pad.c_str(), right_pad.size());
    TFE_OpSetAttrInt(op.get(), "pad_width", pad_width);
    TFE_OpSetAttrBool(op.get(), "preserve_short_sequences", (unsigned char)preserve_short_sequences);
    TFE_OpSetAttrType(op.get(), "Tsplits", Tsplits);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # StringSplit
# Inputs:
*    input
*    delimiter

# Attributes:
*    skip_empty

# Outputs:
*    indices
*    values
*    shape

*/
inline std::vector<tensor> string_split(const tensor& input, const tensor& delimiter, bool skip_empty=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StringSplit", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), delimiter.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "skip_empty", (unsigned char)skip_empty);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # StringSplitV2
# Inputs:
*    input
*    sep

# Attributes:
*    maxsplit

# Outputs:
*    indices
*    values
*    shape

*/
inline std::vector<tensor> string_split_v2(const tensor& input, const tensor& sep, int64_t maxsplit=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StringSplitV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sep.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "maxsplit", maxsplit);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # StringStrip
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor string_strip(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StringStrip", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StringToHashBucket
# Inputs:
*    string_tensor

# Attributes:
*    num_buckets

# Outputs:
*    output

*/
inline tensor string_to_hash_bucket(const tensor& string_input_tensor, int64_t num_buckets) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StringToHashBucket", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), string_input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_buckets", num_buckets);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StringToHashBucketFast
# Inputs:
*    input

# Attributes:
*    num_buckets

# Outputs:
*    output

*/
inline tensor string_to_hash_bucket_fast(const tensor& input, int64_t num_buckets) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StringToHashBucketFast", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_buckets", num_buckets);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StringToHashBucketStrong
# Inputs:
*    input

# Attributes:
*    num_buckets
*    key

# Outputs:
*    output

*/
inline tensor string_to_hash_bucket_strong(const tensor& input, int64_t num_buckets, const std::vector<int64_t>& key) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StringToHashBucketStrong", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_buckets", num_buckets);
    TFE_OpSetAttrIntList(op.get(), "key", key.data(), static_cast<int>(key.size()));

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StringToNumber
# Inputs:
*    string_tensor

# Attributes:
*    out_type

# Outputs:
*    output

*/
inline tensor string_to_number(const tensor& string_input_tensor, datatype out_type=static_cast<datatype>(1)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StringToNumber", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), string_input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # StringUpper
# Inputs:
*    input

# Attributes:
*    encoding

# Outputs:
*    output

*/
inline tensor string_upper(const tensor& input, const std::string& encoding="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StringUpper", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "encoding", (void*) encoding.c_str(), encoding.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Sub
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor sub(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Sub", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Substr
# Inputs:
*    input
*    pos
*    len

# Attributes:
*    unit

# Outputs:
*    output

*/
inline tensor substr(const tensor& input, const tensor& pos, const tensor& len, const std::string& unit="BYTE") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Substr", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), pos.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), len.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "unit", (void*) unit.c_str(), unit.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Sum
# Inputs:
*    input
*    reduction_indices

# Attributes:
*    keep_dims
*    Tidx

# Outputs:
*    output

*/
inline tensor sum(const tensor& input, const tensor& reduction_indices, bool keep_dims=false, datatype Tidx=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Sum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reduction_indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "keep_dims", (unsigned char)keep_dims);
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SummaryWriter
# Inputs:
*    
# Attributes:
*    shared_name
*    container

# Outputs:
*    writer

*/
inline tensor summary_writer(const std::string& shared_name="", const std::string& container="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SummaryWriter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Svd
# Inputs:
*    input

# Attributes:
*    compute_uv
*    full_matrices

# Outputs:
*    s
*    u
*    v

*/
inline std::vector<tensor> svd(const tensor& input, bool compute_uv=true, bool full_matrices=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Svd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "compute_uv", (unsigned char)compute_uv);
    TFE_OpSetAttrBool(op.get(), "full_matrices", (unsigned char)full_matrices);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # Switch
# Inputs:
*    data
*    pred

# Attributes:
*    
# Outputs:
*    output_false
*    output_true

*/
inline std::vector<tensor> tfe_switch(const tensor& data, const tensor& pred) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Switch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), pred.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # SymbolicGradient
# Inputs:
*    input

# Attributes:
*    Tin
*    Tout
*    f

# Outputs:
*    output

*/
inline tensor symbolic_gradient(const std::vector<tensor>&input, const std::vector<datatype>& Tin, const std::vector<datatype>& Tout, int64_t f) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SymbolicGradient", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> input_handles; input_handles.reserve(input.size());
    std::transform(input.begin(), input.end(), std::back_inserter(input_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), input_handles.data(), static_cast<int>(input.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Tin", reinterpret_cast<const enum TF_DataType *>(Tin.data()), static_cast<int>(Tin.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tout", reinterpret_cast<const enum TF_DataType *>(Tout.data()), static_cast<int>(Tout.size()));
    TFE_OpSetAttrInt(op.get(), "f", f);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # SyncDevice
# Inputs:
*    
# Attributes:
*    
# Outputs:
*    
*/
inline void sync_device() {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SyncDevice", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # TFRecordDataset
# Inputs:
*    filenames
*    compression_type
*    buffer_size

# Attributes:
*    metadata

# Outputs:
*    handle

*/
inline tensor t_f_record_dataset(const tensor& filenames, const tensor& compression_type, const tensor& buffer_size, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TFRecordDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filenames.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), compression_type.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TFRecordDatasetV2
# Inputs:
*    filenames
*    compression_type
*    buffer_size
*    byte_offsets

# Attributes:
*    metadata

# Outputs:
*    handle

*/
inline tensor t_f_record_dataset_v2(const tensor& filenames, const tensor& compression_type, const tensor& buffer_size, const tensor& byte_offsets, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TFRecordDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filenames.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), compression_type.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), byte_offsets.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TFRecordReader
# Inputs:
*    
# Attributes:
*    container
*    shared_name
*    compression_type

# Outputs:
*    reader_handle

*/
inline tensor t_f_record_reader(const std::string& container="", const std::string& shared_name="", const std::string& compression_type="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TFRecordReader", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrString(op.get(), "compression_type", (void*) compression_type.c_str(), compression_type.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TFRecordReaderV2
# Inputs:
*    
# Attributes:
*    container
*    shared_name
*    compression_type

# Outputs:
*    reader_handle

*/
inline tensor t_f_record_reader_v2(const std::string& container="", const std::string& shared_name="", const std::string& compression_type="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TFRecordReaderV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrString(op.get(), "compression_type", (void*) compression_type.c_str(), compression_type.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TPUAnnotateTensorsWithDynamicShape
# Inputs:
*    tensors

# Attributes:
*    
# Outputs:
*    tpu_tensors

*/
inline tensor t_p_u_annotate_tensors_with_dynamic_shape(const std::vector<tensor>&tensors) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TPUAnnotateTensorsWithDynamicShape", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> tensors_handles; tensors_handles.reserve(tensors.size());
    std::transform(tensors.begin(), tensors.end(), std::back_inserter(tensors_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), tensors_handles.data(), static_cast<int>(tensors.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TPUCompilationResult
# Inputs:
*    
# Attributes:
*    
# Outputs:
*    output

*/
inline tensor t_p_u_compilation_result() {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TPUCompilationResult", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TPUCopyWithDynamicShape
# Inputs:
*    tensors
*    unpadded_sizes

# Attributes:
*    N

# Outputs:
*    tpu_tensors

*/
inline tensor t_p_u_copy_with_dynamic_shape(const std::vector<tensor>&tensors, const std::vector<tensor>&unpadded_sizes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TPUCopyWithDynamicShape", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> tensors_handles; tensors_handles.reserve(tensors.size());
    std::transform(tensors.begin(), tensors.end(), std::back_inserter(tensors_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), tensors_handles.data(), static_cast<int>(tensors.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> unpadded_sizes_handles; unpadded_sizes_handles.reserve(unpadded_sizes.size());
    std::transform(unpadded_sizes.begin(), unpadded_sizes.end(), std::back_inserter(unpadded_sizes_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), unpadded_sizes_handles.data(), static_cast<int>(unpadded_sizes.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", unpadded_sizes.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TPUEmbeddingActivations
# Inputs:
*    embedding_variable
*    sliced_activations

# Attributes:
*    table_id
*    lookup_id

# Outputs:
*    output

*/
inline tensor t_p_u_embedding_activations(const tensor& embedding_variable, const tensor& sliced_activations, int64_t table_id, int64_t lookup_id) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TPUEmbeddingActivations", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), embedding_variable.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sliced_activations.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrInt(op.get(), "lookup_id", lookup_id);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TPUOrdinalSelector
# Inputs:
*    
# Attributes:
*    
# Outputs:
*    device_ordinals

*/
inline tensor t_p_u_ordinal_selector() {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TPUOrdinalSelector", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TPUPartitionedCall
# Inputs:
*    args
*    device_ordinal

# Attributes:
*    Tin
*    Tout
*    f
*    autotuner_thresh

# Outputs:
*    output

*/
inline tensor t_p_u_partitioned_call(const std::vector<tensor>&args, const tensor& device_ordinal, const std::vector<datatype>& Tin, const std::vector<datatype>& Tout, int64_t f, int64_t autotuner_thresh=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TPUPartitionedCall", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> args_handles; args_handles.reserve(args.size());
    std::transform(args.begin(), args.end(), std::back_inserter(args_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), args_handles.data(), static_cast<int>(args.size()), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), device_ordinal.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Tin", reinterpret_cast<const enum TF_DataType *>(Tin.data()), static_cast<int>(Tin.size()));
    TFE_OpSetAttrTypeList(op.get(), "Tout", reinterpret_cast<const enum TF_DataType *>(Tout.data()), static_cast<int>(Tout.size()));
    TFE_OpSetAttrInt(op.get(), "f", f);
    TFE_OpSetAttrInt(op.get(), "autotuner_thresh", autotuner_thresh);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TPUPartitionedInput
# Inputs:
*    inputs

# Attributes:
*    N
*    partition_dim

# Outputs:
*    output

*/
inline tensor t_p_u_partitioned_input(const std::vector<tensor>&inputs, int64_t partition_dim=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TPUPartitionedInput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), static_cast<int>(inputs.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", inputs.size());
    TFE_OpSetAttrInt(op.get(), "partition_dim", partition_dim);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TPUPartitionedInputV2
# Inputs:
*    inputs

# Attributes:
*    N
*    partition_dims
*    is_packed

# Outputs:
*    output

*/
inline tensor t_p_u_partitioned_input_v2(const std::vector<tensor>&inputs, const std::vector<int64_t>& partition_dims, bool is_packed=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TPUPartitionedInputV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), static_cast<int>(inputs.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", inputs.size());
    TFE_OpSetAttrIntList(op.get(), "partition_dims", partition_dims.data(), static_cast<int>(partition_dims.size()));
    TFE_OpSetAttrBool(op.get(), "is_packed", (unsigned char)is_packed);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TPUPartitionedOutput
# Inputs:
*    inputs

# Attributes:
*    num_splits
*    partition_dim

# Outputs:
*    output

*/
inline tensor t_p_u_partitioned_output(const tensor& inputs, int64_t num_splits, int64_t partition_dim=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TPUPartitionedOutput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), inputs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_splits", num_splits);
    TFE_OpSetAttrInt(op.get(), "partition_dim", partition_dim);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TPUPartitionedOutputV2
# Inputs:
*    inputs

# Attributes:
*    num_splits
*    partition_dims

# Outputs:
*    output

*/
inline tensor t_p_u_partitioned_output_v2(const tensor& inputs, int64_t num_splits, const std::vector<int64_t>& partition_dims) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TPUPartitionedOutputV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), inputs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_splits", num_splits);
    TFE_OpSetAttrIntList(op.get(), "partition_dims", partition_dims.data(), static_cast<int>(partition_dims.size()));

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TPUReplicateMetadata
# Inputs:
*    
# Attributes:
*    num_replicas
*    device_assignment
*    computation_shape
*    host_compute_core
*    padding_map
*    num_cores_per_replica
*    topology
*    use_tpu
*    step_marker_location
*    allow_soft_placement
*    use_spmd_for_xla_partitioning
*    tpu_compile_options_proto

# Outputs:
*    
*/
inline void t_p_u_replicate_metadata(int64_t num_replicas, const std::vector<int64_t>& device_assignment, const std::vector<int64_t>& computation_shape, const std::vector< std::string>& host_compute_core, const std::vector< std::string>& padding_map, int64_t num_cores_per_replica=1, const std::string& topology="", bool use_tpu=true, const std::string& step_marker_location="STEP_MARK_AT_ENTRY", bool allow_soft_placement=false, bool use_spmd_for_xla_partitioning=false, const std::string& tpu_compile_options_proto="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TPUReplicateMetadata", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_replicas", num_replicas);
    TFE_OpSetAttrIntList(op.get(), "device_assignment", device_assignment.data(), static_cast<int>(device_assignment.size()));
    TFE_OpSetAttrIntList(op.get(), "computation_shape", computation_shape.data(), static_cast<int>(computation_shape.size()));
    
    std::vector<std::size_t> host_compute_core_sizes; host_compute_core_sizes.reserve(host_compute_core.size());
    std::transform(host_compute_core.begin(), host_compute_core.end(), std::back_inserter(host_compute_core_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "host_compute_core", reinterpret_cast<const void *const *>(host_compute_core.data()), host_compute_core_sizes.data(), static_cast<int>(host_compute_core.size()));
    
    
    std::vector<std::size_t> padding_map_sizes; padding_map_sizes.reserve(padding_map.size());
    std::transform(padding_map.begin(), padding_map.end(), std::back_inserter(padding_map_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "padding_map", reinterpret_cast<const void *const *>(padding_map.data()), padding_map_sizes.data(), static_cast<int>(padding_map.size()));
    
    TFE_OpSetAttrInt(op.get(), "num_cores_per_replica", num_cores_per_replica);
    TFE_OpSetAttrString(op.get(), "topology", (void*) topology.c_str(), topology.size());
    TFE_OpSetAttrBool(op.get(), "use_tpu", (unsigned char)use_tpu);
    TFE_OpSetAttrString(op.get(), "step_marker_location", (void*) step_marker_location.c_str(), step_marker_location.size());
    TFE_OpSetAttrBool(op.get(), "allow_soft_placement", (unsigned char)allow_soft_placement);
    TFE_OpSetAttrBool(op.get(), "use_spmd_for_xla_partitioning", (unsigned char)use_spmd_for_xla_partitioning);
    TFE_OpSetAttrString(op.get(), "tpu_compile_options_proto", (void*) tpu_compile_options_proto.c_str(), tpu_compile_options_proto.size());

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # TPUReplicatedInput
# Inputs:
*    inputs

# Attributes:
*    N
*    is_mirrored_variable
*    index
*    is_packed

# Outputs:
*    output

*/
inline tensor t_p_u_replicated_input(const std::vector<tensor>&inputs, bool is_mirrored_variable=false, int64_t index=-1, bool is_packed=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TPUReplicatedInput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), static_cast<int>(inputs.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", inputs.size());
    TFE_OpSetAttrBool(op.get(), "is_mirrored_variable", (unsigned char)is_mirrored_variable);
    TFE_OpSetAttrInt(op.get(), "index", index);
    TFE_OpSetAttrBool(op.get(), "is_packed", (unsigned char)is_packed);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TPUReplicatedOutput
# Inputs:
*    input

# Attributes:
*    num_replicas

# Outputs:
*    outputs

*/
inline tensor t_p_u_replicated_output(const tensor& input, int64_t num_replicas) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TPUReplicatedOutput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_replicas", num_replicas);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TakeDataset
# Inputs:
*    input_dataset
*    count

# Attributes:
*    output_types
*    output_shapes
*    metadata

# Outputs:
*    handle

*/
inline tensor take_dataset(const tensor& input_dataset, const tensor& count, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TakeDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), count.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TakeManySparseFromTensorsMap
# Inputs:
*    sparse_handles

# Attributes:
*    dtype
*    container
*    shared_name

# Outputs:
*    sparse_indices
*    sparse_values
*    sparse_shape

*/
inline std::vector<tensor> take_many_sparse_from_tensors_map(const tensor& sparse_handles, datatype dtype, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TakeManySparseFromTensorsMap", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sparse_handles.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # TakeWhileDataset
# Inputs:
*    input_dataset
*    other_arguments

# Attributes:
*    predicate
*    Targuments
*    output_types
*    output_shapes
*    metadata

# Outputs:
*    handle

*/
inline tensor take_while_dataset(const tensor& input_dataset, const std::vector<tensor>&other_arguments, int64_t predicate, const std::vector<datatype>& Targuments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TakeWhileDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> other_arguments_handles; other_arguments_handles.reserve(other_arguments.size());
    std::transform(other_arguments.begin(), other_arguments.end(), std::back_inserter(other_arguments_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), other_arguments_handles.data(), static_cast<int>(other_arguments.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "predicate", predicate);
    TFE_OpSetAttrTypeList(op.get(), "Targuments", reinterpret_cast<const enum TF_DataType *>(Targuments.data()), static_cast<int>(Targuments.size()));
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Tan
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor tan(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Tan", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Tanh
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor tanh(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Tanh", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TanhGrad
# Inputs:
*    y
*    dy

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor tanh_grad(const tensor& y, const tensor& dy) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TanhGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dy.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TemporaryVariable
# Inputs:
*    
# Attributes:
*    shape
*    dtype
*    var_name

# Outputs:
*    ref

*/
inline tensor temporary_variable(const std::vector<int64_t>& shape, datatype dtype, const std::string& var_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TemporaryVariable", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), static_cast<int>(shape.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrString(op.get(), "var_name", (void*) var_name.c_str(), var_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorArray
# Inputs:
*    size

# Attributes:
*    dtype
*    element_shape
*    dynamic_size
*    clear_after_read
*    tensor_array_name

# Outputs:
*    handle

*/
inline tensor tensor_array(const tensor& size, datatype dtype, const std::vector<int64_t>& element_shape, bool dynamic_size=false, bool clear_after_read=true, const std::string& tensor_array_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArray", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "element_shape", element_shape.data(), static_cast<int>(element_shape.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "dynamic_size", (unsigned char)dynamic_size);
    TFE_OpSetAttrBool(op.get(), "clear_after_read", (unsigned char)clear_after_read);
    TFE_OpSetAttrString(op.get(), "tensor_array_name", (void*) tensor_array_name.c_str(), tensor_array_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorArrayClose
# Inputs:
*    handle

# Attributes:
*    
# Outputs:
*    
*/
inline void tensor_array_close(const tensor& handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayClose", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # TensorArrayCloseV2
# Inputs:
*    handle

# Attributes:
*    
# Outputs:
*    
*/
inline void tensor_array_close_v2(const tensor& handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayCloseV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # TensorArrayCloseV3
# Inputs:
*    handle

# Attributes:
*    
# Outputs:
*    
*/
inline void tensor_array_close_v3(const tensor& handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayCloseV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # TensorArrayConcat
# Inputs:
*    handle
*    flow_in

# Attributes:
*    dtype
*    element_shape_except0

# Outputs:
*    value
*    lengths

*/
inline std::vector<tensor> tensor_array_concat(const tensor& handle, const tensor& flow_in, datatype dtype, const std::vector<int64_t>& element_shape_except0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayConcat", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "element_shape_except0", element_shape_except0.data(), static_cast<int>(element_shape_except0.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # TensorArrayConcatV2
# Inputs:
*    handle
*    flow_in

# Attributes:
*    dtype
*    element_shape_except0

# Outputs:
*    value
*    lengths

*/
inline std::vector<tensor> tensor_array_concat_v2(const tensor& handle, const tensor& flow_in, datatype dtype, const std::vector<int64_t>& element_shape_except0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayConcatV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "element_shape_except0", element_shape_except0.data(), static_cast<int>(element_shape_except0.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # TensorArrayConcatV3
# Inputs:
*    handle
*    flow_in

# Attributes:
*    dtype
*    element_shape_except0

# Outputs:
*    value
*    lengths

*/
inline std::vector<tensor> tensor_array_concat_v3(const tensor& handle, const tensor& flow_in, datatype dtype, const std::vector<int64_t>& element_shape_except0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayConcatV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "element_shape_except0", element_shape_except0.data(), static_cast<int>(element_shape_except0.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # TensorArrayGather
# Inputs:
*    handle
*    indices
*    flow_in

# Attributes:
*    dtype
*    element_shape

# Outputs:
*    value

*/
inline tensor tensor_array_gather(const tensor& handle, const tensor& indices, const tensor& flow_in, datatype dtype, const std::vector<int64_t>& element_shape) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayGather", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "element_shape", element_shape.data(), static_cast<int>(element_shape.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorArrayGatherV2
# Inputs:
*    handle
*    indices
*    flow_in

# Attributes:
*    dtype
*    element_shape

# Outputs:
*    value

*/
inline tensor tensor_array_gather_v2(const tensor& handle, const tensor& indices, const tensor& flow_in, datatype dtype, const std::vector<int64_t>& element_shape) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayGatherV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "element_shape", element_shape.data(), static_cast<int>(element_shape.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorArrayGatherV3
# Inputs:
*    handle
*    indices
*    flow_in

# Attributes:
*    dtype
*    element_shape

# Outputs:
*    value

*/
inline tensor tensor_array_gather_v3(const tensor& handle, const tensor& indices, const tensor& flow_in, datatype dtype, const std::vector<int64_t>& element_shape) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayGatherV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "element_shape", element_shape.data(), static_cast<int>(element_shape.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorArrayGrad
# Inputs:
*    handle
*    flow_in

# Attributes:
*    source

# Outputs:
*    grad_handle

*/
inline tensor tensor_array_grad(const tensor& handle, const tensor& flow_in, const std::string& source) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "source", (void*) source.c_str(), source.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorArrayGradV2
# Inputs:
*    handle
*    flow_in

# Attributes:
*    source

# Outputs:
*    grad_handle

*/
inline tensor tensor_array_grad_v2(const tensor& handle, const tensor& flow_in, const std::string& source) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayGradV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "source", (void*) source.c_str(), source.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorArrayGradV3
# Inputs:
*    handle
*    flow_in

# Attributes:
*    source

# Outputs:
*    grad_handle
*    flow_out

*/
inline std::vector<tensor> tensor_array_grad_v3(const tensor& handle, const tensor& flow_in, const std::string& source) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayGradV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "source", (void*) source.c_str(), source.size());

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # TensorArrayGradWithShape
# Inputs:
*    handle
*    flow_in
*    shape_to_prepend

# Attributes:
*    source

# Outputs:
*    grad_handle
*    flow_out

*/
inline std::vector<tensor> tensor_array_grad_with_shape(const tensor& handle, const tensor& flow_in, const tensor& shape_to_prepend, const std::string& source) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayGradWithShape", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape_to_prepend.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "source", (void*) source.c_str(), source.size());

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # TensorArrayPack
# Inputs:
*    handle
*    flow_in

# Attributes:
*    dtype
*    element_shape

# Outputs:
*    value

*/
inline tensor tensor_array_pack(const tensor& handle, const tensor& flow_in, datatype dtype, const std::vector<int64_t>& element_shape) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayPack", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "element_shape", element_shape.data(), static_cast<int>(element_shape.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorArrayRead
# Inputs:
*    handle
*    index
*    flow_in

# Attributes:
*    dtype

# Outputs:
*    value

*/
inline tensor tensor_array_read(const tensor& handle, const tensor& index, const tensor& flow_in, datatype dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayRead", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), index.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorArrayReadV2
# Inputs:
*    handle
*    index
*    flow_in

# Attributes:
*    dtype

# Outputs:
*    value

*/
inline tensor tensor_array_read_v2(const tensor& handle, const tensor& index, const tensor& flow_in, datatype dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayReadV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), index.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorArrayReadV3
# Inputs:
*    handle
*    index
*    flow_in

# Attributes:
*    dtype

# Outputs:
*    value

*/
inline tensor tensor_array_read_v3(const tensor& handle, const tensor& index, const tensor& flow_in, datatype dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayReadV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), index.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorArrayScatter
# Inputs:
*    handle
*    indices
*    value
*    flow_in

# Attributes:
*    
# Outputs:
*    flow_out

*/
inline tensor tensor_array_scatter(const tensor& handle, const tensor& indices, const tensor& value, const tensor& flow_in) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayScatter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorArrayScatterV2
# Inputs:
*    handle
*    indices
*    value
*    flow_in

# Attributes:
*    
# Outputs:
*    flow_out

*/
inline tensor tensor_array_scatter_v2(const tensor& handle, const tensor& indices, const tensor& value, const tensor& flow_in) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayScatterV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorArrayScatterV3
# Inputs:
*    handle
*    indices
*    value
*    flow_in

# Attributes:
*    
# Outputs:
*    flow_out

*/
inline tensor tensor_array_scatter_v3(const tensor& handle, const tensor& indices, const tensor& value, const tensor& flow_in) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayScatterV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorArraySize
# Inputs:
*    handle
*    flow_in

# Attributes:
*    
# Outputs:
*    size

*/
inline tensor tensor_array_size(const tensor& handle, const tensor& flow_in) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArraySize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorArraySizeV2
# Inputs:
*    handle
*    flow_in

# Attributes:
*    
# Outputs:
*    size

*/
inline tensor tensor_array_size_v2(const tensor& handle, const tensor& flow_in) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArraySizeV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorArraySizeV3
# Inputs:
*    handle
*    flow_in

# Attributes:
*    
# Outputs:
*    size

*/
inline tensor tensor_array_size_v3(const tensor& handle, const tensor& flow_in) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArraySizeV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorArraySplit
# Inputs:
*    handle
*    value
*    lengths
*    flow_in

# Attributes:
*    
# Outputs:
*    flow_out

*/
inline tensor tensor_array_split(const tensor& handle, const tensor& value, const tensor& lengths, const tensor& flow_in) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArraySplit", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lengths.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorArraySplitV2
# Inputs:
*    handle
*    value
*    lengths
*    flow_in

# Attributes:
*    
# Outputs:
*    flow_out

*/
inline tensor tensor_array_split_v2(const tensor& handle, const tensor& value, const tensor& lengths, const tensor& flow_in) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArraySplitV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lengths.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorArraySplitV3
# Inputs:
*    handle
*    value
*    lengths
*    flow_in

# Attributes:
*    
# Outputs:
*    flow_out

*/
inline tensor tensor_array_split_v3(const tensor& handle, const tensor& value, const tensor& lengths, const tensor& flow_in) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArraySplitV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lengths.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorArrayUnpack
# Inputs:
*    handle
*    value
*    flow_in

# Attributes:
*    
# Outputs:
*    flow_out

*/
inline tensor tensor_array_unpack(const tensor& handle, const tensor& value, const tensor& flow_in) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayUnpack", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorArrayV2
# Inputs:
*    size

# Attributes:
*    dtype
*    element_shape
*    dynamic_size
*    clear_after_read
*    tensor_array_name

# Outputs:
*    handle

*/
inline tensor tensor_array_v2(const tensor& size, datatype dtype, const std::vector<int64_t>& element_shape, bool dynamic_size=false, bool clear_after_read=true, const std::string& tensor_array_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "element_shape", element_shape.data(), static_cast<int>(element_shape.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "dynamic_size", (unsigned char)dynamic_size);
    TFE_OpSetAttrBool(op.get(), "clear_after_read", (unsigned char)clear_after_read);
    TFE_OpSetAttrString(op.get(), "tensor_array_name", (void*) tensor_array_name.c_str(), tensor_array_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorArrayV3
# Inputs:
*    size

# Attributes:
*    dtype
*    element_shape
*    dynamic_size
*    clear_after_read
*    identical_element_shapes
*    tensor_array_name

# Outputs:
*    handle
*    flow

*/
inline std::vector<tensor> tensor_array_v3(const tensor& size, datatype dtype, const std::vector<int64_t>& element_shape, bool dynamic_size=false, bool clear_after_read=true, bool identical_element_shapes=false, const std::string& tensor_array_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "element_shape", element_shape.data(), static_cast<int>(element_shape.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "dynamic_size", (unsigned char)dynamic_size);
    TFE_OpSetAttrBool(op.get(), "clear_after_read", (unsigned char)clear_after_read);
    TFE_OpSetAttrBool(op.get(), "identical_element_shapes", (unsigned char)identical_element_shapes);
    TFE_OpSetAttrString(op.get(), "tensor_array_name", (void*) tensor_array_name.c_str(), tensor_array_name.size());

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # TensorArrayWrite
# Inputs:
*    handle
*    index
*    value
*    flow_in

# Attributes:
*    
# Outputs:
*    flow_out

*/
inline tensor tensor_array_write(const tensor& handle, const tensor& index, const tensor& value, const tensor& flow_in) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayWrite", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), index.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorArrayWriteV2
# Inputs:
*    handle
*    index
*    value
*    flow_in

# Attributes:
*    
# Outputs:
*    flow_out

*/
inline tensor tensor_array_write_v2(const tensor& handle, const tensor& index, const tensor& value, const tensor& flow_in) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayWriteV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), index.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorArrayWriteV3
# Inputs:
*    handle
*    index
*    value
*    flow_in

# Attributes:
*    
# Outputs:
*    flow_out

*/
inline tensor tensor_array_write_v3(const tensor& handle, const tensor& index, const tensor& value, const tensor& flow_in) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayWriteV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), index.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorDataset
# Inputs:
*    components

# Attributes:
*    Toutput_types
*    output_shapes
*    metadata

# Outputs:
*    handle

*/
inline tensor tensor_dataset(const std::vector<tensor>&components, const std::vector<datatype>& Toutput_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> components_handles; components_handles.reserve(components.size());
    std::transform(components.begin(), components.end(), std::back_inserter(components_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), components_handles.data(), static_cast<int>(components.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Toutput_types", reinterpret_cast<const enum TF_DataType *>(Toutput_types.data()), static_cast<int>(Toutput_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorListConcat
# Inputs:
*    input_handle

# Attributes:
*    element_dtype
*    element_shape

# Outputs:
*    tensor
*    lengths

*/
inline std::vector<tensor> tensor_list_concat(const tensor& input_handle, datatype element_dtype, const std::vector<int64_t>& element_shape) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListConcat", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);
    
    TFE_OpSetAttrShape(op.get(), "element_shape", element_shape.data(), static_cast<int>(element_shape.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # TensorListConcatLists
# Inputs:
*    input_a
*    input_b

# Attributes:
*    element_dtype

# Outputs:
*    output

*/
inline tensor tensor_list_concat_lists(const tensor& input_a, const tensor& input_b, datatype element_dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListConcatLists", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_a.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_b.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorListConcatV2
# Inputs:
*    input_handle
*    element_shape
*    leading_dims

# Attributes:
*    element_dtype
*    shape_type

# Outputs:
*    tensor
*    lengths

*/
inline std::vector<tensor> tensor_list_concat_v2(const tensor& input_handle, const tensor& element_shape, const tensor& leading_dims, datatype element_dtype, datatype shape_type) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListConcatV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), element_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), leading_dims.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);
    TFE_OpSetAttrType(op.get(), "shape_type", shape_type);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # TensorListElementShape
# Inputs:
*    input_handle

# Attributes:
*    shape_type

# Outputs:
*    element_shape

*/
inline tensor tensor_list_element_shape(const tensor& input_handle, datatype shape_type) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListElementShape", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "shape_type", shape_type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorListFromTensor
# Inputs:
*    tensor
*    element_shape

# Attributes:
*    element_dtype
*    shape_type

# Outputs:
*    output_handle

*/
inline tensor tensor_list_from_tensor(const tensor& input_tensor, const tensor& element_shape, datatype element_dtype, datatype shape_type) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListFromTensor", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), element_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);
    TFE_OpSetAttrType(op.get(), "shape_type", shape_type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorListGather
# Inputs:
*    input_handle
*    indices
*    element_shape

# Attributes:
*    element_dtype

# Outputs:
*    values

*/
inline tensor tensor_list_gather(const tensor& input_handle, const tensor& indices, const tensor& element_shape, datatype element_dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListGather", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), element_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorListGetItem
# Inputs:
*    input_handle
*    index
*    element_shape

# Attributes:
*    element_dtype

# Outputs:
*    item

*/
inline tensor tensor_list_get_item(const tensor& input_handle, const tensor& index, const tensor& element_shape, datatype element_dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListGetItem", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), index.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), element_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorListLength
# Inputs:
*    input_handle

# Attributes:
*    
# Outputs:
*    length

*/
inline tensor tensor_list_length(const tensor& input_handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListLength", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorListPopBack
# Inputs:
*    input_handle
*    element_shape

# Attributes:
*    element_dtype

# Outputs:
*    output_handle
*    tensor

*/
inline std::vector<tensor> tensor_list_pop_back(const tensor& input_handle, const tensor& element_shape, datatype element_dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListPopBack", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), element_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # TensorListPushBack
# Inputs:
*    input_handle
*    tensor

# Attributes:
*    element_dtype

# Outputs:
*    output_handle

*/
inline tensor tensor_list_push_back(const tensor& input_handle, const tensor& input_tensor, datatype element_dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListPushBack", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorListPushBackBatch
# Inputs:
*    input_handles
*    tensor

# Attributes:
*    element_dtype

# Outputs:
*    output_handles

*/
inline tensor tensor_list_push_back_batch(const tensor& input_handles, const tensor& input_tensor, datatype element_dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListPushBackBatch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handles.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorListReserve
# Inputs:
*    element_shape
*    num_elements

# Attributes:
*    element_dtype
*    shape_type

# Outputs:
*    handle

*/
inline tensor tensor_list_reserve(const tensor& element_shape, const tensor& num_elements, datatype element_dtype, datatype shape_type) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListReserve", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), element_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_elements.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);
    TFE_OpSetAttrType(op.get(), "shape_type", shape_type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorListResize
# Inputs:
*    input_handle
*    size

# Attributes:
*    
# Outputs:
*    output_handle

*/
inline tensor tensor_list_resize(const tensor& input_handle, const tensor& size) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListResize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorListScatter
# Inputs:
*    tensor
*    indices
*    element_shape

# Attributes:
*    element_dtype
*    shape_type

# Outputs:
*    output_handle

*/
inline tensor tensor_list_scatter(const tensor& input_tensor, const tensor& indices, const tensor& element_shape, datatype element_dtype, datatype shape_type) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListScatter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), element_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);
    TFE_OpSetAttrType(op.get(), "shape_type", shape_type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorListScatterIntoExistingList
# Inputs:
*    input_handle
*    tensor
*    indices

# Attributes:
*    element_dtype

# Outputs:
*    output_handle

*/
inline tensor tensor_list_scatter_into_existing_list(const tensor& input_handle, const tensor& input_tensor, const tensor& indices, datatype element_dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListScatterIntoExistingList", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorListScatterV2
# Inputs:
*    tensor
*    indices
*    element_shape
*    num_elements

# Attributes:
*    element_dtype
*    shape_type

# Outputs:
*    output_handle

*/
inline tensor tensor_list_scatter_v2(const tensor& input_tensor, const tensor& indices, const tensor& element_shape, const tensor& num_elements, datatype element_dtype, datatype shape_type) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListScatterV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), element_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_elements.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);
    TFE_OpSetAttrType(op.get(), "shape_type", shape_type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorListSetItem
# Inputs:
*    input_handle
*    index
*    item

# Attributes:
*    element_dtype
*    resize_if_index_out_of_bounds

# Outputs:
*    output_handle

*/
inline tensor tensor_list_set_item(const tensor& input_handle, const tensor& index, const tensor& item, datatype element_dtype, bool resize_if_index_out_of_bounds=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListSetItem", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), index.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), item.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);
    TFE_OpSetAttrBool(op.get(), "resize_if_index_out_of_bounds", (unsigned char)resize_if_index_out_of_bounds);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorListSplit
# Inputs:
*    tensor
*    element_shape
*    lengths

# Attributes:
*    element_dtype
*    shape_type

# Outputs:
*    output_handle

*/
inline tensor tensor_list_split(const tensor& input_tensor, const tensor& element_shape, const tensor& lengths, datatype element_dtype, datatype shape_type) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListSplit", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), element_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lengths.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);
    TFE_OpSetAttrType(op.get(), "shape_type", shape_type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorListStack
# Inputs:
*    input_handle
*    element_shape

# Attributes:
*    element_dtype
*    num_elements

# Outputs:
*    tensor

*/
inline tensor tensor_list_stack(const tensor& input_handle, const tensor& element_shape, datatype element_dtype, int64_t num_elements=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListStack", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), element_shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);
    TFE_OpSetAttrInt(op.get(), "num_elements", num_elements);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorMapErase
# Inputs:
*    input_handle
*    key

# Attributes:
*    key_dtype
*    value_dtype

# Outputs:
*    output_handle

*/
inline tensor tensor_map_erase(const tensor& input_handle, const tensor& key, datatype key_dtype, datatype value_dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorMapErase", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "key_dtype", key_dtype);
    TFE_OpSetAttrType(op.get(), "value_dtype", value_dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorMapHasKey
# Inputs:
*    input_handle
*    key

# Attributes:
*    key_dtype

# Outputs:
*    has_key

*/
inline tensor tensor_map_has_key(const tensor& input_handle, const tensor& key, datatype key_dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorMapHasKey", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "key_dtype", key_dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorMapInsert
# Inputs:
*    input_handle
*    key
*    value

# Attributes:
*    key_dtype
*    value_dtype

# Outputs:
*    output_handle

*/
inline tensor tensor_map_insert(const tensor& input_handle, const tensor& key, const tensor& value, datatype key_dtype, datatype value_dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorMapInsert", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "key_dtype", key_dtype);
    TFE_OpSetAttrType(op.get(), "value_dtype", value_dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorMapLookup
# Inputs:
*    input_handle
*    key

# Attributes:
*    key_dtype
*    value_dtype

# Outputs:
*    value

*/
inline tensor tensor_map_lookup(const tensor& input_handle, const tensor& key, datatype key_dtype, datatype value_dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorMapLookup", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), key.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "key_dtype", key_dtype);
    TFE_OpSetAttrType(op.get(), "value_dtype", value_dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorMapSize
# Inputs:
*    input_handle

# Attributes:
*    
# Outputs:
*    size

*/
inline tensor tensor_map_size(const tensor& input_handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorMapSize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorMapStackKeys
# Inputs:
*    input_handle

# Attributes:
*    key_dtype

# Outputs:
*    keys

*/
inline tensor tensor_map_stack_keys(const tensor& input_handle, datatype key_dtype) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorMapStackKeys", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "key_dtype", key_dtype);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorScatterAdd
# Inputs:
*    tensor
*    indices
*    updates

# Attributes:
*    Tindices

# Outputs:
*    output

*/
inline tensor tensor_scatter_add(const tensor& input_tensor, const tensor& indices, const tensor& updates, datatype Tindices) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorScatterAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorScatterMax
# Inputs:
*    tensor
*    indices
*    updates

# Attributes:
*    Tindices

# Outputs:
*    output

*/
inline tensor tensor_scatter_max(const tensor& input_tensor, const tensor& indices, const tensor& updates, datatype Tindices) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorScatterMax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorScatterMin
# Inputs:
*    tensor
*    indices
*    updates

# Attributes:
*    Tindices

# Outputs:
*    output

*/
inline tensor tensor_scatter_min(const tensor& input_tensor, const tensor& indices, const tensor& updates, datatype Tindices) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorScatterMin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorScatterSub
# Inputs:
*    tensor
*    indices
*    updates

# Attributes:
*    Tindices

# Outputs:
*    output

*/
inline tensor tensor_scatter_sub(const tensor& input_tensor, const tensor& indices, const tensor& updates, datatype Tindices) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorScatterSub", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorScatterUpdate
# Inputs:
*    tensor
*    indices
*    updates

# Attributes:
*    Tindices

# Outputs:
*    output

*/
inline tensor tensor_scatter_update(const tensor& input_tensor, const tensor& indices, const tensor& updates, datatype Tindices) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorScatterUpdate", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorSliceDataset
# Inputs:
*    components

# Attributes:
*    Toutput_types
*    output_shapes
*    is_files
*    metadata
*    replicate_on_split

# Outputs:
*    handle

*/
inline tensor tensor_slice_dataset(const std::vector<tensor>&components, const std::vector<datatype>& Toutput_types, const std::vector< std::vector<int64_t>>& output_shapes, bool is_files=false, const std::string& metadata="", bool replicate_on_split=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorSliceDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> components_handles; components_handles.reserve(components.size());
    std::transform(components.begin(), components.end(), std::back_inserter(components_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), components_handles.data(), static_cast<int>(components.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Toutput_types", reinterpret_cast<const enum TF_DataType *>(Toutput_types.data()), static_cast<int>(Toutput_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "is_files", (unsigned char)is_files);
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());
    TFE_OpSetAttrBool(op.get(), "replicate_on_split", (unsigned char)replicate_on_split);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorStridedSliceUpdate
# Inputs:
*    input
*    begin
*    end
*    strides
*    value

# Attributes:
*    Index
*    begin_mask
*    end_mask
*    ellipsis_mask
*    new_axis_mask
*    shrink_axis_mask

# Outputs:
*    output

*/
inline tensor tensor_strided_slice_update(const tensor& input, const tensor& begin, const tensor& end, const tensor& strides, const tensor& value, datatype Index, int64_t begin_mask=0, int64_t end_mask=0, int64_t ellipsis_mask=0, int64_t new_axis_mask=0, int64_t shrink_axis_mask=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorStridedSliceUpdate", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), begin.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), end.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), strides.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Index", Index);
    TFE_OpSetAttrInt(op.get(), "begin_mask", begin_mask);
    TFE_OpSetAttrInt(op.get(), "end_mask", end_mask);
    TFE_OpSetAttrInt(op.get(), "ellipsis_mask", ellipsis_mask);
    TFE_OpSetAttrInt(op.get(), "new_axis_mask", new_axis_mask);
    TFE_OpSetAttrInt(op.get(), "shrink_axis_mask", shrink_axis_mask);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorSummary
# Inputs:
*    tensor

# Attributes:
*    labels
*    description
*    display_name

# Outputs:
*    summary

*/
inline tensor tensor_summary(const tensor& input_tensor, const std::vector< std::string>& labels, const std::string& description="", const std::string& display_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> labels_sizes; labels_sizes.reserve(labels.size());
    std::transform(labels.begin(), labels.end(), std::back_inserter(labels_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "labels", reinterpret_cast<const void *const *>(labels.data()), labels_sizes.data(), static_cast<int>(labels.size()));
    
    TFE_OpSetAttrString(op.get(), "description", (void*) description.c_str(), description.size());
    TFE_OpSetAttrString(op.get(), "display_name", (void*) display_name.c_str(), display_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TensorSummaryV2
# Inputs:
*    tag
*    tensor
*    serialized_summary_metadata

# Attributes:
*    
# Outputs:
*    summary

*/
inline tensor tensor_summary_v2(const tensor& tag, const tensor& input_tensor, const tensor& serialized_summary_metadata) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorSummaryV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tag.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), serialized_summary_metadata.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TextLineDataset
# Inputs:
*    filenames
*    compression_type
*    buffer_size

# Attributes:
*    metadata

# Outputs:
*    handle

*/
inline tensor text_line_dataset(const tensor& filenames, const tensor& compression_type, const tensor& buffer_size, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TextLineDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filenames.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), compression_type.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TextLineReader
# Inputs:
*    
# Attributes:
*    skip_header_lines
*    container
*    shared_name

# Outputs:
*    reader_handle

*/
inline tensor text_line_reader(int64_t skip_header_lines=0, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TextLineReader", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "skip_header_lines", skip_header_lines);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TextLineReaderV2
# Inputs:
*    
# Attributes:
*    skip_header_lines
*    container
*    shared_name

# Outputs:
*    reader_handle

*/
inline tensor text_line_reader_v2(int64_t skip_header_lines=0, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TextLineReaderV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "skip_header_lines", skip_header_lines);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ThreadPoolDataset
# Inputs:
*    input_dataset
*    thread_pool

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    handle

*/
inline tensor thread_pool_dataset(const tensor& input_dataset, const tensor& thread_pool, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ThreadPoolDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), thread_pool.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ThreadPoolHandle
# Inputs:
*    
# Attributes:
*    num_threads
*    display_name
*    max_intra_op_parallelism
*    container
*    shared_name

# Outputs:
*    handle

*/
inline tensor thread_pool_handle(int64_t num_threads, const std::string& display_name, int64_t max_intra_op_parallelism=1, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ThreadPoolHandle", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_threads", num_threads);
    TFE_OpSetAttrString(op.get(), "display_name", (void*) display_name.c_str(), display_name.size());
    TFE_OpSetAttrInt(op.get(), "max_intra_op_parallelism", max_intra_op_parallelism);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ThreadUnsafeUnigramCandidateSampler
# Inputs:
*    true_classes

# Attributes:
*    num_true
*    num_sampled
*    unique
*    range_max
*    seed
*    seed2

# Outputs:
*    sampled_candidates
*    true_expected_count
*    sampled_expected_count

*/
inline std::vector<tensor> thread_unsafe_unigram_candidate_sampler(const tensor& true_classes, int64_t num_true, int64_t num_sampled, bool unique, int64_t range_max, int64_t seed=0, int64_t seed2=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ThreadUnsafeUnigramCandidateSampler", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), true_classes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_true", num_true);
    TFE_OpSetAttrInt(op.get(), "num_sampled", num_sampled);
    TFE_OpSetAttrBool(op.get(), "unique", (unsigned char)unique);
    TFE_OpSetAttrInt(op.get(), "range_max", range_max);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # Tile
# Inputs:
*    input
*    multiples

# Attributes:
*    Tmultiples

# Outputs:
*    output

*/
inline tensor tile(const tensor& input, const tensor& multiples, datatype Tmultiples=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Tile", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), multiples.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tmultiples", Tmultiples);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TileGrad
# Inputs:
*    input
*    multiples

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor tile_grad(const tensor& input, const tensor& multiples) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TileGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), multiples.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Timestamp
# Inputs:
*    
# Attributes:
*    
# Outputs:
*    ts

*/
inline tensor timestamp() {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Timestamp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ToBool
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor to_bool(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ToBool", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TopK
# Inputs:
*    input

# Attributes:
*    k
*    sorted

# Outputs:
*    values
*    indices

*/
inline std::vector<tensor> top_k(const tensor& input, int64_t k, bool sorted=true) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TopK", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "k", k);
    TFE_OpSetAttrBool(op.get(), "sorted", (unsigned char)sorted);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # TopKV2
# Inputs:
*    input
*    k

# Attributes:
*    sorted
*    Tk
*    index_type

# Outputs:
*    values
*    indices

*/
inline std::vector<tensor> top_k_v2(const tensor& input, const tensor& k, bool sorted=true, datatype Tk=static_cast<datatype>(3), datatype index_type=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TopKV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), k.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "sorted", (unsigned char)sorted);
    TFE_OpSetAttrType(op.get(), "Tk", Tk);
    TFE_OpSetAttrType(op.get(), "index_type", index_type);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # Transpose
# Inputs:
*    x
*    perm

# Attributes:
*    Tperm

# Outputs:
*    y

*/
inline tensor transpose(const tensor& x, const tensor& perm, datatype Tperm=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Transpose", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), perm.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tperm", Tperm);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TridiagonalMatMul
# Inputs:
*    superdiag
*    maindiag
*    subdiag
*    rhs

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor tridiagonal_mat_mul(const tensor& superdiag, const tensor& maindiag, const tensor& subdiag, const tensor& rhs) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TridiagonalMatMul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), superdiag.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), maindiag.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), subdiag.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TridiagonalSolve
# Inputs:
*    diagonals
*    rhs

# Attributes:
*    partial_pivoting
*    perturb_singular

# Outputs:
*    output

*/
inline tensor tridiagonal_solve(const tensor& diagonals, const tensor& rhs, bool partial_pivoting=true, bool perturb_singular=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TridiagonalSolve", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), diagonals.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "partial_pivoting", (unsigned char)partial_pivoting);
    TFE_OpSetAttrBool(op.get(), "perturb_singular", (unsigned char)perturb_singular);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TruncateDiv
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor truncate_div(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TruncateDiv", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TruncateMod
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor truncate_mod(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TruncateMod", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # TruncatedNormal
# Inputs:
*    shape

# Attributes:
*    dtype
*    seed
*    seed2

# Outputs:
*    output

*/
inline tensor truncated_normal(const tensor& shape, datatype dtype, int64_t seed=0, int64_t seed2=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TruncatedNormal", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Unbatch
# Inputs:
*    batched_tensor
*    batch_index
*    id

# Attributes:
*    timeout_micros
*    container
*    shared_name

# Outputs:
*    unbatched_tensor

*/
inline tensor unbatch(const tensor& batched_input_tensor, const tensor& batch_index, const tensor& id, int64_t timeout_micros, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Unbatch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), batched_input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), batch_index.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), id.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "timeout_micros", timeout_micros);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # UnbatchDataset
# Inputs:
*    input_dataset

# Attributes:
*    output_types
*    output_shapes
*    metadata

# Outputs:
*    handle

*/
inline tensor unbatch_dataset(const tensor& input_dataset, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnbatchDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # UnbatchGrad
# Inputs:
*    original_input
*    batch_index
*    grad
*    id

# Attributes:
*    container
*    shared_name

# Outputs:
*    batched_grad

*/
inline tensor unbatch_grad(const tensor& original_input, const tensor& batch_index, const tensor& grad, const tensor& id, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnbatchGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), original_input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), batch_index.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), id.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # UncompressElement
# Inputs:
*    compressed

# Attributes:
*    output_types
*    output_shapes

# Outputs:
*    components

*/
inline tensor uncompress_element(const tensor& compressed, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UncompressElement", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), compressed.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # UnicodeDecode
# Inputs:
*    input

# Attributes:
*    input_encoding
*    errors
*    replacement_char
*    replace_control_characters
*    Tsplits

# Outputs:
*    row_splits
*    char_values

*/
inline std::vector<tensor> unicode_decode(const tensor& input, const std::string& input_encoding, const std::string& errors="replace", int64_t replacement_char=65533, bool replace_control_characters=false, datatype Tsplits=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnicodeDecode", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "input_encoding", (void*) input_encoding.c_str(), input_encoding.size());
    TFE_OpSetAttrString(op.get(), "errors", (void*) errors.c_str(), errors.size());
    TFE_OpSetAttrInt(op.get(), "replacement_char", replacement_char);
    TFE_OpSetAttrBool(op.get(), "replace_control_characters", (unsigned char)replace_control_characters);
    TFE_OpSetAttrType(op.get(), "Tsplits", Tsplits);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # UnicodeDecodeWithOffsets
# Inputs:
*    input

# Attributes:
*    input_encoding
*    errors
*    replacement_char
*    replace_control_characters
*    Tsplits

# Outputs:
*    row_splits
*    char_values
*    char_to_byte_starts

*/
inline std::vector<tensor> unicode_decode_with_offsets(const tensor& input, const std::string& input_encoding, const std::string& errors="replace", int64_t replacement_char=65533, bool replace_control_characters=false, datatype Tsplits=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnicodeDecodeWithOffsets", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "input_encoding", (void*) input_encoding.c_str(), input_encoding.size());
    TFE_OpSetAttrString(op.get(), "errors", (void*) errors.c_str(), errors.size());
    TFE_OpSetAttrInt(op.get(), "replacement_char", replacement_char);
    TFE_OpSetAttrBool(op.get(), "replace_control_characters", (unsigned char)replace_control_characters);
    TFE_OpSetAttrType(op.get(), "Tsplits", Tsplits);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # UnicodeEncode
# Inputs:
*    input_values
*    input_splits

# Attributes:
*    output_encoding
*    errors
*    replacement_char
*    Tsplits

# Outputs:
*    output

*/
inline tensor unicode_encode(const tensor& input_values, const tensor& input_splits, const std::string& output_encoding, const std::string& errors="replace", int64_t replacement_char=65533, datatype Tsplits=static_cast<datatype>(9)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnicodeEncode", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_splits.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "output_encoding", (void*) output_encoding.c_str(), output_encoding.size());
    TFE_OpSetAttrString(op.get(), "errors", (void*) errors.c_str(), errors.size());
    TFE_OpSetAttrInt(op.get(), "replacement_char", replacement_char);
    TFE_OpSetAttrType(op.get(), "Tsplits", Tsplits);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # UnicodeScript
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    output

*/
inline tensor unicode_script(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnicodeScript", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # UnicodeTranscode
# Inputs:
*    input

# Attributes:
*    input_encoding
*    output_encoding
*    errors
*    replacement_char
*    replace_control_characters

# Outputs:
*    output

*/
inline tensor unicode_transcode(const tensor& input, const std::string& input_encoding, const std::string& output_encoding, const std::string& errors="replace", int64_t replacement_char=65533, bool replace_control_characters=false) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnicodeTranscode", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "input_encoding", (void*) input_encoding.c_str(), input_encoding.size());
    TFE_OpSetAttrString(op.get(), "output_encoding", (void*) output_encoding.c_str(), output_encoding.size());
    TFE_OpSetAttrString(op.get(), "errors", (void*) errors.c_str(), errors.size());
    TFE_OpSetAttrInt(op.get(), "replacement_char", replacement_char);
    TFE_OpSetAttrBool(op.get(), "replace_control_characters", (unsigned char)replace_control_characters);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # UniformCandidateSampler
# Inputs:
*    true_classes

# Attributes:
*    num_true
*    num_sampled
*    unique
*    range_max
*    seed
*    seed2

# Outputs:
*    sampled_candidates
*    true_expected_count
*    sampled_expected_count

*/
inline std::vector<tensor> uniform_candidate_sampler(const tensor& true_classes, int64_t num_true, int64_t num_sampled, bool unique, int64_t range_max, int64_t seed=0, int64_t seed2=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UniformCandidateSampler", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), true_classes.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_true", num_true);
    TFE_OpSetAttrInt(op.get(), "num_sampled", num_sampled);
    TFE_OpSetAttrBool(op.get(), "unique", (unsigned char)unique);
    TFE_OpSetAttrInt(op.get(), "range_max", range_max);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # UniformDequantize
# Inputs:
*    input
*    scales
*    zero_points

# Attributes:
*    Tin
*    Tout
*    quantization_min_val
*    quantization_max_val
*    quantization_axis

# Outputs:
*    output

*/
inline tensor uniform_dequantize(const tensor& input, const tensor& scales, const tensor& zero_points, datatype Tin, datatype Tout, int64_t quantization_min_val, int64_t quantization_max_val, int64_t quantization_axis=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UniformDequantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scales.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), zero_points.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tin", Tin);
    TFE_OpSetAttrType(op.get(), "Tout", Tout);
    TFE_OpSetAttrInt(op.get(), "quantization_min_val", quantization_min_val);
    TFE_OpSetAttrInt(op.get(), "quantization_max_val", quantization_max_val);
    TFE_OpSetAttrInt(op.get(), "quantization_axis", quantization_axis);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # UniformQuantize
# Inputs:
*    input
*    scales
*    zero_points

# Attributes:
*    Tin
*    Tout
*    quantization_min_val
*    quantization_max_val
*    quantization_axis

# Outputs:
*    output

*/
inline tensor uniform_quantize(const tensor& input, const tensor& scales, const tensor& zero_points, datatype Tin, datatype Tout, int64_t quantization_min_val, int64_t quantization_max_val, int64_t quantization_axis=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UniformQuantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scales.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), zero_points.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tin", Tin);
    TFE_OpSetAttrType(op.get(), "Tout", Tout);
    TFE_OpSetAttrInt(op.get(), "quantization_min_val", quantization_min_val);
    TFE_OpSetAttrInt(op.get(), "quantization_max_val", quantization_max_val);
    TFE_OpSetAttrInt(op.get(), "quantization_axis", quantization_axis);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # UniformQuantizedAdd
# Inputs:
*    lhs
*    rhs
*    lhs_scales
*    lhs_zero_points
*    rhs_scales
*    rhs_zero_points
*    output_scales
*    output_zero_points

# Attributes:
*    lhs_quantization_min_val
*    lhs_quantization_max_val
*    rhs_quantization_min_val
*    rhs_quantization_max_val
*    output_quantization_min_val
*    output_quantization_max_val
*    lhs_quantization_axis
*    rhs_quantization_axis
*    output_quantization_axis

# Outputs:
*    output

*/
inline tensor uniform_quantized_add(const tensor& lhs, const tensor& rhs, const tensor& lhs_scales, const tensor& lhs_zero_points, const tensor& rhs_scales, const tensor& rhs_zero_points, const tensor& output_scales, const tensor& output_zero_points, int64_t lhs_quantization_min_val, int64_t lhs_quantization_max_val, int64_t rhs_quantization_min_val, int64_t rhs_quantization_max_val, int64_t output_quantization_min_val, int64_t output_quantization_max_val, int64_t lhs_quantization_axis=-1, int64_t rhs_quantization_axis=-1, int64_t output_quantization_axis=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UniformQuantizedAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), lhs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lhs_scales.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lhs_zero_points.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs_scales.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs_zero_points.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_scales.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_zero_points.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "lhs_quantization_min_val", lhs_quantization_min_val);
    TFE_OpSetAttrInt(op.get(), "lhs_quantization_max_val", lhs_quantization_max_val);
    TFE_OpSetAttrInt(op.get(), "rhs_quantization_min_val", rhs_quantization_min_val);
    TFE_OpSetAttrInt(op.get(), "rhs_quantization_max_val", rhs_quantization_max_val);
    TFE_OpSetAttrInt(op.get(), "output_quantization_min_val", output_quantization_min_val);
    TFE_OpSetAttrInt(op.get(), "output_quantization_max_val", output_quantization_max_val);
    TFE_OpSetAttrInt(op.get(), "lhs_quantization_axis", lhs_quantization_axis);
    TFE_OpSetAttrInt(op.get(), "rhs_quantization_axis", rhs_quantization_axis);
    TFE_OpSetAttrInt(op.get(), "output_quantization_axis", output_quantization_axis);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # UniformQuantizedClipByValue
# Inputs:
*    operand
*    min
*    max
*    scales
*    zero_points

# Attributes:
*    quantization_min_val
*    quantization_max_val
*    quantization_axis

# Outputs:
*    output

*/
inline tensor uniform_quantized_clip_by_value(const tensor& operand, const tensor& min, const tensor& max, const tensor& scales, const tensor& zero_points, int64_t quantization_min_val, int64_t quantization_max_val, int64_t quantization_axis=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UniformQuantizedClipByValue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), operand.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scales.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), zero_points.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "quantization_min_val", quantization_min_val);
    TFE_OpSetAttrInt(op.get(), "quantization_max_val", quantization_max_val);
    TFE_OpSetAttrInt(op.get(), "quantization_axis", quantization_axis);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # UniformQuantizedConvolution
# Inputs:
*    lhs
*    rhs
*    lhs_scales
*    lhs_zero_points
*    rhs_scales
*    rhs_zero_points
*    output_scales
*    output_zero_points

# Attributes:
*    Tin
*    Tout
*    window_strides
*    padding
*    explicit_padding
*    lhs_dilation
*    rhs_dilation
*    lhs_quantization_min_val
*    lhs_quantization_max_val
*    rhs_quantization_min_val
*    rhs_quantization_max_val
*    output_quantization_min_val
*    output_quantization_max_val
*    batch_group_count
*    feature_group_count
*    dimension_numbers
*    lhs_quantization_axis
*    rhs_quantization_axis
*    output_quantization_axis

# Outputs:
*    output

*/
inline tensor uniform_quantized_convolution(const tensor& lhs, const tensor& rhs, const tensor& lhs_scales, const tensor& lhs_zero_points, const tensor& rhs_scales, const tensor& rhs_zero_points, const tensor& output_scales, const tensor& output_zero_points, datatype Tin, datatype Tout, const std::vector<int64_t>& window_strides, const std::string& padding, const std::vector<int64_t>& explicit_padding, const std::vector<int64_t>& lhs_dilation, const std::vector<int64_t>& rhs_dilation, int64_t lhs_quantization_min_val, int64_t lhs_quantization_max_val, int64_t rhs_quantization_min_val, int64_t rhs_quantization_max_val, int64_t output_quantization_min_val, int64_t output_quantization_max_val, int64_t batch_group_count=1, int64_t feature_group_count=1, const std::string& dimension_numbers="", int64_t lhs_quantization_axis=-1, int64_t rhs_quantization_axis=-1, int64_t output_quantization_axis=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UniformQuantizedConvolution", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), lhs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lhs_scales.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lhs_zero_points.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs_scales.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs_zero_points.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_scales.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_zero_points.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tin", Tin);
    TFE_OpSetAttrType(op.get(), "Tout", Tout);
    TFE_OpSetAttrIntList(op.get(), "window_strides", window_strides.data(), static_cast<int>(window_strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "explicit_padding", explicit_padding.data(), static_cast<int>(explicit_padding.size()));
    TFE_OpSetAttrIntList(op.get(), "lhs_dilation", lhs_dilation.data(), static_cast<int>(lhs_dilation.size()));
    TFE_OpSetAttrIntList(op.get(), "rhs_dilation", rhs_dilation.data(), static_cast<int>(rhs_dilation.size()));
    TFE_OpSetAttrInt(op.get(), "lhs_quantization_min_val", lhs_quantization_min_val);
    TFE_OpSetAttrInt(op.get(), "lhs_quantization_max_val", lhs_quantization_max_val);
    TFE_OpSetAttrInt(op.get(), "rhs_quantization_min_val", rhs_quantization_min_val);
    TFE_OpSetAttrInt(op.get(), "rhs_quantization_max_val", rhs_quantization_max_val);
    TFE_OpSetAttrInt(op.get(), "output_quantization_min_val", output_quantization_min_val);
    TFE_OpSetAttrInt(op.get(), "output_quantization_max_val", output_quantization_max_val);
    TFE_OpSetAttrInt(op.get(), "batch_group_count", batch_group_count);
    TFE_OpSetAttrInt(op.get(), "feature_group_count", feature_group_count);
    TFE_OpSetAttrString(op.get(), "dimension_numbers", (void*) dimension_numbers.c_str(), dimension_numbers.size());
    TFE_OpSetAttrInt(op.get(), "lhs_quantization_axis", lhs_quantization_axis);
    TFE_OpSetAttrInt(op.get(), "rhs_quantization_axis", rhs_quantization_axis);
    TFE_OpSetAttrInt(op.get(), "output_quantization_axis", output_quantization_axis);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # UniformQuantizedConvolutionHybrid
# Inputs:
*    lhs
*    rhs
*    rhs_scales
*    rhs_zero_points

# Attributes:
*    Tlhs
*    Trhs
*    Tout
*    window_strides
*    padding
*    explicit_padding
*    lhs_dilation
*    rhs_dilation
*    rhs_quantization_min_val
*    rhs_quantization_max_val
*    batch_group_count
*    feature_group_count
*    dimension_numbers
*    rhs_quantization_axis

# Outputs:
*    output

*/
inline tensor uniform_quantized_convolution_hybrid(const tensor& lhs, const tensor& rhs, const tensor& rhs_scales, const tensor& rhs_zero_points, datatype Tlhs, datatype Trhs, datatype Tout, const std::vector<int64_t>& window_strides, const std::string& padding, const std::vector<int64_t>& explicit_padding, const std::vector<int64_t>& lhs_dilation, const std::vector<int64_t>& rhs_dilation, int64_t rhs_quantization_min_val, int64_t rhs_quantization_max_val, int64_t batch_group_count=1, int64_t feature_group_count=1, const std::string& dimension_numbers="", int64_t rhs_quantization_axis=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UniformQuantizedConvolutionHybrid", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), lhs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs_scales.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs_zero_points.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tlhs", Tlhs);
    TFE_OpSetAttrType(op.get(), "Trhs", Trhs);
    TFE_OpSetAttrType(op.get(), "Tout", Tout);
    TFE_OpSetAttrIntList(op.get(), "window_strides", window_strides.data(), static_cast<int>(window_strides.size()));
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "explicit_padding", explicit_padding.data(), static_cast<int>(explicit_padding.size()));
    TFE_OpSetAttrIntList(op.get(), "lhs_dilation", lhs_dilation.data(), static_cast<int>(lhs_dilation.size()));
    TFE_OpSetAttrIntList(op.get(), "rhs_dilation", rhs_dilation.data(), static_cast<int>(rhs_dilation.size()));
    TFE_OpSetAttrInt(op.get(), "rhs_quantization_min_val", rhs_quantization_min_val);
    TFE_OpSetAttrInt(op.get(), "rhs_quantization_max_val", rhs_quantization_max_val);
    TFE_OpSetAttrInt(op.get(), "batch_group_count", batch_group_count);
    TFE_OpSetAttrInt(op.get(), "feature_group_count", feature_group_count);
    TFE_OpSetAttrString(op.get(), "dimension_numbers", (void*) dimension_numbers.c_str(), dimension_numbers.size());
    TFE_OpSetAttrInt(op.get(), "rhs_quantization_axis", rhs_quantization_axis);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # UniformQuantizedDot
# Inputs:
*    lhs
*    rhs
*    lhs_scales
*    lhs_zero_points
*    rhs_scales
*    rhs_zero_points
*    output_scales
*    output_zero_points

# Attributes:
*    Tin
*    Tout
*    lhs_quantization_min_val
*    lhs_quantization_max_val
*    rhs_quantization_min_val
*    rhs_quantization_max_val
*    output_quantization_min_val
*    output_quantization_max_val
*    lhs_quantization_axis
*    rhs_quantization_axis
*    output_quantization_axis

# Outputs:
*    output

*/
inline tensor uniform_quantized_dot(const tensor& lhs, const tensor& rhs, const tensor& lhs_scales, const tensor& lhs_zero_points, const tensor& rhs_scales, const tensor& rhs_zero_points, const tensor& output_scales, const tensor& output_zero_points, datatype Tin, datatype Tout, int64_t lhs_quantization_min_val, int64_t lhs_quantization_max_val, int64_t rhs_quantization_min_val, int64_t rhs_quantization_max_val, int64_t output_quantization_min_val, int64_t output_quantization_max_val, int64_t lhs_quantization_axis=-1, int64_t rhs_quantization_axis=-1, int64_t output_quantization_axis=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UniformQuantizedDot", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), lhs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lhs_scales.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lhs_zero_points.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs_scales.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs_zero_points.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_scales.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_zero_points.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tin", Tin);
    TFE_OpSetAttrType(op.get(), "Tout", Tout);
    TFE_OpSetAttrInt(op.get(), "lhs_quantization_min_val", lhs_quantization_min_val);
    TFE_OpSetAttrInt(op.get(), "lhs_quantization_max_val", lhs_quantization_max_val);
    TFE_OpSetAttrInt(op.get(), "rhs_quantization_min_val", rhs_quantization_min_val);
    TFE_OpSetAttrInt(op.get(), "rhs_quantization_max_val", rhs_quantization_max_val);
    TFE_OpSetAttrInt(op.get(), "output_quantization_min_val", output_quantization_min_val);
    TFE_OpSetAttrInt(op.get(), "output_quantization_max_val", output_quantization_max_val);
    TFE_OpSetAttrInt(op.get(), "lhs_quantization_axis", lhs_quantization_axis);
    TFE_OpSetAttrInt(op.get(), "rhs_quantization_axis", rhs_quantization_axis);
    TFE_OpSetAttrInt(op.get(), "output_quantization_axis", output_quantization_axis);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # UniformQuantizedDotHybrid
# Inputs:
*    lhs
*    rhs
*    rhs_scales
*    rhs_zero_points

# Attributes:
*    Tlhs
*    Trhs
*    Tout
*    rhs_quantization_min_val
*    rhs_quantization_max_val
*    rhs_quantization_axis

# Outputs:
*    output

*/
inline tensor uniform_quantized_dot_hybrid(const tensor& lhs, const tensor& rhs, const tensor& rhs_scales, const tensor& rhs_zero_points, datatype Tlhs, datatype Trhs, datatype Tout, int64_t rhs_quantization_min_val, int64_t rhs_quantization_max_val, int64_t rhs_quantization_axis=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UniformQuantizedDotHybrid", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), lhs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs_scales.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs_zero_points.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tlhs", Tlhs);
    TFE_OpSetAttrType(op.get(), "Trhs", Trhs);
    TFE_OpSetAttrType(op.get(), "Tout", Tout);
    TFE_OpSetAttrInt(op.get(), "rhs_quantization_min_val", rhs_quantization_min_val);
    TFE_OpSetAttrInt(op.get(), "rhs_quantization_max_val", rhs_quantization_max_val);
    TFE_OpSetAttrInt(op.get(), "rhs_quantization_axis", rhs_quantization_axis);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # UniformRequantize
# Inputs:
*    input
*    input_scales
*    input_zero_points
*    output_scales
*    output_zero_points

# Attributes:
*    Tin
*    Tout
*    input_quantization_min_val
*    input_quantization_max_val
*    output_quantization_min_val
*    output_quantization_max_val
*    input_quantization_axis
*    output_quantization_axis

# Outputs:
*    output

*/
inline tensor uniform_requantize(const tensor& input, const tensor& input_scales, const tensor& input_zero_points, const tensor& output_scales, const tensor& output_zero_points, datatype Tin, datatype Tout, int64_t input_quantization_min_val, int64_t input_quantization_max_val, int64_t output_quantization_min_val, int64_t output_quantization_max_val, int64_t input_quantization_axis=-1, int64_t output_quantization_axis=-1) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UniformRequantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_scales.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_zero_points.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_scales.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_zero_points.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tin", Tin);
    TFE_OpSetAttrType(op.get(), "Tout", Tout);
    TFE_OpSetAttrInt(op.get(), "input_quantization_min_val", input_quantization_min_val);
    TFE_OpSetAttrInt(op.get(), "input_quantization_max_val", input_quantization_max_val);
    TFE_OpSetAttrInt(op.get(), "output_quantization_min_val", output_quantization_min_val);
    TFE_OpSetAttrInt(op.get(), "output_quantization_max_val", output_quantization_max_val);
    TFE_OpSetAttrInt(op.get(), "input_quantization_axis", input_quantization_axis);
    TFE_OpSetAttrInt(op.get(), "output_quantization_axis", output_quantization_axis);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Unique
# Inputs:
*    x

# Attributes:
*    out_idx

# Outputs:
*    y
*    idx

*/
inline std::vector<tensor> unique(const tensor& x, datatype out_idx=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Unique", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_idx", out_idx);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # UniqueDataset
# Inputs:
*    input_dataset

# Attributes:
*    output_types
*    output_shapes
*    metadata

# Outputs:
*    handle

*/
inline tensor unique_dataset(const tensor& input_dataset, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UniqueDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # UniqueV2
# Inputs:
*    x
*    axis

# Attributes:
*    Taxis
*    out_idx

# Outputs:
*    y
*    idx

*/
inline std::vector<tensor> unique_v2(const tensor& x, const tensor& axis, datatype Taxis=static_cast<datatype>(9), datatype out_idx=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UniqueV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), axis.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Taxis", Taxis);
    TFE_OpSetAttrType(op.get(), "out_idx", out_idx);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # UniqueWithCounts
# Inputs:
*    x

# Attributes:
*    out_idx

# Outputs:
*    y
*    idx
*    count

*/
inline std::vector<tensor> unique_with_counts(const tensor& x, datatype out_idx=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UniqueWithCounts", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_idx", out_idx);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # UniqueWithCountsV2
# Inputs:
*    x
*    axis

# Attributes:
*    Taxis
*    out_idx

# Outputs:
*    y
*    idx
*    count

*/
inline std::vector<tensor> unique_with_counts_v2(const tensor& x, const tensor& axis, datatype Taxis=static_cast<datatype>(9), datatype out_idx=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UniqueWithCountsV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), axis.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Taxis", Taxis);
    TFE_OpSetAttrType(op.get(), "out_idx", out_idx);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # Unpack
# Inputs:
*    value

# Attributes:
*    num
*    axis

# Outputs:
*    output

*/
inline tensor unpack(const tensor& value, int64_t num, int64_t axis=0) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Unpack", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num", num);
    TFE_OpSetAttrInt(op.get(), "axis", axis);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # UnravelIndex
# Inputs:
*    indices
*    dims

# Attributes:
*    Tidx

# Outputs:
*    output

*/
inline tensor unravel_index(const tensor& indices, const tensor& dims, datatype Tidx=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnravelIndex", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dims.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # UnsortedSegmentJoin
# Inputs:
*    inputs
*    segment_ids
*    num_segments

# Attributes:
*    Tindices
*    separator
*    Tnumsegments

# Outputs:
*    output

*/
inline tensor unsorted_segment_join(const tensor& inputs, const tensor& segment_ids, const tensor& num_segments, datatype Tindices, const std::string& separator="", datatype Tnumsegments=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnsortedSegmentJoin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), inputs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_segments.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrString(op.get(), "separator", (void*) separator.c_str(), separator.size());
    TFE_OpSetAttrType(op.get(), "Tnumsegments", Tnumsegments);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # UnsortedSegmentMax
# Inputs:
*    data
*    segment_ids
*    num_segments

# Attributes:
*    Tindices
*    Tnumsegments

# Outputs:
*    output

*/
inline tensor unsorted_segment_max(const tensor& data, const tensor& segment_ids, const tensor& num_segments, datatype Tindices, datatype Tnumsegments=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnsortedSegmentMax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_segments.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrType(op.get(), "Tnumsegments", Tnumsegments);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # UnsortedSegmentMin
# Inputs:
*    data
*    segment_ids
*    num_segments

# Attributes:
*    Tindices
*    Tnumsegments

# Outputs:
*    output

*/
inline tensor unsorted_segment_min(const tensor& data, const tensor& segment_ids, const tensor& num_segments, datatype Tindices, datatype Tnumsegments=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnsortedSegmentMin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_segments.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrType(op.get(), "Tnumsegments", Tnumsegments);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # UnsortedSegmentProd
# Inputs:
*    data
*    segment_ids
*    num_segments

# Attributes:
*    Tindices
*    Tnumsegments

# Outputs:
*    output

*/
inline tensor unsorted_segment_prod(const tensor& data, const tensor& segment_ids, const tensor& num_segments, datatype Tindices, datatype Tnumsegments=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnsortedSegmentProd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_segments.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrType(op.get(), "Tnumsegments", Tnumsegments);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # UnsortedSegmentSum
# Inputs:
*    data
*    segment_ids
*    num_segments

# Attributes:
*    Tindices
*    Tnumsegments

# Outputs:
*    output

*/
inline tensor unsorted_segment_sum(const tensor& data, const tensor& segment_ids, const tensor& num_segments, datatype Tindices, datatype Tnumsegments=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnsortedSegmentSum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_segments.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrType(op.get(), "Tnumsegments", Tnumsegments);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Unstage
# Inputs:
*    
# Attributes:
*    dtypes
*    capacity
*    memory_limit
*    container
*    shared_name

# Outputs:
*    values

*/
inline tensor unstage(const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Unstage", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), static_cast<int>(dtypes.size()));
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # UnwrapDatasetVariant
# Inputs:
*    input_handle

# Attributes:
*    
# Outputs:
*    output_handle

*/
inline tensor unwrap_dataset_variant(const tensor& input_handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnwrapDatasetVariant", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # UpperBound
# Inputs:
*    sorted_inputs
*    values

# Attributes:
*    out_type

# Outputs:
*    output

*/
inline tensor upper_bound(const tensor& sorted_inputs, const tensor& values, datatype out_type=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UpperBound", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sorted_inputs.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # VarHandleOp
# Inputs:
*    
# Attributes:
*    dtype
*    shape
*    allowed_devices
*    container
*    shared_name
*    debug_name

# Outputs:
*    resource

*/
inline tensor var_handle_op(datatype dtype, const std::vector<int64_t>& shape, const std::vector< std::string>& allowed_devices, const std::string& container="", const std::string& shared_name="", const std::string& debug_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "VarHandleOp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), static_cast<int>(shape.size()), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<std::size_t> allowed_devices_sizes; allowed_devices_sizes.reserve(allowed_devices.size());
    std::transform(allowed_devices.begin(), allowed_devices.end(), std::back_inserter(allowed_devices_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "allowed_devices", reinterpret_cast<const void *const *>(allowed_devices.data()), allowed_devices_sizes.data(), static_cast<int>(allowed_devices.size()));
    
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrString(op.get(), "debug_name", (void*) debug_name.c_str(), debug_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # VarIsInitializedOp
# Inputs:
*    resource

# Attributes:
*    
# Outputs:
*    is_initialized

*/
inline tensor var_is_initialized_op(const tensor& resource) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "VarIsInitializedOp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Variable
# Inputs:
*    
# Attributes:
*    shape
*    dtype
*    container
*    shared_name

# Outputs:
*    ref

*/
inline tensor variable(const std::vector<int64_t>& shape, datatype dtype, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Variable", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), static_cast<int>(shape.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # VariableShape
# Inputs:
*    input

# Attributes:
*    out_type

# Outputs:
*    output

*/
inline tensor variable_shape(const tensor& input, datatype out_type=static_cast<datatype>(3)) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "VariableShape", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # VariableV2
# Inputs:
*    
# Attributes:
*    shape
*    dtype
*    container
*    shared_name

# Outputs:
*    ref

*/
inline tensor variable_v2(const std::vector<int64_t>& shape, datatype dtype, const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "VariableV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), static_cast<int>(shape.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Where
# Inputs:
*    input

# Attributes:
*    
# Outputs:
*    index

*/
inline tensor where(const tensor& input) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Where", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # While
# Inputs:
*    input

# Attributes:
*    cond
*    body
*    output_shapes
*    parallel_iterations

# Outputs:
*    output

*/
inline tensor tfe_while(const std::vector<tensor>&input, int64_t cond, int64_t body, const std::vector< std::vector<int64_t>>& output_shapes, int64_t parallel_iterations=10) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "While", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> input_handles; input_handles.reserve(input.size());
    std::transform(input.begin(), input.end(), std::back_inserter(input_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), input_handles.data(), static_cast<int>(input.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "cond", cond);
    TFE_OpSetAttrInt(op.get(), "body", body);
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "parallel_iterations", parallel_iterations);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # WholeFileReader
# Inputs:
*    
# Attributes:
*    container
*    shared_name

# Outputs:
*    reader_handle

*/
inline tensor whole_file_reader(const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WholeFileReader", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # WholeFileReaderV2
# Inputs:
*    
# Attributes:
*    container
*    shared_name

# Outputs:
*    reader_handle

*/
inline tensor whole_file_reader_v2(const std::string& container="", const std::string& shared_name="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WholeFileReaderV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # WindowDataset
# Inputs:
*    input_dataset
*    size
*    shift
*    stride
*    drop_remainder

# Attributes:
*    output_types
*    output_shapes
*    metadata

# Outputs:
*    handle

*/
inline tensor window_dataset(const tensor& input_dataset, const tensor& size, const tensor& shift, const tensor& stride, const tensor& drop_remainder, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WindowDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shift.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), stride.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), drop_remainder.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # WindowOp
# Inputs:
*    inputs

# Attributes:
*    output_types
*    output_shapes
*    Tinputs

# Outputs:
*    handle

*/
inline tensor window_op(const std::vector<tensor>&inputs, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::vector<datatype>& Tinputs) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WindowOp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), static_cast<int>(inputs.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrTypeList(op.get(), "Tinputs", reinterpret_cast<const enum TF_DataType *>(Tinputs.data()), static_cast<int>(Tinputs.size()));

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # WorkerHeartbeat
# Inputs:
*    request

# Attributes:
*    
# Outputs:
*    response

*/
inline tensor worker_heartbeat(const tensor& request) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WorkerHeartbeat", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), request.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # WrapDatasetVariant
# Inputs:
*    input_handle

# Attributes:
*    
# Outputs:
*    output_handle

*/
inline tensor wrap_dataset_variant(const tensor& input_handle) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WrapDatasetVariant", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # WriteAudioSummary
# Inputs:
*    writer
*    step
*    tag
*    tensor
*    sample_rate

# Attributes:
*    max_outputs

# Outputs:
*    
*/
inline void write_audio_summary(const tensor& writer, const tensor& step, const tensor& tag, const tensor& input_tensor, const tensor& sample_rate, int64_t max_outputs=3) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WriteAudioSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), writer.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), step.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tag.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sample_rate.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "max_outputs", max_outputs);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # WriteFile
# Inputs:
*    filename
*    contents

# Attributes:
*    
# Outputs:
*    
*/
inline void write_file(const tensor& filename, const tensor& contents) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WriteFile", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filename.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), contents.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # WriteGraphSummary
# Inputs:
*    writer
*    step
*    tensor

# Attributes:
*    
# Outputs:
*    
*/
inline void write_graph_summary(const tensor& writer, const tensor& step, const tensor& input_tensor) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WriteGraphSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), writer.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), step.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # WriteHistogramSummary
# Inputs:
*    writer
*    step
*    tag
*    values

# Attributes:
*    
# Outputs:
*    
*/
inline void write_histogram_summary(const tensor& writer, const tensor& step, const tensor& tag, const tensor& values) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WriteHistogramSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), writer.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), step.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tag.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # WriteImageSummary
# Inputs:
*    writer
*    step
*    tag
*    tensor
*    bad_color

# Attributes:
*    max_images

# Outputs:
*    
*/
inline void write_image_summary(const tensor& writer, const tensor& step, const tensor& tag, const tensor& input_tensor, const tensor& bad_color, int64_t max_images=3) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WriteImageSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), writer.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), step.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tag.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bad_color.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "max_images", max_images);

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # WriteRawProtoSummary
# Inputs:
*    writer
*    step
*    tensor

# Attributes:
*    
# Outputs:
*    
*/
inline void write_raw_proto_summary(const tensor& writer, const tensor& step, const tensor& input_tensor) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WriteRawProtoSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), writer.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), step.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # WriteScalarSummary
# Inputs:
*    writer
*    step
*    tag
*    value

# Attributes:
*    
# Outputs:
*    
*/
inline void write_scalar_summary(const tensor& writer, const tensor& step, const tensor& tag, const tensor& value) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WriteScalarSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), writer.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), step.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tag.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # WriteSummary
# Inputs:
*    writer
*    step
*    tensor
*    tag
*    summary_metadata

# Attributes:
*    
# Outputs:
*    
*/
inline void write_summary(const tensor& writer, const tensor& step, const tensor& input_tensor, const tensor& tag, const tensor& summary_metadata) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WriteSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), writer.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), step.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tag.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), summary_metadata.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 0;
    TFE_TensorHandle* res[1] = {nullptr};
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
}

/* # Xdivy
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor xdivy(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Xdivy", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # XlaConcatND
# Inputs:
*    inputs

# Attributes:
*    N
*    num_concats
*    paddings

# Outputs:
*    output

*/
inline tensor xla_concat_n_d(const std::vector<tensor>&inputs, const std::vector<int64_t>& num_concats, const std::vector<int64_t>& paddings) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "XlaConcatND", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), static_cast<int>(inputs.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", inputs.size());
    TFE_OpSetAttrIntList(op.get(), "num_concats", num_concats.data(), static_cast<int>(num_concats.size()));
    TFE_OpSetAttrIntList(op.get(), "paddings", paddings.data(), static_cast<int>(paddings.size()));

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # XlaSparseCoreAdagrad
# Inputs:
*    indices
*    gradient
*    learning_rate
*    accumulator
*    embedding_table

# Attributes:
*    feature_width

# Outputs:
*    updated_embedding_table
*    updated_accumulator

*/
inline std::vector<tensor> xla_sparse_core_adagrad(const tensor& indices, const tensor& gradient, const tensor& learning_rate, const tensor& accumulator, const tensor& embedding_table, int64_t feature_width) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "XlaSparseCoreAdagrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), learning_rate.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accumulator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), embedding_table.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "feature_width", feature_width);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # XlaSparseCoreAdagradMomentum
# Inputs:
*    indices
*    gradient
*    learning_rate
*    beta_1
*    epsilon
*    accumulator
*    momentum
*    embedding_table

# Attributes:
*    feature_width
*    use_nesterov
*    beta_2
*    exponent

# Outputs:
*    updated_embedding_table
*    updated_accumulator
*    updated_momentum

*/
inline std::vector<tensor> xla_sparse_core_adagrad_momentum(const tensor& indices, const tensor& gradient, const tensor& learning_rate, const tensor& beta_1, const tensor& epsilon, const tensor& accumulator, const tensor& momentum, const tensor& embedding_table, int64_t feature_width, bool use_nesterov, float beta_2, float exponent) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "XlaSparseCoreAdagradMomentum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), learning_rate.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta_1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accumulator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), embedding_table.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "feature_width", feature_width);
    TFE_OpSetAttrBool(op.get(), "use_nesterov", (unsigned char)use_nesterov);
    TFE_OpSetAttrFloat(op.get(), "beta_2", beta_2);
    TFE_OpSetAttrFloat(op.get(), "exponent", exponent);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # XlaSparseCoreAdam
# Inputs:
*    embedding_table
*    indices
*    gradient
*    learning_rate
*    momentum
*    velocity
*    beta_1
*    beta_2
*    epsilon

# Attributes:
*    feature_width
*    use_sum_inside_sqrt

# Outputs:
*    updated_embedding_table
*    updated_velocity
*    updated_momentum

*/
inline std::vector<tensor> xla_sparse_core_adam(const tensor& embedding_table, const tensor& indices, const tensor& gradient, const tensor& learning_rate, const tensor& momentum, const tensor& velocity, const tensor& beta_1, const tensor& beta_2, const tensor& epsilon, int64_t feature_width, bool use_sum_inside_sqrt) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "XlaSparseCoreAdam", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), embedding_table.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), learning_rate.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), velocity.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta_1.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta_2.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "feature_width", feature_width);
    TFE_OpSetAttrBool(op.get(), "use_sum_inside_sqrt", (unsigned char)use_sum_inside_sqrt);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # XlaSparseCoreFtrl
# Inputs:
*    embedding_table
*    accumulator
*    linear
*    learning_rate
*    indices
*    gradient
*    beta
*    learning_rate_power
*    l2_regularization_strength

# Attributes:
*    feature_width
*    multiply_linear_by_learning_rate
*    l1_regularization_strength

# Outputs:
*    updated_embedding_table
*    updated_accumulator
*    updated_linear

*/
inline std::vector<tensor> xla_sparse_core_ftrl(const tensor& embedding_table, const tensor& accumulator, const tensor& linear, const tensor& learning_rate, const tensor& indices, const tensor& gradient, const tensor& beta, const tensor& learning_rate_power, const tensor& l2_regularization_strength, int64_t feature_width, bool multiply_linear_by_learning_rate, float l1_regularization_strength) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "XlaSparseCoreFtrl", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), embedding_table.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accumulator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), linear.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), learning_rate.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), learning_rate_power.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2_regularization_strength.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "feature_width", feature_width);
    TFE_OpSetAttrBool(op.get(), "multiply_linear_by_learning_rate", (unsigned char)multiply_linear_by_learning_rate);
    TFE_OpSetAttrFloat(op.get(), "l1_regularization_strength", l1_regularization_strength);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # XlaSparseCoreSgd
# Inputs:
*    indices
*    gradient
*    learning_rate
*    embedding_table

# Attributes:
*    feature_width

# Outputs:
*    updated_embedding_table

*/
inline tensor xla_sparse_core_sgd(const tensor& indices, const tensor& gradient, const tensor& learning_rate, const tensor& embedding_table, int64_t feature_width) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "XlaSparseCoreSgd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), indices.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), learning_rate.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), embedding_table.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "feature_width", feature_width);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # XlaSparseDenseMatmul
# Inputs:
*    row_ids
*    col_ids
*    values
*    offsets
*    embedding_table

# Attributes:
*    max_ids_per_partition
*    max_unique_ids_per_partition
*    input_size

# Outputs:
*    activations
*    row_pointers
*    sorted_embedding_ids
*    sorted_sample_ids
*    sorted_gains

*/
inline std::vector<tensor> xla_sparse_dense_matmul(const tensor& row_ids, const tensor& col_ids, const tensor& values, const tensor& offsets, const tensor& embedding_table, int64_t max_ids_per_partition, int64_t max_unique_ids_per_partition, int64_t input_size) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "XlaSparseDenseMatmul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), row_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), col_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), offsets.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), embedding_table.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "max_ids_per_partition", max_ids_per_partition);
    TFE_OpSetAttrInt(op.get(), "max_unique_ids_per_partition", max_unique_ids_per_partition);
    TFE_OpSetAttrInt(op.get(), "input_size", input_size);

    // Execute Op
    int num_outputs_op = 5;
    TFE_TensorHandle* res[5] = { nullptr,nullptr,nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]),tensor(res[3]),tensor(res[4]), };
}

/* # XlaSparseDenseMatmulGradWithAdagradAndCsrInput
# Inputs:
*    row_pointers
*    sorted_sample_ids
*    sorted_token_ids
*    sorted_gains
*    activation_gradients
*    learning_rate
*    embedding_table
*    accumulator
*    num_minibatches_per_physical_sparse_core

# Attributes:
*    table_name
*    clip_weight_min
*    clip_weight_max

# Outputs:
*    updated_embedding_table
*    updated_accumulator

*/
inline std::vector<tensor> xla_sparse_dense_matmul_grad_with_adagrad_and_csr_input(const tensor& row_pointers, const tensor& sorted_sample_ids, const tensor& sorted_token_ids, const tensor& sorted_gains, const tensor& activation_gradients, const tensor& learning_rate, const tensor& embedding_table, const tensor& accumulator, const tensor& num_minibatches_per_physical_sparse_core, const std::string& table_name, float clip_weight_min=-std::numeric_limits<float>::infinity(), float clip_weight_max=std::numeric_limits<float>::infinity()) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "XlaSparseDenseMatmulGradWithAdagradAndCsrInput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), row_pointers.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sorted_sample_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sorted_token_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sorted_gains.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), activation_gradients.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), learning_rate.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), embedding_table.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accumulator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_minibatches_per_physical_sparse_core.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrFloat(op.get(), "clip_weight_min", clip_weight_min);
    TFE_OpSetAttrFloat(op.get(), "clip_weight_max", clip_weight_max);

    // Execute Op
    int num_outputs_op = 2;
    TFE_TensorHandle* res[2] = { nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]), };
}

/* # XlaSparseDenseMatmulGradWithAdagradMomentumAndCsrInput
# Inputs:
*    row_pointers
*    sorted_sample_ids
*    sorted_token_ids
*    sorted_gains
*    activation_gradients
*    learning_rate
*    embedding_table
*    accumulator
*    momenta
*    num_minibatches_per_physical_sparse_core

# Attributes:
*    use_nesterov
*    exponent
*    beta1
*    beta2
*    epsilon
*    table_name
*    clip_weight_min
*    clip_weight_max

# Outputs:
*    updated_embedding_table
*    updated_accumulator
*    updated_momenta

*/
inline std::vector<tensor> xla_sparse_dense_matmul_grad_with_adagrad_momentum_and_csr_input(const tensor& row_pointers, const tensor& sorted_sample_ids, const tensor& sorted_token_ids, const tensor& sorted_gains, const tensor& activation_gradients, const tensor& learning_rate, const tensor& embedding_table, const tensor& accumulator, const tensor& momenta, const tensor& num_minibatches_per_physical_sparse_core, bool use_nesterov, float exponent, float beta1, float beta2, float epsilon, const std::string& table_name, float clip_weight_min=-std::numeric_limits<float>::infinity(), float clip_weight_max=std::numeric_limits<float>::infinity()) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "XlaSparseDenseMatmulGradWithAdagradMomentumAndCsrInput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), row_pointers.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sorted_sample_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sorted_token_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sorted_gains.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), activation_gradients.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), learning_rate.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), embedding_table.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accumulator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momenta.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_minibatches_per_physical_sparse_core.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_nesterov", (unsigned char)use_nesterov);
    TFE_OpSetAttrFloat(op.get(), "exponent", exponent);
    TFE_OpSetAttrFloat(op.get(), "beta1", beta1);
    TFE_OpSetAttrFloat(op.get(), "beta2", beta2);
    TFE_OpSetAttrFloat(op.get(), "epsilon", epsilon);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrFloat(op.get(), "clip_weight_min", clip_weight_min);
    TFE_OpSetAttrFloat(op.get(), "clip_weight_max", clip_weight_max);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # XlaSparseDenseMatmulGradWithAdamAndCsrInput
# Inputs:
*    row_pointers
*    sorted_sample_ids
*    sorted_token_ids
*    sorted_gains
*    activation_gradients
*    learning_rate
*    embedding_table
*    momenta
*    velocity
*    num_minibatches_per_physical_sparse_core

# Attributes:
*    use_sum_inside_sqrt
*    beta1
*    beta2
*    epsilon
*    table_name
*    clip_weight_min
*    clip_weight_max

# Outputs:
*    updated_embedding_table
*    updated_momenta
*    updated_velocity

*/
inline std::vector<tensor> xla_sparse_dense_matmul_grad_with_adam_and_csr_input(const tensor& row_pointers, const tensor& sorted_sample_ids, const tensor& sorted_token_ids, const tensor& sorted_gains, const tensor& activation_gradients, const tensor& learning_rate, const tensor& embedding_table, const tensor& momenta, const tensor& velocity, const tensor& num_minibatches_per_physical_sparse_core, bool use_sum_inside_sqrt, float beta1, float beta2, float epsilon, const std::string& table_name, float clip_weight_min=-std::numeric_limits<float>::infinity(), float clip_weight_max=std::numeric_limits<float>::infinity()) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "XlaSparseDenseMatmulGradWithAdamAndCsrInput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), row_pointers.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sorted_sample_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sorted_token_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sorted_gains.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), activation_gradients.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), learning_rate.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), embedding_table.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momenta.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), velocity.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_minibatches_per_physical_sparse_core.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_sum_inside_sqrt", (unsigned char)use_sum_inside_sqrt);
    TFE_OpSetAttrFloat(op.get(), "beta1", beta1);
    TFE_OpSetAttrFloat(op.get(), "beta2", beta2);
    TFE_OpSetAttrFloat(op.get(), "epsilon", epsilon);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrFloat(op.get(), "clip_weight_min", clip_weight_min);
    TFE_OpSetAttrFloat(op.get(), "clip_weight_max", clip_weight_max);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # XlaSparseDenseMatmulGradWithFtrlAndCsrInput
# Inputs:
*    row_pointers
*    sorted_sample_ids
*    sorted_token_ids
*    sorted_gains
*    activation_gradients
*    learning_rate
*    embedding_table
*    accumulator
*    linear
*    num_minibatches_per_physical_sparse_core

# Attributes:
*    multiply_linear_by_learning_rate
*    beta
*    learning_rate_power
*    l1_regularization_strength
*    l2_regularization_strength
*    table_name
*    clip_weight_min
*    clip_weight_max

# Outputs:
*    updated_embedding_table
*    updated_accumulator
*    updated_linear

*/
inline std::vector<tensor> xla_sparse_dense_matmul_grad_with_ftrl_and_csr_input(const tensor& row_pointers, const tensor& sorted_sample_ids, const tensor& sorted_token_ids, const tensor& sorted_gains, const tensor& activation_gradients, const tensor& learning_rate, const tensor& embedding_table, const tensor& accumulator, const tensor& linear, const tensor& num_minibatches_per_physical_sparse_core, bool multiply_linear_by_learning_rate, float beta, float learning_rate_power, float l1_regularization_strength, float l2_regularization_strength, const std::string& table_name, float clip_weight_min=-std::numeric_limits<float>::infinity(), float clip_weight_max=std::numeric_limits<float>::infinity()) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "XlaSparseDenseMatmulGradWithFtrlAndCsrInput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), row_pointers.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sorted_sample_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sorted_token_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sorted_gains.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), activation_gradients.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), learning_rate.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), embedding_table.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accumulator.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), linear.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_minibatches_per_physical_sparse_core.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "multiply_linear_by_learning_rate", (unsigned char)multiply_linear_by_learning_rate);
    TFE_OpSetAttrFloat(op.get(), "beta", beta);
    TFE_OpSetAttrFloat(op.get(), "learning_rate_power", learning_rate_power);
    TFE_OpSetAttrFloat(op.get(), "l1_regularization_strength", l1_regularization_strength);
    TFE_OpSetAttrFloat(op.get(), "l2_regularization_strength", l2_regularization_strength);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrFloat(op.get(), "clip_weight_min", clip_weight_min);
    TFE_OpSetAttrFloat(op.get(), "clip_weight_max", clip_weight_max);

    // Execute Op
    int num_outputs_op = 3;
    TFE_TensorHandle* res[3] = { nullptr,nullptr,nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return { tensor(res[0]),tensor(res[1]),tensor(res[2]), };
}

/* # XlaSparseDenseMatmulGradWithSgdAndCsrInput
# Inputs:
*    row_pointers
*    sorted_sample_ids
*    sorted_token_ids
*    sorted_gains
*    activation_gradients
*    learning_rate
*    embedding_table
*    num_minibatches_per_physical_sparse_core

# Attributes:
*    table_name
*    clip_weight_min
*    clip_weight_max

# Outputs:
*    updated_embedding_table

*/
inline tensor xla_sparse_dense_matmul_grad_with_sgd_and_csr_input(const tensor& row_pointers, const tensor& sorted_sample_ids, const tensor& sorted_token_ids, const tensor& sorted_gains, const tensor& activation_gradients, const tensor& learning_rate, const tensor& embedding_table, const tensor& num_minibatches_per_physical_sparse_core, const std::string& table_name, float clip_weight_min=-std::numeric_limits<float>::infinity(), float clip_weight_max=std::numeric_limits<float>::infinity()) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "XlaSparseDenseMatmulGradWithSgdAndCsrInput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), row_pointers.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sorted_sample_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sorted_token_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sorted_gains.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), activation_gradients.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), learning_rate.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), embedding_table.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_minibatches_per_physical_sparse_core.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrFloat(op.get(), "clip_weight_min", clip_weight_min);
    TFE_OpSetAttrFloat(op.get(), "clip_weight_max", clip_weight_max);

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # XlaSparseDenseMatmulWithCsrInput
# Inputs:
*    row_pointers
*    sorted_sample_ids
*    sorted_token_ids
*    sorted_gains
*    embedding_table
*    num_minibatches_per_physical_sparse_core

# Attributes:
*    input_size
*    quantization_config_low
*    quantization_config_high
*    quantization_config_num_buckets
*    table_name

# Outputs:
*    activations

*/
inline tensor xla_sparse_dense_matmul_with_csr_input(const tensor& row_pointers, const tensor& sorted_sample_ids, const tensor& sorted_token_ids, const tensor& sorted_gains, const tensor& embedding_table, const tensor& num_minibatches_per_physical_sparse_core, int64_t input_size, float quantization_config_low, float quantization_config_high, int64_t quantization_config_num_buckets, const std::string& table_name) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "XlaSparseDenseMatmulWithCsrInput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), row_pointers.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sorted_sample_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sorted_token_ids.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sorted_gains.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), embedding_table.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_minibatches_per_physical_sparse_core.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "input_size", input_size);
    TFE_OpSetAttrFloat(op.get(), "quantization_config_low", quantization_config_low);
    TFE_OpSetAttrFloat(op.get(), "quantization_config_high", quantization_config_high);
    TFE_OpSetAttrInt(op.get(), "quantization_config_num_buckets", quantization_config_num_buckets);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # XlaSplitND
# Inputs:
*    input

# Attributes:
*    N
*    num_splits
*    paddings

# Outputs:
*    outputs

*/
inline tensor xla_split_n_d(const tensor& input, int64_t N, const std::vector<int64_t>& num_splits, const std::vector<int64_t>& paddings) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "XlaSplitND", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", N);
    TFE_OpSetAttrIntList(op.get(), "num_splits", num_splits.data(), static_cast<int>(num_splits.size()));
    TFE_OpSetAttrIntList(op.get(), "paddings", paddings.data(), static_cast<int>(paddings.size()));

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Xlog1py
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor xlog1py(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Xlog1py", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Xlogy
# Inputs:
*    x
*    y

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor xlogy(const tensor& x, const tensor& y) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Xlogy", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ZerosLike
# Inputs:
*    x

# Attributes:
*    
# Outputs:
*    y

*/
inline tensor zeros_like(const tensor& x) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ZerosLike", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # Zeta
# Inputs:
*    x
*    q

# Attributes:
*    
# Outputs:
*    z

*/
inline tensor zeta(const tensor& x, const tensor& q) {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Zeta", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), q.tfe_handle.get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}

/* # ZipDataset
# Inputs:
*    input_datasets

# Attributes:
*    output_types
*    output_shapes
*    N
*    metadata

# Outputs:
*    handle

*/
inline tensor zip_dataset(const std::vector<tensor>&input_datasets, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& metadata="") {

    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ZipDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> input_datasets_handles; input_datasets_handles.reserve(input_datasets.size());
    std::transform(input_datasets.begin(), input_datasets.end(), std::back_inserter(input_datasets_handles), [](const auto& t) { return t.tfe_handle.get();});
    TFE_OpAddInputList(op.get(), input_datasets_handles.data(), static_cast<int>(input_datasets.size()), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), static_cast<int>(output_types.size()));
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return static_cast<int>(v.size());});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), static_cast<int>(output_shapes.size()), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "N", input_datasets.size());
    TFE_OpSetAttrString(op.get(), "metadata", (void*) metadata.c_str(), metadata.size());

    // Execute Op
    int num_outputs_op = 1;
    TFE_TensorHandle* res[1] = { nullptr };
    TFE_Execute(op.get(), res, &num_outputs_op, context::get_status());
    status_check(context::get_status());
    return tensor(res[0]);
}


}  // namespace cppflow

#endif  // INCLUDE_CPPFLOW_RAW_OPS_H_

